{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from MSC.StrategicModels import StrategicModel\n",
    "from MSC.SocialMeasures import Utility\n",
    "from MSC.CommonFunctions import *\n",
    "import DataGeneration as data\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "matplotlib.rc('font', size=14)\n",
    "\n",
    "PATH = \"./Results/utility\"\n",
    "if not os.path.exists(PATH):\n",
    "    os.makedirs(PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# credit dataset\n",
    "X, Y = data.load_credit_default_data()\n",
    "X, Y = X[:3000], Y[:3000]\n",
    "X, Y, Xval, Yval, Xtest, Ytest = data.split_validation_test(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.05 0.1  0.15 0.2  0.25 0.3  0.35 0.4  0.45 0.5  0.55 0.6  0.65 0.7\n",
      " 0.75 0.8  0.85 0.9  0.95 1.   1.05 1.1  1.15 1.2 ]\n"
     ]
    }
   ],
   "source": [
    "x_dim = len(X[0])\n",
    "scale = 1 # 1 / x_dim\n",
    "epochs = 10\n",
    "batch_size = 64\n",
    "\n",
    "lambda_range = np.arange(0.05, 1.201, 0.05)\n",
    "print(lambda_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Training with lambda=0 ----------\n",
      "Starting epoch 001 / 010.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\technion\\.conda\\envs\\SCMP\\lib\\site-packages\\cvxpy\\reductions\\solvers\\solving_chain.py:163: UserWarning: You are solving a parameterized problem that is not DPP. Because the problem is not DPP, subsequent solves will not be faster than the first one. For more information, see the documentation on Discplined Parametrized Programming, at\n",
      "\thttps://www.cvxpy.org/tutorial/advanced/index.html#disciplined-parametrized-programming\n",
      "  warnings.warn(dpp_error_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  batch 001 / 029 | loss: 0.87442 | error: 0.40625 | utility: 0.93142\n",
      "  batch 002 / 029 | loss: 0.86309 | error: 0.40625 | utility: 0.92997\n",
      "  batch 003 / 029 | loss: 0.92107 | error: 0.44792 | utility: 0.94154\n",
      "  batch 004 / 029 | loss: 0.91831 | error: 0.45312 | utility: 0.94454\n",
      "  batch 005 / 029 | loss: 0.90621 | error: 0.45312 | utility: 0.94243\n",
      "  batch 006 / 029 | loss: 0.91022 | error: 0.45833 | utility: 0.93526\n",
      "  batch 007 / 029 | loss: 0.91913 | error: 0.46875 | utility: 0.91787\n",
      "  batch 008 / 029 | loss: 0.93124 | error: 0.48047 | utility: 0.89706\n",
      "  batch 009 / 029 | loss: 0.94589 | error: 0.49653 | utility: 0.88326\n",
      "  batch 010 / 029 | loss: 0.93917 | error: 0.49375 | utility: 0.85926\n",
      "  batch 011 / 029 | loss: 0.92464 | error: 0.48864 | utility: 0.87629\n",
      "  batch 012 / 029 | loss: 0.93360 | error: 0.49479 | utility: 0.80194\n",
      "  batch 013 / 029 | loss: 0.92422 | error: 0.48918 | utility: 0.75488\n",
      "  batch 014 / 029 | loss: 0.91955 | error: 0.48996 | utility: 0.73737\n",
      "  batch 015 / 029 | loss: 0.90868 | error: 0.48125 | utility: 0.60873\n",
      "  batch 016 / 029 | loss: 0.90651 | error: 0.47852 | utility: 0.68371\n",
      "  batch 017 / 029 | loss: 0.89672 | error: 0.47151 | utility: 0.51757\n",
      "  batch 018 / 029 | loss: 0.89530 | error: 0.47049 | utility: 0.55309\n",
      "  batch 019 / 029 | loss: 0.89226 | error: 0.46464 | utility: 0.48072\n",
      "  batch 020 / 029 | loss: 0.88711 | error: 0.46094 | utility: 0.52923\n",
      "  batch 021 / 029 | loss: 0.88016 | error: 0.45610 | utility: 0.57558\n",
      "  batch 022 / 029 | loss: 0.87057 | error: 0.44815 | utility: 0.46692\n",
      "  batch 023 / 029 | loss: 0.86403 | error: 0.44158 | utility: 0.23435\n",
      "  batch 024 / 029 | loss: 0.85888 | error: 0.43685 | utility: 0.40403\n",
      "  batch 025 / 029 | loss: 0.85666 | error: 0.43438 | utility: 0.44514\n",
      "  batch 026 / 029 | loss: 0.85552 | error: 0.43269 | utility: 0.44102\n",
      "  batch 027 / 029 | loss: 0.85487 | error: 0.42882 | utility: 0.38351\n",
      "  batch 028 / 029 | loss: 0.84960 | error: 0.42467 | utility: 0.43096\n",
      "  batch 029 / 029 | loss: 0.84157 | error: 0.42295 | utility: 0.48897\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 001 / 010 | time: 046 sec | loss: 0.75525 | error: 0.35000 | utility: 0.38608\n",
      "Saving model to ./Results/utility/utility_0.000_model.pt.\n",
      "Starting epoch 002 / 010.\n",
      "  batch 001 / 029 | loss: 0.77388 | error: 0.40625 | utility: 0.21699\n",
      "  batch 002 / 029 | loss: 0.76267 | error: 0.38281 | utility: 0.33654\n",
      "  batch 003 / 029 | loss: 0.78358 | error: 0.40104 | utility: 0.28967\n",
      "  batch 004 / 029 | loss: 0.77341 | error: 0.38281 | utility: 0.44270\n",
      "  batch 005 / 029 | loss: 0.75237 | error: 0.37500 | utility: 0.25105\n",
      "  batch 006 / 029 | loss: 0.73338 | error: 0.35938 | utility: 0.33745\n",
      "  batch 007 / 029 | loss: 0.72355 | error: 0.34821 | utility: 0.05448\n",
      "  batch 008 / 029 | loss: 0.70768 | error: 0.33789 | utility: 0.30691\n",
      "  batch 009 / 029 | loss: 0.69690 | error: 0.32812 | utility: 0.23845\n",
      "  batch 010 / 029 | loss: 0.69198 | error: 0.32188 | utility: 0.19064\n",
      "  batch 011 / 029 | loss: 0.69272 | error: 0.31960 | utility: 0.35372\n",
      "  batch 012 / 029 | loss: 0.68640 | error: 0.31641 | utility: 0.01272\n",
      "  batch 013 / 029 | loss: 0.68711 | error: 0.31851 | utility: 0.13424\n",
      "  batch 014 / 029 | loss: 0.70716 | error: 0.32924 | utility: 0.11035\n",
      "  batch 015 / 029 | loss: 0.70564 | error: 0.32812 | utility: 0.37405\n",
      "  batch 016 / 029 | loss: 0.69952 | error: 0.32227 | utility: 0.12256\n",
      "  batch 017 / 029 | loss: 0.69864 | error: 0.31985 | utility: 0.14833\n",
      "  batch 018 / 029 | loss: 0.69895 | error: 0.32292 | utility: 0.20704\n",
      "  batch 019 / 029 | loss: 0.69807 | error: 0.32401 | utility: 0.08040\n",
      "  batch 020 / 029 | loss: 0.69932 | error: 0.32344 | utility: 0.18468\n",
      "  batch 021 / 029 | loss: 0.71315 | error: 0.33110 | utility: 0.04908\n",
      "  batch 022 / 029 | loss: 0.70918 | error: 0.32670 | utility: 0.00142\n",
      "  batch 023 / 029 | loss: 0.70627 | error: 0.32473 | utility: 0.24961\n",
      "  batch 024 / 029 | loss: 0.71001 | error: 0.32617 | utility: 0.03394\n",
      "  batch 025 / 029 | loss: 0.70858 | error: 0.32625 | utility: -0.03334\n",
      "  batch 026 / 029 | loss: 0.70458 | error: 0.32332 | utility: 0.04883\n",
      "  batch 027 / 029 | loss: 0.70294 | error: 0.32176 | utility: 0.04518\n",
      "  batch 028 / 029 | loss: 0.70305 | error: 0.32031 | utility: 0.03812\n",
      "  batch 029 / 029 | loss: 0.69396 | error: 0.31358 | utility: 0.05244\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 002 / 010 | time: 050 sec | loss: 0.79538 | error: 0.32396 | utility: 0.04527\n",
      "Validation accuracy improved.\n",
      "Saving model to ./Results/utility/utility_0.000_model.pt.\n",
      "Starting epoch 003 / 010.\n",
      "  batch 001 / 029 | loss: 0.79322 | error: 0.34375 | utility: -0.10893\n",
      "  batch 002 / 029 | loss: 0.73565 | error: 0.28906 | utility: -0.16710\n",
      "  batch 003 / 029 | loss: 0.67186 | error: 0.27083 | utility: 0.06593\n",
      "  batch 004 / 029 | loss: 0.69459 | error: 0.28906 | utility: 0.13026\n",
      "  batch 005 / 029 | loss: 0.67942 | error: 0.28125 | utility: 0.07581\n",
      "  batch 006 / 029 | loss: 0.68456 | error: 0.29167 | utility: 0.00006\n",
      "  batch 007 / 029 | loss: 0.66965 | error: 0.28571 | utility: 0.27598\n",
      "  batch 008 / 029 | loss: 0.68814 | error: 0.30078 | utility: 0.14202\n",
      "  batch 009 / 029 | loss: 0.66250 | error: 0.28819 | utility: -0.00895\n",
      "  batch 010 / 029 | loss: 0.66776 | error: 0.28906 | utility: 0.14428\n",
      "  batch 011 / 029 | loss: 0.67133 | error: 0.28977 | utility: 0.11204\n",
      "  batch 012 / 029 | loss: 0.67696 | error: 0.29297 | utility: -0.08629\n",
      "  batch 013 / 029 | loss: 0.67204 | error: 0.29567 | utility: -0.05129\n",
      "  batch 014 / 029 | loss: 0.66507 | error: 0.29464 | utility: 0.19696\n",
      "  batch 015 / 029 | loss: 0.67118 | error: 0.29583 | utility: 0.06833\n",
      "  batch 016 / 029 | loss: 0.67711 | error: 0.30371 | utility: -0.05885\n",
      "  batch 017 / 029 | loss: 0.68004 | error: 0.30423 | utility: 0.17555\n",
      "  batch 018 / 029 | loss: 0.68957 | error: 0.30729 | utility: -0.04543\n",
      "  batch 019 / 029 | loss: 0.69932 | error: 0.31086 | utility: 0.11026\n",
      "  batch 020 / 029 | loss: 0.70211 | error: 0.31250 | utility: 0.23232\n",
      "  batch 021 / 029 | loss: 0.69482 | error: 0.30655 | utility: 0.06390\n",
      "  batch 022 / 029 | loss: 0.69566 | error: 0.30611 | utility: 0.02646\n",
      "  batch 023 / 029 | loss: 0.69547 | error: 0.30571 | utility: 0.20155\n",
      "  batch 024 / 029 | loss: 0.69691 | error: 0.30599 | utility: 0.03025\n",
      "  batch 025 / 029 | loss: 0.69909 | error: 0.30812 | utility: 0.01661\n",
      "  batch 026 / 029 | loss: 0.69693 | error: 0.30829 | utility: 0.05408\n",
      "  batch 027 / 029 | loss: 0.69339 | error: 0.30671 | utility: 0.03589\n",
      "  batch 028 / 029 | loss: 0.68586 | error: 0.30469 | utility: -0.03816\n",
      "  batch 029 / 029 | loss: 0.67059 | error: 0.29418 | utility: 0.10355\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 003 / 010 | time: 055 sec | loss: 0.82557 | error: 0.33177 | utility: 0.08158\n",
      "Starting epoch 004 / 010.\n",
      "  batch 001 / 029 | loss: 0.70875 | error: 0.32812 | utility: 0.06280\n",
      "  batch 002 / 029 | loss: 0.77493 | error: 0.36719 | utility: 0.02787\n",
      "  batch 003 / 029 | loss: 0.69201 | error: 0.30729 | utility: 0.03598\n",
      "  batch 004 / 029 | loss: 0.66935 | error: 0.30078 | utility: 0.27572\n",
      "  batch 005 / 029 | loss: 0.69152 | error: 0.30938 | utility: 0.10443\n",
      "  batch 006 / 029 | loss: 0.68063 | error: 0.30729 | utility: 0.02495\n",
      "  batch 007 / 029 | loss: 0.66817 | error: 0.29911 | utility: 0.10638\n",
      "  batch 008 / 029 | loss: 0.67408 | error: 0.30469 | utility: 0.08330\n",
      "  batch 009 / 029 | loss: 0.70520 | error: 0.31597 | utility: 0.00189\n",
      "  batch 010 / 029 | loss: 0.68172 | error: 0.30312 | utility: 0.03665\n",
      "  batch 011 / 029 | loss: 0.68912 | error: 0.30824 | utility: -0.27306\n",
      "  batch 012 / 029 | loss: 0.69495 | error: 0.30599 | utility: -0.07405\n",
      "  batch 013 / 029 | loss: 0.67495 | error: 0.29808 | utility: 0.10741\n",
      "  batch 014 / 029 | loss: 0.67176 | error: 0.29464 | utility: 0.06582\n",
      "  batch 015 / 029 | loss: 0.67118 | error: 0.29271 | utility: 0.08487\n",
      "  batch 016 / 029 | loss: 0.68352 | error: 0.29590 | utility: 0.10136\n",
      "  batch 017 / 029 | loss: 0.68387 | error: 0.29596 | utility: 0.03675\n",
      "  batch 018 / 029 | loss: 0.68331 | error: 0.29688 | utility: 0.08584\n",
      "  batch 019 / 029 | loss: 0.68384 | error: 0.29770 | utility: -0.01795\n",
      "  batch 020 / 029 | loss: 0.68880 | error: 0.29922 | utility: -0.00328\n",
      "  batch 021 / 029 | loss: 0.68582 | error: 0.29836 | utility: 0.10613\n",
      "  batch 022 / 029 | loss: 0.69142 | error: 0.30185 | utility: 0.01995\n",
      "  batch 023 / 029 | loss: 0.69331 | error: 0.30163 | utility: -0.07052\n",
      "  batch 024 / 029 | loss: 0.69321 | error: 0.30143 | utility: -0.11689\n",
      "  batch 025 / 029 | loss: 0.69086 | error: 0.30125 | utility: -0.04107\n",
      "  batch 026 / 029 | loss: 0.68637 | error: 0.29868 | utility: 0.09162\n",
      "  batch 027 / 029 | loss: 0.68545 | error: 0.29861 | utility: -0.15417\n",
      "  batch 028 / 029 | loss: 0.68353 | error: 0.29743 | utility: -0.17839\n",
      "  batch 029 / 029 | loss: 0.68576 | error: 0.30011 | utility: -0.40927\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 004 / 010 | time: 058 sec | loss: 0.84671 | error: 0.33542 | utility: 0.06974\n",
      "Starting epoch 005 / 010.\n",
      "  batch 001 / 029 | loss: 0.75646 | error: 0.28125 | utility: -0.16640\n",
      "  batch 002 / 029 | loss: 0.75419 | error: 0.32031 | utility: -0.06721\n",
      "  batch 003 / 029 | loss: 0.71347 | error: 0.30208 | utility: -0.07034\n",
      "  batch 004 / 029 | loss: 0.71938 | error: 0.30078 | utility: -0.03223\n",
      "  batch 005 / 029 | loss: 0.70071 | error: 0.29063 | utility: -0.02582\n",
      "  batch 006 / 029 | loss: 0.66424 | error: 0.28125 | utility: -0.04685\n",
      "  batch 007 / 029 | loss: 0.66511 | error: 0.28348 | utility: -0.02890\n",
      "  batch 008 / 029 | loss: 0.65964 | error: 0.28320 | utility: -0.00722\n",
      "  batch 009 / 029 | loss: 0.67802 | error: 0.29167 | utility: 0.22090\n",
      "  batch 010 / 029 | loss: 0.67370 | error: 0.28594 | utility: -0.05450\n",
      "  batch 011 / 029 | loss: 0.68405 | error: 0.29119 | utility: 0.17883\n",
      "  batch 012 / 029 | loss: 0.67735 | error: 0.29036 | utility: -0.05713\n",
      "  batch 013 / 029 | loss: 0.67620 | error: 0.28966 | utility: 0.07706\n",
      "  batch 014 / 029 | loss: 0.68061 | error: 0.29129 | utility: -0.05944\n",
      "  batch 015 / 029 | loss: 0.68959 | error: 0.29688 | utility: 0.07760\n",
      "  batch 016 / 029 | loss: 0.69963 | error: 0.30273 | utility: 0.07067\n",
      "  batch 017 / 029 | loss: 0.70160 | error: 0.30515 | utility: 0.13023\n",
      "  batch 018 / 029 | loss: 0.69703 | error: 0.30295 | utility: 0.04744\n",
      "  batch 019 / 029 | loss: 0.69554 | error: 0.30263 | utility: -0.09665\n",
      "  batch 020 / 029 | loss: 0.68877 | error: 0.29922 | utility: -0.09707\n",
      "  batch 021 / 029 | loss: 0.68483 | error: 0.29836 | utility: -0.00378\n",
      "  batch 022 / 029 | loss: 0.68457 | error: 0.29972 | utility: 0.00741\n",
      "  batch 023 / 029 | loss: 0.67995 | error: 0.29755 | utility: -0.00880\n",
      "  batch 024 / 029 | loss: 0.68267 | error: 0.30013 | utility: -0.07267\n",
      "  batch 025 / 029 | loss: 0.68015 | error: 0.29750 | utility: -0.08067\n",
      "  batch 026 / 029 | loss: 0.68486 | error: 0.30048 | utility: 0.10149\n",
      "  batch 027 / 029 | loss: 0.68428 | error: 0.29977 | utility: 0.07859\n",
      "  batch 028 / 029 | loss: 0.68430 | error: 0.30078 | utility: -0.23145\n",
      "  batch 029 / 029 | loss: 0.67169 | error: 0.29472 | utility: -0.17906\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 005 / 010 | time: 064 sec | loss: 0.84915 | error: 0.32760 | utility: 0.05582\n",
      "Starting epoch 006 / 010.\n",
      "  batch 001 / 029 | loss: 0.52186 | error: 0.23438 | utility: 0.07197\n",
      "  batch 002 / 029 | loss: 0.61143 | error: 0.28906 | utility: -0.31712\n",
      "  batch 003 / 029 | loss: 0.64468 | error: 0.30208 | utility: 0.01340\n",
      "  batch 004 / 029 | loss: 0.69491 | error: 0.31250 | utility: -0.25366\n",
      "  batch 005 / 029 | loss: 0.66158 | error: 0.28750 | utility: -0.04486\n",
      "  batch 006 / 029 | loss: 0.65592 | error: 0.29167 | utility: -0.20661\n",
      "  batch 007 / 029 | loss: 0.65549 | error: 0.29688 | utility: -0.10881\n",
      "  batch 008 / 029 | loss: 0.66479 | error: 0.30078 | utility: 0.04440\n",
      "  batch 009 / 029 | loss: 0.66347 | error: 0.29861 | utility: -0.01136\n",
      "  batch 010 / 029 | loss: 0.65958 | error: 0.29375 | utility: 0.12643\n",
      "  batch 011 / 029 | loss: 0.67970 | error: 0.30256 | utility: 0.06659\n",
      "  batch 012 / 029 | loss: 0.67471 | error: 0.29818 | utility: 0.00579\n",
      "  batch 013 / 029 | loss: 0.67828 | error: 0.30168 | utility: -0.00749\n",
      "  batch 014 / 029 | loss: 0.67672 | error: 0.29911 | utility: 0.02959\n",
      "  batch 015 / 029 | loss: 0.66506 | error: 0.29375 | utility: 0.11660\n",
      "  batch 016 / 029 | loss: 0.67758 | error: 0.29980 | utility: -0.23135\n",
      "  batch 017 / 029 | loss: 0.68046 | error: 0.30055 | utility: -0.14284\n",
      "  batch 018 / 029 | loss: 0.67206 | error: 0.29514 | utility: 0.04107\n",
      "  batch 019 / 029 | loss: 0.67707 | error: 0.29770 | utility: -0.21855\n",
      "  batch 020 / 029 | loss: 0.68311 | error: 0.30234 | utility: -0.08011\n",
      "  batch 021 / 029 | loss: 0.67605 | error: 0.29836 | utility: 0.15502\n",
      "  batch 022 / 029 | loss: 0.67515 | error: 0.29901 | utility: -0.02397\n",
      "  batch 023 / 029 | loss: 0.67403 | error: 0.30027 | utility: 0.07464\n",
      "  batch 024 / 029 | loss: 0.67211 | error: 0.30013 | utility: -0.08295\n",
      "  batch 025 / 029 | loss: 0.67603 | error: 0.30250 | utility: -0.06000\n",
      "  batch 026 / 029 | loss: 0.67437 | error: 0.30168 | utility: 0.16611\n",
      "  batch 027 / 029 | loss: 0.67527 | error: 0.30208 | utility: 0.05637\n",
      "  batch 028 / 029 | loss: 0.67795 | error: 0.30190 | utility: -0.05822\n",
      "  batch 029 / 029 | loss: 0.70686 | error: 0.31304 | utility: -0.52876\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 006 / 010 | time: 067 sec | loss: 0.83499 | error: 0.32917 | utility: 0.04668\n",
      "Ending training due to 4 consecutive epochs without improvement in validation accuracy.\n",
      "Total training time: 6 minutes (339.8663983345032 seconds).\n",
      "Loading model from ./Results/utility/utility_0.000_model.pt.\n",
      "---------- Training with lambda=0.05 ----------\n",
      "Starting epoch 001 / 010.\n",
      "  batch 001 / 029 | loss: 0.85236 | error: 0.40625 | utility: 0.93142\n",
      "  batch 002 / 029 | loss: 0.84007 | error: 0.40625 | utility: 0.92997\n",
      "  batch 003 / 029 | loss: 0.89742 | error: 0.44792 | utility: 0.94116\n",
      "  batch 004 / 029 | loss: 0.89436 | error: 0.45312 | utility: 0.94500\n",
      "  batch 005 / 029 | loss: 0.88251 | error: 0.45312 | utility: 0.94388\n",
      "  batch 006 / 029 | loss: 0.88699 | error: 0.45833 | utility: 0.93778\n",
      "  batch 007 / 029 | loss: 0.89699 | error: 0.46875 | utility: 0.92333\n",
      "  batch 008 / 029 | loss: 0.91040 | error: 0.48047 | utility: 0.90574\n",
      "  batch 009 / 029 | loss: 0.92663 | error: 0.49653 | utility: 0.89514\n",
      "  batch 010 / 029 | loss: 0.92034 | error: 0.49375 | utility: 0.87461\n",
      "  batch 011 / 029 | loss: 0.90605 | error: 0.48864 | utility: 0.88938\n",
      "  batch 012 / 029 | loss: 0.91586 | error: 0.49479 | utility: 0.82367\n",
      "  batch 013 / 029 | loss: 0.90679 | error: 0.48918 | utility: 0.77916\n",
      "  batch 014 / 029 | loss: 0.90287 | error: 0.48996 | utility: 0.76661\n",
      "  batch 015 / 029 | loss: 0.89220 | error: 0.48125 | utility: 0.65425\n",
      "  batch 016 / 029 | loss: 0.89018 | error: 0.48047 | utility: 0.72170\n",
      "  batch 017 / 029 | loss: 0.88133 | error: 0.47335 | utility: 0.56678\n",
      "  batch 018 / 029 | loss: 0.88084 | error: 0.47309 | utility: 0.60096\n",
      "  batch 019 / 029 | loss: 0.87867 | error: 0.46875 | utility: 0.53243\n",
      "  batch 020 / 029 | loss: 0.87428 | error: 0.46719 | utility: 0.56666\n",
      "  batch 021 / 029 | loss: 0.86742 | error: 0.46131 | utility: 0.61406\n",
      "  batch 022 / 029 | loss: 0.85796 | error: 0.45241 | utility: 0.51705\n",
      "  batch 023 / 029 | loss: 0.85216 | error: 0.44633 | utility: 0.29308\n",
      "  batch 024 / 029 | loss: 0.84756 | error: 0.44206 | utility: 0.43894\n",
      "  batch 025 / 029 | loss: 0.84554 | error: 0.44000 | utility: 0.48497\n",
      "  batch 026 / 029 | loss: 0.84452 | error: 0.43810 | utility: 0.49711\n",
      "  batch 027 / 029 | loss: 0.84429 | error: 0.43461 | utility: 0.43289\n",
      "  batch 028 / 029 | loss: 0.83958 | error: 0.43080 | utility: 0.48436\n",
      "  batch 029 / 029 | loss: 0.83214 | error: 0.42888 | utility: 0.52523\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 001 / 010 | time: 043 sec | loss: 0.75726 | error: 0.36094 | utility: 0.45685\n",
      "Saving model to ./Results/utility/utility_0.050_model.pt.\n",
      "Starting epoch 002 / 010.\n",
      "  batch 001 / 029 | loss: 0.78716 | error: 0.42188 | utility: 0.28632\n",
      "  batch 002 / 029 | loss: 0.77401 | error: 0.38281 | utility: 0.39389\n",
      "  batch 003 / 029 | loss: 0.79323 | error: 0.40104 | utility: 0.35242\n",
      "  batch 004 / 029 | loss: 0.78142 | error: 0.38281 | utility: 0.47070\n",
      "  batch 005 / 029 | loss: 0.76243 | error: 0.37812 | utility: 0.30883\n",
      "  batch 006 / 029 | loss: 0.74294 | error: 0.36198 | utility: 0.38169\n",
      "  batch 007 / 029 | loss: 0.73690 | error: 0.35268 | utility: 0.08234\n",
      "  batch 008 / 029 | loss: 0.71962 | error: 0.34570 | utility: 0.35726\n",
      "  batch 009 / 029 | loss: 0.70755 | error: 0.33681 | utility: 0.26629\n",
      "  batch 010 / 029 | loss: 0.70176 | error: 0.32812 | utility: 0.22505\n",
      "  batch 011 / 029 | loss: 0.70181 | error: 0.32528 | utility: 0.37808\n",
      "  batch 012 / 029 | loss: 0.69638 | error: 0.32031 | utility: 0.04707\n",
      "  batch 013 / 029 | loss: 0.69576 | error: 0.32452 | utility: 0.15042\n",
      "  batch 014 / 029 | loss: 0.71409 | error: 0.33482 | utility: 0.14551\n",
      "  batch 015 / 029 | loss: 0.71098 | error: 0.33333 | utility: 0.39623\n",
      "  batch 016 / 029 | loss: 0.70517 | error: 0.32715 | utility: 0.16784\n",
      "  batch 017 / 029 | loss: 0.70407 | error: 0.32629 | utility: 0.19667\n",
      "  batch 018 / 029 | loss: 0.70494 | error: 0.32899 | utility: 0.26061\n",
      "  batch 019 / 029 | loss: 0.70430 | error: 0.33059 | utility: 0.12916\n",
      "  batch 020 / 029 | loss: 0.70444 | error: 0.32891 | utility: 0.22285\n",
      "  batch 021 / 029 | loss: 0.71864 | error: 0.33780 | utility: 0.11234\n",
      "  batch 022 / 029 | loss: 0.71508 | error: 0.33523 | utility: 0.06528\n",
      "  batch 023 / 029 | loss: 0.71210 | error: 0.33288 | utility: 0.29641\n",
      "  batch 024 / 029 | loss: 0.71579 | error: 0.33464 | utility: 0.09073\n",
      "  batch 025 / 029 | loss: 0.71439 | error: 0.33437 | utility: 0.02283\n",
      "  batch 026 / 029 | loss: 0.71036 | error: 0.33113 | utility: 0.07711\n",
      "  batch 027 / 029 | loss: 0.70882 | error: 0.32928 | utility: 0.09306\n",
      "  batch 028 / 029 | loss: 0.70906 | error: 0.32701 | utility: 0.09305\n",
      "  batch 029 / 029 | loss: 0.70141 | error: 0.32004 | utility: 0.11153\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 002 / 010 | time: 047 sec | loss: 0.78142 | error: 0.32240 | utility: 0.05789\n",
      "Validation accuracy improved.\n",
      "Saving model to ./Results/utility/utility_0.050_model.pt.\n",
      "Starting epoch 003 / 010.\n",
      "  batch 001 / 029 | loss: 0.81948 | error: 0.34375 | utility: -0.04414\n",
      "  batch 002 / 029 | loss: 0.75621 | error: 0.28906 | utility: -0.12299\n",
      "  batch 003 / 029 | loss: 0.69080 | error: 0.26562 | utility: 0.10891\n",
      "  batch 004 / 029 | loss: 0.71149 | error: 0.28125 | utility: 0.16751\n",
      "  batch 005 / 029 | loss: 0.69215 | error: 0.28437 | utility: 0.11212\n",
      "  batch 006 / 029 | loss: 0.69934 | error: 0.28906 | utility: 0.03510\n",
      "  batch 007 / 029 | loss: 0.68041 | error: 0.28571 | utility: 0.30270\n",
      "  batch 008 / 029 | loss: 0.69871 | error: 0.30273 | utility: 0.18907\n",
      "  batch 009 / 029 | loss: 0.67250 | error: 0.29167 | utility: 0.02748\n",
      "  batch 010 / 029 | loss: 0.67708 | error: 0.29531 | utility: 0.17009\n",
      "  batch 011 / 029 | loss: 0.68065 | error: 0.29830 | utility: 0.13371\n",
      "  batch 012 / 029 | loss: 0.68672 | error: 0.30078 | utility: -0.07401\n",
      "  batch 013 / 029 | loss: 0.68149 | error: 0.30288 | utility: -0.04741\n",
      "  batch 014 / 029 | loss: 0.67415 | error: 0.30134 | utility: 0.20669\n",
      "  batch 015 / 029 | loss: 0.68013 | error: 0.30208 | utility: 0.07821\n",
      "  batch 016 / 029 | loss: 0.68600 | error: 0.30664 | utility: -0.04897\n",
      "  batch 017 / 029 | loss: 0.68836 | error: 0.30790 | utility: 0.18721\n",
      "  batch 018 / 029 | loss: 0.69674 | error: 0.31076 | utility: -0.03265\n",
      "  batch 019 / 029 | loss: 0.70686 | error: 0.31414 | utility: 0.12930\n",
      "  batch 020 / 029 | loss: 0.70910 | error: 0.31641 | utility: 0.26800\n",
      "  batch 021 / 029 | loss: 0.70218 | error: 0.31027 | utility: 0.07781\n",
      "  batch 022 / 029 | loss: 0.70252 | error: 0.31108 | utility: 0.05959\n",
      "  batch 023 / 029 | loss: 0.70150 | error: 0.31182 | utility: 0.24891\n",
      "  batch 024 / 029 | loss: 0.70344 | error: 0.31250 | utility: 0.09078\n",
      "  batch 025 / 029 | loss: 0.70472 | error: 0.31500 | utility: 0.06289\n",
      "  batch 026 / 029 | loss: 0.70305 | error: 0.31611 | utility: 0.11125\n",
      "  batch 027 / 029 | loss: 0.69923 | error: 0.31424 | utility: 0.06706\n",
      "  batch 028 / 029 | loss: 0.69165 | error: 0.31250 | utility: -0.00697\n",
      "  batch 029 / 029 | loss: 0.67688 | error: 0.30603 | utility: 0.10802\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 003 / 010 | time: 053 sec | loss: 0.81564 | error: 0.33021 | utility: 0.08873\n",
      "Starting epoch 004 / 010.\n",
      "  batch 001 / 029 | loss: 0.70959 | error: 0.32812 | utility: 0.08174\n",
      "  batch 002 / 029 | loss: 0.77021 | error: 0.35938 | utility: 0.04923\n",
      "  batch 003 / 029 | loss: 0.68998 | error: 0.30208 | utility: 0.04552\n",
      "  batch 004 / 029 | loss: 0.66713 | error: 0.29688 | utility: 0.30153\n",
      "  batch 005 / 029 | loss: 0.68964 | error: 0.31250 | utility: 0.13938\n",
      "  batch 006 / 029 | loss: 0.67882 | error: 0.30990 | utility: 0.05559\n",
      "  batch 007 / 029 | loss: 0.66709 | error: 0.29911 | utility: 0.13759\n",
      "  batch 008 / 029 | loss: 0.67302 | error: 0.30664 | utility: 0.10420\n",
      "  batch 009 / 029 | loss: 0.70490 | error: 0.31944 | utility: 0.05368\n",
      "  batch 010 / 029 | loss: 0.68147 | error: 0.30625 | utility: 0.08082\n",
      "  batch 011 / 029 | loss: 0.69000 | error: 0.31108 | utility: -0.21922\n",
      "  batch 012 / 029 | loss: 0.69664 | error: 0.30859 | utility: -0.03161\n",
      "  batch 013 / 029 | loss: 0.67689 | error: 0.30048 | utility: 0.12702\n",
      "  batch 014 / 029 | loss: 0.67384 | error: 0.29799 | utility: 0.09070\n",
      "  batch 015 / 029 | loss: 0.67308 | error: 0.29583 | utility: 0.10754\n",
      "  batch 016 / 029 | loss: 0.68554 | error: 0.29883 | utility: 0.12481\n",
      "  batch 017 / 029 | loss: 0.68622 | error: 0.29871 | utility: 0.05877\n",
      "  batch 018 / 029 | loss: 0.68551 | error: 0.29948 | utility: 0.10437\n",
      "  batch 019 / 029 | loss: 0.68635 | error: 0.30099 | utility: 0.01097\n",
      "  batch 020 / 029 | loss: 0.69095 | error: 0.30234 | utility: 0.01979\n",
      "  batch 021 / 029 | loss: 0.68806 | error: 0.30134 | utility: 0.13560\n",
      "  batch 022 / 029 | loss: 0.69353 | error: 0.30398 | utility: 0.06935\n",
      "  batch 023 / 029 | loss: 0.69603 | error: 0.30367 | utility: -0.01662\n",
      "  batch 024 / 029 | loss: 0.69725 | error: 0.30273 | utility: -0.06171\n",
      "  batch 025 / 029 | loss: 0.69493 | error: 0.30312 | utility: 0.01398\n",
      "  batch 026 / 029 | loss: 0.69083 | error: 0.30048 | utility: 0.13827\n",
      "  batch 027 / 029 | loss: 0.68979 | error: 0.30035 | utility: -0.10758\n",
      "  batch 028 / 029 | loss: 0.68812 | error: 0.29911 | utility: -0.14023\n",
      "  batch 029 / 029 | loss: 0.68897 | error: 0.30172 | utility: -0.34093\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 004 / 010 | time: 054 sec | loss: 0.83686 | error: 0.33542 | utility: 0.07885\n",
      "Starting epoch 005 / 010.\n",
      "  batch 001 / 029 | loss: 0.78515 | error: 0.29688 | utility: -0.12068\n",
      "  batch 002 / 029 | loss: 0.77085 | error: 0.32812 | utility: -0.02428\n",
      "  batch 003 / 029 | loss: 0.72894 | error: 0.31250 | utility: -0.02375\n",
      "  batch 004 / 029 | loss: 0.73103 | error: 0.30859 | utility: 0.01844\n",
      "  batch 005 / 029 | loss: 0.71251 | error: 0.29688 | utility: 0.00073\n",
      "  batch 006 / 029 | loss: 0.67653 | error: 0.28646 | utility: -0.01666\n",
      "  batch 007 / 029 | loss: 0.67677 | error: 0.28795 | utility: -0.00781\n",
      "  batch 008 / 029 | loss: 0.67113 | error: 0.28711 | utility: 0.01978\n",
      "  batch 009 / 029 | loss: 0.68674 | error: 0.29688 | utility: 0.24048\n",
      "  batch 010 / 029 | loss: 0.68273 | error: 0.29219 | utility: -0.01666\n",
      "  batch 011 / 029 | loss: 0.69197 | error: 0.29545 | utility: 0.21811\n",
      "  batch 012 / 029 | loss: 0.68585 | error: 0.29167 | utility: -0.00753\n",
      "  batch 013 / 029 | loss: 0.68377 | error: 0.29087 | utility: 0.12569\n",
      "  batch 014 / 029 | loss: 0.68922 | error: 0.29241 | utility: -0.03379\n",
      "  batch 015 / 029 | loss: 0.69627 | error: 0.29688 | utility: 0.11354\n",
      "  batch 016 / 029 | loss: 0.70432 | error: 0.30078 | utility: 0.10468\n",
      "  batch 017 / 029 | loss: 0.70554 | error: 0.30239 | utility: 0.16763\n",
      "  batch 018 / 029 | loss: 0.70132 | error: 0.29948 | utility: 0.08287\n",
      "  batch 019 / 029 | loss: 0.70026 | error: 0.29770 | utility: -0.04447\n",
      "  batch 020 / 029 | loss: 0.69366 | error: 0.29688 | utility: -0.03968\n",
      "  batch 021 / 029 | loss: 0.69006 | error: 0.29539 | utility: 0.02699\n",
      "  batch 022 / 029 | loss: 0.68939 | error: 0.29545 | utility: 0.04890\n",
      "  batch 023 / 029 | loss: 0.68474 | error: 0.29348 | utility: 0.02900\n",
      "  batch 024 / 029 | loss: 0.68786 | error: 0.29557 | utility: -0.01607\n",
      "  batch 025 / 029 | loss: 0.68534 | error: 0.29437 | utility: -0.04078\n",
      "  batch 026 / 029 | loss: 0.69011 | error: 0.29748 | utility: 0.13067\n",
      "  batch 027 / 029 | loss: 0.68957 | error: 0.29630 | utility: 0.11370\n",
      "  batch 028 / 029 | loss: 0.68937 | error: 0.29799 | utility: -0.17636\n",
      "  batch 029 / 029 | loss: 0.67898 | error: 0.29203 | utility: -0.17709\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 005 / 010 | time: 056 sec | loss: 0.83247 | error: 0.32917 | utility: 0.07129\n",
      "Starting epoch 006 / 010.\n",
      "  batch 001 / 029 | loss: 0.54499 | error: 0.23438 | utility: 0.08955\n",
      "  batch 002 / 029 | loss: 0.63152 | error: 0.28906 | utility: -0.28513\n",
      "  batch 003 / 029 | loss: 0.65936 | error: 0.29688 | utility: 0.05824\n",
      "  batch 004 / 029 | loss: 0.71141 | error: 0.30859 | utility: -0.20148\n",
      "  batch 005 / 029 | loss: 0.67832 | error: 0.28437 | utility: -0.03032\n",
      "  batch 006 / 029 | loss: 0.67105 | error: 0.28646 | utility: -0.19087\n",
      "  batch 007 / 029 | loss: 0.66922 | error: 0.29241 | utility: -0.07433\n",
      "  batch 008 / 029 | loss: 0.67729 | error: 0.29688 | utility: 0.06985\n",
      "  batch 009 / 029 | loss: 0.67388 | error: 0.29514 | utility: 0.00880\n",
      "  batch 010 / 029 | loss: 0.66935 | error: 0.29063 | utility: 0.14586\n",
      "  batch 011 / 029 | loss: 0.68837 | error: 0.30256 | utility: 0.10508\n",
      "  batch 012 / 029 | loss: 0.68202 | error: 0.30078 | utility: 0.05377\n",
      "  batch 013 / 029 | loss: 0.68599 | error: 0.30649 | utility: 0.05214\n",
      "  batch 014 / 029 | loss: 0.68454 | error: 0.30246 | utility: 0.10930\n",
      "  batch 015 / 029 | loss: 0.67221 | error: 0.29688 | utility: 0.16123\n",
      "  batch 016 / 029 | loss: 0.68579 | error: 0.30371 | utility: -0.14646\n",
      "  batch 017 / 029 | loss: 0.68911 | error: 0.30331 | utility: -0.07435\n",
      "  batch 018 / 029 | loss: 0.68118 | error: 0.29774 | utility: 0.08586\n",
      "  batch 019 / 029 | loss: 0.68592 | error: 0.30016 | utility: -0.17815\n",
      "  batch 020 / 029 | loss: 0.69192 | error: 0.30469 | utility: -0.04710\n",
      "  batch 021 / 029 | loss: 0.68498 | error: 0.30060 | utility: 0.18397\n",
      "  batch 022 / 029 | loss: 0.68397 | error: 0.30114 | utility: 0.00988\n",
      "  batch 023 / 029 | loss: 0.68280 | error: 0.30231 | utility: 0.10974\n",
      "  batch 024 / 029 | loss: 0.68055 | error: 0.30143 | utility: -0.05860\n",
      "  batch 025 / 029 | loss: 0.68458 | error: 0.30312 | utility: -0.01413\n",
      "  batch 026 / 029 | loss: 0.68259 | error: 0.30228 | utility: 0.20842\n",
      "  batch 027 / 029 | loss: 0.68320 | error: 0.30324 | utility: 0.09294\n",
      "  batch 028 / 029 | loss: 0.68613 | error: 0.30413 | utility: -0.02458\n",
      "  batch 029 / 029 | loss: 0.71453 | error: 0.31519 | utility: -0.45441\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 006 / 010 | time: 060 sec | loss: 0.81956 | error: 0.32760 | utility: 0.05750\n",
      "Ending training due to 4 consecutive epochs without improvement in validation accuracy.\n",
      "Total training time: 5 minutes (312.8578419685364 seconds).\n",
      "Loading model from ./Results/utility/utility_0.050_model.pt.\n",
      "---------- Training with lambda=0.1 ----------\n",
      "Starting epoch 001 / 010.\n",
      "  batch 001 / 029 | loss: 0.83030 | error: 0.40625 | utility: 0.93142\n",
      "  batch 002 / 029 | loss: 0.81705 | error: 0.40625 | utility: 0.92997\n",
      "  batch 003 / 029 | loss: 0.87416 | error: 0.44792 | utility: 0.94032\n",
      "  batch 004 / 029 | loss: 0.87064 | error: 0.45312 | utility: 0.94499\n",
      "  batch 005 / 029 | loss: 0.85900 | error: 0.45312 | utility: 0.94472\n",
      "  batch 006 / 029 | loss: 0.86397 | error: 0.45833 | utility: 0.93989\n",
      "  batch 007 / 029 | loss: 0.87518 | error: 0.46875 | utility: 0.92845\n",
      "  batch 008 / 029 | loss: 0.88982 | error: 0.48047 | utility: 0.91403\n",
      "  batch 009 / 029 | loss: 0.90765 | error: 0.49653 | utility: 0.90637\n",
      "  batch 010 / 029 | loss: 0.90177 | error: 0.49531 | utility: 0.89024\n",
      "  batch 011 / 029 | loss: 0.88767 | error: 0.49006 | utility: 0.90199\n",
      "  batch 012 / 029 | loss: 0.89846 | error: 0.49740 | utility: 0.84536\n",
      "  batch 013 / 029 | loss: 0.88949 | error: 0.49159 | utility: 0.80334\n",
      "  batch 014 / 029 | loss: 0.88638 | error: 0.49219 | utility: 0.79600\n",
      "  batch 015 / 029 | loss: 0.87571 | error: 0.48542 | utility: 0.70091\n",
      "  batch 016 / 029 | loss: 0.87369 | error: 0.48438 | utility: 0.76078\n",
      "  batch 017 / 029 | loss: 0.86554 | error: 0.48162 | utility: 0.61951\n",
      "  batch 018 / 029 | loss: 0.86596 | error: 0.48264 | utility: 0.65230\n",
      "  batch 019 / 029 | loss: 0.86456 | error: 0.48026 | utility: 0.59081\n",
      "  batch 020 / 029 | loss: 0.86091 | error: 0.47813 | utility: 0.60901\n",
      "  batch 021 / 029 | loss: 0.85393 | error: 0.47321 | utility: 0.65706\n",
      "  batch 022 / 029 | loss: 0.84441 | error: 0.46449 | utility: 0.57046\n",
      "  batch 023 / 029 | loss: 0.83924 | error: 0.45856 | utility: 0.35607\n",
      "  batch 024 / 029 | loss: 0.83508 | error: 0.45312 | utility: 0.47820\n",
      "  batch 025 / 029 | loss: 0.83321 | error: 0.45062 | utility: 0.52571\n",
      "  batch 026 / 029 | loss: 0.83224 | error: 0.44952 | utility: 0.54490\n",
      "  batch 027 / 029 | loss: 0.83229 | error: 0.44734 | utility: 0.47849\n",
      "  batch 028 / 029 | loss: 0.82811 | error: 0.44308 | utility: 0.53195\n",
      "  batch 029 / 029 | loss: 0.82088 | error: 0.44073 | utility: 0.55950\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 001 / 010 | time: 041 sec | loss: 0.75739 | error: 0.37031 | utility: 0.50365\n",
      "Saving model to ./Results/utility/utility_0.100_model.pt.\n",
      "Starting epoch 002 / 010.\n",
      "  batch 001 / 029 | loss: 0.79725 | error: 0.40625 | utility: 0.35341\n",
      "  batch 002 / 029 | loss: 0.78161 | error: 0.38281 | utility: 0.44492\n",
      "  batch 003 / 029 | loss: 0.79866 | error: 0.39583 | utility: 0.40756\n",
      "  batch 004 / 029 | loss: 0.78459 | error: 0.37891 | utility: 0.49810\n",
      "  batch 005 / 029 | loss: 0.76751 | error: 0.37500 | utility: 0.35665\n",
      "  batch 006 / 029 | loss: 0.74797 | error: 0.35938 | utility: 0.42192\n",
      "  batch 007 / 029 | loss: 0.74520 | error: 0.35045 | utility: 0.11578\n",
      "  batch 008 / 029 | loss: 0.72667 | error: 0.34375 | utility: 0.41028\n",
      "  batch 009 / 029 | loss: 0.71380 | error: 0.33507 | utility: 0.30429\n",
      "  batch 010 / 029 | loss: 0.70685 | error: 0.32656 | utility: 0.27473\n",
      "  batch 011 / 029 | loss: 0.70645 | error: 0.32670 | utility: 0.42161\n",
      "  batch 012 / 029 | loss: 0.70224 | error: 0.32161 | utility: 0.09676\n",
      "  batch 013 / 029 | loss: 0.70146 | error: 0.32572 | utility: 0.17959\n",
      "  batch 014 / 029 | loss: 0.71871 | error: 0.33817 | utility: 0.20256\n",
      "  batch 015 / 029 | loss: 0.71400 | error: 0.33646 | utility: 0.43595\n",
      "  batch 016 / 029 | loss: 0.70807 | error: 0.33203 | utility: 0.21808\n",
      "  batch 017 / 029 | loss: 0.70673 | error: 0.33272 | utility: 0.25132\n",
      "  batch 018 / 029 | loss: 0.70793 | error: 0.33507 | utility: 0.30796\n",
      "  batch 019 / 029 | loss: 0.70756 | error: 0.33635 | utility: 0.17422\n",
      "  batch 020 / 029 | loss: 0.70726 | error: 0.33437 | utility: 0.25193\n",
      "  batch 021 / 029 | loss: 0.72175 | error: 0.34449 | utility: 0.15327\n",
      "  batch 022 / 029 | loss: 0.71819 | error: 0.34233 | utility: 0.10442\n",
      "  batch 023 / 029 | loss: 0.71490 | error: 0.34171 | utility: 0.33118\n",
      "  batch 024 / 029 | loss: 0.71814 | error: 0.34245 | utility: 0.12208\n",
      "  batch 025 / 029 | loss: 0.71691 | error: 0.34187 | utility: 0.05867\n",
      "  batch 026 / 029 | loss: 0.71264 | error: 0.33834 | utility: 0.10107\n",
      "  batch 027 / 029 | loss: 0.71111 | error: 0.33681 | utility: 0.13185\n",
      "  batch 028 / 029 | loss: 0.71137 | error: 0.33538 | utility: 0.14679\n",
      "  batch 029 / 029 | loss: 0.70413 | error: 0.32812 | utility: 0.16106\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 002 / 010 | time: 047 sec | loss: 0.77097 | error: 0.32083 | utility: 0.06747\n",
      "Validation accuracy improved.\n",
      "Saving model to ./Results/utility/utility_0.100_model.pt.\n",
      "Starting epoch 003 / 010.\n",
      "  batch 001 / 029 | loss: 0.82829 | error: 0.31250 | utility: 0.00845\n",
      "  batch 002 / 029 | loss: 0.75977 | error: 0.28906 | utility: -0.08618\n",
      "  batch 003 / 029 | loss: 0.69444 | error: 0.26562 | utility: 0.14238\n",
      "  batch 004 / 029 | loss: 0.71373 | error: 0.29297 | utility: 0.20704\n",
      "  batch 005 / 029 | loss: 0.69359 | error: 0.29688 | utility: 0.14407\n",
      "  batch 006 / 029 | loss: 0.70357 | error: 0.30208 | utility: 0.05929\n",
      "  batch 007 / 029 | loss: 0.68321 | error: 0.29464 | utility: 0.31207\n",
      "  batch 008 / 029 | loss: 0.70211 | error: 0.31055 | utility: 0.22436\n",
      "  batch 009 / 029 | loss: 0.67591 | error: 0.29688 | utility: 0.05360\n",
      "  batch 010 / 029 | loss: 0.68021 | error: 0.30000 | utility: 0.18210\n",
      "  batch 011 / 029 | loss: 0.68387 | error: 0.30256 | utility: 0.14698\n",
      "  batch 012 / 029 | loss: 0.69043 | error: 0.30469 | utility: -0.05978\n",
      "  batch 013 / 029 | loss: 0.68559 | error: 0.30649 | utility: -0.03914\n",
      "  batch 014 / 029 | loss: 0.67823 | error: 0.30469 | utility: 0.22111\n",
      "  batch 015 / 029 | loss: 0.68480 | error: 0.30521 | utility: 0.08991\n",
      "  batch 016 / 029 | loss: 0.69089 | error: 0.31250 | utility: -0.01049\n",
      "  batch 017 / 029 | loss: 0.69285 | error: 0.31250 | utility: 0.21430\n",
      "  batch 018 / 029 | loss: 0.70065 | error: 0.31424 | utility: -0.00957\n",
      "  batch 019 / 029 | loss: 0.71125 | error: 0.31743 | utility: 0.16082\n",
      "  batch 020 / 029 | loss: 0.71317 | error: 0.31875 | utility: 0.30866\n",
      "  batch 021 / 029 | loss: 0.70618 | error: 0.31250 | utility: 0.09811\n",
      "  batch 022 / 029 | loss: 0.70609 | error: 0.31250 | utility: 0.09551\n",
      "  batch 023 / 029 | loss: 0.70421 | error: 0.31386 | utility: 0.27673\n",
      "  batch 024 / 029 | loss: 0.70634 | error: 0.31641 | utility: 0.13033\n",
      "  batch 025 / 029 | loss: 0.70661 | error: 0.31750 | utility: 0.09351\n",
      "  batch 026 / 029 | loss: 0.70577 | error: 0.31671 | utility: 0.14405\n",
      "  batch 027 / 029 | loss: 0.70182 | error: 0.31481 | utility: 0.08541\n",
      "  batch 028 / 029 | loss: 0.69443 | error: 0.31362 | utility: 0.02141\n",
      "  batch 029 / 029 | loss: 0.68006 | error: 0.30711 | utility: 0.13435\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 003 / 010 | time: 052 sec | loss: 0.80360 | error: 0.32865 | utility: 0.09668\n",
      "Starting epoch 004 / 010.\n",
      "  batch 001 / 029 | loss: 0.71843 | error: 0.32812 | utility: 0.09961\n",
      "  batch 002 / 029 | loss: 0.77304 | error: 0.36719 | utility: 0.07604\n",
      "  batch 003 / 029 | loss: 0.69181 | error: 0.30729 | utility: 0.08692\n",
      "  batch 004 / 029 | loss: 0.66706 | error: 0.29688 | utility: 0.32777\n",
      "  batch 005 / 029 | loss: 0.69016 | error: 0.30625 | utility: 0.17564\n",
      "  batch 006 / 029 | loss: 0.67989 | error: 0.30729 | utility: 0.08690\n",
      "  batch 007 / 029 | loss: 0.66920 | error: 0.29688 | utility: 0.16693\n",
      "  batch 008 / 029 | loss: 0.67459 | error: 0.30273 | utility: 0.12858\n",
      "  batch 009 / 029 | loss: 0.70574 | error: 0.31944 | utility: 0.08681\n",
      "  batch 010 / 029 | loss: 0.68265 | error: 0.30938 | utility: 0.11442\n",
      "  batch 011 / 029 | loss: 0.69174 | error: 0.31250 | utility: -0.17442\n",
      "  batch 012 / 029 | loss: 0.69883 | error: 0.30729 | utility: -0.00213\n",
      "  batch 013 / 029 | loss: 0.67897 | error: 0.30048 | utility: 0.14920\n",
      "  batch 014 / 029 | loss: 0.67598 | error: 0.29911 | utility: 0.12147\n",
      "  batch 015 / 029 | loss: 0.67461 | error: 0.29792 | utility: 0.14115\n",
      "  batch 016 / 029 | loss: 0.68680 | error: 0.29883 | utility: 0.16596\n",
      "  batch 017 / 029 | loss: 0.68831 | error: 0.30055 | utility: 0.09398\n",
      "  batch 018 / 029 | loss: 0.68778 | error: 0.30122 | utility: 0.14049\n",
      "  batch 019 / 029 | loss: 0.68869 | error: 0.30181 | utility: 0.06975\n",
      "  batch 020 / 029 | loss: 0.69280 | error: 0.30391 | utility: 0.05855\n",
      "  batch 021 / 029 | loss: 0.68991 | error: 0.30283 | utility: 0.16818\n",
      "  batch 022 / 029 | loss: 0.69528 | error: 0.30540 | utility: 0.10635\n",
      "  batch 023 / 029 | loss: 0.69818 | error: 0.30571 | utility: 0.03372\n",
      "  batch 024 / 029 | loss: 0.69977 | error: 0.30664 | utility: -0.00184\n",
      "  batch 025 / 029 | loss: 0.69755 | error: 0.30625 | utility: 0.07216\n",
      "  batch 026 / 029 | loss: 0.69351 | error: 0.30469 | utility: 0.18434\n",
      "  batch 027 / 029 | loss: 0.69243 | error: 0.30382 | utility: -0.06575\n",
      "  batch 028 / 029 | loss: 0.69089 | error: 0.30246 | utility: -0.10766\n",
      "  batch 029 / 029 | loss: 0.69148 | error: 0.30496 | utility: -0.28800\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 004 / 010 | time: 052 sec | loss: 0.82710 | error: 0.33698 | utility: 0.08660\n",
      "Starting epoch 005 / 010.\n",
      "  batch 001 / 029 | loss: 0.79239 | error: 0.32812 | utility: -0.08132\n",
      "  batch 002 / 029 | loss: 0.77356 | error: 0.33594 | utility: 0.01146\n",
      "  batch 003 / 029 | loss: 0.73352 | error: 0.31771 | utility: 0.02706\n",
      "  batch 004 / 029 | loss: 0.73461 | error: 0.32031 | utility: 0.08148\n",
      "  batch 005 / 029 | loss: 0.71783 | error: 0.30938 | utility: 0.04747\n",
      "  batch 006 / 029 | loss: 0.68129 | error: 0.29688 | utility: 0.04670\n",
      "  batch 007 / 029 | loss: 0.68166 | error: 0.29911 | utility: 0.03859\n",
      "  batch 008 / 029 | loss: 0.67752 | error: 0.29492 | utility: 0.09470\n",
      "  batch 009 / 029 | loss: 0.69164 | error: 0.30208 | utility: 0.28085\n",
      "  batch 010 / 029 | loss: 0.68792 | error: 0.29688 | utility: 0.05791\n",
      "  batch 011 / 029 | loss: 0.69649 | error: 0.29972 | utility: 0.27457\n",
      "  batch 012 / 029 | loss: 0.69039 | error: 0.29688 | utility: 0.05267\n",
      "  batch 013 / 029 | loss: 0.68773 | error: 0.29567 | utility: 0.16874\n",
      "  batch 014 / 029 | loss: 0.69397 | error: 0.29911 | utility: -0.00391\n",
      "  batch 015 / 029 | loss: 0.69943 | error: 0.30208 | utility: 0.14645\n",
      "  batch 016 / 029 | loss: 0.70602 | error: 0.30566 | utility: 0.13467\n",
      "  batch 017 / 029 | loss: 0.70667 | error: 0.30607 | utility: 0.20592\n",
      "  batch 018 / 029 | loss: 0.70283 | error: 0.30382 | utility: 0.11658\n",
      "  batch 019 / 029 | loss: 0.70252 | error: 0.30181 | utility: 0.00630\n",
      "  batch 020 / 029 | loss: 0.69617 | error: 0.30078 | utility: 0.02148\n",
      "  batch 021 / 029 | loss: 0.69311 | error: 0.29911 | utility: 0.06735\n",
      "  batch 022 / 029 | loss: 0.69229 | error: 0.29830 | utility: 0.09222\n",
      "  batch 023 / 029 | loss: 0.68745 | error: 0.29552 | utility: 0.07404\n",
      "  batch 024 / 029 | loss: 0.69104 | error: 0.29688 | utility: 0.05842\n",
      "  batch 025 / 029 | loss: 0.68869 | error: 0.29500 | utility: 0.02696\n",
      "  batch 026 / 029 | loss: 0.69323 | error: 0.29928 | utility: 0.17526\n",
      "  batch 027 / 029 | loss: 0.69262 | error: 0.30035 | utility: 0.16711\n",
      "  batch 028 / 029 | loss: 0.69223 | error: 0.30190 | utility: -0.10437\n",
      "  batch 029 / 029 | loss: 0.68224 | error: 0.29580 | utility: -0.14688\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 005 / 010 | time: 052 sec | loss: 0.81682 | error: 0.32917 | utility: 0.08091\n",
      "Starting epoch 006 / 010.\n",
      "  batch 001 / 029 | loss: 0.54959 | error: 0.23438 | utility: 0.12317\n",
      "  batch 002 / 029 | loss: 0.64056 | error: 0.27344 | utility: -0.22702\n",
      "  batch 003 / 029 | loss: 0.66697 | error: 0.29167 | utility: 0.12411\n",
      "  batch 004 / 029 | loss: 0.72209 | error: 0.30469 | utility: -0.11539\n",
      "  batch 005 / 029 | loss: 0.68775 | error: 0.28125 | utility: 0.00561\n",
      "  batch 006 / 029 | loss: 0.68032 | error: 0.28385 | utility: -0.15252\n",
      "  batch 007 / 029 | loss: 0.67847 | error: 0.29241 | utility: -0.00908\n",
      "  batch 008 / 029 | loss: 0.68452 | error: 0.29492 | utility: 0.12835\n",
      "  batch 009 / 029 | loss: 0.67968 | error: 0.29340 | utility: 0.08911\n",
      "  batch 010 / 029 | loss: 0.67501 | error: 0.29219 | utility: 0.23942\n",
      "  batch 011 / 029 | loss: 0.69417 | error: 0.29972 | utility: 0.20293\n",
      "  batch 012 / 029 | loss: 0.68730 | error: 0.29818 | utility: 0.11793\n",
      "  batch 013 / 029 | loss: 0.69053 | error: 0.30288 | utility: 0.09926\n",
      "  batch 014 / 029 | loss: 0.68950 | error: 0.30134 | utility: 0.16025\n",
      "  batch 015 / 029 | loss: 0.67671 | error: 0.29583 | utility: 0.17100\n",
      "  batch 016 / 029 | loss: 0.69017 | error: 0.30176 | utility: -0.12545\n",
      "  batch 017 / 029 | loss: 0.69355 | error: 0.30239 | utility: -0.05083\n",
      "  batch 018 / 029 | loss: 0.68601 | error: 0.29688 | utility: 0.11733\n",
      "  batch 019 / 029 | loss: 0.69082 | error: 0.29852 | utility: -0.13733\n",
      "  batch 020 / 029 | loss: 0.69684 | error: 0.30312 | utility: 0.00240\n",
      "  batch 021 / 029 | loss: 0.68990 | error: 0.29911 | utility: 0.23650\n",
      "  batch 022 / 029 | loss: 0.68823 | error: 0.29972 | utility: 0.07038\n",
      "  batch 023 / 029 | loss: 0.68681 | error: 0.29891 | utility: 0.18122\n",
      "  batch 024 / 029 | loss: 0.68453 | error: 0.29753 | utility: -0.02069\n",
      "  batch 025 / 029 | loss: 0.68812 | error: 0.29938 | utility: 0.05772\n",
      "  batch 026 / 029 | loss: 0.68638 | error: 0.29808 | utility: 0.25533\n",
      "  batch 027 / 029 | loss: 0.68798 | error: 0.29977 | utility: 0.12526\n",
      "  batch 028 / 029 | loss: 0.69148 | error: 0.30134 | utility: 0.02323\n",
      "  batch 029 / 029 | loss: 0.71572 | error: 0.31250 | utility: -0.36660\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 006 / 010 | time: 055 sec | loss: 0.80078 | error: 0.33177 | utility: 0.07203\n",
      "Ending training due to 4 consecutive epochs without improvement in validation accuracy.\n",
      "Total training time: 5 minutes (298.8351788520813 seconds).\n",
      "Loading model from ./Results/utility/utility_0.100_model.pt.\n",
      "---------- Training with lambda=0.15000000000000002 ----------\n",
      "Starting epoch 001 / 010.\n",
      "  batch 001 / 029 | loss: 0.80824 | error: 0.40625 | utility: 0.93142\n",
      "  batch 002 / 029 | loss: 0.79403 | error: 0.40625 | utility: 0.92997\n",
      "  batch 003 / 029 | loss: 0.85141 | error: 0.44792 | utility: 0.93889\n",
      "  batch 004 / 029 | loss: 0.84716 | error: 0.45312 | utility: 0.94423\n",
      "  batch 005 / 029 | loss: 0.83558 | error: 0.45312 | utility: 0.94447\n",
      "  batch 006 / 029 | loss: 0.84083 | error: 0.45833 | utility: 0.94072\n",
      "  batch 007 / 029 | loss: 0.85282 | error: 0.46875 | utility: 0.93111\n",
      "  batch 008 / 029 | loss: 0.86803 | error: 0.48047 | utility: 0.91887\n",
      "  batch 009 / 029 | loss: 0.88694 | error: 0.49653 | utility: 0.91386\n",
      "  batch 010 / 029 | loss: 0.88111 | error: 0.49531 | utility: 0.90134\n",
      "  batch 011 / 029 | loss: 0.86707 | error: 0.49006 | utility: 0.91144\n",
      "  batch 012 / 029 | loss: 0.87860 | error: 0.49740 | utility: 0.86113\n",
      "  batch 013 / 029 | loss: 0.86982 | error: 0.49279 | utility: 0.82173\n",
      "  batch 014 / 029 | loss: 0.86717 | error: 0.49330 | utility: 0.81748\n",
      "  batch 015 / 029 | loss: 0.85663 | error: 0.48958 | utility: 0.73741\n",
      "  batch 016 / 029 | loss: 0.85469 | error: 0.48730 | utility: 0.79046\n",
      "  batch 017 / 029 | loss: 0.84729 | error: 0.48438 | utility: 0.66284\n",
      "  batch 018 / 029 | loss: 0.84859 | error: 0.48611 | utility: 0.69639\n",
      "  batch 019 / 029 | loss: 0.84796 | error: 0.48438 | utility: 0.64161\n",
      "  batch 020 / 029 | loss: 0.84498 | error: 0.48203 | utility: 0.64721\n",
      "  batch 021 / 029 | loss: 0.83795 | error: 0.47693 | utility: 0.69498\n",
      "  batch 022 / 029 | loss: 0.82844 | error: 0.46733 | utility: 0.62441\n",
      "  batch 023 / 029 | loss: 0.82389 | error: 0.46196 | utility: 0.42340\n",
      "  batch 024 / 029 | loss: 0.82024 | error: 0.45638 | utility: 0.51978\n",
      "  batch 025 / 029 | loss: 0.81850 | error: 0.45312 | utility: 0.57043\n",
      "  batch 026 / 029 | loss: 0.81767 | error: 0.45192 | utility: 0.59680\n",
      "  batch 027 / 029 | loss: 0.81795 | error: 0.45023 | utility: 0.52482\n",
      "  batch 028 / 029 | loss: 0.81425 | error: 0.44754 | utility: 0.58307\n",
      "  batch 029 / 029 | loss: 0.80743 | error: 0.44504 | utility: 0.60081\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 001 / 010 | time: 041 sec | loss: 0.76155 | error: 0.38698 | utility: 0.56432\n",
      "Saving model to ./Results/utility/utility_0.150_model.pt.\n",
      "Starting epoch 002 / 010.\n",
      "  batch 001 / 029 | loss: 0.80696 | error: 0.40625 | utility: 0.42751\n",
      "  batch 002 / 029 | loss: 0.78893 | error: 0.39844 | utility: 0.50703\n",
      "  batch 003 / 029 | loss: 0.80445 | error: 0.41146 | utility: 0.47797\n",
      "  batch 004 / 029 | loss: 0.78826 | error: 0.39062 | utility: 0.53505\n",
      "  batch 005 / 029 | loss: 0.77317 | error: 0.39062 | utility: 0.42247\n",
      "  batch 006 / 029 | loss: 0.75328 | error: 0.37500 | utility: 0.46884\n",
      "  batch 007 / 029 | loss: 0.75287 | error: 0.36384 | utility: 0.16456\n",
      "  batch 008 / 029 | loss: 0.73340 | error: 0.35742 | utility: 0.47174\n",
      "  batch 009 / 029 | loss: 0.71999 | error: 0.34722 | utility: 0.35233\n",
      "  batch 010 / 029 | loss: 0.71254 | error: 0.33750 | utility: 0.33141\n",
      "  batch 011 / 029 | loss: 0.71184 | error: 0.33665 | utility: 0.46761\n",
      "  batch 012 / 029 | loss: 0.70948 | error: 0.33203 | utility: 0.15318\n",
      "  batch 013 / 029 | loss: 0.70863 | error: 0.33413 | utility: 0.21254\n",
      "  batch 014 / 029 | loss: 0.72474 | error: 0.34710 | utility: 0.25659\n",
      "  batch 015 / 029 | loss: 0.71873 | error: 0.34479 | utility: 0.47231\n",
      "  batch 016 / 029 | loss: 0.71256 | error: 0.34082 | utility: 0.26960\n",
      "  batch 017 / 029 | loss: 0.71112 | error: 0.34191 | utility: 0.30954\n",
      "  batch 018 / 029 | loss: 0.71247 | error: 0.34375 | utility: 0.36309\n",
      "  batch 019 / 029 | loss: 0.71222 | error: 0.34539 | utility: 0.22115\n",
      "  batch 020 / 029 | loss: 0.71118 | error: 0.34297 | utility: 0.28729\n",
      "  batch 021 / 029 | loss: 0.72567 | error: 0.35268 | utility: 0.21397\n",
      "  batch 022 / 029 | loss: 0.72210 | error: 0.35085 | utility: 0.17343\n",
      "  batch 023 / 029 | loss: 0.71842 | error: 0.34918 | utility: 0.38635\n",
      "  batch 024 / 029 | loss: 0.72121 | error: 0.34896 | utility: 0.18288\n",
      "  batch 025 / 029 | loss: 0.72034 | error: 0.34687 | utility: 0.11419\n",
      "  batch 026 / 029 | loss: 0.71573 | error: 0.34315 | utility: 0.14235\n",
      "  batch 027 / 029 | loss: 0.71437 | error: 0.34086 | utility: 0.18287\n",
      "  batch 028 / 029 | loss: 0.71460 | error: 0.34096 | utility: 0.21792\n",
      "  batch 029 / 029 | loss: 0.70732 | error: 0.33351 | utility: 0.20242\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 002 / 010 | time: 046 sec | loss: 0.76003 | error: 0.32083 | utility: 0.07559\n",
      "Validation accuracy improved.\n",
      "Saving model to ./Results/utility/utility_0.150_model.pt.\n",
      "Starting epoch 003 / 010.\n",
      "  batch 001 / 029 | loss: 0.83479 | error: 0.34375 | utility: 0.08079\n",
      "  batch 002 / 029 | loss: 0.75734 | error: 0.30469 | utility: -0.03736\n",
      "  batch 003 / 029 | loss: 0.69189 | error: 0.29167 | utility: 0.18916\n",
      "  batch 004 / 029 | loss: 0.71005 | error: 0.30859 | utility: 0.26096\n",
      "  batch 005 / 029 | loss: 0.69191 | error: 0.30938 | utility: 0.20383\n",
      "  batch 006 / 029 | loss: 0.70453 | error: 0.32031 | utility: 0.09566\n",
      "  batch 007 / 029 | loss: 0.68256 | error: 0.31027 | utility: 0.32570\n",
      "  batch 008 / 029 | loss: 0.70271 | error: 0.32422 | utility: 0.26179\n",
      "  batch 009 / 029 | loss: 0.67760 | error: 0.30903 | utility: 0.07390\n",
      "  batch 010 / 029 | loss: 0.68049 | error: 0.30938 | utility: 0.20179\n",
      "  batch 011 / 029 | loss: 0.68406 | error: 0.31108 | utility: 0.16599\n",
      "  batch 012 / 029 | loss: 0.69101 | error: 0.31250 | utility: -0.03552\n",
      "  batch 013 / 029 | loss: 0.68703 | error: 0.31130 | utility: -0.02062\n",
      "  batch 014 / 029 | loss: 0.67955 | error: 0.30804 | utility: 0.24602\n",
      "  batch 015 / 029 | loss: 0.68628 | error: 0.30938 | utility: 0.12113\n",
      "  batch 016 / 029 | loss: 0.69247 | error: 0.31836 | utility: 0.04587\n",
      "  batch 017 / 029 | loss: 0.69421 | error: 0.31801 | utility: 0.25854\n",
      "  batch 018 / 029 | loss: 0.70173 | error: 0.32031 | utility: 0.02096\n",
      "  batch 019 / 029 | loss: 0.71272 | error: 0.32484 | utility: 0.20598\n",
      "  batch 020 / 029 | loss: 0.71423 | error: 0.32656 | utility: 0.35744\n",
      "  batch 021 / 029 | loss: 0.70730 | error: 0.31994 | utility: 0.12430\n",
      "  batch 022 / 029 | loss: 0.70706 | error: 0.32031 | utility: 0.13513\n",
      "  batch 023 / 029 | loss: 0.70457 | error: 0.32133 | utility: 0.30602\n",
      "  batch 024 / 029 | loss: 0.70679 | error: 0.32422 | utility: 0.16671\n",
      "  batch 025 / 029 | loss: 0.70642 | error: 0.32500 | utility: 0.12796\n",
      "  batch 026 / 029 | loss: 0.70576 | error: 0.32512 | utility: 0.18392\n",
      "  batch 027 / 029 | loss: 0.70164 | error: 0.32292 | utility: 0.11132\n",
      "  batch 028 / 029 | loss: 0.69424 | error: 0.32031 | utility: 0.06401\n",
      "  batch 029 / 029 | loss: 0.68037 | error: 0.31358 | utility: 0.17169\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 003 / 010 | time: 050 sec | loss: 0.78924 | error: 0.32865 | utility: 0.10302\n",
      "Starting epoch 004 / 010.\n",
      "  batch 001 / 029 | loss: 0.72892 | error: 0.32812 | utility: 0.13637\n",
      "  batch 002 / 029 | loss: 0.77232 | error: 0.36719 | utility: 0.11611\n",
      "  batch 003 / 029 | loss: 0.69100 | error: 0.30729 | utility: 0.12188\n",
      "  batch 004 / 029 | loss: 0.66428 | error: 0.29688 | utility: 0.34689\n",
      "  batch 005 / 029 | loss: 0.68727 | error: 0.30938 | utility: 0.20961\n",
      "  batch 006 / 029 | loss: 0.67730 | error: 0.30729 | utility: 0.11461\n",
      "  batch 007 / 029 | loss: 0.66826 | error: 0.30357 | utility: 0.20699\n",
      "  batch 008 / 029 | loss: 0.67261 | error: 0.30664 | utility: 0.16754\n",
      "  batch 009 / 029 | loss: 0.70342 | error: 0.32292 | utility: 0.14460\n",
      "  batch 010 / 029 | loss: 0.68030 | error: 0.30938 | utility: 0.18109\n",
      "  batch 011 / 029 | loss: 0.69071 | error: 0.31108 | utility: -0.07072\n",
      "  batch 012 / 029 | loss: 0.69891 | error: 0.31641 | utility: 0.09534\n",
      "  batch 013 / 029 | loss: 0.67890 | error: 0.30649 | utility: 0.19129\n",
      "  batch 014 / 029 | loss: 0.67585 | error: 0.30469 | utility: 0.19348\n",
      "  batch 015 / 029 | loss: 0.67429 | error: 0.30521 | utility: 0.22478\n",
      "  batch 016 / 029 | loss: 0.68682 | error: 0.30957 | utility: 0.25611\n",
      "  batch 017 / 029 | loss: 0.68934 | error: 0.31158 | utility: 0.17393\n",
      "  batch 018 / 029 | loss: 0.68800 | error: 0.31250 | utility: 0.19571\n",
      "  batch 019 / 029 | loss: 0.68983 | error: 0.31250 | utility: 0.14745\n",
      "  batch 020 / 029 | loss: 0.69371 | error: 0.31406 | utility: 0.11033\n",
      "  batch 021 / 029 | loss: 0.69087 | error: 0.31324 | utility: 0.22315\n",
      "  batch 022 / 029 | loss: 0.69566 | error: 0.31392 | utility: 0.19561\n",
      "  batch 023 / 029 | loss: 0.69879 | error: 0.31590 | utility: 0.11451\n",
      "  batch 024 / 029 | loss: 0.70113 | error: 0.31641 | utility: 0.07989\n",
      "  batch 025 / 029 | loss: 0.69887 | error: 0.31562 | utility: 0.16452\n",
      "  batch 026 / 029 | loss: 0.69557 | error: 0.31490 | utility: 0.24212\n",
      "  batch 027 / 029 | loss: 0.69439 | error: 0.31366 | utility: 0.01231\n",
      "  batch 028 / 029 | loss: 0.69291 | error: 0.31362 | utility: -0.01568\n",
      "  batch 029 / 029 | loss: 0.69254 | error: 0.31573 | utility: -0.15517\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 004 / 010 | time: 050 sec | loss: 0.79656 | error: 0.33698 | utility: 0.09733\n",
      "Starting epoch 005 / 010.\n",
      "  batch 001 / 029 | loss: 0.79789 | error: 0.37500 | utility: -0.00147\n",
      "  batch 002 / 029 | loss: 0.77380 | error: 0.35156 | utility: 0.06760\n",
      "  batch 003 / 029 | loss: 0.73574 | error: 0.32812 | utility: 0.08579\n",
      "  batch 004 / 029 | loss: 0.73370 | error: 0.33984 | utility: 0.14333\n",
      "  batch 005 / 029 | loss: 0.71907 | error: 0.33437 | utility: 0.09702\n",
      "  batch 006 / 029 | loss: 0.68433 | error: 0.30729 | utility: 0.11548\n",
      "  batch 007 / 029 | loss: 0.68395 | error: 0.30134 | utility: 0.08845\n",
      "  batch 008 / 029 | loss: 0.67949 | error: 0.29688 | utility: 0.17202\n",
      "  batch 009 / 029 | loss: 0.69194 | error: 0.30556 | utility: 0.32660\n",
      "  batch 010 / 029 | loss: 0.68934 | error: 0.30625 | utility: 0.14502\n",
      "  batch 011 / 029 | loss: 0.69721 | error: 0.31250 | utility: 0.35265\n",
      "  batch 012 / 029 | loss: 0.69113 | error: 0.30859 | utility: 0.12953\n",
      "  batch 013 / 029 | loss: 0.68769 | error: 0.30649 | utility: 0.23229\n",
      "  batch 014 / 029 | loss: 0.69525 | error: 0.30915 | utility: 0.04284\n",
      "  batch 015 / 029 | loss: 0.69913 | error: 0.31146 | utility: 0.19539\n",
      "  batch 016 / 029 | loss: 0.70432 | error: 0.31543 | utility: 0.18333\n",
      "  batch 017 / 029 | loss: 0.70467 | error: 0.31526 | utility: 0.25823\n",
      "  batch 018 / 029 | loss: 0.70130 | error: 0.31250 | utility: 0.15428\n",
      "  batch 019 / 029 | loss: 0.70194 | error: 0.31086 | utility: 0.06168\n",
      "  batch 020 / 029 | loss: 0.69572 | error: 0.30859 | utility: 0.08225\n",
      "  batch 021 / 029 | loss: 0.69313 | error: 0.30580 | utility: 0.12168\n",
      "  batch 022 / 029 | loss: 0.69298 | error: 0.30398 | utility: 0.13521\n",
      "  batch 023 / 029 | loss: 0.68770 | error: 0.30163 | utility: 0.12388\n",
      "  batch 024 / 029 | loss: 0.69161 | error: 0.30273 | utility: 0.15030\n",
      "  batch 025 / 029 | loss: 0.68953 | error: 0.30125 | utility: 0.09862\n",
      "  batch 026 / 029 | loss: 0.69383 | error: 0.30469 | utility: 0.22889\n",
      "  batch 027 / 029 | loss: 0.69315 | error: 0.30613 | utility: 0.22423\n",
      "  batch 028 / 029 | loss: 0.69271 | error: 0.30748 | utility: 0.00117\n",
      "  batch 029 / 029 | loss: 0.68364 | error: 0.30119 | utility: -0.10271\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 005 / 010 | time: 050 sec | loss: 0.78717 | error: 0.32604 | utility: 0.09718\n",
      "Starting epoch 006 / 010.\n",
      "  batch 001 / 029 | loss: 0.55350 | error: 0.23438 | utility: 0.17472\n",
      "  batch 002 / 029 | loss: 0.65071 | error: 0.26562 | utility: -0.13208\n",
      "  batch 003 / 029 | loss: 0.67224 | error: 0.29688 | utility: 0.21993\n",
      "  batch 004 / 029 | loss: 0.72893 | error: 0.31641 | utility: 0.01506\n",
      "  batch 005 / 029 | loss: 0.69360 | error: 0.30312 | utility: 0.05944\n",
      "  batch 006 / 029 | loss: 0.68509 | error: 0.29948 | utility: -0.09170\n",
      "  batch 007 / 029 | loss: 0.68131 | error: 0.29464 | utility: 0.08030\n",
      "  batch 008 / 029 | loss: 0.68549 | error: 0.29883 | utility: 0.19227\n",
      "  batch 009 / 029 | loss: 0.67855 | error: 0.29861 | utility: 0.17304\n",
      "  batch 010 / 029 | loss: 0.67468 | error: 0.30312 | utility: 0.32685\n",
      "  batch 011 / 029 | loss: 0.69258 | error: 0.31392 | utility: 0.28322\n",
      "  batch 012 / 029 | loss: 0.68429 | error: 0.30859 | utility: 0.15971\n",
      "  batch 013 / 029 | loss: 0.68715 | error: 0.31010 | utility: 0.13495\n",
      "  batch 014 / 029 | loss: 0.68713 | error: 0.31250 | utility: 0.22293\n",
      "  batch 015 / 029 | loss: 0.67459 | error: 0.30729 | utility: 0.19199\n",
      "  batch 016 / 029 | loss: 0.68870 | error: 0.31445 | utility: -0.06893\n",
      "  batch 017 / 029 | loss: 0.69263 | error: 0.31526 | utility: 0.02277\n",
      "  batch 018 / 029 | loss: 0.68596 | error: 0.31076 | utility: 0.17517\n",
      "  batch 019 / 029 | loss: 0.69076 | error: 0.31250 | utility: -0.06100\n",
      "  batch 020 / 029 | loss: 0.69673 | error: 0.31562 | utility: 0.08352\n",
      "  batch 021 / 029 | loss: 0.68972 | error: 0.31176 | utility: 0.31445\n",
      "  batch 022 / 029 | loss: 0.68722 | error: 0.30895 | utility: 0.16392\n",
      "  batch 023 / 029 | loss: 0.68578 | error: 0.30707 | utility: 0.28621\n",
      "  batch 024 / 029 | loss: 0.68362 | error: 0.30599 | utility: 0.05309\n",
      "  batch 025 / 029 | loss: 0.68728 | error: 0.30875 | utility: 0.15464\n",
      "  batch 026 / 029 | loss: 0.68631 | error: 0.30829 | utility: 0.30001\n",
      "  batch 027 / 029 | loss: 0.68843 | error: 0.30961 | utility: 0.18241\n",
      "  batch 028 / 029 | loss: 0.69232 | error: 0.31194 | utility: 0.08104\n",
      "  batch 029 / 029 | loss: 0.71525 | error: 0.32274 | utility: -0.22435\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 006 / 010 | time: 052 sec | loss: 0.76989 | error: 0.32552 | utility: 0.08960\n",
      "Ending training due to 4 consecutive epochs without improvement in validation accuracy.\n",
      "Total training time: 5 minutes (288.67712807655334 seconds).\n",
      "Loading model from ./Results/utility/utility_0.150_model.pt.\n",
      "---------- Training with lambda=0.2 ----------\n",
      "Starting epoch 001 / 010.\n",
      "  batch 001 / 029 | loss: 0.78618 | error: 0.40625 | utility: 0.93142\n",
      "  batch 002 / 029 | loss: 0.77101 | error: 0.40625 | utility: 0.92997\n",
      "  batch 003 / 029 | loss: 0.82725 | error: 0.44792 | utility: 0.93897\n",
      "  batch 004 / 029 | loss: 0.82237 | error: 0.45312 | utility: 0.94458\n",
      "  batch 005 / 029 | loss: 0.81056 | error: 0.45312 | utility: 0.94532\n",
      "  batch 006 / 029 | loss: 0.81601 | error: 0.45833 | utility: 0.94215\n",
      "  batch 007 / 029 | loss: 0.82843 | error: 0.46875 | utility: 0.93404\n",
      "  batch 008 / 029 | loss: 0.84444 | error: 0.48047 | utility: 0.92363\n",
      "  batch 009 / 029 | loss: 0.86467 | error: 0.49653 | utility: 0.92031\n",
      "  batch 010 / 029 | loss: 0.85907 | error: 0.49531 | utility: 0.91097\n",
      "  batch 011 / 029 | loss: 0.84511 | error: 0.49006 | utility: 0.92004\n",
      "  batch 012 / 029 | loss: 0.85753 | error: 0.49740 | utility: 0.87563\n",
      "  batch 013 / 029 | loss: 0.84902 | error: 0.49279 | utility: 0.83869\n",
      "  batch 014 / 029 | loss: 0.84702 | error: 0.49442 | utility: 0.83914\n",
      "  batch 015 / 029 | loss: 0.83647 | error: 0.48854 | utility: 0.77722\n",
      "  batch 016 / 029 | loss: 0.83460 | error: 0.48633 | utility: 0.82219\n",
      "  batch 017 / 029 | loss: 0.82783 | error: 0.48438 | utility: 0.71103\n",
      "  batch 018 / 029 | loss: 0.83006 | error: 0.48785 | utility: 0.74467\n",
      "  batch 019 / 029 | loss: 0.83017 | error: 0.49013 | utility: 0.69880\n",
      "  batch 020 / 029 | loss: 0.82789 | error: 0.48750 | utility: 0.69082\n",
      "  batch 021 / 029 | loss: 0.82062 | error: 0.48140 | utility: 0.73843\n",
      "  batch 022 / 029 | loss: 0.81086 | error: 0.47159 | utility: 0.68355\n",
      "  batch 023 / 029 | loss: 0.80681 | error: 0.46739 | utility: 0.49789\n",
      "  batch 024 / 029 | loss: 0.80358 | error: 0.46224 | utility: 0.57043\n",
      "  batch 025 / 029 | loss: 0.80190 | error: 0.45875 | utility: 0.62029\n",
      "  batch 026 / 029 | loss: 0.80108 | error: 0.45853 | utility: 0.64829\n",
      "  batch 027 / 029 | loss: 0.80155 | error: 0.45718 | utility: 0.57693\n",
      "  batch 028 / 029 | loss: 0.79823 | error: 0.45424 | utility: 0.63001\n",
      "  batch 029 / 029 | loss: 0.79184 | error: 0.45151 | utility: 0.65016\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 001 / 010 | time: 041 sec | loss: 0.76328 | error: 0.39948 | utility: 0.61176\n",
      "Saving model to ./Results/utility/utility_0.200_model.pt.\n",
      "Starting epoch 002 / 010.\n",
      "  batch 001 / 029 | loss: 0.80843 | error: 0.40625 | utility: 0.49926\n",
      "  batch 002 / 029 | loss: 0.78820 | error: 0.40625 | utility: 0.56057\n",
      "  batch 003 / 029 | loss: 0.80224 | error: 0.41667 | utility: 0.54177\n",
      "  batch 004 / 029 | loss: 0.78496 | error: 0.40234 | utility: 0.57803\n",
      "  batch 005 / 029 | loss: 0.77123 | error: 0.39687 | utility: 0.48590\n",
      "  batch 006 / 029 | loss: 0.75171 | error: 0.38542 | utility: 0.51944\n",
      "  batch 007 / 029 | loss: 0.75351 | error: 0.37277 | utility: 0.22626\n",
      "  batch 008 / 029 | loss: 0.73292 | error: 0.36523 | utility: 0.54077\n",
      "  batch 009 / 029 | loss: 0.71957 | error: 0.35417 | utility: 0.41492\n",
      "  batch 010 / 029 | loss: 0.71124 | error: 0.34531 | utility: 0.40326\n",
      "  batch 011 / 029 | loss: 0.71024 | error: 0.34659 | utility: 0.52967\n",
      "  batch 012 / 029 | loss: 0.71036 | error: 0.34115 | utility: 0.24787\n",
      "  batch 013 / 029 | loss: 0.71016 | error: 0.34495 | utility: 0.26637\n",
      "  batch 014 / 029 | loss: 0.72579 | error: 0.35714 | utility: 0.34189\n",
      "  batch 015 / 029 | loss: 0.71834 | error: 0.35521 | utility: 0.52117\n",
      "  batch 016 / 029 | loss: 0.71210 | error: 0.35156 | utility: 0.34418\n",
      "  batch 017 / 029 | loss: 0.71064 | error: 0.35202 | utility: 0.38383\n",
      "  batch 018 / 029 | loss: 0.71245 | error: 0.35330 | utility: 0.43573\n",
      "  batch 019 / 029 | loss: 0.71392 | error: 0.35444 | utility: 0.27097\n",
      "  batch 020 / 029 | loss: 0.71217 | error: 0.35156 | utility: 0.33223\n",
      "  batch 021 / 029 | loss: 0.72676 | error: 0.36012 | utility: 0.27979\n",
      "  batch 022 / 029 | loss: 0.72334 | error: 0.35866 | utility: 0.23647\n",
      "  batch 023 / 029 | loss: 0.71975 | error: 0.35734 | utility: 0.43076\n",
      "  batch 024 / 029 | loss: 0.72194 | error: 0.35482 | utility: 0.23988\n",
      "  batch 025 / 029 | loss: 0.72221 | error: 0.35313 | utility: 0.16209\n",
      "  batch 026 / 029 | loss: 0.71739 | error: 0.34976 | utility: 0.18543\n",
      "  batch 027 / 029 | loss: 0.71613 | error: 0.34722 | utility: 0.23788\n",
      "  batch 028 / 029 | loss: 0.71632 | error: 0.34821 | utility: 0.28397\n",
      "  batch 029 / 029 | loss: 0.70871 | error: 0.34052 | utility: 0.22085\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 002 / 010 | time: 052 sec | loss: 0.74558 | error: 0.32292 | utility: 0.22563\n",
      "Validation accuracy improved.\n",
      "Saving model to ./Results/utility/utility_0.200_model.pt.\n",
      "Starting epoch 003 / 010.\n",
      "  batch 001 / 029 | loss: 0.83284 | error: 0.35938 | utility: 0.14031\n",
      "  batch 002 / 029 | loss: 0.75115 | error: 0.32812 | utility: 0.00769\n",
      "  batch 003 / 029 | loss: 0.69009 | error: 0.30729 | utility: 0.23777\n",
      "  batch 004 / 029 | loss: 0.70534 | error: 0.31641 | utility: 0.29848\n",
      "  batch 005 / 029 | loss: 0.68967 | error: 0.31875 | utility: 0.24539\n",
      "  batch 006 / 029 | loss: 0.70291 | error: 0.32812 | utility: 0.13250\n",
      "  batch 007 / 029 | loss: 0.67997 | error: 0.31696 | utility: 0.34636\n",
      "  batch 008 / 029 | loss: 0.70163 | error: 0.33008 | utility: 0.30112\n",
      "  batch 009 / 029 | loss: 0.67749 | error: 0.31597 | utility: 0.10527\n",
      "  batch 010 / 029 | loss: 0.67932 | error: 0.31562 | utility: 0.23594\n",
      "  batch 011 / 029 | loss: 0.68378 | error: 0.31818 | utility: 0.21239\n",
      "  batch 012 / 029 | loss: 0.69120 | error: 0.31901 | utility: 0.00105\n",
      "  batch 013 / 029 | loss: 0.68826 | error: 0.31971 | utility: 0.01998\n",
      "  batch 014 / 029 | loss: 0.68034 | error: 0.31696 | utility: 0.29298\n",
      "  batch 015 / 029 | loss: 0.68658 | error: 0.31562 | utility: 0.15348\n",
      "  batch 016 / 029 | loss: 0.69319 | error: 0.32422 | utility: 0.10278\n",
      "  batch 017 / 029 | loss: 0.69482 | error: 0.32445 | utility: 0.29301\n",
      "  batch 018 / 029 | loss: 0.70225 | error: 0.32812 | utility: 0.03795\n",
      "  batch 019 / 029 | loss: 0.71298 | error: 0.33141 | utility: 0.23570\n",
      "  batch 020 / 029 | loss: 0.71415 | error: 0.33203 | utility: 0.38582\n",
      "  batch 021 / 029 | loss: 0.70750 | error: 0.32515 | utility: 0.14469\n",
      "  batch 022 / 029 | loss: 0.70699 | error: 0.32599 | utility: 0.16872\n",
      "  batch 023 / 029 | loss: 0.70416 | error: 0.32677 | utility: 0.33988\n",
      "  batch 024 / 029 | loss: 0.70652 | error: 0.32943 | utility: 0.20592\n",
      "  batch 025 / 029 | loss: 0.70559 | error: 0.32937 | utility: 0.17408\n",
      "  batch 026 / 029 | loss: 0.70533 | error: 0.32993 | utility: 0.24992\n",
      "  batch 027 / 029 | loss: 0.70122 | error: 0.32639 | utility: 0.15643\n",
      "  batch 028 / 029 | loss: 0.69368 | error: 0.32254 | utility: 0.14685\n",
      "  batch 029 / 029 | loss: 0.67988 | error: 0.31573 | utility: 0.21315\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 003 / 010 | time: 048 sec | loss: 0.77209 | error: 0.32865 | utility: 0.11014\n",
      "Starting epoch 004 / 010.\n",
      "  batch 001 / 029 | loss: 0.73236 | error: 0.31250 | utility: 0.17538\n",
      "  batch 002 / 029 | loss: 0.76979 | error: 0.35156 | utility: 0.16179\n",
      "  batch 003 / 029 | loss: 0.68772 | error: 0.28646 | utility: 0.15436\n",
      "  batch 004 / 029 | loss: 0.65951 | error: 0.27734 | utility: 0.37178\n",
      "  batch 005 / 029 | loss: 0.68254 | error: 0.29063 | utility: 0.24721\n",
      "  batch 006 / 029 | loss: 0.67241 | error: 0.29167 | utility: 0.14768\n",
      "  batch 007 / 029 | loss: 0.66470 | error: 0.29018 | utility: 0.24517\n",
      "  batch 008 / 029 | loss: 0.66907 | error: 0.29297 | utility: 0.20980\n",
      "  batch 009 / 029 | loss: 0.70081 | error: 0.31250 | utility: 0.20378\n",
      "  batch 010 / 029 | loss: 0.67739 | error: 0.30000 | utility: 0.24339\n",
      "  batch 011 / 029 | loss: 0.68795 | error: 0.30540 | utility: 0.00838\n",
      "  batch 012 / 029 | loss: 0.69696 | error: 0.31510 | utility: 0.15679\n",
      "  batch 013 / 029 | loss: 0.67727 | error: 0.30529 | utility: 0.21719\n",
      "  batch 014 / 029 | loss: 0.67414 | error: 0.30469 | utility: 0.23167\n",
      "  batch 015 / 029 | loss: 0.67245 | error: 0.30833 | utility: 0.26346\n",
      "  batch 016 / 029 | loss: 0.68481 | error: 0.31543 | utility: 0.29885\n",
      "  batch 017 / 029 | loss: 0.68757 | error: 0.31710 | utility: 0.21602\n",
      "  batch 018 / 029 | loss: 0.68582 | error: 0.31858 | utility: 0.21995\n",
      "  batch 019 / 029 | loss: 0.68789 | error: 0.31826 | utility: 0.18733\n",
      "  batch 020 / 029 | loss: 0.69196 | error: 0.32188 | utility: 0.14257\n",
      "  batch 021 / 029 | loss: 0.68917 | error: 0.32292 | utility: 0.26266\n",
      "  batch 022 / 029 | loss: 0.69358 | error: 0.32386 | utility: 0.26024\n",
      "  batch 023 / 029 | loss: 0.69706 | error: 0.32677 | utility: 0.18187\n",
      "  batch 024 / 029 | loss: 0.69958 | error: 0.32682 | utility: 0.14250\n",
      "  batch 025 / 029 | loss: 0.69708 | error: 0.32625 | utility: 0.21581\n",
      "  batch 026 / 029 | loss: 0.69392 | error: 0.32632 | utility: 0.27377\n",
      "  batch 027 / 029 | loss: 0.69299 | error: 0.32581 | utility: 0.04811\n",
      "  batch 028 / 029 | loss: 0.69169 | error: 0.32589 | utility: 0.02692\n",
      "  batch 029 / 029 | loss: 0.69158 | error: 0.32759 | utility: -0.11311\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 004 / 010 | time: 049 sec | loss: 0.78993 | error: 0.33698 | utility: 0.09960\n",
      "Starting epoch 005 / 010.\n",
      "  batch 001 / 029 | loss: 0.80222 | error: 0.39062 | utility: 0.04376\n",
      "  batch 002 / 029 | loss: 0.77556 | error: 0.35156 | utility: 0.10256\n",
      "  batch 003 / 029 | loss: 0.73779 | error: 0.32812 | utility: 0.12167\n",
      "  batch 004 / 029 | loss: 0.73501 | error: 0.33594 | utility: 0.17363\n",
      "  batch 005 / 029 | loss: 0.71942 | error: 0.33437 | utility: 0.12407\n",
      "  batch 006 / 029 | loss: 0.68450 | error: 0.30729 | utility: 0.15511\n",
      "  batch 007 / 029 | loss: 0.68387 | error: 0.30580 | utility: 0.12138\n",
      "  batch 008 / 029 | loss: 0.67903 | error: 0.30273 | utility: 0.22405\n",
      "  batch 009 / 029 | loss: 0.69031 | error: 0.31076 | utility: 0.35730\n",
      "  batch 010 / 029 | loss: 0.68852 | error: 0.31562 | utility: 0.19882\n",
      "  batch 011 / 029 | loss: 0.69570 | error: 0.32386 | utility: 0.39145\n",
      "  batch 012 / 029 | loss: 0.68978 | error: 0.32292 | utility: 0.17175\n",
      "  batch 013 / 029 | loss: 0.68604 | error: 0.32091 | utility: 0.27370\n",
      "  batch 014 / 029 | loss: 0.69431 | error: 0.32366 | utility: 0.07718\n",
      "  batch 015 / 029 | loss: 0.69703 | error: 0.32708 | utility: 0.23191\n",
      "  batch 016 / 029 | loss: 0.70108 | error: 0.33105 | utility: 0.22201\n",
      "  batch 017 / 029 | loss: 0.70102 | error: 0.32996 | utility: 0.30243\n",
      "  batch 018 / 029 | loss: 0.69824 | error: 0.32639 | utility: 0.18066\n",
      "  batch 019 / 029 | loss: 0.69917 | error: 0.32566 | utility: 0.11702\n",
      "  batch 020 / 029 | loss: 0.69295 | error: 0.32422 | utility: 0.13642\n",
      "  batch 021 / 029 | loss: 0.69176 | error: 0.32440 | utility: 0.18112\n",
      "  batch 022 / 029 | loss: 0.69190 | error: 0.32173 | utility: 0.18601\n",
      "  batch 023 / 029 | loss: 0.68621 | error: 0.31929 | utility: 0.16964\n",
      "  batch 024 / 029 | loss: 0.69034 | error: 0.32096 | utility: 0.24715\n",
      "  batch 025 / 029 | loss: 0.68883 | error: 0.32062 | utility: 0.15269\n",
      "  batch 026 / 029 | loss: 0.69292 | error: 0.32512 | utility: 0.28251\n",
      "  batch 027 / 029 | loss: 0.69215 | error: 0.32581 | utility: 0.25547\n",
      "  batch 028 / 029 | loss: 0.69136 | error: 0.32589 | utility: 0.09958\n",
      "  batch 029 / 029 | loss: 0.68289 | error: 0.31897 | utility: -0.06343\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 005 / 010 | time: 049 sec | loss: 0.76857 | error: 0.32604 | utility: 0.10533\n",
      "Starting epoch 006 / 010.\n",
      "  batch 001 / 029 | loss: 0.55955 | error: 0.26562 | utility: 0.21864\n",
      "  batch 002 / 029 | loss: 0.65731 | error: 0.31250 | utility: -0.06692\n",
      "  batch 003 / 029 | loss: 0.67467 | error: 0.32812 | utility: 0.27850\n",
      "  batch 004 / 029 | loss: 0.73287 | error: 0.34766 | utility: 0.10073\n",
      "  batch 005 / 029 | loss: 0.69708 | error: 0.32812 | utility: 0.09208\n",
      "  batch 006 / 029 | loss: 0.68819 | error: 0.31250 | utility: -0.05731\n",
      "  batch 007 / 029 | loss: 0.68331 | error: 0.30134 | utility: 0.13584\n",
      "  batch 008 / 029 | loss: 0.68652 | error: 0.30664 | utility: 0.23432\n",
      "  batch 009 / 029 | loss: 0.67756 | error: 0.30556 | utility: 0.23133\n",
      "  batch 010 / 029 | loss: 0.67363 | error: 0.31250 | utility: 0.38084\n",
      "  batch 011 / 029 | loss: 0.69047 | error: 0.32244 | utility: 0.33615\n",
      "  batch 012 / 029 | loss: 0.68197 | error: 0.31641 | utility: 0.19837\n",
      "  batch 013 / 029 | loss: 0.68545 | error: 0.31611 | utility: 0.17678\n",
      "  batch 014 / 029 | loss: 0.68557 | error: 0.31696 | utility: 0.27851\n",
      "  batch 015 / 029 | loss: 0.67322 | error: 0.31250 | utility: 0.21123\n",
      "  batch 016 / 029 | loss: 0.68804 | error: 0.32031 | utility: -0.02396\n",
      "  batch 017 / 029 | loss: 0.69206 | error: 0.32261 | utility: 0.07173\n",
      "  batch 018 / 029 | loss: 0.68594 | error: 0.31944 | utility: 0.20971\n",
      "  batch 019 / 029 | loss: 0.69098 | error: 0.31990 | utility: -0.01913\n",
      "  batch 020 / 029 | loss: 0.69706 | error: 0.32344 | utility: 0.13200\n",
      "  batch 021 / 029 | loss: 0.68979 | error: 0.31994 | utility: 0.35578\n",
      "  batch 022 / 029 | loss: 0.68707 | error: 0.31747 | utility: 0.22141\n",
      "  batch 023 / 029 | loss: 0.68555 | error: 0.31658 | utility: 0.34587\n",
      "  batch 024 / 029 | loss: 0.68348 | error: 0.31315 | utility: 0.11144\n",
      "  batch 025 / 029 | loss: 0.68700 | error: 0.31625 | utility: 0.21506\n",
      "  batch 026 / 029 | loss: 0.68577 | error: 0.31550 | utility: 0.32750\n",
      "  batch 027 / 029 | loss: 0.68800 | error: 0.31655 | utility: 0.23254\n",
      "  batch 028 / 029 | loss: 0.69207 | error: 0.31864 | utility: 0.12471\n",
      "  batch 029 / 029 | loss: 0.71462 | error: 0.32489 | utility: -0.09317\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 006 / 010 | time: 054 sec | loss: 0.74433 | error: 0.31615 | utility: 0.14725\n",
      "Validation accuracy improved.\n",
      "Saving model to ./Results/utility/utility_0.200_model.pt.\n",
      "Starting epoch 007 / 010.\n",
      "  batch 001 / 029 | loss: 0.85088 | error: 0.43750 | utility: 0.25702\n",
      "  batch 002 / 029 | loss: 0.83697 | error: 0.42969 | utility: 0.27691\n",
      "  batch 003 / 029 | loss: 0.84546 | error: 0.42188 | utility: 0.32000\n",
      "  batch 004 / 029 | loss: 0.78794 | error: 0.38281 | utility: 0.17601\n",
      "  batch 005 / 029 | loss: 0.73568 | error: 0.36250 | utility: 0.31056\n",
      "  batch 006 / 029 | loss: 0.71897 | error: 0.34115 | utility: 0.05562\n",
      "  batch 007 / 029 | loss: 0.71530 | error: 0.33482 | utility: 0.27818\n",
      "  batch 008 / 029 | loss: 0.70647 | error: 0.33203 | utility: 0.15844\n",
      "  batch 009 / 029 | loss: 0.70794 | error: 0.32465 | utility: 0.06695\n",
      "  batch 010 / 029 | loss: 0.70365 | error: 0.31719 | utility: 0.20686\n",
      "  batch 011 / 029 | loss: 0.71262 | error: 0.31960 | utility: 0.21207\n",
      "  batch 012 / 029 | loss: 0.70427 | error: 0.31641 | utility: 0.05597\n",
      "  batch 013 / 029 | loss: 0.69500 | error: 0.31130 | utility: 0.21994\n",
      "  batch 014 / 029 | loss: 0.69728 | error: 0.31473 | utility: 0.22889\n",
      "  batch 015 / 029 | loss: 0.69167 | error: 0.31354 | utility: 0.16814\n",
      "  batch 016 / 029 | loss: 0.68584 | error: 0.30762 | utility: 0.08352\n",
      "  batch 017 / 029 | loss: 0.68178 | error: 0.30790 | utility: 0.24090\n",
      "  batch 018 / 029 | loss: 0.68661 | error: 0.31076 | utility: 0.17879\n",
      "  batch 019 / 029 | loss: 0.69108 | error: 0.31497 | utility: 0.16639\n",
      "  batch 020 / 029 | loss: 0.69647 | error: 0.31797 | utility: 0.26459\n",
      "  batch 021 / 029 | loss: 0.69780 | error: 0.31994 | utility: 0.15529\n",
      "  batch 022 / 029 | loss: 0.69916 | error: 0.32173 | utility: 0.24139\n",
      "  batch 023 / 029 | loss: 0.70005 | error: 0.32133 | utility: 0.22341\n",
      "  batch 024 / 029 | loss: 0.70166 | error: 0.32096 | utility: 0.19498\n",
      "  batch 025 / 029 | loss: 0.70285 | error: 0.32125 | utility: 0.14319\n",
      "  batch 026 / 029 | loss: 0.69591 | error: 0.31911 | utility: 0.01695\n",
      "  batch 027 / 029 | loss: 0.69482 | error: 0.31829 | utility: 0.24494\n",
      "  batch 028 / 029 | loss: 0.69592 | error: 0.32087 | utility: 0.17411\n",
      "  batch 029 / 029 | loss: 0.70158 | error: 0.31843 | utility: -0.04147\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 007 / 010 | time: 048 sec | loss: 0.78575 | error: 0.33021 | utility: 0.08765\n",
      "Starting epoch 008 / 010.\n",
      "  batch 001 / 029 | loss: 0.69644 | error: 0.39062 | utility: 0.23810\n",
      "  batch 002 / 029 | loss: 0.65582 | error: 0.37500 | utility: 0.30520\n",
      "  batch 003 / 029 | loss: 0.72208 | error: 0.36458 | utility: 0.18117\n",
      "  batch 004 / 029 | loss: 0.68714 | error: 0.34375 | utility: 0.43430\n",
      "  batch 005 / 029 | loss: 0.67860 | error: 0.33437 | utility: 0.13370\n",
      "  batch 006 / 029 | loss: 0.70147 | error: 0.34375 | utility: 0.09117\n",
      "  batch 007 / 029 | loss: 0.71854 | error: 0.34821 | utility: 0.06289\n",
      "  batch 008 / 029 | loss: 0.71606 | error: 0.34375 | utility: 0.07988\n",
      "  batch 009 / 029 | loss: 0.70912 | error: 0.34201 | utility: 0.07014\n",
      "  batch 010 / 029 | loss: 0.71133 | error: 0.33906 | utility: 0.05062\n",
      "  batch 011 / 029 | loss: 0.72090 | error: 0.34091 | utility: 0.06699\n",
      "  batch 012 / 029 | loss: 0.71861 | error: 0.33724 | utility: 0.12854\n",
      "  batch 013 / 029 | loss: 0.71636 | error: 0.33774 | utility: 0.01573\n",
      "  batch 014 / 029 | loss: 0.70745 | error: 0.33259 | utility: 0.17683\n",
      "  batch 015 / 029 | loss: 0.71270 | error: 0.33333 | utility: 0.10810\n",
      "  batch 016 / 029 | loss: 0.70758 | error: 0.33203 | utility: 0.21486\n",
      "  batch 017 / 029 | loss: 0.71395 | error: 0.33640 | utility: 0.19693\n",
      "  batch 018 / 029 | loss: 0.71574 | error: 0.33941 | utility: 0.22051\n",
      "  batch 019 / 029 | loss: 0.71045 | error: 0.33717 | utility: 0.32502\n",
      "  batch 020 / 029 | loss: 0.71288 | error: 0.33906 | utility: 0.26493\n",
      "  batch 021 / 029 | loss: 0.70787 | error: 0.33557 | utility: 0.30418\n",
      "  batch 022 / 029 | loss: 0.69626 | error: 0.32884 | utility: 0.20520\n",
      "  batch 023 / 029 | loss: 0.69477 | error: 0.32745 | utility: 0.22796\n",
      "  batch 024 / 029 | loss: 0.69019 | error: 0.32422 | utility: 0.25928\n",
      "  batch 025 / 029 | loss: 0.69006 | error: 0.32438 | utility: 0.16050\n",
      "  batch 026 / 029 | loss: 0.68783 | error: 0.32272 | utility: 0.36754\n",
      "  batch 027 / 029 | loss: 0.68957 | error: 0.32292 | utility: 0.04858\n",
      "  batch 028 / 029 | loss: 0.69193 | error: 0.32366 | utility: 0.19332\n",
      "  batch 029 / 029 | loss: 0.70139 | error: 0.32543 | utility: -0.22185\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 008 / 010 | time: 051 sec | loss: 0.75818 | error: 0.32344 | utility: 0.10019\n",
      "Starting epoch 009 / 010.\n",
      "  batch 001 / 029 | loss: 0.60326 | error: 0.31250 | utility: 0.31183\n",
      "  batch 002 / 029 | loss: 0.62624 | error: 0.28906 | utility: 0.04276\n",
      "  batch 003 / 029 | loss: 0.66932 | error: 0.31250 | utility: 0.26705\n",
      "  batch 004 / 029 | loss: 0.66338 | error: 0.31250 | utility: 0.17557\n",
      "  batch 005 / 029 | loss: 0.68518 | error: 0.31875 | utility: 0.00280\n",
      "  batch 006 / 029 | loss: 0.66098 | error: 0.30469 | utility: 0.13139\n",
      "  batch 007 / 029 | loss: 0.66080 | error: 0.30134 | utility: 0.18751\n",
      "  batch 008 / 029 | loss: 0.66105 | error: 0.30078 | utility: 0.12791\n",
      "  batch 009 / 029 | loss: 0.64887 | error: 0.28993 | utility: 0.02858\n",
      "  batch 010 / 029 | loss: 0.67219 | error: 0.29844 | utility: 0.11536\n",
      "  batch 011 / 029 | loss: 0.68217 | error: 0.30682 | utility: 0.27240\n",
      "  batch 012 / 029 | loss: 0.68265 | error: 0.30729 | utility: 0.26371\n",
      "  batch 013 / 029 | loss: 0.69022 | error: 0.31130 | utility: 0.16143\n",
      "  batch 014 / 029 | loss: 0.68906 | error: 0.31027 | utility: 0.14914\n",
      "  batch 015 / 029 | loss: 0.68436 | error: 0.31146 | utility: 0.34462\n",
      "  batch 016 / 029 | loss: 0.68590 | error: 0.30957 | utility: 0.04121\n",
      "  batch 017 / 029 | loss: 0.68281 | error: 0.31250 | utility: 0.25547\n",
      "  batch 018 / 029 | loss: 0.68512 | error: 0.31250 | utility: 0.20970\n",
      "  batch 019 / 029 | loss: 0.68253 | error: 0.31086 | utility: 0.16592\n",
      "  batch 020 / 029 | loss: 0.67473 | error: 0.30938 | utility: 0.28328\n",
      "  batch 021 / 029 | loss: 0.67822 | error: 0.31176 | utility: 0.22571\n",
      "  batch 022 / 029 | loss: 0.68152 | error: 0.31250 | utility: 0.14310\n",
      "  batch 023 / 029 | loss: 0.68049 | error: 0.30910 | utility: 0.21223\n",
      "  batch 024 / 029 | loss: 0.68254 | error: 0.30859 | utility: 0.14691\n",
      "  batch 025 / 029 | loss: 0.68486 | error: 0.31125 | utility: 0.42245\n",
      "  batch 026 / 029 | loss: 0.68538 | error: 0.31070 | utility: 0.16688\n",
      "  batch 027 / 029 | loss: 0.69015 | error: 0.31481 | utility: 0.26251\n",
      "  batch 028 / 029 | loss: 0.69515 | error: 0.31808 | utility: 0.16811\n",
      "  batch 029 / 029 | loss: 0.68432 | error: 0.31573 | utility: 0.47524\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 009 / 010 | time: 050 sec | loss: 0.78034 | error: 0.32760 | utility: 0.08912\n",
      "Starting epoch 010 / 010.\n",
      "  batch 001 / 029 | loss: 0.70308 | error: 0.31250 | utility: 0.20677\n",
      "  batch 002 / 029 | loss: 0.76638 | error: 0.34375 | utility: 0.09244\n",
      "  batch 003 / 029 | loss: 0.69496 | error: 0.31250 | utility: 0.41376\n",
      "  batch 004 / 029 | loss: 0.68609 | error: 0.30859 | utility: 0.13810\n",
      "  batch 005 / 029 | loss: 0.69580 | error: 0.31250 | utility: 0.17132\n",
      "  batch 006 / 029 | loss: 0.66065 | error: 0.29427 | utility: 0.17115\n",
      "  batch 007 / 029 | loss: 0.66064 | error: 0.29688 | utility: 0.18899\n",
      "  batch 008 / 029 | loss: 0.65513 | error: 0.30078 | utility: 0.27608\n",
      "  batch 009 / 029 | loss: 0.65111 | error: 0.30903 | utility: 0.41146\n",
      "  batch 010 / 029 | loss: 0.66055 | error: 0.31250 | utility: 0.09324\n",
      "  batch 011 / 029 | loss: 0.64891 | error: 0.30966 | utility: 0.34592\n",
      "  batch 012 / 029 | loss: 0.66894 | error: 0.32031 | utility: 0.07204\n",
      "  batch 013 / 029 | loss: 0.67725 | error: 0.32332 | utility: 0.01115\n",
      "  batch 014 / 029 | loss: 0.68010 | error: 0.32254 | utility: 0.09900\n",
      "  batch 015 / 029 | loss: 0.68727 | error: 0.32604 | utility: -0.00566\n",
      "  batch 016 / 029 | loss: 0.69574 | error: 0.32617 | utility: -0.01971\n",
      "  batch 017 / 029 | loss: 0.70095 | error: 0.32904 | utility: 0.11224\n",
      "  batch 018 / 029 | loss: 0.69538 | error: 0.32639 | utility: 0.29888\n",
      "  batch 019 / 029 | loss: 0.69114 | error: 0.32566 | utility: 0.35228\n",
      "  batch 020 / 029 | loss: 0.68688 | error: 0.32500 | utility: 0.34561\n",
      "  batch 021 / 029 | loss: 0.68302 | error: 0.32589 | utility: 0.22615\n",
      "  batch 022 / 029 | loss: 0.68777 | error: 0.32670 | utility: 0.03882\n",
      "  batch 023 / 029 | loss: 0.68308 | error: 0.32065 | utility: 0.05712\n",
      "  batch 024 / 029 | loss: 0.68306 | error: 0.32292 | utility: 0.37324\n",
      "  batch 025 / 029 | loss: 0.68257 | error: 0.32312 | utility: 0.23850\n",
      "  batch 026 / 029 | loss: 0.68460 | error: 0.32332 | utility: 0.10428\n",
      "  batch 027 / 029 | loss: 0.68526 | error: 0.32292 | utility: 0.16491\n",
      "  batch 028 / 029 | loss: 0.69320 | error: 0.32701 | utility: 0.22837\n",
      "  batch 029 / 029 | loss: 0.70563 | error: 0.33297 | utility: 0.31599\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 010 / 010 | time: 043 sec | loss: 0.77702 | error: 0.32760 | utility: 0.10549\n",
      "Total training time: 8 minutes (483.9226384162903 seconds).\n",
      "Loading model from ./Results/utility/utility_0.200_model.pt.\n",
      "---------- Training with lambda=0.25 ----------\n",
      "Starting epoch 001 / 010.\n",
      "  batch 001 / 029 | loss: 0.76411 | error: 0.40625 | utility: 0.93142\n",
      "  batch 002 / 029 | loss: 0.74885 | error: 0.40625 | utility: 0.93357\n",
      "  batch 003 / 029 | loss: 0.80054 | error: 0.44792 | utility: 0.94188\n",
      "  batch 004 / 029 | loss: 0.79590 | error: 0.45312 | utility: 0.94627\n",
      "  batch 005 / 029 | loss: 0.78391 | error: 0.45312 | utility: 0.94776\n",
      "  batch 006 / 029 | loss: 0.79009 | error: 0.45833 | utility: 0.94504\n",
      "  batch 007 / 029 | loss: 0.80308 | error: 0.46875 | utility: 0.93906\n",
      "  batch 008 / 029 | loss: 0.82074 | error: 0.48047 | utility: 0.93080\n",
      "  batch 009 / 029 | loss: 0.84355 | error: 0.49653 | utility: 0.92919\n",
      "  batch 010 / 029 | loss: 0.83857 | error: 0.49531 | utility: 0.92426\n",
      "  batch 011 / 029 | loss: 0.82483 | error: 0.49006 | utility: 0.93159\n",
      "  batch 012 / 029 | loss: 0.83855 | error: 0.49740 | utility: 0.89712\n",
      "  batch 013 / 029 | loss: 0.83019 | error: 0.49399 | utility: 0.86236\n",
      "  batch 014 / 029 | loss: 0.82951 | error: 0.49665 | utility: 0.87104\n",
      "  batch 015 / 029 | loss: 0.81879 | error: 0.49062 | utility: 0.83299\n",
      "  batch 016 / 029 | loss: 0.81681 | error: 0.48828 | utility: 0.86320\n",
      "  batch 017 / 029 | loss: 0.81057 | error: 0.48805 | utility: 0.77823\n",
      "  batch 018 / 029 | loss: 0.81376 | error: 0.49306 | utility: 0.80611\n",
      "  batch 019 / 029 | loss: 0.81484 | error: 0.49589 | utility: 0.77255\n",
      "  batch 020 / 029 | loss: 0.81325 | error: 0.49688 | utility: 0.75200\n",
      "  batch 021 / 029 | loss: 0.80572 | error: 0.49256 | utility: 0.79321\n",
      "  batch 022 / 029 | loss: 0.79586 | error: 0.48366 | utility: 0.75157\n",
      "  batch 023 / 029 | loss: 0.79215 | error: 0.48098 | utility: 0.58912\n",
      "  batch 024 / 029 | loss: 0.78934 | error: 0.47591 | utility: 0.64117\n",
      "  batch 025 / 029 | loss: 0.78755 | error: 0.47250 | utility: 0.68231\n",
      "  batch 026 / 029 | loss: 0.78668 | error: 0.46995 | utility: 0.71394\n",
      "  batch 027 / 029 | loss: 0.78715 | error: 0.46817 | utility: 0.64997\n",
      "  batch 028 / 029 | loss: 0.78407 | error: 0.46540 | utility: 0.69727\n",
      "  batch 029 / 029 | loss: 0.77850 | error: 0.46659 | utility: 0.73137\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 001 / 010 | time: 032 sec | loss: 0.79114 | error: 0.44948 | utility: 0.72164\n",
      "Saving model to ./Results/utility/utility_0.250_model.pt.\n",
      "Starting epoch 002 / 010.\n",
      "  batch 001 / 029 | loss: 0.80636 | error: 0.45312 | utility: 0.59021\n",
      "  batch 002 / 029 | loss: 0.78355 | error: 0.45312 | utility: 0.63291\n",
      "  batch 003 / 029 | loss: 0.79587 | error: 0.45312 | utility: 0.62553\n",
      "  batch 004 / 029 | loss: 0.77732 | error: 0.42969 | utility: 0.63966\n",
      "  batch 005 / 029 | loss: 0.76528 | error: 0.41875 | utility: 0.57028\n",
      "  batch 006 / 029 | loss: 0.74681 | error: 0.40625 | utility: 0.58103\n",
      "  batch 007 / 029 | loss: 0.75105 | error: 0.39509 | utility: 0.32032\n",
      "  batch 008 / 029 | loss: 0.72947 | error: 0.38281 | utility: 0.62330\n",
      "  batch 009 / 029 | loss: 0.71624 | error: 0.37326 | utility: 0.49421\n",
      "  batch 010 / 029 | loss: 0.70653 | error: 0.36719 | utility: 0.49954\n",
      "  batch 011 / 029 | loss: 0.70505 | error: 0.36790 | utility: 0.61841\n",
      "  batch 012 / 029 | loss: 0.70750 | error: 0.36458 | utility: 0.36882\n",
      "  batch 013 / 029 | loss: 0.70838 | error: 0.36538 | utility: 0.35069\n",
      "  batch 014 / 029 | loss: 0.72370 | error: 0.37723 | utility: 0.46121\n",
      "  batch 015 / 029 | loss: 0.71450 | error: 0.37604 | utility: 0.60064\n",
      "  batch 016 / 029 | loss: 0.70802 | error: 0.37012 | utility: 0.43784\n",
      "  batch 017 / 029 | loss: 0.70696 | error: 0.37132 | utility: 0.49145\n",
      "  batch 018 / 029 | loss: 0.70935 | error: 0.37240 | utility: 0.54103\n",
      "  batch 019 / 029 | loss: 0.71265 | error: 0.37500 | utility: 0.36508\n",
      "  batch 020 / 029 | loss: 0.71052 | error: 0.37188 | utility: 0.40819\n",
      "  batch 021 / 029 | loss: 0.72567 | error: 0.37872 | utility: 0.38887\n",
      "  batch 022 / 029 | loss: 0.72276 | error: 0.37713 | utility: 0.35291\n",
      "  batch 023 / 029 | loss: 0.71949 | error: 0.37636 | utility: 0.51224\n",
      "  batch 024 / 029 | loss: 0.72120 | error: 0.37500 | utility: 0.36255\n",
      "  batch 025 / 029 | loss: 0.72333 | error: 0.37250 | utility: 0.26071\n",
      "  batch 026 / 029 | loss: 0.71875 | error: 0.36899 | utility: 0.27858\n",
      "  batch 027 / 029 | loss: 0.71825 | error: 0.36863 | utility: 0.35621\n",
      "  batch 028 / 029 | loss: 0.71836 | error: 0.36942 | utility: 0.41849\n",
      "  batch 029 / 029 | loss: 0.71224 | error: 0.36530 | utility: 0.29463\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 002 / 010 | time: 034 sec | loss: 0.72668 | error: 0.33333 | utility: 0.36190\n",
      "Validation accuracy improved.\n",
      "Saving model to ./Results/utility/utility_0.250_model.pt.\n",
      "Starting epoch 003 / 010.\n",
      "  batch 001 / 029 | loss: 0.83450 | error: 0.40625 | utility: 0.25472\n",
      "  batch 002 / 029 | loss: 0.74718 | error: 0.36719 | utility: 0.13005\n",
      "  batch 003 / 029 | loss: 0.69048 | error: 0.33854 | utility: 0.32375\n",
      "  batch 004 / 029 | loss: 0.69997 | error: 0.34375 | utility: 0.36835\n",
      "  batch 005 / 029 | loss: 0.69021 | error: 0.34063 | utility: 0.30577\n",
      "  batch 006 / 029 | loss: 0.70534 | error: 0.34635 | utility: 0.21513\n",
      "  batch 007 / 029 | loss: 0.68141 | error: 0.33259 | utility: 0.39195\n",
      "  batch 008 / 029 | loss: 0.70284 | error: 0.34766 | utility: 0.37147\n",
      "  batch 009 / 029 | loss: 0.68020 | error: 0.32986 | utility: 0.15930\n",
      "  batch 010 / 029 | loss: 0.68044 | error: 0.32969 | utility: 0.29473\n",
      "  batch 011 / 029 | loss: 0.68559 | error: 0.33523 | utility: 0.27971\n",
      "  batch 012 / 029 | loss: 0.69307 | error: 0.33464 | utility: 0.07103\n",
      "  batch 013 / 029 | loss: 0.69179 | error: 0.33293 | utility: 0.07427\n",
      "  batch 014 / 029 | loss: 0.68335 | error: 0.32924 | utility: 0.36473\n",
      "  batch 015 / 029 | loss: 0.68850 | error: 0.32917 | utility: 0.20768\n",
      "  batch 016 / 029 | loss: 0.69514 | error: 0.33496 | utility: 0.20096\n",
      "  batch 017 / 029 | loss: 0.69654 | error: 0.33456 | utility: 0.35631\n",
      "  batch 018 / 029 | loss: 0.70334 | error: 0.33767 | utility: 0.07518\n",
      "  batch 019 / 029 | loss: 0.71365 | error: 0.34046 | utility: 0.28287\n",
      "  batch 020 / 029 | loss: 0.71419 | error: 0.34063 | utility: 0.43366\n",
      "  batch 021 / 029 | loss: 0.70793 | error: 0.33482 | utility: 0.17095\n",
      "  batch 022 / 029 | loss: 0.70751 | error: 0.33523 | utility: 0.21715\n",
      "  batch 023 / 029 | loss: 0.70447 | error: 0.33628 | utility: 0.38178\n",
      "  batch 024 / 029 | loss: 0.70700 | error: 0.33854 | utility: 0.24398\n",
      "  batch 025 / 029 | loss: 0.70567 | error: 0.33750 | utility: 0.21766\n",
      "  batch 026 / 029 | loss: 0.70538 | error: 0.33774 | utility: 0.29842\n",
      "  batch 027 / 029 | loss: 0.70088 | error: 0.33391 | utility: 0.19381\n",
      "  batch 028 / 029 | loss: 0.69331 | error: 0.32980 | utility: 0.20002\n",
      "  batch 029 / 029 | loss: 0.67966 | error: 0.32274 | utility: 0.24275\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 003 / 010 | time: 036 sec | loss: 0.75430 | error: 0.32917 | utility: 0.14400\n",
      "Validation accuracy improved.\n",
      "Saving model to ./Results/utility/utility_0.250_model.pt.\n",
      "Starting epoch 004 / 010.\n",
      "  batch 001 / 029 | loss: 0.72968 | error: 0.34375 | utility: 0.22465\n",
      "  batch 002 / 029 | loss: 0.76315 | error: 0.36719 | utility: 0.22767\n",
      "  batch 003 / 029 | loss: 0.68049 | error: 0.31771 | utility: 0.20298\n",
      "  batch 004 / 029 | loss: 0.65012 | error: 0.30078 | utility: 0.40514\n",
      "  batch 005 / 029 | loss: 0.67411 | error: 0.31562 | utility: 0.28924\n",
      "  batch 006 / 029 | loss: 0.66587 | error: 0.31250 | utility: 0.17977\n",
      "  batch 007 / 029 | loss: 0.65907 | error: 0.31027 | utility: 0.27802\n",
      "  batch 008 / 029 | loss: 0.66366 | error: 0.30664 | utility: 0.24860\n",
      "  batch 009 / 029 | loss: 0.69628 | error: 0.32986 | utility: 0.24395\n",
      "  batch 010 / 029 | loss: 0.67303 | error: 0.31562 | utility: 0.28527\n",
      "  batch 011 / 029 | loss: 0.68391 | error: 0.31676 | utility: 0.07579\n",
      "  batch 012 / 029 | loss: 0.69383 | error: 0.32812 | utility: 0.21642\n",
      "  batch 013 / 029 | loss: 0.67460 | error: 0.31731 | utility: 0.24345\n",
      "  batch 014 / 029 | loss: 0.67148 | error: 0.31696 | utility: 0.27539\n",
      "  batch 015 / 029 | loss: 0.66977 | error: 0.31979 | utility: 0.30876\n",
      "  batch 016 / 029 | loss: 0.68172 | error: 0.32715 | utility: 0.34189\n",
      "  batch 017 / 029 | loss: 0.68475 | error: 0.32904 | utility: 0.25663\n",
      "  batch 018 / 029 | loss: 0.68313 | error: 0.32899 | utility: 0.25120\n",
      "  batch 019 / 029 | loss: 0.68524 | error: 0.32895 | utility: 0.23692\n",
      "  batch 020 / 029 | loss: 0.68930 | error: 0.33047 | utility: 0.18277\n",
      "  batch 021 / 029 | loss: 0.68641 | error: 0.33185 | utility: 0.30451\n",
      "  batch 022 / 029 | loss: 0.69053 | error: 0.33381 | utility: 0.31142\n",
      "  batch 023 / 029 | loss: 0.69425 | error: 0.33696 | utility: 0.22322\n",
      "  batch 024 / 029 | loss: 0.69688 | error: 0.33659 | utility: 0.17864\n",
      "  batch 025 / 029 | loss: 0.69437 | error: 0.33500 | utility: 0.25943\n",
      "  batch 026 / 029 | loss: 0.69129 | error: 0.33534 | utility: 0.30836\n",
      "  batch 027 / 029 | loss: 0.69039 | error: 0.33391 | utility: 0.09575\n",
      "  batch 028 / 029 | loss: 0.68930 | error: 0.33259 | utility: 0.07437\n",
      "  batch 029 / 029 | loss: 0.68929 | error: 0.33405 | utility: -0.05459\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 004 / 010 | time: 037 sec | loss: 0.78366 | error: 0.33542 | utility: 0.10075\n",
      "Starting epoch 005 / 010.\n",
      "  batch 001 / 029 | loss: 0.80765 | error: 0.40625 | utility: 0.09445\n",
      "  batch 002 / 029 | loss: 0.77822 | error: 0.35938 | utility: 0.14047\n",
      "  batch 003 / 029 | loss: 0.74036 | error: 0.33854 | utility: 0.16467\n",
      "  batch 004 / 029 | loss: 0.73648 | error: 0.34375 | utility: 0.21334\n",
      "  batch 005 / 029 | loss: 0.72115 | error: 0.34375 | utility: 0.15378\n",
      "  batch 006 / 029 | loss: 0.68568 | error: 0.31771 | utility: 0.19750\n",
      "  batch 007 / 029 | loss: 0.68545 | error: 0.31696 | utility: 0.14888\n",
      "  batch 008 / 029 | loss: 0.68021 | error: 0.31445 | utility: 0.26567\n",
      "  batch 009 / 029 | loss: 0.69032 | error: 0.32292 | utility: 0.38113\n",
      "  batch 010 / 029 | loss: 0.68879 | error: 0.32656 | utility: 0.24394\n",
      "  batch 011 / 029 | loss: 0.69520 | error: 0.33381 | utility: 0.42749\n",
      "  batch 012 / 029 | loss: 0.68931 | error: 0.33073 | utility: 0.21844\n",
      "  batch 013 / 029 | loss: 0.68491 | error: 0.32933 | utility: 0.31839\n",
      "  batch 014 / 029 | loss: 0.69388 | error: 0.33259 | utility: 0.10927\n",
      "  batch 015 / 029 | loss: 0.69580 | error: 0.33333 | utility: 0.27075\n",
      "  batch 016 / 029 | loss: 0.69907 | error: 0.33594 | utility: 0.25378\n",
      "  batch 017 / 029 | loss: 0.69842 | error: 0.33640 | utility: 0.34041\n",
      "  batch 018 / 029 | loss: 0.69591 | error: 0.33333 | utility: 0.20944\n",
      "  batch 019 / 029 | loss: 0.69707 | error: 0.33306 | utility: 0.16355\n",
      "  batch 020 / 029 | loss: 0.69119 | error: 0.33125 | utility: 0.18037\n",
      "  batch 021 / 029 | loss: 0.69011 | error: 0.33185 | utility: 0.22128\n",
      "  batch 022 / 029 | loss: 0.69012 | error: 0.33026 | utility: 0.21864\n",
      "  batch 023 / 029 | loss: 0.68434 | error: 0.32880 | utility: 0.19548\n",
      "  batch 024 / 029 | loss: 0.68843 | error: 0.33073 | utility: 0.29619\n",
      "  batch 025 / 029 | loss: 0.68705 | error: 0.33125 | utility: 0.19299\n",
      "  batch 026 / 029 | loss: 0.69106 | error: 0.33534 | utility: 0.30524\n",
      "  batch 027 / 029 | loss: 0.69022 | error: 0.33565 | utility: 0.28371\n",
      "  batch 028 / 029 | loss: 0.68963 | error: 0.33482 | utility: 0.14440\n",
      "  batch 029 / 029 | loss: 0.68205 | error: 0.33190 | utility: -0.04951\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 005 / 010 | time: 037 sec | loss: 0.76096 | error: 0.32604 | utility: 0.11752\n",
      "Validation accuracy improved.\n",
      "Saving model to ./Results/utility/utility_0.250_model.pt.\n",
      "Starting epoch 006 / 010.\n",
      "  batch 001 / 029 | loss: 0.55990 | error: 0.28125 | utility: 0.23279\n",
      "  batch 002 / 029 | loss: 0.65963 | error: 0.32031 | utility: -0.03724\n",
      "  batch 003 / 029 | loss: 0.67500 | error: 0.33333 | utility: 0.30458\n",
      "  batch 004 / 029 | loss: 0.73321 | error: 0.35547 | utility: 0.12544\n",
      "  batch 005 / 029 | loss: 0.69766 | error: 0.33437 | utility: 0.10098\n",
      "  batch 006 / 029 | loss: 0.68904 | error: 0.32031 | utility: -0.04739\n",
      "  batch 007 / 029 | loss: 0.68261 | error: 0.30804 | utility: 0.15291\n",
      "  batch 008 / 029 | loss: 0.68467 | error: 0.31250 | utility: 0.25267\n",
      "  batch 009 / 029 | loss: 0.67520 | error: 0.31076 | utility: 0.25659\n",
      "  batch 010 / 029 | loss: 0.67111 | error: 0.31719 | utility: 0.41730\n",
      "  batch 011 / 029 | loss: 0.68798 | error: 0.33097 | utility: 0.37839\n",
      "  batch 012 / 029 | loss: 0.67951 | error: 0.32552 | utility: 0.23523\n",
      "  batch 013 / 029 | loss: 0.68340 | error: 0.32692 | utility: 0.21311\n",
      "  batch 014 / 029 | loss: 0.68408 | error: 0.32924 | utility: 0.33125\n",
      "  batch 015 / 029 | loss: 0.67214 | error: 0.32396 | utility: 0.23095\n",
      "  batch 016 / 029 | loss: 0.68724 | error: 0.33008 | utility: 0.02573\n",
      "  batch 017 / 029 | loss: 0.69132 | error: 0.33272 | utility: 0.11783\n",
      "  batch 018 / 029 | loss: 0.68553 | error: 0.32899 | utility: 0.23696\n",
      "  batch 019 / 029 | loss: 0.69081 | error: 0.32895 | utility: 0.00473\n",
      "  batch 020 / 029 | loss: 0.69698 | error: 0.33047 | utility: 0.15770\n",
      "  batch 021 / 029 | loss: 0.68954 | error: 0.32664 | utility: 0.37147\n",
      "  batch 022 / 029 | loss: 0.68674 | error: 0.32386 | utility: 0.24677\n",
      "  batch 023 / 029 | loss: 0.68499 | error: 0.32269 | utility: 0.37438\n",
      "  batch 024 / 029 | loss: 0.68311 | error: 0.31966 | utility: 0.15459\n",
      "  batch 025 / 029 | loss: 0.68617 | error: 0.32188 | utility: 0.25742\n",
      "  batch 026 / 029 | loss: 0.68441 | error: 0.32091 | utility: 0.35119\n",
      "  batch 027 / 029 | loss: 0.68656 | error: 0.32176 | utility: 0.27508\n",
      "  batch 028 / 029 | loss: 0.69077 | error: 0.32422 | utility: 0.16726\n",
      "  batch 029 / 029 | loss: 0.71252 | error: 0.33459 | utility: 0.02679\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 006 / 010 | time: 042 sec | loss: 0.72501 | error: 0.32083 | utility: 0.24409\n",
      "Validation accuracy improved.\n",
      "Saving model to ./Results/utility/utility_0.250_model.pt.\n",
      "Starting epoch 007 / 010.\n",
      "  batch 001 / 029 | loss: 0.85340 | error: 0.45312 | utility: 0.29568\n",
      "  batch 002 / 029 | loss: 0.84490 | error: 0.44531 | utility: 0.32705\n",
      "  batch 003 / 029 | loss: 0.85343 | error: 0.43229 | utility: 0.37547\n",
      "  batch 004 / 029 | loss: 0.79496 | error: 0.39062 | utility: 0.23001\n",
      "  batch 005 / 029 | loss: 0.74063 | error: 0.36562 | utility: 0.36261\n",
      "  batch 006 / 029 | loss: 0.72329 | error: 0.34635 | utility: 0.12219\n",
      "  batch 007 / 029 | loss: 0.71661 | error: 0.34152 | utility: 0.34759\n",
      "  batch 008 / 029 | loss: 0.70870 | error: 0.33789 | utility: 0.21656\n",
      "  batch 009 / 029 | loss: 0.70980 | error: 0.33160 | utility: 0.13228\n",
      "  batch 010 / 029 | loss: 0.70491 | error: 0.32500 | utility: 0.26243\n",
      "  batch 011 / 029 | loss: 0.71335 | error: 0.32955 | utility: 0.27381\n",
      "  batch 012 / 029 | loss: 0.70471 | error: 0.32682 | utility: 0.09135\n",
      "  batch 013 / 029 | loss: 0.69467 | error: 0.32091 | utility: 0.24827\n",
      "  batch 014 / 029 | loss: 0.69610 | error: 0.32366 | utility: 0.27189\n",
      "  batch 015 / 029 | loss: 0.69076 | error: 0.32188 | utility: 0.20107\n",
      "  batch 016 / 029 | loss: 0.68531 | error: 0.31641 | utility: 0.11895\n",
      "  batch 017 / 029 | loss: 0.68105 | error: 0.31618 | utility: 0.28651\n",
      "  batch 018 / 029 | loss: 0.68564 | error: 0.31858 | utility: 0.24022\n",
      "  batch 019 / 029 | loss: 0.69060 | error: 0.32237 | utility: 0.21250\n",
      "  batch 020 / 029 | loss: 0.69613 | error: 0.32422 | utility: 0.31643\n",
      "  batch 021 / 029 | loss: 0.69815 | error: 0.32664 | utility: 0.22628\n",
      "  batch 022 / 029 | loss: 0.69943 | error: 0.32741 | utility: 0.30114\n",
      "  batch 023 / 029 | loss: 0.70046 | error: 0.32812 | utility: 0.27794\n",
      "  batch 024 / 029 | loss: 0.70218 | error: 0.32943 | utility: 0.30385\n",
      "  batch 025 / 029 | loss: 0.70300 | error: 0.33000 | utility: 0.20711\n",
      "  batch 026 / 029 | loss: 0.69577 | error: 0.32692 | utility: 0.09101\n",
      "  batch 027 / 029 | loss: 0.69437 | error: 0.32639 | utility: 0.32712\n",
      "  batch 028 / 029 | loss: 0.69559 | error: 0.32812 | utility: 0.22680\n",
      "  batch 029 / 029 | loss: 0.70164 | error: 0.32543 | utility: 0.00002\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 007 / 010 | time: 046 sec | loss: 0.76312 | error: 0.32240 | utility: 0.15426\n",
      "Starting epoch 008 / 010.\n",
      "  batch 001 / 029 | loss: 0.69715 | error: 0.39062 | utility: 0.29133\n",
      "  batch 002 / 029 | loss: 0.65518 | error: 0.37500 | utility: 0.34824\n",
      "  batch 003 / 029 | loss: 0.71987 | error: 0.38021 | utility: 0.22822\n",
      "  batch 004 / 029 | loss: 0.68137 | error: 0.35547 | utility: 0.48118\n",
      "  batch 005 / 029 | loss: 0.67458 | error: 0.34375 | utility: 0.16334\n",
      "  batch 006 / 029 | loss: 0.69871 | error: 0.35677 | utility: 0.13638\n",
      "  batch 007 / 029 | loss: 0.71616 | error: 0.35938 | utility: 0.11834\n",
      "  batch 008 / 029 | loss: 0.71446 | error: 0.35352 | utility: 0.13217\n",
      "  batch 009 / 029 | loss: 0.70776 | error: 0.35069 | utility: 0.12007\n",
      "  batch 010 / 029 | loss: 0.70939 | error: 0.34844 | utility: 0.10145\n",
      "  batch 011 / 029 | loss: 0.71965 | error: 0.34943 | utility: 0.12063\n",
      "  batch 012 / 029 | loss: 0.71757 | error: 0.34635 | utility: 0.19197\n",
      "  batch 013 / 029 | loss: 0.71401 | error: 0.34255 | utility: 0.10124\n",
      "  batch 014 / 029 | loss: 0.70471 | error: 0.33594 | utility: 0.25572\n",
      "  batch 015 / 029 | loss: 0.70961 | error: 0.34063 | utility: 0.19497\n",
      "  batch 016 / 029 | loss: 0.70480 | error: 0.33789 | utility: 0.26240\n",
      "  batch 017 / 029 | loss: 0.71208 | error: 0.34375 | utility: 0.26318\n",
      "  batch 018 / 029 | loss: 0.71455 | error: 0.34635 | utility: 0.25255\n",
      "  batch 019 / 029 | loss: 0.70911 | error: 0.34293 | utility: 0.35084\n",
      "  batch 020 / 029 | loss: 0.71115 | error: 0.34531 | utility: 0.29964\n",
      "  batch 021 / 029 | loss: 0.70604 | error: 0.34152 | utility: 0.32730\n",
      "  batch 022 / 029 | loss: 0.69436 | error: 0.33523 | utility: 0.22690\n",
      "  batch 023 / 029 | loss: 0.69278 | error: 0.33288 | utility: 0.27101\n",
      "  batch 024 / 029 | loss: 0.68803 | error: 0.33073 | utility: 0.29222\n",
      "  batch 025 / 029 | loss: 0.68777 | error: 0.33125 | utility: 0.20438\n",
      "  batch 026 / 029 | loss: 0.68539 | error: 0.33053 | utility: 0.40426\n",
      "  batch 027 / 029 | loss: 0.68746 | error: 0.33044 | utility: 0.08783\n",
      "  batch 028 / 029 | loss: 0.69007 | error: 0.33147 | utility: 0.24920\n",
      "  batch 029 / 029 | loss: 0.69995 | error: 0.33297 | utility: -0.13730\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 008 / 010 | time: 042 sec | loss: 0.73716 | error: 0.31562 | utility: 0.19455\n",
      "Validation accuracy improved.\n",
      "Saving model to ./Results/utility/utility_0.250_model.pt.\n",
      "Starting epoch 009 / 010.\n",
      "  batch 001 / 029 | loss: 0.60300 | error: 0.32812 | utility: 0.34037\n",
      "  batch 002 / 029 | loss: 0.63376 | error: 0.32812 | utility: 0.11025\n",
      "  batch 003 / 029 | loss: 0.67172 | error: 0.34896 | utility: 0.32256\n",
      "  batch 004 / 029 | loss: 0.66111 | error: 0.34375 | utility: 0.25018\n",
      "  batch 005 / 029 | loss: 0.68685 | error: 0.35000 | utility: 0.05858\n",
      "  batch 006 / 029 | loss: 0.66166 | error: 0.33333 | utility: 0.20040\n",
      "  batch 007 / 029 | loss: 0.66028 | error: 0.32366 | utility: 0.24800\n",
      "  batch 008 / 029 | loss: 0.66135 | error: 0.33008 | utility: 0.19760\n",
      "  batch 009 / 029 | loss: 0.64914 | error: 0.31944 | utility: 0.07349\n",
      "  batch 010 / 029 | loss: 0.67228 | error: 0.32656 | utility: 0.18325\n",
      "  batch 011 / 029 | loss: 0.68148 | error: 0.33239 | utility: 0.30838\n",
      "  batch 012 / 029 | loss: 0.68183 | error: 0.33464 | utility: 0.31808\n",
      "  batch 013 / 029 | loss: 0.68881 | error: 0.33654 | utility: 0.21376\n",
      "  batch 014 / 029 | loss: 0.68740 | error: 0.33371 | utility: 0.18480\n",
      "  batch 015 / 029 | loss: 0.68223 | error: 0.33333 | utility: 0.38574\n",
      "  batch 016 / 029 | loss: 0.68412 | error: 0.33203 | utility: 0.08657\n",
      "  batch 017 / 029 | loss: 0.68179 | error: 0.33456 | utility: 0.30852\n",
      "  batch 018 / 029 | loss: 0.68466 | error: 0.33594 | utility: 0.26893\n",
      "  batch 019 / 029 | loss: 0.68246 | error: 0.33388 | utility: 0.21822\n",
      "  batch 020 / 029 | loss: 0.67443 | error: 0.33047 | utility: 0.31734\n",
      "  batch 021 / 029 | loss: 0.67720 | error: 0.33185 | utility: 0.28018\n",
      "  batch 022 / 029 | loss: 0.68045 | error: 0.33239 | utility: 0.18091\n",
      "  batch 023 / 029 | loss: 0.67928 | error: 0.33084 | utility: 0.26577\n",
      "  batch 024 / 029 | loss: 0.68096 | error: 0.33008 | utility: 0.18929\n",
      "  batch 025 / 029 | loss: 0.68304 | error: 0.33250 | utility: 0.46163\n",
      "  batch 026 / 029 | loss: 0.68351 | error: 0.33173 | utility: 0.20678\n",
      "  batch 027 / 029 | loss: 0.68825 | error: 0.33623 | utility: 0.29761\n",
      "  batch 028 / 029 | loss: 0.69343 | error: 0.33929 | utility: 0.21416\n",
      "  batch 029 / 029 | loss: 0.68259 | error: 0.33621 | utility: 0.50375\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 009 / 010 | time: 041 sec | loss: 0.75431 | error: 0.31510 | utility: 0.15144\n",
      "Validation accuracy improved.\n",
      "Saving model to ./Results/utility/utility_0.250_model.pt.\n",
      "Starting epoch 010 / 010.\n",
      "  batch 001 / 029 | loss: 0.69557 | error: 0.34375 | utility: 0.26289\n",
      "  batch 002 / 029 | loss: 0.76111 | error: 0.35156 | utility: 0.16682\n",
      "  batch 003 / 029 | loss: 0.68251 | error: 0.31771 | utility: 0.47324\n",
      "  batch 004 / 029 | loss: 0.67782 | error: 0.32031 | utility: 0.20844\n",
      "  batch 005 / 029 | loss: 0.69021 | error: 0.32500 | utility: 0.22845\n",
      "  batch 006 / 029 | loss: 0.65713 | error: 0.30729 | utility: 0.19916\n",
      "  batch 007 / 029 | loss: 0.65768 | error: 0.31027 | utility: 0.22796\n",
      "  batch 008 / 029 | loss: 0.65195 | error: 0.31445 | utility: 0.30993\n",
      "  batch 009 / 029 | loss: 0.64809 | error: 0.32118 | utility: 0.44699\n",
      "  batch 010 / 029 | loss: 0.65783 | error: 0.32500 | utility: 0.13822\n",
      "  batch 011 / 029 | loss: 0.64532 | error: 0.31818 | utility: 0.38376\n",
      "  batch 012 / 029 | loss: 0.66591 | error: 0.32682 | utility: 0.12165\n",
      "  batch 013 / 029 | loss: 0.67450 | error: 0.33053 | utility: 0.05896\n",
      "  batch 014 / 029 | loss: 0.67729 | error: 0.32812 | utility: 0.16761\n",
      "  batch 015 / 029 | loss: 0.68425 | error: 0.33229 | utility: 0.04709\n",
      "  batch 016 / 029 | loss: 0.69355 | error: 0.33496 | utility: 0.07476\n",
      "  batch 017 / 029 | loss: 0.69981 | error: 0.33640 | utility: 0.17520\n",
      "  batch 018 / 029 | loss: 0.69446 | error: 0.33420 | utility: 0.34769\n",
      "  batch 019 / 029 | loss: 0.68995 | error: 0.33306 | utility: 0.39484\n",
      "  batch 020 / 029 | loss: 0.68552 | error: 0.33281 | utility: 0.39351\n",
      "  batch 021 / 029 | loss: 0.68214 | error: 0.33333 | utility: 0.28600\n",
      "  batch 022 / 029 | loss: 0.68703 | error: 0.33452 | utility: 0.09100\n",
      "  batch 023 / 029 | loss: 0.68243 | error: 0.32880 | utility: 0.10955\n",
      "  batch 024 / 029 | loss: 0.68206 | error: 0.33073 | utility: 0.40176\n",
      "  batch 025 / 029 | loss: 0.68138 | error: 0.33000 | utility: 0.28214\n",
      "  batch 026 / 029 | loss: 0.68305 | error: 0.32993 | utility: 0.16071\n",
      "  batch 027 / 029 | loss: 0.68363 | error: 0.32986 | utility: 0.18771\n",
      "  batch 028 / 029 | loss: 0.69131 | error: 0.33482 | utility: 0.28202\n",
      "  batch 029 / 029 | loss: 0.70456 | error: 0.34052 | utility: 0.34365\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 010 / 010 | time: 039 sec | loss: 0.75498 | error: 0.32135 | utility: 0.12944\n",
      "Total training time: 6 minutes (384.14601826667786 seconds).\n",
      "Loading model from ./Results/utility/utility_0.250_model.pt.\n",
      "---------- Training with lambda=0.3 ----------\n",
      "Starting epoch 001 / 010.\n",
      "  batch 001 / 029 | loss: 0.74205 | error: 0.40625 | utility: 0.93142\n",
      "  batch 002 / 029 | loss: 0.72589 | error: 0.40625 | utility: 0.93357\n",
      "  batch 003 / 029 | loss: 0.77662 | error: 0.44792 | utility: 0.94174\n",
      "  batch 004 / 029 | loss: 0.77123 | error: 0.45312 | utility: 0.94621\n",
      "  batch 005 / 029 | loss: 0.75877 | error: 0.45312 | utility: 0.94799\n",
      "  batch 006 / 029 | loss: 0.76478 | error: 0.45833 | utility: 0.94559\n",
      "  batch 007 / 029 | loss: 0.77807 | error: 0.46875 | utility: 0.94039\n",
      "  batch 008 / 029 | loss: 0.79612 | error: 0.48047 | utility: 0.93308\n",
      "  batch 009 / 029 | loss: 0.81963 | error: 0.49653 | utility: 0.93237\n",
      "  batch 010 / 029 | loss: 0.81468 | error: 0.49531 | utility: 0.92919\n",
      "  batch 011 / 029 | loss: 0.80096 | error: 0.49006 | utility: 0.93585\n",
      "  batch 012 / 029 | loss: 0.81520 | error: 0.49870 | utility: 0.90664\n",
      "  batch 013 / 029 | loss: 0.80694 | error: 0.49519 | utility: 0.87316\n",
      "  batch 014 / 029 | loss: 0.80687 | error: 0.49777 | utility: 0.88566\n",
      "  batch 015 / 029 | loss: 0.79627 | error: 0.49167 | utility: 0.85608\n",
      "  batch 016 / 029 | loss: 0.79431 | error: 0.48926 | utility: 0.88154\n",
      "  batch 017 / 029 | loss: 0.78858 | error: 0.48989 | utility: 0.80997\n",
      "  batch 018 / 029 | loss: 0.79240 | error: 0.49479 | utility: 0.83538\n",
      "  batch 019 / 029 | loss: 0.79413 | error: 0.49753 | utility: 0.80972\n",
      "  batch 020 / 029 | loss: 0.79305 | error: 0.49844 | utility: 0.78765\n",
      "  batch 021 / 029 | loss: 0.78534 | error: 0.49405 | utility: 0.82586\n",
      "  batch 022 / 029 | loss: 0.77530 | error: 0.48722 | utility: 0.79397\n",
      "  batch 023 / 029 | loss: 0.77188 | error: 0.48505 | utility: 0.65021\n",
      "  batch 024 / 029 | loss: 0.76936 | error: 0.48047 | utility: 0.69369\n",
      "  batch 025 / 029 | loss: 0.76754 | error: 0.47750 | utility: 0.72801\n",
      "  batch 026 / 029 | loss: 0.76665 | error: 0.47476 | utility: 0.75496\n",
      "  batch 027 / 029 | loss: 0.76720 | error: 0.47222 | utility: 0.70094\n",
      "  batch 028 / 029 | loss: 0.76434 | error: 0.47042 | utility: 0.74137\n",
      "  batch 029 / 029 | loss: 0.75920 | error: 0.47144 | utility: 0.78010\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 001 / 010 | time: 030 sec | loss: 0.79461 | error: 0.47813 | utility: 0.78469\n",
      "Saving model to ./Results/utility/utility_0.300_model.pt.\n",
      "Starting epoch 002 / 010.\n",
      "  batch 001 / 029 | loss: 0.79515 | error: 0.45312 | utility: 0.65159\n",
      "  batch 002 / 029 | loss: 0.77128 | error: 0.45312 | utility: 0.68263\n",
      "  batch 003 / 029 | loss: 0.78326 | error: 0.45833 | utility: 0.67950\n",
      "  batch 004 / 029 | loss: 0.76350 | error: 0.43750 | utility: 0.69021\n",
      "  batch 005 / 029 | loss: 0.75293 | error: 0.42812 | utility: 0.63737\n",
      "  batch 006 / 029 | loss: 0.73511 | error: 0.41667 | utility: 0.63654\n",
      "  batch 007 / 029 | loss: 0.74148 | error: 0.41071 | utility: 0.42442\n",
      "  batch 008 / 029 | loss: 0.71880 | error: 0.39844 | utility: 0.68624\n",
      "  batch 009 / 029 | loss: 0.70456 | error: 0.39062 | utility: 0.56927\n",
      "  batch 010 / 029 | loss: 0.69352 | error: 0.38125 | utility: 0.58466\n",
      "  batch 011 / 029 | loss: 0.69166 | error: 0.38210 | utility: 0.69423\n",
      "  batch 012 / 029 | loss: 0.69612 | error: 0.38411 | utility: 0.48081\n",
      "  batch 013 / 029 | loss: 0.69815 | error: 0.38341 | utility: 0.43010\n",
      "  batch 014 / 029 | loss: 0.71322 | error: 0.39174 | utility: 0.55984\n",
      "  batch 015 / 029 | loss: 0.70313 | error: 0.38958 | utility: 0.66366\n",
      "  batch 016 / 029 | loss: 0.69699 | error: 0.38379 | utility: 0.50909\n",
      "  batch 017 / 029 | loss: 0.69602 | error: 0.38603 | utility: 0.56793\n",
      "  batch 018 / 029 | loss: 0.69828 | error: 0.38802 | utility: 0.61088\n",
      "  batch 019 / 029 | loss: 0.70213 | error: 0.38898 | utility: 0.43281\n",
      "  batch 020 / 029 | loss: 0.69958 | error: 0.38438 | utility: 0.46094\n",
      "  batch 021 / 029 | loss: 0.71479 | error: 0.39211 | utility: 0.46104\n",
      "  batch 022 / 029 | loss: 0.71284 | error: 0.39134 | utility: 0.43145\n",
      "  batch 023 / 029 | loss: 0.71002 | error: 0.38995 | utility: 0.57135\n",
      "  batch 024 / 029 | loss: 0.71186 | error: 0.38932 | utility: 0.45874\n",
      "  batch 025 / 029 | loss: 0.71483 | error: 0.38688 | utility: 0.35044\n",
      "  batch 026 / 029 | loss: 0.71074 | error: 0.38401 | utility: 0.37457\n",
      "  batch 027 / 029 | loss: 0.71063 | error: 0.38310 | utility: 0.46978\n",
      "  batch 028 / 029 | loss: 0.71080 | error: 0.38449 | utility: 0.55147\n",
      "  batch 029 / 029 | loss: 0.70573 | error: 0.37985 | utility: 0.41573\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 002 / 010 | time: 033 sec | loss: 0.71510 | error: 0.35573 | utility: 0.50201\n",
      "Validation accuracy improved.\n",
      "Saving model to ./Results/utility/utility_0.300_model.pt.\n",
      "Starting epoch 003 / 010.\n",
      "  batch 001 / 029 | loss: 0.85308 | error: 0.50000 | utility: 0.38889\n",
      "  batch 002 / 029 | loss: 0.75413 | error: 0.45312 | utility: 0.31437\n",
      "  batch 003 / 029 | loss: 0.69680 | error: 0.40104 | utility: 0.43365\n",
      "  batch 004 / 029 | loss: 0.70005 | error: 0.39844 | utility: 0.47338\n",
      "  batch 005 / 029 | loss: 0.69354 | error: 0.38438 | utility: 0.39773\n",
      "  batch 006 / 029 | loss: 0.71199 | error: 0.38542 | utility: 0.34362\n",
      "  batch 007 / 029 | loss: 0.68577 | error: 0.36830 | utility: 0.46138\n",
      "  batch 008 / 029 | loss: 0.70705 | error: 0.38086 | utility: 0.46877\n",
      "  batch 009 / 029 | loss: 0.68644 | error: 0.36632 | utility: 0.24337\n",
      "  batch 010 / 029 | loss: 0.68573 | error: 0.36562 | utility: 0.38332\n",
      "  batch 011 / 029 | loss: 0.69127 | error: 0.36790 | utility: 0.36405\n",
      "  batch 012 / 029 | loss: 0.69783 | error: 0.36458 | utility: 0.17193\n",
      "  batch 013 / 029 | loss: 0.69922 | error: 0.36058 | utility: 0.14203\n",
      "  batch 014 / 029 | loss: 0.69007 | error: 0.35603 | utility: 0.42215\n",
      "  batch 015 / 029 | loss: 0.69393 | error: 0.35417 | utility: 0.27263\n",
      "  batch 016 / 029 | loss: 0.70053 | error: 0.35840 | utility: 0.31081\n",
      "  batch 017 / 029 | loss: 0.70095 | error: 0.35754 | utility: 0.43695\n",
      "  batch 018 / 029 | loss: 0.70631 | error: 0.36111 | utility: 0.14649\n",
      "  batch 019 / 029 | loss: 0.71629 | error: 0.36513 | utility: 0.36004\n",
      "  batch 020 / 029 | loss: 0.71592 | error: 0.36328 | utility: 0.51961\n",
      "  batch 021 / 029 | loss: 0.71035 | error: 0.35640 | utility: 0.23942\n",
      "  batch 022 / 029 | loss: 0.71038 | error: 0.35653 | utility: 0.30949\n",
      "  batch 023 / 029 | loss: 0.70694 | error: 0.35598 | utility: 0.45275\n",
      "  batch 024 / 029 | loss: 0.70937 | error: 0.35872 | utility: 0.32140\n",
      "  batch 025 / 029 | loss: 0.70759 | error: 0.35687 | utility: 0.29148\n",
      "  batch 026 / 029 | loss: 0.70772 | error: 0.35637 | utility: 0.37346\n",
      "  batch 027 / 029 | loss: 0.70314 | error: 0.35243 | utility: 0.24725\n",
      "  batch 028 / 029 | loss: 0.69588 | error: 0.34766 | utility: 0.25436\n",
      "  batch 029 / 029 | loss: 0.68250 | error: 0.33998 | utility: 0.31194\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 003 / 010 | time: 037 sec | loss: 0.71515 | error: 0.32656 | utility: 0.31180\n",
      "Validation accuracy improved.\n",
      "Saving model to ./Results/utility/utility_0.300_model.pt.\n",
      "Starting epoch 004 / 010.\n",
      "  batch 001 / 029 | loss: 0.74277 | error: 0.34375 | utility: 0.27920\n",
      "  batch 002 / 029 | loss: 0.76681 | error: 0.35938 | utility: 0.30566\n",
      "  batch 003 / 029 | loss: 0.68450 | error: 0.32292 | utility: 0.27969\n",
      "  batch 004 / 029 | loss: 0.65025 | error: 0.30469 | utility: 0.45143\n",
      "  batch 005 / 029 | loss: 0.67123 | error: 0.31875 | utility: 0.33934\n",
      "  batch 006 / 029 | loss: 0.66355 | error: 0.31510 | utility: 0.23008\n",
      "  batch 007 / 029 | loss: 0.65697 | error: 0.31473 | utility: 0.31840\n",
      "  batch 008 / 029 | loss: 0.66094 | error: 0.31250 | utility: 0.28114\n",
      "  batch 009 / 029 | loss: 0.69288 | error: 0.33507 | utility: 0.27530\n",
      "  batch 010 / 029 | loss: 0.67023 | error: 0.32188 | utility: 0.30799\n",
      "  batch 011 / 029 | loss: 0.68063 | error: 0.32244 | utility: 0.10679\n",
      "  batch 012 / 029 | loss: 0.69046 | error: 0.33333 | utility: 0.24037\n",
      "  batch 013 / 029 | loss: 0.67258 | error: 0.32212 | utility: 0.26095\n",
      "  batch 014 / 029 | loss: 0.66979 | error: 0.32254 | utility: 0.30038\n",
      "  batch 015 / 029 | loss: 0.66769 | error: 0.32500 | utility: 0.34056\n",
      "  batch 016 / 029 | loss: 0.67890 | error: 0.33301 | utility: 0.37058\n",
      "  batch 017 / 029 | loss: 0.68268 | error: 0.33548 | utility: 0.29219\n",
      "  batch 018 / 029 | loss: 0.68173 | error: 0.33420 | utility: 0.29042\n",
      "  batch 019 / 029 | loss: 0.68372 | error: 0.33470 | utility: 0.29813\n",
      "  batch 020 / 029 | loss: 0.68704 | error: 0.33672 | utility: 0.23891\n",
      "  batch 021 / 029 | loss: 0.68431 | error: 0.33854 | utility: 0.35197\n",
      "  batch 022 / 029 | loss: 0.68832 | error: 0.34091 | utility: 0.35783\n",
      "  batch 023 / 029 | loss: 0.69243 | error: 0.34579 | utility: 0.27388\n",
      "  batch 024 / 029 | loss: 0.69498 | error: 0.34505 | utility: 0.23189\n",
      "  batch 025 / 029 | loss: 0.69235 | error: 0.34375 | utility: 0.32045\n",
      "  batch 026 / 029 | loss: 0.68912 | error: 0.34435 | utility: 0.33274\n",
      "  batch 027 / 029 | loss: 0.68879 | error: 0.34259 | utility: 0.11111\n",
      "  batch 028 / 029 | loss: 0.68797 | error: 0.34152 | utility: 0.08297\n",
      "  batch 029 / 029 | loss: 0.68830 | error: 0.34267 | utility: -0.03979\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 004 / 010 | time: 040 sec | loss: 0.77476 | error: 0.33385 | utility: 0.14415\n",
      "Starting epoch 005 / 010.\n",
      "  batch 001 / 029 | loss: 0.80708 | error: 0.39062 | utility: 0.11591\n",
      "  batch 002 / 029 | loss: 0.77770 | error: 0.35156 | utility: 0.17238\n",
      "  batch 003 / 029 | loss: 0.74084 | error: 0.33854 | utility: 0.21546\n",
      "  batch 004 / 029 | loss: 0.73645 | error: 0.34375 | utility: 0.27654\n",
      "  batch 005 / 029 | loss: 0.72515 | error: 0.34687 | utility: 0.20409\n",
      "  batch 006 / 029 | loss: 0.68776 | error: 0.32552 | utility: 0.26643\n",
      "  batch 007 / 029 | loss: 0.68809 | error: 0.32812 | utility: 0.19041\n",
      "  batch 008 / 029 | loss: 0.68294 | error: 0.32617 | utility: 0.30222\n",
      "  batch 009 / 029 | loss: 0.69170 | error: 0.33333 | utility: 0.39111\n",
      "  batch 010 / 029 | loss: 0.68973 | error: 0.33594 | utility: 0.25883\n",
      "  batch 011 / 029 | loss: 0.69519 | error: 0.34233 | utility: 0.43723\n",
      "  batch 012 / 029 | loss: 0.68944 | error: 0.33854 | utility: 0.23327\n",
      "  batch 013 / 029 | loss: 0.68452 | error: 0.33774 | utility: 0.33790\n",
      "  batch 014 / 029 | loss: 0.69347 | error: 0.34152 | utility: 0.13111\n",
      "  batch 015 / 029 | loss: 0.69460 | error: 0.34063 | utility: 0.29809\n",
      "  batch 016 / 029 | loss: 0.69695 | error: 0.34375 | utility: 0.28439\n",
      "  batch 017 / 029 | loss: 0.69573 | error: 0.34559 | utility: 0.38131\n",
      "  batch 018 / 029 | loss: 0.69358 | error: 0.34288 | utility: 0.24231\n",
      "  batch 019 / 029 | loss: 0.69516 | error: 0.34293 | utility: 0.21907\n",
      "  batch 020 / 029 | loss: 0.68992 | error: 0.34063 | utility: 0.22664\n",
      "  batch 021 / 029 | loss: 0.68881 | error: 0.34077 | utility: 0.25833\n",
      "  batch 022 / 029 | loss: 0.68875 | error: 0.33878 | utility: 0.24949\n",
      "  batch 023 / 029 | loss: 0.68297 | error: 0.33696 | utility: 0.21979\n",
      "  batch 024 / 029 | loss: 0.68685 | error: 0.33854 | utility: 0.33343\n",
      "  batch 025 / 029 | loss: 0.68547 | error: 0.33937 | utility: 0.22259\n",
      "  batch 026 / 029 | loss: 0.68945 | error: 0.34255 | utility: 0.32577\n",
      "  batch 027 / 029 | loss: 0.68841 | error: 0.34317 | utility: 0.30611\n",
      "  batch 028 / 029 | loss: 0.68803 | error: 0.34152 | utility: 0.17517\n",
      "  batch 029 / 029 | loss: 0.68097 | error: 0.33836 | utility: -0.04147\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 005 / 010 | time: 040 sec | loss: 0.74235 | error: 0.31667 | utility: 0.19428\n",
      "Validation accuracy improved.\n",
      "Saving model to ./Results/utility/utility_0.300_model.pt.\n",
      "Starting epoch 006 / 010.\n",
      "  batch 001 / 029 | loss: 0.56154 | error: 0.28125 | utility: 0.25292\n",
      "  batch 002 / 029 | loss: 0.66339 | error: 0.30469 | utility: 0.00780\n",
      "  batch 003 / 029 | loss: 0.67528 | error: 0.32292 | utility: 0.34726\n",
      "  batch 004 / 029 | loss: 0.73478 | error: 0.35547 | utility: 0.19162\n",
      "  batch 005 / 029 | loss: 0.69888 | error: 0.33750 | utility: 0.13199\n",
      "  batch 006 / 029 | loss: 0.68991 | error: 0.32031 | utility: -0.01043\n",
      "  batch 007 / 029 | loss: 0.68249 | error: 0.31027 | utility: 0.20703\n",
      "  batch 008 / 029 | loss: 0.68365 | error: 0.32031 | utility: 0.28982\n",
      "  batch 009 / 029 | loss: 0.67323 | error: 0.31944 | utility: 0.29437\n",
      "  batch 010 / 029 | loss: 0.66925 | error: 0.32500 | utility: 0.45605\n",
      "  batch 011 / 029 | loss: 0.68602 | error: 0.33807 | utility: 0.42202\n",
      "  batch 012 / 029 | loss: 0.67709 | error: 0.33203 | utility: 0.27678\n",
      "  batch 013 / 029 | loss: 0.68131 | error: 0.33413 | utility: 0.25185\n",
      "  batch 014 / 029 | loss: 0.68240 | error: 0.33705 | utility: 0.37177\n",
      "  batch 015 / 029 | loss: 0.67076 | error: 0.33125 | utility: 0.25251\n",
      "  batch 016 / 029 | loss: 0.68611 | error: 0.33594 | utility: 0.08036\n",
      "  batch 017 / 029 | loss: 0.68997 | error: 0.33824 | utility: 0.17832\n",
      "  batch 018 / 029 | loss: 0.68446 | error: 0.33507 | utility: 0.27742\n",
      "  batch 019 / 029 | loss: 0.68992 | error: 0.33470 | utility: 0.04534\n",
      "  batch 020 / 029 | loss: 0.69621 | error: 0.33672 | utility: 0.20287\n",
      "  batch 021 / 029 | loss: 0.68840 | error: 0.33333 | utility: 0.40178\n",
      "  batch 022 / 029 | loss: 0.68528 | error: 0.33097 | utility: 0.29454\n",
      "  batch 023 / 029 | loss: 0.68334 | error: 0.33016 | utility: 0.42168\n",
      "  batch 024 / 029 | loss: 0.68152 | error: 0.32747 | utility: 0.21139\n",
      "  batch 025 / 029 | loss: 0.68435 | error: 0.32937 | utility: 0.30517\n",
      "  batch 026 / 029 | loss: 0.68227 | error: 0.32812 | utility: 0.37673\n",
      "  batch 027 / 029 | loss: 0.68460 | error: 0.32986 | utility: 0.31809\n",
      "  batch 028 / 029 | loss: 0.68913 | error: 0.33259 | utility: 0.19892\n",
      "  batch 029 / 029 | loss: 0.71024 | error: 0.34267 | utility: 0.12282\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 006 / 010 | time: 042 sec | loss: 0.71151 | error: 0.32396 | utility: 0.27963\n",
      "Starting epoch 007 / 010.\n",
      "  batch 001 / 029 | loss: 0.84554 | error: 0.43750 | utility: 0.32090\n",
      "  batch 002 / 029 | loss: 0.83945 | error: 0.43750 | utility: 0.35022\n",
      "  batch 003 / 029 | loss: 0.84650 | error: 0.42708 | utility: 0.39671\n",
      "  batch 004 / 029 | loss: 0.78894 | error: 0.39062 | utility: 0.24806\n",
      "  batch 005 / 029 | loss: 0.73440 | error: 0.36562 | utility: 0.38199\n",
      "  batch 006 / 029 | loss: 0.71749 | error: 0.34896 | utility: 0.15099\n",
      "  batch 007 / 029 | loss: 0.71029 | error: 0.34375 | utility: 0.38406\n",
      "  batch 008 / 029 | loss: 0.70344 | error: 0.34180 | utility: 0.25172\n",
      "  batch 009 / 029 | loss: 0.70438 | error: 0.33333 | utility: 0.17824\n",
      "  batch 010 / 029 | loss: 0.69931 | error: 0.32656 | utility: 0.31398\n",
      "  batch 011 / 029 | loss: 0.70773 | error: 0.33097 | utility: 0.33993\n",
      "  batch 012 / 029 | loss: 0.69930 | error: 0.32812 | utility: 0.13526\n",
      "  batch 013 / 029 | loss: 0.68905 | error: 0.32332 | utility: 0.28185\n",
      "  batch 014 / 029 | loss: 0.69074 | error: 0.32589 | utility: 0.31398\n",
      "  batch 015 / 029 | loss: 0.68598 | error: 0.32292 | utility: 0.24939\n",
      "  batch 016 / 029 | loss: 0.68118 | error: 0.31836 | utility: 0.15218\n",
      "  batch 017 / 029 | loss: 0.67732 | error: 0.31801 | utility: 0.32815\n",
      "  batch 018 / 029 | loss: 0.68224 | error: 0.32118 | utility: 0.27950\n",
      "  batch 019 / 029 | loss: 0.68770 | error: 0.32484 | utility: 0.24744\n",
      "  batch 020 / 029 | loss: 0.69331 | error: 0.32656 | utility: 0.35833\n",
      "  batch 021 / 029 | loss: 0.69596 | error: 0.32961 | utility: 0.27084\n",
      "  batch 022 / 029 | loss: 0.69709 | error: 0.33097 | utility: 0.34742\n",
      "  batch 023 / 029 | loss: 0.69816 | error: 0.33220 | utility: 0.31615\n",
      "  batch 024 / 029 | loss: 0.70006 | error: 0.33464 | utility: 0.37412\n",
      "  batch 025 / 029 | loss: 0.70087 | error: 0.33625 | utility: 0.24734\n",
      "  batch 026 / 029 | loss: 0.69384 | error: 0.33293 | utility: 0.13485\n",
      "  batch 027 / 029 | loss: 0.69215 | error: 0.33160 | utility: 0.37626\n",
      "  batch 028 / 029 | loss: 0.69363 | error: 0.33203 | utility: 0.26039\n",
      "  batch 029 / 029 | loss: 0.69984 | error: 0.32920 | utility: 0.04249\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 007 / 010 | time: 042 sec | loss: 0.75044 | error: 0.32292 | utility: 0.24890\n",
      "Starting epoch 008 / 010.\n",
      "  batch 001 / 029 | loss: 0.69689 | error: 0.39062 | utility: 0.32776\n",
      "  batch 002 / 029 | loss: 0.65205 | error: 0.35938 | utility: 0.37519\n",
      "  batch 003 / 029 | loss: 0.71504 | error: 0.36979 | utility: 0.26543\n",
      "  batch 004 / 029 | loss: 0.67330 | error: 0.34766 | utility: 0.51452\n",
      "  batch 005 / 029 | loss: 0.67069 | error: 0.34063 | utility: 0.19278\n",
      "  batch 006 / 029 | loss: 0.69638 | error: 0.35417 | utility: 0.18604\n",
      "  batch 007 / 029 | loss: 0.71449 | error: 0.36161 | utility: 0.17651\n",
      "  batch 008 / 029 | loss: 0.71485 | error: 0.35547 | utility: 0.17897\n",
      "  batch 009 / 029 | loss: 0.70885 | error: 0.34896 | utility: 0.16456\n",
      "  batch 010 / 029 | loss: 0.70967 | error: 0.34844 | utility: 0.13291\n",
      "  batch 011 / 029 | loss: 0.72011 | error: 0.34943 | utility: 0.15014\n",
      "  batch 012 / 029 | loss: 0.71772 | error: 0.34766 | utility: 0.22407\n",
      "  batch 013 / 029 | loss: 0.71401 | error: 0.34375 | utility: 0.12609\n",
      "  batch 014 / 029 | loss: 0.70496 | error: 0.33817 | utility: 0.28400\n",
      "  batch 015 / 029 | loss: 0.70948 | error: 0.34271 | utility: 0.22949\n",
      "  batch 016 / 029 | loss: 0.70430 | error: 0.33984 | utility: 0.27033\n",
      "  batch 017 / 029 | loss: 0.71090 | error: 0.34651 | utility: 0.28606\n",
      "  batch 018 / 029 | loss: 0.71384 | error: 0.34896 | utility: 0.26944\n",
      "  batch 019 / 029 | loss: 0.70804 | error: 0.34704 | utility: 0.37443\n",
      "  batch 020 / 029 | loss: 0.70995 | error: 0.34922 | utility: 0.35326\n",
      "  batch 021 / 029 | loss: 0.70462 | error: 0.34598 | utility: 0.37905\n",
      "  batch 022 / 029 | loss: 0.69232 | error: 0.34020 | utility: 0.26070\n",
      "  batch 023 / 029 | loss: 0.69089 | error: 0.33899 | utility: 0.32731\n",
      "  batch 024 / 029 | loss: 0.68606 | error: 0.33724 | utility: 0.32412\n",
      "  batch 025 / 029 | loss: 0.68571 | error: 0.33750 | utility: 0.23575\n",
      "  batch 026 / 029 | loss: 0.68310 | error: 0.33654 | utility: 0.41853\n",
      "  batch 027 / 029 | loss: 0.68501 | error: 0.33681 | utility: 0.10130\n",
      "  batch 028 / 029 | loss: 0.68752 | error: 0.33761 | utility: 0.26097\n",
      "  batch 029 / 029 | loss: 0.69738 | error: 0.33890 | utility: -0.11758\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 008 / 010 | time: 042 sec | loss: 0.73531 | error: 0.31562 | utility: 0.20899\n",
      "Validation accuracy improved.\n",
      "Saving model to ./Results/utility/utility_0.300_model.pt.\n",
      "Starting epoch 009 / 010.\n",
      "  batch 001 / 029 | loss: 0.59813 | error: 0.32812 | utility: 0.34536\n",
      "  batch 002 / 029 | loss: 0.62962 | error: 0.32812 | utility: 0.12765\n",
      "  batch 003 / 029 | loss: 0.66650 | error: 0.34896 | utility: 0.34066\n",
      "  batch 004 / 029 | loss: 0.65468 | error: 0.33984 | utility: 0.27518\n",
      "  batch 005 / 029 | loss: 0.68182 | error: 0.35000 | utility: 0.09251\n",
      "  batch 006 / 029 | loss: 0.65742 | error: 0.32812 | utility: 0.23132\n",
      "  batch 007 / 029 | loss: 0.65598 | error: 0.32143 | utility: 0.27533\n",
      "  batch 008 / 029 | loss: 0.65759 | error: 0.33008 | utility: 0.23566\n",
      "  batch 009 / 029 | loss: 0.64562 | error: 0.31771 | utility: 0.11591\n",
      "  batch 010 / 029 | loss: 0.66895 | error: 0.32656 | utility: 0.24769\n",
      "  batch 011 / 029 | loss: 0.67692 | error: 0.33381 | utility: 0.34496\n",
      "  batch 012 / 029 | loss: 0.67708 | error: 0.33464 | utility: 0.37868\n",
      "  batch 013 / 029 | loss: 0.68401 | error: 0.33894 | utility: 0.27086\n",
      "  batch 014 / 029 | loss: 0.68312 | error: 0.33594 | utility: 0.21863\n",
      "  batch 015 / 029 | loss: 0.67768 | error: 0.33437 | utility: 0.41576\n",
      "  batch 016 / 029 | loss: 0.68042 | error: 0.33301 | utility: 0.11442\n",
      "  batch 017 / 029 | loss: 0.67821 | error: 0.33548 | utility: 0.33322\n",
      "  batch 018 / 029 | loss: 0.68101 | error: 0.33681 | utility: 0.29317\n",
      "  batch 019 / 029 | loss: 0.67915 | error: 0.33470 | utility: 0.23476\n",
      "  batch 020 / 029 | loss: 0.67105 | error: 0.33125 | utility: 0.33327\n",
      "  batch 021 / 029 | loss: 0.67354 | error: 0.33259 | utility: 0.30427\n",
      "  batch 022 / 029 | loss: 0.67698 | error: 0.33452 | utility: 0.20704\n",
      "  batch 023 / 029 | loss: 0.67578 | error: 0.33356 | utility: 0.30885\n",
      "  batch 024 / 029 | loss: 0.67726 | error: 0.33333 | utility: 0.23777\n",
      "  batch 025 / 029 | loss: 0.67927 | error: 0.33563 | utility: 0.50522\n",
      "  batch 026 / 029 | loss: 0.67998 | error: 0.33594 | utility: 0.26086\n",
      "  batch 027 / 029 | loss: 0.68481 | error: 0.34028 | utility: 0.34656\n",
      "  batch 028 / 029 | loss: 0.69060 | error: 0.34263 | utility: 0.26153\n",
      "  batch 029 / 029 | loss: 0.67995 | error: 0.33944 | utility: 0.52921\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 009 / 010 | time: 052 sec | loss: 0.74575 | error: 0.32292 | utility: 0.24025\n",
      "Starting epoch 010 / 010.\n",
      "  batch 001 / 029 | loss: 0.69040 | error: 0.34375 | utility: 0.31585\n",
      "  batch 002 / 029 | loss: 0.75884 | error: 0.35938 | utility: 0.21722\n",
      "  batch 003 / 029 | loss: 0.67546 | error: 0.31771 | utility: 0.50249\n",
      "  batch 004 / 029 | loss: 0.67386 | error: 0.32031 | utility: 0.22709\n",
      "  batch 005 / 029 | loss: 0.68528 | error: 0.32500 | utility: 0.23478\n",
      "  batch 006 / 029 | loss: 0.65285 | error: 0.30729 | utility: 0.20603\n",
      "  batch 007 / 029 | loss: 0.65326 | error: 0.31027 | utility: 0.22912\n",
      "  batch 008 / 029 | loss: 0.64607 | error: 0.31445 | utility: 0.31412\n",
      "  batch 009 / 029 | loss: 0.64188 | error: 0.32118 | utility: 0.45457\n",
      "  batch 010 / 029 | loss: 0.65224 | error: 0.32500 | utility: 0.15845\n",
      "  batch 011 / 029 | loss: 0.63879 | error: 0.31818 | utility: 0.40562\n",
      "  batch 012 / 029 | loss: 0.66042 | error: 0.32682 | utility: 0.15881\n",
      "  batch 013 / 029 | loss: 0.66933 | error: 0.33053 | utility: 0.10043\n",
      "  batch 014 / 029 | loss: 0.67188 | error: 0.32812 | utility: 0.22283\n",
      "  batch 015 / 029 | loss: 0.67908 | error: 0.33229 | utility: 0.08803\n",
      "  batch 016 / 029 | loss: 0.68885 | error: 0.33594 | utility: 0.13644\n",
      "  batch 017 / 029 | loss: 0.69524 | error: 0.33732 | utility: 0.18790\n",
      "  batch 018 / 029 | loss: 0.68964 | error: 0.33507 | utility: 0.36395\n",
      "  batch 019 / 029 | loss: 0.68504 | error: 0.33470 | utility: 0.39919\n",
      "  batch 020 / 029 | loss: 0.68049 | error: 0.33437 | utility: 0.41140\n",
      "  batch 021 / 029 | loss: 0.67724 | error: 0.33482 | utility: 0.31263\n",
      "  batch 022 / 029 | loss: 0.68234 | error: 0.33736 | utility: 0.12340\n",
      "  batch 023 / 029 | loss: 0.67789 | error: 0.33084 | utility: 0.14109\n",
      "  batch 024 / 029 | loss: 0.67723 | error: 0.33268 | utility: 0.42720\n",
      "  batch 025 / 029 | loss: 0.67655 | error: 0.33313 | utility: 0.32659\n",
      "  batch 026 / 029 | loss: 0.67796 | error: 0.33233 | utility: 0.20820\n",
      "  batch 027 / 029 | loss: 0.67885 | error: 0.33160 | utility: 0.21163\n",
      "  batch 028 / 029 | loss: 0.68652 | error: 0.33594 | utility: 0.31404\n",
      "  batch 029 / 029 | loss: 0.70018 | error: 0.34159 | utility: 0.36181\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 010 / 010 | time: 051 sec | loss: 0.74698 | error: 0.32135 | utility: 0.20977\n",
      "Total training time: 7 minutes (409.7312786579132 seconds).\n",
      "Loading model from ./Results/utility/utility_0.300_model.pt.\n",
      "---------- Training with lambda=0.35000000000000003 ----------\n",
      "Starting epoch 001 / 010.\n",
      "  batch 001 / 029 | loss: 0.71999 | error: 0.40625 | utility: 0.93142\n",
      "  batch 002 / 029 | loss: 0.70294 | error: 0.40625 | utility: 0.93357\n",
      "  batch 003 / 029 | loss: 0.75270 | error: 0.44792 | utility: 0.94161\n",
      "  batch 004 / 029 | loss: 0.74653 | error: 0.45312 | utility: 0.94612\n",
      "  batch 005 / 029 | loss: 0.73360 | error: 0.45312 | utility: 0.94810\n",
      "  batch 006 / 029 | loss: 0.73941 | error: 0.45833 | utility: 0.94597\n",
      "  batch 007 / 029 | loss: 0.75276 | error: 0.46875 | utility: 0.94149\n",
      "  batch 008 / 029 | loss: 0.77108 | error: 0.48047 | utility: 0.93490\n",
      "  batch 009 / 029 | loss: 0.79535 | error: 0.49653 | utility: 0.93504\n",
      "  batch 010 / 029 | loss: 0.79049 | error: 0.49531 | utility: 0.93336\n",
      "  batch 011 / 029 | loss: 0.77680 | error: 0.49006 | utility: 0.93955\n",
      "  batch 012 / 029 | loss: 0.79176 | error: 0.49870 | utility: 0.91468\n",
      "  batch 013 / 029 | loss: 0.78360 | error: 0.49519 | utility: 0.88253\n",
      "  batch 014 / 029 | loss: 0.78418 | error: 0.49888 | utility: 0.89827\n",
      "  batch 015 / 029 | loss: 0.77362 | error: 0.49375 | utility: 0.87601\n",
      "  batch 016 / 029 | loss: 0.77175 | error: 0.49121 | utility: 0.89665\n",
      "  batch 017 / 029 | loss: 0.76638 | error: 0.49265 | utility: 0.83724\n",
      "  batch 018 / 029 | loss: 0.77083 | error: 0.49740 | utility: 0.86025\n",
      "  batch 019 / 029 | loss: 0.77316 | error: 0.50082 | utility: 0.84099\n",
      "  batch 020 / 029 | loss: 0.77250 | error: 0.50234 | utility: 0.82106\n",
      "  batch 021 / 029 | loss: 0.76463 | error: 0.49702 | utility: 0.85505\n",
      "  batch 022 / 029 | loss: 0.75452 | error: 0.49006 | utility: 0.83096\n",
      "  batch 023 / 029 | loss: 0.75142 | error: 0.48777 | utility: 0.70718\n",
      "  batch 024 / 029 | loss: 0.74924 | error: 0.48633 | utility: 0.74631\n",
      "  batch 025 / 029 | loss: 0.74743 | error: 0.48438 | utility: 0.77128\n",
      "  batch 026 / 029 | loss: 0.74652 | error: 0.48197 | utility: 0.79346\n",
      "  batch 027 / 029 | loss: 0.74714 | error: 0.48148 | utility: 0.75226\n",
      "  batch 028 / 029 | loss: 0.74444 | error: 0.47991 | utility: 0.78790\n",
      "  batch 029 / 029 | loss: 0.74000 | error: 0.48060 | utility: 0.83566\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 001 / 010 | time: 034 sec | loss: 0.77495 | error: 0.49375 | utility: 0.83157\n",
      "Saving model to ./Results/utility/utility_0.350_model.pt.\n",
      "Starting epoch 002 / 010.\n",
      "  batch 001 / 029 | loss: 0.78616 | error: 0.46875 | utility: 0.72068\n",
      "  batch 002 / 029 | loss: 0.76137 | error: 0.47656 | utility: 0.74029\n",
      "  batch 003 / 029 | loss: 0.77314 | error: 0.48438 | utility: 0.74304\n",
      "  batch 004 / 029 | loss: 0.75235 | error: 0.46875 | utility: 0.75236\n",
      "  batch 005 / 029 | loss: 0.74305 | error: 0.45937 | utility: 0.72234\n",
      "  batch 006 / 029 | loss: 0.72523 | error: 0.44792 | utility: 0.70066\n",
      "  batch 007 / 029 | loss: 0.73310 | error: 0.44866 | utility: 0.55711\n",
      "  batch 008 / 029 | loss: 0.70835 | error: 0.43164 | utility: 0.75017\n",
      "  batch 009 / 029 | loss: 0.69305 | error: 0.42014 | utility: 0.65164\n",
      "  batch 010 / 029 | loss: 0.68096 | error: 0.40781 | utility: 0.66613\n",
      "  batch 011 / 029 | loss: 0.67860 | error: 0.40767 | utility: 0.76347\n",
      "  batch 012 / 029 | loss: 0.68394 | error: 0.40755 | utility: 0.58019\n",
      "  batch 013 / 029 | loss: 0.68607 | error: 0.40385 | utility: 0.51370\n",
      "  batch 014 / 029 | loss: 0.70025 | error: 0.41071 | utility: 0.65242\n",
      "  batch 015 / 029 | loss: 0.68904 | error: 0.40729 | utility: 0.72890\n",
      "  batch 016 / 029 | loss: 0.68294 | error: 0.40234 | utility: 0.58575\n",
      "  batch 017 / 029 | loss: 0.68189 | error: 0.40349 | utility: 0.65764\n",
      "  batch 018 / 029 | loss: 0.68412 | error: 0.40538 | utility: 0.70152\n",
      "  batch 019 / 029 | loss: 0.68872 | error: 0.40543 | utility: 0.54237\n",
      "  batch 020 / 029 | loss: 0.68562 | error: 0.40000 | utility: 0.54542\n",
      "  batch 021 / 029 | loss: 0.70117 | error: 0.40848 | utility: 0.58080\n",
      "  batch 022 / 029 | loss: 0.69987 | error: 0.40909 | utility: 0.55728\n",
      "  batch 023 / 029 | loss: 0.69724 | error: 0.40829 | utility: 0.66705\n",
      "  batch 024 / 029 | loss: 0.69871 | error: 0.40951 | utility: 0.59783\n",
      "  batch 025 / 029 | loss: 0.70249 | error: 0.40687 | utility: 0.49453\n",
      "  batch 026 / 029 | loss: 0.69865 | error: 0.40445 | utility: 0.52243\n",
      "  batch 027 / 029 | loss: 0.69878 | error: 0.40394 | utility: 0.60558\n",
      "  batch 028 / 029 | loss: 0.69884 | error: 0.40513 | utility: 0.68942\n",
      "  batch 029 / 029 | loss: 0.69449 | error: 0.40409 | utility: 0.59998\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 002 / 010 | time: 040 sec | loss: 0.76130 | error: 0.43281 | utility: 0.66935\n",
      "Validation accuracy improved.\n",
      "Saving model to ./Results/utility/utility_0.350_model.pt.\n",
      "Starting epoch 003 / 010.\n",
      "  batch 001 / 029 | loss: 0.86891 | error: 0.51562 | utility: 0.53884\n",
      "  batch 002 / 029 | loss: 0.76352 | error: 0.47656 | utility: 0.50124\n",
      "  batch 003 / 029 | loss: 0.70561 | error: 0.43229 | utility: 0.55322\n",
      "  batch 004 / 029 | loss: 0.70140 | error: 0.42969 | utility: 0.60288\n",
      "  batch 005 / 029 | loss: 0.69319 | error: 0.40937 | utility: 0.52747\n",
      "  batch 006 / 029 | loss: 0.71177 | error: 0.41146 | utility: 0.49651\n",
      "  batch 007 / 029 | loss: 0.68543 | error: 0.38616 | utility: 0.55099\n",
      "  batch 008 / 029 | loss: 0.70549 | error: 0.39648 | utility: 0.57211\n",
      "  batch 009 / 029 | loss: 0.68700 | error: 0.38194 | utility: 0.36726\n",
      "  batch 010 / 029 | loss: 0.68541 | error: 0.38438 | utility: 0.50626\n",
      "  batch 011 / 029 | loss: 0.69057 | error: 0.38778 | utility: 0.49421\n",
      "  batch 012 / 029 | loss: 0.69755 | error: 0.38802 | utility: 0.36972\n",
      "  batch 013 / 029 | loss: 0.70094 | error: 0.38462 | utility: 0.31046\n",
      "  batch 014 / 029 | loss: 0.69092 | error: 0.37835 | utility: 0.56166\n",
      "  batch 015 / 029 | loss: 0.69339 | error: 0.37604 | utility: 0.42863\n",
      "  batch 016 / 029 | loss: 0.69957 | error: 0.37793 | utility: 0.50484\n",
      "  batch 017 / 029 | loss: 0.69940 | error: 0.38051 | utility: 0.58285\n",
      "  batch 018 / 029 | loss: 0.70434 | error: 0.38194 | utility: 0.30990\n",
      "  batch 019 / 029 | loss: 0.71473 | error: 0.38898 | utility: 0.52590\n",
      "  batch 020 / 029 | loss: 0.71330 | error: 0.38906 | utility: 0.65990\n",
      "  batch 021 / 029 | loss: 0.70767 | error: 0.38616 | utility: 0.40189\n",
      "  batch 022 / 029 | loss: 0.70767 | error: 0.38423 | utility: 0.48131\n",
      "  batch 023 / 029 | loss: 0.70387 | error: 0.38247 | utility: 0.58510\n",
      "  batch 024 / 029 | loss: 0.70689 | error: 0.38411 | utility: 0.46305\n",
      "  batch 025 / 029 | loss: 0.70425 | error: 0.38000 | utility: 0.45800\n",
      "  batch 026 / 029 | loss: 0.70476 | error: 0.38101 | utility: 0.52462\n",
      "  batch 027 / 029 | loss: 0.70089 | error: 0.37731 | utility: 0.39501\n",
      "  batch 028 / 029 | loss: 0.69488 | error: 0.37165 | utility: 0.38757\n",
      "  batch 029 / 029 | loss: 0.68194 | error: 0.36746 | utility: 0.53836\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 003 / 010 | time: 040 sec | loss: 0.70046 | error: 0.35885 | utility: 0.53040\n",
      "Validation accuracy improved.\n",
      "Saving model to ./Results/utility/utility_0.350_model.pt.\n",
      "Starting epoch 004 / 010.\n",
      "  batch 001 / 029 | loss: 0.74392 | error: 0.37500 | utility: 0.40835\n",
      "  batch 002 / 029 | loss: 0.75266 | error: 0.39062 | utility: 0.43523\n",
      "  batch 003 / 029 | loss: 0.67692 | error: 0.34896 | utility: 0.39478\n",
      "  batch 004 / 029 | loss: 0.64213 | error: 0.32422 | utility: 0.52980\n",
      "  batch 005 / 029 | loss: 0.65906 | error: 0.34063 | utility: 0.42844\n",
      "  batch 006 / 029 | loss: 0.65555 | error: 0.33333 | utility: 0.33986\n",
      "  batch 007 / 029 | loss: 0.65152 | error: 0.33259 | utility: 0.45382\n",
      "  batch 008 / 029 | loss: 0.65415 | error: 0.33398 | utility: 0.42210\n",
      "  batch 009 / 029 | loss: 0.68325 | error: 0.35590 | utility: 0.41953\n",
      "  batch 010 / 029 | loss: 0.66236 | error: 0.34531 | utility: 0.44297\n",
      "  batch 011 / 029 | loss: 0.67277 | error: 0.34659 | utility: 0.34268\n",
      "  batch 012 / 029 | loss: 0.68358 | error: 0.35807 | utility: 0.39169\n",
      "  batch 013 / 029 | loss: 0.66876 | error: 0.34615 | utility: 0.38723\n",
      "  batch 014 / 029 | loss: 0.66610 | error: 0.34598 | utility: 0.41787\n",
      "  batch 015 / 029 | loss: 0.66517 | error: 0.35000 | utility: 0.47172\n",
      "  batch 016 / 029 | loss: 0.67541 | error: 0.35840 | utility: 0.48074\n",
      "  batch 017 / 029 | loss: 0.68104 | error: 0.36029 | utility: 0.40896\n",
      "  batch 018 / 029 | loss: 0.68102 | error: 0.35851 | utility: 0.35022\n",
      "  batch 019 / 029 | loss: 0.68334 | error: 0.35691 | utility: 0.39962\n",
      "  batch 020 / 029 | loss: 0.68636 | error: 0.35781 | utility: 0.32157\n",
      "  batch 021 / 029 | loss: 0.68362 | error: 0.35938 | utility: 0.44008\n",
      "  batch 022 / 029 | loss: 0.68711 | error: 0.36080 | utility: 0.42520\n",
      "  batch 023 / 029 | loss: 0.69143 | error: 0.36481 | utility: 0.36682\n",
      "  batch 024 / 029 | loss: 0.69456 | error: 0.36458 | utility: 0.34686\n",
      "  batch 025 / 029 | loss: 0.69189 | error: 0.36375 | utility: 0.43124\n",
      "  batch 026 / 029 | loss: 0.68970 | error: 0.36358 | utility: 0.40428\n",
      "  batch 027 / 029 | loss: 0.68968 | error: 0.36169 | utility: 0.21377\n",
      "  batch 028 / 029 | loss: 0.68912 | error: 0.35993 | utility: 0.18379\n",
      "  batch 029 / 029 | loss: 0.68872 | error: 0.36045 | utility: 0.06007\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 004 / 010 | time: 045 sec | loss: 0.72777 | error: 0.33073 | utility: 0.35786\n",
      "Validation accuracy improved.\n",
      "Saving model to ./Results/utility/utility_0.350_model.pt.\n",
      "Starting epoch 005 / 010.\n",
      "  batch 001 / 029 | loss: 0.80547 | error: 0.40625 | utility: 0.21376\n",
      "  batch 002 / 029 | loss: 0.77353 | error: 0.36719 | utility: 0.26151\n",
      "  batch 003 / 029 | loss: 0.74072 | error: 0.34896 | utility: 0.30803\n",
      "  batch 004 / 029 | loss: 0.73256 | error: 0.35938 | utility: 0.34633\n",
      "  batch 005 / 029 | loss: 0.72523 | error: 0.35938 | utility: 0.26051\n",
      "  batch 006 / 029 | loss: 0.68807 | error: 0.33854 | utility: 0.34178\n",
      "  batch 007 / 029 | loss: 0.68769 | error: 0.33705 | utility: 0.25593\n",
      "  batch 008 / 029 | loss: 0.68236 | error: 0.33594 | utility: 0.39196\n",
      "  batch 009 / 029 | loss: 0.69099 | error: 0.34375 | utility: 0.44343\n",
      "  batch 010 / 029 | loss: 0.68886 | error: 0.34687 | utility: 0.34897\n",
      "  batch 011 / 029 | loss: 0.69459 | error: 0.35227 | utility: 0.49885\n",
      "  batch 012 / 029 | loss: 0.68884 | error: 0.34766 | utility: 0.32477\n",
      "  batch 013 / 029 | loss: 0.68273 | error: 0.34736 | utility: 0.41798\n",
      "  batch 014 / 029 | loss: 0.69297 | error: 0.35268 | utility: 0.19456\n",
      "  batch 015 / 029 | loss: 0.69216 | error: 0.35313 | utility: 0.35789\n",
      "  batch 016 / 029 | loss: 0.69415 | error: 0.35352 | utility: 0.33225\n",
      "  batch 017 / 029 | loss: 0.69271 | error: 0.35570 | utility: 0.43444\n",
      "  batch 018 / 029 | loss: 0.69126 | error: 0.35417 | utility: 0.28609\n",
      "  batch 019 / 029 | loss: 0.69353 | error: 0.35280 | utility: 0.27042\n",
      "  batch 020 / 029 | loss: 0.68867 | error: 0.35000 | utility: 0.27250\n",
      "  batch 021 / 029 | loss: 0.68755 | error: 0.34970 | utility: 0.31146\n",
      "  batch 022 / 029 | loss: 0.68710 | error: 0.34801 | utility: 0.29743\n",
      "  batch 023 / 029 | loss: 0.68150 | error: 0.34579 | utility: 0.24984\n",
      "  batch 024 / 029 | loss: 0.68515 | error: 0.34766 | utility: 0.39409\n",
      "  batch 025 / 029 | loss: 0.68391 | error: 0.34750 | utility: 0.27246\n",
      "  batch 026 / 029 | loss: 0.68804 | error: 0.35096 | utility: 0.36495\n",
      "  batch 027 / 029 | loss: 0.68683 | error: 0.35069 | utility: 0.35156\n",
      "  batch 028 / 029 | loss: 0.68663 | error: 0.34933 | utility: 0.24544\n",
      "  batch 029 / 029 | loss: 0.68104 | error: 0.34591 | utility: -0.01359\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 005 / 010 | time: 039 sec | loss: 0.72162 | error: 0.31875 | utility: 0.30032\n",
      "Validation accuracy improved.\n",
      "Saving model to ./Results/utility/utility_0.350_model.pt.\n",
      "Starting epoch 006 / 010.\n",
      "  batch 001 / 029 | loss: 0.56218 | error: 0.28125 | utility: 0.28040\n",
      "  batch 002 / 029 | loss: 0.66611 | error: 0.31250 | utility: 0.06488\n",
      "  batch 003 / 029 | loss: 0.67556 | error: 0.32812 | utility: 0.39261\n",
      "  batch 004 / 029 | loss: 0.73489 | error: 0.35547 | utility: 0.24497\n",
      "  batch 005 / 029 | loss: 0.69907 | error: 0.33750 | utility: 0.15712\n",
      "  batch 006 / 029 | loss: 0.68884 | error: 0.32031 | utility: 0.01693\n",
      "  batch 007 / 029 | loss: 0.67983 | error: 0.31027 | utility: 0.23819\n",
      "  batch 008 / 029 | loss: 0.68043 | error: 0.32031 | utility: 0.31245\n",
      "  batch 009 / 029 | loss: 0.66921 | error: 0.31771 | utility: 0.31477\n",
      "  batch 010 / 029 | loss: 0.66532 | error: 0.32344 | utility: 0.48093\n",
      "  batch 011 / 029 | loss: 0.68193 | error: 0.33665 | utility: 0.45700\n",
      "  batch 012 / 029 | loss: 0.67249 | error: 0.32943 | utility: 0.32228\n",
      "  batch 013 / 029 | loss: 0.67702 | error: 0.33173 | utility: 0.28610\n",
      "  batch 014 / 029 | loss: 0.67861 | error: 0.33594 | utility: 0.41210\n",
      "  batch 015 / 029 | loss: 0.66765 | error: 0.32917 | utility: 0.28050\n",
      "  batch 016 / 029 | loss: 0.68352 | error: 0.33789 | utility: 0.14583\n",
      "  batch 017 / 029 | loss: 0.68736 | error: 0.34191 | utility: 0.25597\n",
      "  batch 018 / 029 | loss: 0.68213 | error: 0.34201 | utility: 0.33032\n",
      "  batch 019 / 029 | loss: 0.68777 | error: 0.34293 | utility: 0.09659\n",
      "  batch 020 / 029 | loss: 0.69423 | error: 0.34531 | utility: 0.25340\n",
      "  batch 021 / 029 | loss: 0.68592 | error: 0.34301 | utility: 0.43220\n",
      "  batch 022 / 029 | loss: 0.68242 | error: 0.34020 | utility: 0.33948\n",
      "  batch 023 / 029 | loss: 0.68031 | error: 0.33967 | utility: 0.45985\n",
      "  batch 024 / 029 | loss: 0.67841 | error: 0.33724 | utility: 0.26028\n",
      "  batch 025 / 029 | loss: 0.68120 | error: 0.33875 | utility: 0.34234\n",
      "  batch 026 / 029 | loss: 0.67872 | error: 0.33714 | utility: 0.39440\n",
      "  batch 027 / 029 | loss: 0.68115 | error: 0.33912 | utility: 0.34384\n",
      "  batch 028 / 029 | loss: 0.68607 | error: 0.34208 | utility: 0.22477\n",
      "  batch 029 / 029 | loss: 0.70656 | error: 0.34752 | utility: 0.19261\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 006 / 010 | time: 040 sec | loss: 0.69162 | error: 0.31823 | utility: 0.31871\n",
      "Validation accuracy improved.\n",
      "Saving model to ./Results/utility/utility_0.350_model.pt.\n",
      "Starting epoch 007 / 010.\n",
      "  batch 001 / 029 | loss: 0.84334 | error: 0.43750 | utility: 0.34809\n",
      "  batch 002 / 029 | loss: 0.83801 | error: 0.44531 | utility: 0.37636\n",
      "  batch 003 / 029 | loss: 0.84372 | error: 0.44271 | utility: 0.43168\n",
      "  batch 004 / 029 | loss: 0.78809 | error: 0.40234 | utility: 0.28518\n",
      "  batch 005 / 029 | loss: 0.73248 | error: 0.37188 | utility: 0.41849\n",
      "  batch 006 / 029 | loss: 0.71616 | error: 0.35938 | utility: 0.19840\n",
      "  batch 007 / 029 | loss: 0.70649 | error: 0.35491 | utility: 0.43953\n",
      "  batch 008 / 029 | loss: 0.70109 | error: 0.35742 | utility: 0.30085\n",
      "  batch 009 / 029 | loss: 0.70156 | error: 0.35243 | utility: 0.25811\n",
      "  batch 010 / 029 | loss: 0.69637 | error: 0.34531 | utility: 0.38081\n",
      "  batch 011 / 029 | loss: 0.70360 | error: 0.35085 | utility: 0.40830\n",
      "  batch 012 / 029 | loss: 0.69520 | error: 0.34896 | utility: 0.19835\n",
      "  batch 013 / 029 | loss: 0.68472 | error: 0.34255 | utility: 0.32575\n",
      "  batch 014 / 029 | loss: 0.68597 | error: 0.34487 | utility: 0.37688\n",
      "  batch 015 / 029 | loss: 0.68199 | error: 0.34375 | utility: 0.31257\n",
      "  batch 016 / 029 | loss: 0.67809 | error: 0.34180 | utility: 0.20574\n",
      "  batch 017 / 029 | loss: 0.67423 | error: 0.34007 | utility: 0.37976\n",
      "  batch 018 / 029 | loss: 0.67949 | error: 0.34115 | utility: 0.33828\n",
      "  batch 019 / 029 | loss: 0.68558 | error: 0.34375 | utility: 0.29299\n",
      "  batch 020 / 029 | loss: 0.69076 | error: 0.34609 | utility: 0.40694\n",
      "  batch 021 / 029 | loss: 0.69374 | error: 0.34821 | utility: 0.32054\n",
      "  batch 022 / 029 | loss: 0.69450 | error: 0.34801 | utility: 0.39106\n",
      "  batch 023 / 029 | loss: 0.69559 | error: 0.34851 | utility: 0.35922\n",
      "  batch 024 / 029 | loss: 0.69741 | error: 0.35156 | utility: 0.44141\n",
      "  batch 025 / 029 | loss: 0.69813 | error: 0.35250 | utility: 0.29037\n",
      "  batch 026 / 029 | loss: 0.69157 | error: 0.34736 | utility: 0.18535\n",
      "  batch 027 / 029 | loss: 0.68950 | error: 0.34664 | utility: 0.43212\n",
      "  batch 028 / 029 | loss: 0.69137 | error: 0.34710 | utility: 0.30319\n",
      "  batch 029 / 029 | loss: 0.69798 | error: 0.34375 | utility: 0.12657\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 007 / 010 | time: 047 sec | loss: 0.72589 | error: 0.31979 | utility: 0.34001\n",
      "Starting epoch 008 / 010.\n",
      "  batch 001 / 029 | loss: 0.70249 | error: 0.40625 | utility: 0.38862\n",
      "  batch 002 / 029 | loss: 0.64905 | error: 0.36719 | utility: 0.43005\n",
      "  batch 003 / 029 | loss: 0.70835 | error: 0.37500 | utility: 0.32979\n",
      "  batch 004 / 029 | loss: 0.66248 | error: 0.35156 | utility: 0.56249\n",
      "  batch 005 / 029 | loss: 0.66406 | error: 0.34375 | utility: 0.22527\n",
      "  batch 006 / 029 | loss: 0.69087 | error: 0.35938 | utility: 0.24074\n",
      "  batch 007 / 029 | loss: 0.71025 | error: 0.36830 | utility: 0.23610\n",
      "  batch 008 / 029 | loss: 0.71235 | error: 0.36328 | utility: 0.23027\n",
      "  batch 009 / 029 | loss: 0.70794 | error: 0.35938 | utility: 0.22155\n",
      "  batch 010 / 029 | loss: 0.70849 | error: 0.35781 | utility: 0.18181\n",
      "  batch 011 / 029 | loss: 0.71976 | error: 0.36222 | utility: 0.21340\n",
      "  batch 012 / 029 | loss: 0.71726 | error: 0.36328 | utility: 0.27962\n",
      "  batch 013 / 029 | loss: 0.71195 | error: 0.35938 | utility: 0.20106\n",
      "  batch 014 / 029 | loss: 0.70293 | error: 0.35268 | utility: 0.35405\n",
      "  batch 015 / 029 | loss: 0.70684 | error: 0.35729 | utility: 0.30040\n",
      "  batch 016 / 029 | loss: 0.70217 | error: 0.35352 | utility: 0.31441\n",
      "  batch 017 / 029 | loss: 0.70879 | error: 0.35938 | utility: 0.32981\n",
      "  batch 018 / 029 | loss: 0.71194 | error: 0.36024 | utility: 0.30656\n",
      "  batch 019 / 029 | loss: 0.70599 | error: 0.35773 | utility: 0.40049\n",
      "  batch 020 / 029 | loss: 0.70781 | error: 0.36016 | utility: 0.40099\n",
      "  batch 021 / 029 | loss: 0.70226 | error: 0.35640 | utility: 0.42634\n",
      "  batch 022 / 029 | loss: 0.68958 | error: 0.35014 | utility: 0.29473\n",
      "  batch 023 / 029 | loss: 0.68799 | error: 0.34986 | utility: 0.38026\n",
      "  batch 024 / 029 | loss: 0.68271 | error: 0.34766 | utility: 0.36937\n",
      "  batch 025 / 029 | loss: 0.68214 | error: 0.34687 | utility: 0.28533\n",
      "  batch 026 / 029 | loss: 0.67952 | error: 0.34615 | utility: 0.46723\n",
      "  batch 027 / 029 | loss: 0.68271 | error: 0.34549 | utility: 0.15035\n",
      "  batch 028 / 029 | loss: 0.68547 | error: 0.34654 | utility: 0.31368\n",
      "  batch 029 / 029 | loss: 0.69556 | error: 0.34752 | utility: -0.05380\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 008 / 010 | time: 039 sec | loss: 0.71353 | error: 0.32135 | utility: 0.30179\n",
      "Starting epoch 009 / 010.\n",
      "  batch 001 / 029 | loss: 0.59740 | error: 0.32812 | utility: 0.37339\n",
      "  batch 002 / 029 | loss: 0.63630 | error: 0.33594 | utility: 0.19166\n",
      "  batch 003 / 029 | loss: 0.66677 | error: 0.35417 | utility: 0.39192\n",
      "  batch 004 / 029 | loss: 0.65051 | error: 0.33984 | utility: 0.33132\n",
      "  batch 005 / 029 | loss: 0.68195 | error: 0.35313 | utility: 0.14837\n",
      "  batch 006 / 029 | loss: 0.65695 | error: 0.33854 | utility: 0.29375\n",
      "  batch 007 / 029 | loss: 0.65401 | error: 0.33036 | utility: 0.32255\n",
      "  batch 008 / 029 | loss: 0.65677 | error: 0.33789 | utility: 0.27825\n",
      "  batch 009 / 029 | loss: 0.64584 | error: 0.33160 | utility: 0.16494\n",
      "  batch 010 / 029 | loss: 0.66907 | error: 0.34219 | utility: 0.30333\n",
      "  batch 011 / 029 | loss: 0.67525 | error: 0.34801 | utility: 0.38094\n",
      "  batch 012 / 029 | loss: 0.67497 | error: 0.34896 | utility: 0.43218\n",
      "  batch 013 / 029 | loss: 0.68117 | error: 0.35337 | utility: 0.32497\n",
      "  batch 014 / 029 | loss: 0.68035 | error: 0.34933 | utility: 0.26068\n",
      "  batch 015 / 029 | loss: 0.67466 | error: 0.34687 | utility: 0.45333\n",
      "  batch 016 / 029 | loss: 0.67820 | error: 0.34473 | utility: 0.15308\n",
      "  batch 017 / 029 | loss: 0.67622 | error: 0.34651 | utility: 0.37238\n",
      "  batch 018 / 029 | loss: 0.67928 | error: 0.34722 | utility: 0.33255\n",
      "  batch 019 / 029 | loss: 0.67774 | error: 0.34457 | utility: 0.27051\n",
      "  batch 020 / 029 | loss: 0.66964 | error: 0.34141 | utility: 0.36026\n",
      "  batch 021 / 029 | loss: 0.67168 | error: 0.34301 | utility: 0.34094\n",
      "  batch 022 / 029 | loss: 0.67499 | error: 0.34517 | utility: 0.23504\n",
      "  batch 023 / 029 | loss: 0.67351 | error: 0.34375 | utility: 0.34176\n",
      "  batch 024 / 029 | loss: 0.67468 | error: 0.34375 | utility: 0.26868\n",
      "  batch 025 / 029 | loss: 0.67641 | error: 0.34563 | utility: 0.53344\n",
      "  batch 026 / 029 | loss: 0.67710 | error: 0.34615 | utility: 0.29585\n",
      "  batch 027 / 029 | loss: 0.68185 | error: 0.34954 | utility: 0.37488\n",
      "  batch 028 / 029 | loss: 0.68805 | error: 0.35156 | utility: 0.29244\n",
      "  batch 029 / 029 | loss: 0.67757 | error: 0.34806 | utility: 0.54500\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 009 / 010 | time: 040 sec | loss: 0.72985 | error: 0.32448 | utility: 0.28882\n",
      "Starting epoch 010 / 010.\n",
      "  batch 001 / 029 | loss: 0.68488 | error: 0.32812 | utility: 0.35760\n",
      "  batch 002 / 029 | loss: 0.75355 | error: 0.35938 | utility: 0.27847\n",
      "  batch 003 / 029 | loss: 0.66266 | error: 0.31771 | utility: 0.55079\n",
      "  batch 004 / 029 | loss: 0.66516 | error: 0.32422 | utility: 0.28508\n",
      "  batch 005 / 029 | loss: 0.67832 | error: 0.32812 | utility: 0.28540\n",
      "  batch 006 / 029 | loss: 0.64891 | error: 0.31771 | utility: 0.24065\n",
      "  batch 007 / 029 | loss: 0.64941 | error: 0.32143 | utility: 0.26651\n",
      "  batch 008 / 029 | loss: 0.64251 | error: 0.32422 | utility: 0.34088\n",
      "  batch 009 / 029 | loss: 0.63827 | error: 0.32986 | utility: 0.48382\n",
      "  batch 010 / 029 | loss: 0.64922 | error: 0.33437 | utility: 0.19130\n",
      "  batch 011 / 029 | loss: 0.63540 | error: 0.32670 | utility: 0.42800\n",
      "  batch 012 / 029 | loss: 0.65726 | error: 0.33464 | utility: 0.18051\n",
      "  batch 013 / 029 | loss: 0.66620 | error: 0.33774 | utility: 0.12165\n",
      "  batch 014 / 029 | loss: 0.66885 | error: 0.33482 | utility: 0.24616\n",
      "  batch 015 / 029 | loss: 0.67616 | error: 0.33750 | utility: 0.10800\n",
      "  batch 016 / 029 | loss: 0.68652 | error: 0.34082 | utility: 0.16901\n",
      "  batch 017 / 029 | loss: 0.69351 | error: 0.34191 | utility: 0.22136\n",
      "  batch 018 / 029 | loss: 0.68783 | error: 0.34028 | utility: 0.38872\n",
      "  batch 019 / 029 | loss: 0.68273 | error: 0.33882 | utility: 0.42582\n",
      "  batch 020 / 029 | loss: 0.67788 | error: 0.33828 | utility: 0.44036\n",
      "  batch 021 / 029 | loss: 0.67471 | error: 0.33854 | utility: 0.35045\n",
      "  batch 022 / 029 | loss: 0.67946 | error: 0.34091 | utility: 0.15675\n",
      "  batch 023 / 029 | loss: 0.67514 | error: 0.33696 | utility: 0.18738\n",
      "  batch 024 / 029 | loss: 0.67423 | error: 0.33789 | utility: 0.45235\n",
      "  batch 025 / 029 | loss: 0.67352 | error: 0.33875 | utility: 0.37001\n",
      "  batch 026 / 029 | loss: 0.67438 | error: 0.33774 | utility: 0.24866\n",
      "  batch 027 / 029 | loss: 0.67552 | error: 0.33796 | utility: 0.24205\n",
      "  batch 028 / 029 | loss: 0.68305 | error: 0.34208 | utility: 0.36130\n",
      "  batch 029 / 029 | loss: 0.69731 | error: 0.34752 | utility: 0.39258\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 010 / 010 | time: 041 sec | loss: 0.73269 | error: 0.32708 | utility: 0.28589\n",
      "Total training time: 7 minutes (405.5067141056061 seconds).\n",
      "Loading model from ./Results/utility/utility_0.350_model.pt.\n",
      "---------- Training with lambda=0.4 ----------\n",
      "Starting epoch 001 / 010.\n",
      "  batch 001 / 029 | loss: 0.69793 | error: 0.40625 | utility: 0.93142\n",
      "  batch 002 / 029 | loss: 0.67998 | error: 0.40625 | utility: 0.93357\n",
      "  batch 003 / 029 | loss: 0.72879 | error: 0.44792 | utility: 0.94148\n",
      "  batch 004 / 029 | loss: 0.72181 | error: 0.45312 | utility: 0.94602\n",
      "  batch 005 / 029 | loss: 0.70831 | error: 0.45312 | utility: 0.94816\n",
      "  batch 006 / 029 | loss: 0.71386 | error: 0.45833 | utility: 0.94626\n",
      "  batch 007 / 029 | loss: 0.72729 | error: 0.46875 | utility: 0.94238\n",
      "  batch 008 / 029 | loss: 0.74578 | error: 0.48047 | utility: 0.93644\n",
      "  batch 009 / 029 | loss: 0.77064 | error: 0.49653 | utility: 0.93732\n",
      "  batch 010 / 029 | loss: 0.76579 | error: 0.49531 | utility: 0.93678\n",
      "  batch 011 / 029 | loss: 0.75207 | error: 0.49006 | utility: 0.94271\n",
      "  batch 012 / 029 | loss: 0.76746 | error: 0.49870 | utility: 0.92200\n",
      "  batch 013 / 029 | loss: 0.75932 | error: 0.49519 | utility: 0.89077\n",
      "  batch 014 / 029 | loss: 0.76043 | error: 0.49888 | utility: 0.91006\n",
      "  batch 015 / 029 | loss: 0.74992 | error: 0.49375 | utility: 0.89267\n",
      "  batch 016 / 029 | loss: 0.74815 | error: 0.49219 | utility: 0.90885\n",
      "  batch 017 / 029 | loss: 0.74314 | error: 0.49265 | utility: 0.86007\n",
      "  batch 018 / 029 | loss: 0.74825 | error: 0.49826 | utility: 0.88073\n",
      "  batch 019 / 029 | loss: 0.75117 | error: 0.50247 | utility: 0.86697\n",
      "  batch 020 / 029 | loss: 0.75103 | error: 0.50391 | utility: 0.85163\n",
      "  batch 021 / 029 | loss: 0.74277 | error: 0.49926 | utility: 0.88210\n",
      "  batch 022 / 029 | loss: 0.73223 | error: 0.49290 | utility: 0.86469\n",
      "  batch 023 / 029 | loss: 0.72922 | error: 0.49117 | utility: 0.76372\n",
      "  batch 024 / 029 | loss: 0.72725 | error: 0.48958 | utility: 0.80003\n",
      "  batch 025 / 029 | loss: 0.72532 | error: 0.48688 | utility: 0.81792\n",
      "  batch 026 / 029 | loss: 0.72428 | error: 0.48438 | utility: 0.82751\n",
      "  batch 027 / 029 | loss: 0.72484 | error: 0.48438 | utility: 0.79945\n",
      "  batch 028 / 029 | loss: 0.72228 | error: 0.48382 | utility: 0.82958\n",
      "  batch 029 / 029 | loss: 0.71817 | error: 0.48438 | utility: 0.86944\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 001 / 010 | time: 028 sec | loss: 0.74532 | error: 0.49531 | utility: 0.86035\n",
      "Saving model to ./Results/utility/utility_0.400_model.pt.\n",
      "Starting epoch 002 / 010.\n",
      "  batch 001 / 029 | loss: 0.76778 | error: 0.46875 | utility: 0.77864\n",
      "  batch 002 / 029 | loss: 0.74253 | error: 0.49219 | utility: 0.78891\n",
      "  batch 003 / 029 | loss: 0.75438 | error: 0.49479 | utility: 0.78603\n",
      "  batch 004 / 029 | loss: 0.73250 | error: 0.47656 | utility: 0.80302\n",
      "  batch 005 / 029 | loss: 0.72432 | error: 0.48125 | utility: 0.78642\n",
      "  batch 006 / 029 | loss: 0.70749 | error: 0.47135 | utility: 0.75411\n",
      "  batch 007 / 029 | loss: 0.71689 | error: 0.49107 | utility: 0.66770\n",
      "  batch 008 / 029 | loss: 0.69098 | error: 0.47266 | utility: 0.80374\n",
      "  batch 009 / 029 | loss: 0.67514 | error: 0.46181 | utility: 0.72887\n",
      "  batch 010 / 029 | loss: 0.66168 | error: 0.44844 | utility: 0.74319\n",
      "  batch 011 / 029 | loss: 0.65897 | error: 0.44886 | utility: 0.82591\n",
      "  batch 012 / 029 | loss: 0.66570 | error: 0.45182 | utility: 0.67876\n",
      "  batch 013 / 029 | loss: 0.66866 | error: 0.44952 | utility: 0.59989\n",
      "  batch 014 / 029 | loss: 0.68252 | error: 0.45424 | utility: 0.73674\n",
      "  batch 015 / 029 | loss: 0.67048 | error: 0.44896 | utility: 0.78697\n",
      "  batch 016 / 029 | loss: 0.66430 | error: 0.44238 | utility: 0.64751\n",
      "  batch 017 / 029 | loss: 0.66329 | error: 0.44210 | utility: 0.73157\n",
      "  batch 018 / 029 | loss: 0.66561 | error: 0.44358 | utility: 0.77579\n",
      "  batch 019 / 029 | loss: 0.67071 | error: 0.44408 | utility: 0.63408\n",
      "  batch 020 / 029 | loss: 0.66718 | error: 0.43906 | utility: 0.62066\n",
      "  batch 021 / 029 | loss: 0.68307 | error: 0.44494 | utility: 0.68039\n",
      "  batch 022 / 029 | loss: 0.68222 | error: 0.44389 | utility: 0.65930\n",
      "  batch 023 / 029 | loss: 0.67960 | error: 0.44293 | utility: 0.74771\n",
      "  batch 024 / 029 | loss: 0.68074 | error: 0.44206 | utility: 0.70512\n",
      "  batch 025 / 029 | loss: 0.68500 | error: 0.44188 | utility: 0.62667\n",
      "  batch 026 / 029 | loss: 0.68128 | error: 0.43810 | utility: 0.63833\n",
      "  batch 027 / 029 | loss: 0.68167 | error: 0.43808 | utility: 0.70790\n",
      "  batch 028 / 029 | loss: 0.68170 | error: 0.43806 | utility: 0.77513\n",
      "  batch 029 / 029 | loss: 0.67793 | error: 0.43588 | utility: 0.71570\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 002 / 010 | time: 031 sec | loss: 0.75027 | error: 0.46667 | utility: 0.76922\n",
      "Validation accuracy improved.\n",
      "Saving model to ./Results/utility/utility_0.400_model.pt.\n",
      "Starting epoch 003 / 010.\n",
      "  batch 001 / 029 | loss: 0.86872 | error: 0.51562 | utility: 0.64618\n",
      "  batch 002 / 029 | loss: 0.75828 | error: 0.45312 | utility: 0.62977\n",
      "  batch 003 / 029 | loss: 0.69987 | error: 0.42708 | utility: 0.65225\n",
      "  batch 004 / 029 | loss: 0.69144 | error: 0.42188 | utility: 0.70074\n",
      "  batch 005 / 029 | loss: 0.68277 | error: 0.41250 | utility: 0.63915\n",
      "  batch 006 / 029 | loss: 0.70216 | error: 0.41927 | utility: 0.62377\n",
      "  batch 007 / 029 | loss: 0.67447 | error: 0.39732 | utility: 0.63035\n",
      "  batch 008 / 029 | loss: 0.69429 | error: 0.41211 | utility: 0.65945\n",
      "  batch 009 / 029 | loss: 0.67687 | error: 0.39583 | utility: 0.49126\n",
      "  batch 010 / 029 | loss: 0.67487 | error: 0.39531 | utility: 0.61393\n",
      "  batch 011 / 029 | loss: 0.68039 | error: 0.40341 | utility: 0.60683\n",
      "  batch 012 / 029 | loss: 0.68718 | error: 0.40365 | utility: 0.53470\n",
      "  batch 013 / 029 | loss: 0.69185 | error: 0.40264 | utility: 0.47176\n",
      "  batch 014 / 029 | loss: 0.68094 | error: 0.39732 | utility: 0.66960\n",
      "  batch 015 / 029 | loss: 0.68216 | error: 0.39896 | utility: 0.56477\n",
      "  batch 016 / 029 | loss: 0.68814 | error: 0.40137 | utility: 0.63197\n",
      "  batch 017 / 029 | loss: 0.68733 | error: 0.40257 | utility: 0.67887\n",
      "  batch 018 / 029 | loss: 0.69193 | error: 0.40365 | utility: 0.45143\n",
      "  batch 019 / 029 | loss: 0.70259 | error: 0.40954 | utility: 0.65528\n",
      "  batch 020 / 029 | loss: 0.70031 | error: 0.40859 | utility: 0.75378\n",
      "  batch 021 / 029 | loss: 0.69483 | error: 0.40551 | utility: 0.54513\n",
      "  batch 022 / 029 | loss: 0.69457 | error: 0.40483 | utility: 0.62886\n",
      "  batch 023 / 029 | loss: 0.69005 | error: 0.40217 | utility: 0.70266\n",
      "  batch 024 / 029 | loss: 0.69323 | error: 0.40430 | utility: 0.59631\n",
      "  batch 025 / 029 | loss: 0.68955 | error: 0.39937 | utility: 0.61402\n",
      "  batch 026 / 029 | loss: 0.69013 | error: 0.40024 | utility: 0.66020\n",
      "  batch 027 / 029 | loss: 0.68696 | error: 0.39641 | utility: 0.56058\n",
      "  batch 028 / 029 | loss: 0.68127 | error: 0.39174 | utility: 0.57127\n",
      "  batch 029 / 029 | loss: 0.66888 | error: 0.39116 | utility: 0.72731\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 003 / 010 | time: 033 sec | loss: 0.75995 | error: 0.45208 | utility: 0.73705\n",
      "Validation accuracy improved.\n",
      "Saving model to ./Results/utility/utility_0.400_model.pt.\n",
      "Starting epoch 004 / 010.\n",
      "  batch 001 / 029 | loss: 0.73669 | error: 0.42188 | utility: 0.60678\n",
      "  batch 002 / 029 | loss: 0.73504 | error: 0.41406 | utility: 0.62002\n",
      "  batch 003 / 029 | loss: 0.66145 | error: 0.38021 | utility: 0.57724\n",
      "  batch 004 / 029 | loss: 0.62635 | error: 0.35938 | utility: 0.65892\n",
      "  batch 005 / 029 | loss: 0.64117 | error: 0.37500 | utility: 0.58308\n",
      "  batch 006 / 029 | loss: 0.64311 | error: 0.36458 | utility: 0.51873\n",
      "  batch 007 / 029 | loss: 0.64187 | error: 0.37277 | utility: 0.63188\n",
      "  batch 008 / 029 | loss: 0.64207 | error: 0.37500 | utility: 0.60159\n",
      "  batch 009 / 029 | loss: 0.66898 | error: 0.39410 | utility: 0.60858\n",
      "  batch 010 / 029 | loss: 0.64875 | error: 0.38594 | utility: 0.63431\n",
      "  batch 011 / 029 | loss: 0.65895 | error: 0.38920 | utility: 0.59846\n",
      "  batch 012 / 029 | loss: 0.67185 | error: 0.39974 | utility: 0.57440\n",
      "  batch 013 / 029 | loss: 0.65865 | error: 0.39303 | utility: 0.61434\n",
      "  batch 014 / 029 | loss: 0.65658 | error: 0.39062 | utility: 0.59455\n",
      "  batch 015 / 029 | loss: 0.65592 | error: 0.38958 | utility: 0.66885\n",
      "  batch 016 / 029 | loss: 0.66607 | error: 0.39648 | utility: 0.67080\n",
      "  batch 017 / 029 | loss: 0.67363 | error: 0.40165 | utility: 0.64091\n",
      "  batch 018 / 029 | loss: 0.67384 | error: 0.39844 | utility: 0.53424\n",
      "  batch 019 / 029 | loss: 0.67615 | error: 0.39803 | utility: 0.62443\n",
      "  batch 020 / 029 | loss: 0.67774 | error: 0.39687 | utility: 0.55630\n",
      "  batch 021 / 029 | loss: 0.67462 | error: 0.39732 | utility: 0.66860\n",
      "  batch 022 / 029 | loss: 0.67730 | error: 0.39773 | utility: 0.62406\n",
      "  batch 023 / 029 | loss: 0.68161 | error: 0.39946 | utility: 0.62241\n",
      "  batch 024 / 029 | loss: 0.68491 | error: 0.40104 | utility: 0.63358\n",
      "  batch 025 / 029 | loss: 0.68181 | error: 0.39937 | utility: 0.68474\n",
      "  batch 026 / 029 | loss: 0.68164 | error: 0.39904 | utility: 0.60276\n",
      "  batch 027 / 029 | loss: 0.68197 | error: 0.39815 | utility: 0.53298\n",
      "  batch 028 / 029 | loss: 0.68142 | error: 0.39676 | utility: 0.49826\n",
      "  batch 029 / 029 | loss: 0.67861 | error: 0.39170 | utility: 0.31592\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 004 / 010 | time: 034 sec | loss: 0.76083 | error: 0.44010 | utility: 0.70535\n",
      "Validation accuracy improved.\n",
      "Saving model to ./Results/utility/utility_0.400_model.pt.\n",
      "Starting epoch 005 / 010.\n",
      "  batch 001 / 029 | loss: 0.79297 | error: 0.48438 | utility: 0.57748\n",
      "  batch 002 / 029 | loss: 0.75502 | error: 0.45312 | utility: 0.58701\n",
      "  batch 003 / 029 | loss: 0.73060 | error: 0.43229 | utility: 0.60365\n",
      "  batch 004 / 029 | loss: 0.71968 | error: 0.42969 | utility: 0.54884\n",
      "  batch 005 / 029 | loss: 0.72556 | error: 0.43125 | utility: 0.51179\n",
      "  batch 006 / 029 | loss: 0.68629 | error: 0.40104 | utility: 0.60759\n",
      "  batch 007 / 029 | loss: 0.68659 | error: 0.40179 | utility: 0.54409\n",
      "  batch 008 / 029 | loss: 0.68258 | error: 0.40234 | utility: 0.64732\n",
      "  batch 009 / 029 | loss: 0.69063 | error: 0.40625 | utility: 0.66056\n",
      "  batch 010 / 029 | loss: 0.68905 | error: 0.40781 | utility: 0.62252\n",
      "  batch 011 / 029 | loss: 0.69253 | error: 0.41051 | utility: 0.70186\n",
      "  batch 012 / 029 | loss: 0.68701 | error: 0.40495 | utility: 0.60564\n",
      "  batch 013 / 029 | loss: 0.67739 | error: 0.40264 | utility: 0.67613\n",
      "  batch 014 / 029 | loss: 0.69088 | error: 0.41071 | utility: 0.51174\n",
      "  batch 015 / 029 | loss: 0.68613 | error: 0.40625 | utility: 0.59623\n",
      "  batch 016 / 029 | loss: 0.68574 | error: 0.40234 | utility: 0.56371\n",
      "  batch 017 / 029 | loss: 0.68345 | error: 0.40074 | utility: 0.63711\n",
      "  batch 018 / 029 | loss: 0.68336 | error: 0.40017 | utility: 0.54194\n",
      "  batch 019 / 029 | loss: 0.68661 | error: 0.40132 | utility: 0.54839\n",
      "  batch 020 / 029 | loss: 0.68235 | error: 0.39766 | utility: 0.54299\n",
      "  batch 021 / 029 | loss: 0.68204 | error: 0.39881 | utility: 0.60305\n",
      "  batch 022 / 029 | loss: 0.68088 | error: 0.39915 | utility: 0.59684\n",
      "  batch 023 / 029 | loss: 0.67569 | error: 0.39538 | utility: 0.47590\n",
      "  batch 024 / 029 | loss: 0.67886 | error: 0.39779 | utility: 0.67154\n",
      "  batch 025 / 029 | loss: 0.67889 | error: 0.39563 | utility: 0.52593\n",
      "  batch 026 / 029 | loss: 0.68277 | error: 0.39784 | utility: 0.63209\n",
      "  batch 027 / 029 | loss: 0.68145 | error: 0.39815 | utility: 0.58615\n",
      "  batch 028 / 029 | loss: 0.67978 | error: 0.39565 | utility: 0.62525\n",
      "  batch 029 / 029 | loss: 0.67900 | error: 0.39062 | utility: 0.29056\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 005 / 010 | time: 032 sec | loss: 0.74788 | error: 0.42760 | utility: 0.68764\n",
      "Validation accuracy improved.\n",
      "Saving model to ./Results/utility/utility_0.400_model.pt.\n",
      "Starting epoch 006 / 010.\n",
      "  batch 001 / 029 | loss: 0.61524 | error: 0.34375 | utility: 0.56641\n",
      "  batch 002 / 029 | loss: 0.71788 | error: 0.37500 | utility: 0.43782\n",
      "  batch 003 / 029 | loss: 0.70339 | error: 0.38542 | utility: 0.65186\n",
      "  batch 004 / 029 | loss: 0.74970 | error: 0.42188 | utility: 0.56663\n",
      "  batch 005 / 029 | loss: 0.71437 | error: 0.40625 | utility: 0.44163\n",
      "  batch 006 / 029 | loss: 0.70183 | error: 0.38542 | utility: 0.32895\n",
      "  batch 007 / 029 | loss: 0.69104 | error: 0.37277 | utility: 0.51153\n",
      "  batch 008 / 029 | loss: 0.69093 | error: 0.37500 | utility: 0.51676\n",
      "  batch 009 / 029 | loss: 0.67685 | error: 0.36806 | utility: 0.54587\n",
      "  batch 010 / 029 | loss: 0.67142 | error: 0.36875 | utility: 0.68775\n",
      "  batch 011 / 029 | loss: 0.68472 | error: 0.37926 | utility: 0.70689\n",
      "  batch 012 / 029 | loss: 0.67124 | error: 0.37240 | utility: 0.58761\n",
      "  batch 013 / 029 | loss: 0.67533 | error: 0.37380 | utility: 0.49753\n",
      "  batch 014 / 029 | loss: 0.67745 | error: 0.37723 | utility: 0.63580\n",
      "  batch 015 / 029 | loss: 0.66896 | error: 0.37396 | utility: 0.53711\n",
      "  batch 016 / 029 | loss: 0.68287 | error: 0.38184 | utility: 0.44828\n",
      "  batch 017 / 029 | loss: 0.68684 | error: 0.38511 | utility: 0.56503\n",
      "  batch 018 / 029 | loss: 0.68282 | error: 0.38455 | utility: 0.58835\n",
      "  batch 019 / 029 | loss: 0.68754 | error: 0.38487 | utility: 0.39798\n",
      "  batch 020 / 029 | loss: 0.69377 | error: 0.38672 | utility: 0.51866\n",
      "  batch 021 / 029 | loss: 0.68591 | error: 0.38393 | utility: 0.60015\n",
      "  batch 022 / 029 | loss: 0.68039 | error: 0.38068 | utility: 0.55794\n",
      "  batch 023 / 029 | loss: 0.67746 | error: 0.37908 | utility: 0.65229\n",
      "  batch 024 / 029 | loss: 0.67493 | error: 0.37760 | utility: 0.53067\n",
      "  batch 025 / 029 | loss: 0.67646 | error: 0.37875 | utility: 0.57767\n",
      "  batch 026 / 029 | loss: 0.67326 | error: 0.37800 | utility: 0.56991\n",
      "  batch 027 / 029 | loss: 0.67588 | error: 0.37905 | utility: 0.56108\n",
      "  batch 028 / 029 | loss: 0.68181 | error: 0.38170 | utility: 0.42160\n",
      "  batch 029 / 029 | loss: 0.69406 | error: 0.38578 | utility: 0.45290\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 006 / 010 | time: 034 sec | loss: 0.68714 | error: 0.38698 | utility: 0.60047\n",
      "Validation accuracy improved.\n",
      "Saving model to ./Results/utility/utility_0.400_model.pt.\n",
      "Starting epoch 007 / 010.\n",
      "  batch 001 / 029 | loss: 0.80351 | error: 0.43750 | utility: 0.54755\n",
      "  batch 002 / 029 | loss: 0.82321 | error: 0.46094 | utility: 0.57169\n",
      "  batch 003 / 029 | loss: 0.83440 | error: 0.46875 | utility: 0.62427\n",
      "  batch 004 / 029 | loss: 0.78007 | error: 0.43750 | utility: 0.51260\n",
      "  batch 005 / 029 | loss: 0.72426 | error: 0.40625 | utility: 0.62543\n",
      "  batch 006 / 029 | loss: 0.71085 | error: 0.39844 | utility: 0.47573\n",
      "  batch 007 / 029 | loss: 0.69498 | error: 0.39286 | utility: 0.66187\n",
      "  batch 008 / 029 | loss: 0.69478 | error: 0.39648 | utility: 0.53437\n",
      "  batch 009 / 029 | loss: 0.69228 | error: 0.39583 | utility: 0.54675\n",
      "  batch 010 / 029 | loss: 0.68694 | error: 0.39375 | utility: 0.63902\n",
      "  batch 011 / 029 | loss: 0.68999 | error: 0.39631 | utility: 0.64262\n",
      "  batch 012 / 029 | loss: 0.68240 | error: 0.39062 | utility: 0.47089\n",
      "  batch 013 / 029 | loss: 0.67335 | error: 0.38582 | utility: 0.54543\n",
      "  batch 014 / 029 | loss: 0.67347 | error: 0.38504 | utility: 0.61895\n",
      "  batch 015 / 029 | loss: 0.66982 | error: 0.38333 | utility: 0.59293\n",
      "  batch 016 / 029 | loss: 0.67034 | error: 0.38281 | utility: 0.50589\n",
      "  batch 017 / 029 | loss: 0.66588 | error: 0.38143 | utility: 0.61265\n",
      "  batch 018 / 029 | loss: 0.66992 | error: 0.38281 | utility: 0.61868\n",
      "  batch 019 / 029 | loss: 0.67783 | error: 0.38651 | utility: 0.52643\n",
      "  batch 020 / 029 | loss: 0.68218 | error: 0.39219 | utility: 0.64470\n",
      "  batch 021 / 029 | loss: 0.68597 | error: 0.39509 | utility: 0.58884\n",
      "  batch 022 / 029 | loss: 0.68645 | error: 0.39489 | utility: 0.58088\n",
      "  batch 023 / 029 | loss: 0.68782 | error: 0.39402 | utility: 0.61479\n",
      "  batch 024 / 029 | loss: 0.68949 | error: 0.39714 | utility: 0.70993\n",
      "  batch 025 / 029 | loss: 0.68949 | error: 0.39687 | utility: 0.52624\n",
      "  batch 026 / 029 | loss: 0.68374 | error: 0.39002 | utility: 0.47429\n",
      "  batch 027 / 029 | loss: 0.68106 | error: 0.39062 | utility: 0.70138\n",
      "  batch 028 / 029 | loss: 0.68314 | error: 0.39007 | utility: 0.55319\n",
      "  batch 029 / 029 | loss: 0.69050 | error: 0.39817 | utility: 0.64690\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 007 / 010 | time: 034 sec | loss: 0.75948 | error: 0.44219 | utility: 0.70942\n",
      "Starting epoch 008 / 010.\n",
      "  batch 001 / 029 | loss: 0.72375 | error: 0.40625 | utility: 0.63942\n",
      "  batch 002 / 029 | loss: 0.64823 | error: 0.38281 | utility: 0.67180\n",
      "  batch 003 / 029 | loss: 0.69409 | error: 0.42188 | utility: 0.64690\n",
      "  batch 004 / 029 | loss: 0.63372 | error: 0.38672 | utility: 0.76103\n",
      "  batch 005 / 029 | loss: 0.64574 | error: 0.38125 | utility: 0.46321\n",
      "  batch 006 / 029 | loss: 0.67727 | error: 0.40365 | utility: 0.52607\n",
      "  batch 007 / 029 | loss: 0.69889 | error: 0.41964 | utility: 0.54584\n",
      "  batch 008 / 029 | loss: 0.70236 | error: 0.41797 | utility: 0.55115\n",
      "  batch 009 / 029 | loss: 0.70221 | error: 0.41319 | utility: 0.53143\n",
      "  batch 010 / 029 | loss: 0.70100 | error: 0.41250 | utility: 0.47429\n",
      "  batch 011 / 029 | loss: 0.71477 | error: 0.41619 | utility: 0.52863\n",
      "  batch 012 / 029 | loss: 0.71437 | error: 0.41667 | utility: 0.53753\n",
      "  batch 013 / 029 | loss: 0.70528 | error: 0.40385 | utility: 0.53096\n",
      "  batch 014 / 029 | loss: 0.69638 | error: 0.39955 | utility: 0.66693\n",
      "  batch 015 / 029 | loss: 0.69841 | error: 0.40208 | utility: 0.63145\n",
      "  batch 016 / 029 | loss: 0.69629 | error: 0.40137 | utility: 0.60201\n",
      "  batch 017 / 029 | loss: 0.70456 | error: 0.40625 | utility: 0.60921\n",
      "  batch 018 / 029 | loss: 0.71006 | error: 0.41059 | utility: 0.57882\n",
      "  batch 019 / 029 | loss: 0.70452 | error: 0.40789 | utility: 0.59572\n",
      "  batch 020 / 029 | loss: 0.70488 | error: 0.40781 | utility: 0.65252\n",
      "  batch 021 / 029 | loss: 0.69870 | error: 0.40476 | utility: 0.69043\n",
      "  batch 022 / 029 | loss: 0.68545 | error: 0.39773 | utility: 0.53879\n",
      "  batch 023 / 029 | loss: 0.68343 | error: 0.39674 | utility: 0.61389\n",
      "  batch 024 / 029 | loss: 0.67741 | error: 0.39453 | utility: 0.59183\n",
      "  batch 025 / 029 | loss: 0.67667 | error: 0.39250 | utility: 0.53992\n",
      "  batch 026 / 029 | loss: 0.67418 | error: 0.39183 | utility: 0.66560\n",
      "  batch 027 / 029 | loss: 0.67843 | error: 0.39178 | utility: 0.45149\n",
      "  batch 028 / 029 | loss: 0.68090 | error: 0.39230 | utility: 0.55161\n",
      "  batch 029 / 029 | loss: 0.68714 | error: 0.39601 | utility: 0.30493\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 008 / 010 | time: 032 sec | loss: 0.72687 | error: 0.41823 | utility: 0.65868\n",
      "Starting epoch 009 / 010.\n",
      "  batch 001 / 029 | loss: 0.60472 | error: 0.37500 | utility: 0.54423\n",
      "  batch 002 / 029 | loss: 0.65143 | error: 0.41406 | utility: 0.53937\n",
      "  batch 003 / 029 | loss: 0.65870 | error: 0.40625 | utility: 0.62716\n",
      "  batch 004 / 029 | loss: 0.63682 | error: 0.37109 | utility: 0.58883\n",
      "  batch 005 / 029 | loss: 0.67925 | error: 0.39687 | utility: 0.48266\n",
      "  batch 006 / 029 | loss: 0.65606 | error: 0.38542 | utility: 0.59162\n",
      "  batch 007 / 029 | loss: 0.64888 | error: 0.37946 | utility: 0.56757\n",
      "  batch 008 / 029 | loss: 0.65415 | error: 0.38281 | utility: 0.52740\n",
      "  batch 009 / 029 | loss: 0.64674 | error: 0.37500 | utility: 0.50897\n",
      "  batch 010 / 029 | loss: 0.66676 | error: 0.38594 | utility: 0.61331\n",
      "  batch 011 / 029 | loss: 0.66566 | error: 0.38636 | utility: 0.63379\n",
      "  batch 012 / 029 | loss: 0.66345 | error: 0.38542 | utility: 0.68557\n",
      "  batch 013 / 029 | loss: 0.66675 | error: 0.38822 | utility: 0.61890\n",
      "  batch 014 / 029 | loss: 0.66631 | error: 0.38504 | utility: 0.56247\n",
      "  batch 015 / 029 | loss: 0.65944 | error: 0.38125 | utility: 0.70049\n",
      "  batch 016 / 029 | loss: 0.66755 | error: 0.38281 | utility: 0.45211\n",
      "  batch 017 / 029 | loss: 0.66670 | error: 0.38327 | utility: 0.59186\n",
      "  batch 018 / 029 | loss: 0.66986 | error: 0.38628 | utility: 0.62472\n",
      "  batch 019 / 029 | loss: 0.67046 | error: 0.38569 | utility: 0.56765\n",
      "  batch 020 / 029 | loss: 0.66345 | error: 0.38281 | utility: 0.62539\n",
      "  batch 021 / 029 | loss: 0.66426 | error: 0.38021 | utility: 0.61373\n",
      "  batch 022 / 029 | loss: 0.66684 | error: 0.38210 | utility: 0.52051\n",
      "  batch 023 / 029 | loss: 0.66567 | error: 0.38247 | utility: 0.66548\n",
      "  batch 024 / 029 | loss: 0.66462 | error: 0.38411 | utility: 0.61955\n",
      "  batch 025 / 029 | loss: 0.66637 | error: 0.38688 | utility: 0.76772\n",
      "  batch 026 / 029 | loss: 0.66909 | error: 0.38822 | utility: 0.61732\n",
      "  batch 027 / 029 | loss: 0.67424 | error: 0.39120 | utility: 0.65567\n",
      "  batch 028 / 029 | loss: 0.68235 | error: 0.39565 | utility: 0.60991\n",
      "  batch 029 / 029 | loss: 0.67284 | error: 0.39062 | utility: 0.75308\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 009 / 010 | time: 033 sec | loss: 0.75963 | error: 0.44740 | utility: 0.71219\n",
      "Starting epoch 010 / 010.\n",
      "  batch 001 / 029 | loss: 0.68988 | error: 0.40625 | utility: 0.61047\n",
      "  batch 002 / 029 | loss: 0.72591 | error: 0.42188 | utility: 0.63573\n",
      "  batch 003 / 029 | loss: 0.62896 | error: 0.36458 | utility: 0.76086\n",
      "  batch 004 / 029 | loss: 0.64299 | error: 0.37891 | utility: 0.64444\n",
      "  batch 005 / 029 | loss: 0.66075 | error: 0.39375 | utility: 0.60443\n",
      "  batch 006 / 029 | loss: 0.64117 | error: 0.38281 | utility: 0.59376\n",
      "  batch 007 / 029 | loss: 0.64179 | error: 0.38170 | utility: 0.55571\n",
      "  batch 008 / 029 | loss: 0.63753 | error: 0.38086 | utility: 0.61451\n",
      "  batch 009 / 029 | loss: 0.63765 | error: 0.38368 | utility: 0.69114\n",
      "  batch 010 / 029 | loss: 0.65354 | error: 0.38750 | utility: 0.53189\n",
      "  batch 011 / 029 | loss: 0.63758 | error: 0.37784 | utility: 0.69342\n",
      "  batch 012 / 029 | loss: 0.66193 | error: 0.38411 | utility: 0.50197\n",
      "  batch 013 / 029 | loss: 0.67035 | error: 0.38822 | utility: 0.49538\n",
      "  batch 014 / 029 | loss: 0.67229 | error: 0.38616 | utility: 0.55806\n",
      "  batch 015 / 029 | loss: 0.67785 | error: 0.38542 | utility: 0.45370\n",
      "  batch 016 / 029 | loss: 0.68777 | error: 0.39160 | utility: 0.52812\n",
      "  batch 017 / 029 | loss: 0.69854 | error: 0.39798 | utility: 0.55040\n",
      "  batch 018 / 029 | loss: 0.69187 | error: 0.39670 | utility: 0.62656\n",
      "  batch 019 / 029 | loss: 0.68567 | error: 0.39391 | utility: 0.69047\n",
      "  batch 020 / 029 | loss: 0.68011 | error: 0.39219 | utility: 0.66705\n",
      "  batch 021 / 029 | loss: 0.67875 | error: 0.39286 | utility: 0.62680\n",
      "  batch 022 / 029 | loss: 0.68242 | error: 0.39489 | utility: 0.52785\n",
      "  batch 023 / 029 | loss: 0.67724 | error: 0.39402 | utility: 0.56848\n",
      "  batch 024 / 029 | loss: 0.67582 | error: 0.39388 | utility: 0.69166\n",
      "  batch 025 / 029 | loss: 0.67396 | error: 0.39313 | utility: 0.64980\n",
      "  batch 026 / 029 | loss: 0.67320 | error: 0.39062 | utility: 0.52998\n",
      "  batch 027 / 029 | loss: 0.67513 | error: 0.39062 | utility: 0.48508\n",
      "  batch 028 / 029 | loss: 0.68127 | error: 0.39509 | utility: 0.57841\n",
      "  batch 029 / 029 | loss: 0.69633 | error: 0.40302 | utility: 0.65876\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 010 / 010 | time: 033 sec | loss: 0.74357 | error: 0.42396 | utility: 0.67326\n",
      "Total training time: 5 minutes (323.201256275177 seconds).\n",
      "Loading model from ./Results/utility/utility_0.400_model.pt.\n",
      "---------- Training with lambda=0.45 ----------\n",
      "Starting epoch 001 / 010.\n",
      "  batch 001 / 029 | loss: 0.67587 | error: 0.40625 | utility: 0.93142\n",
      "  batch 002 / 029 | loss: 0.65702 | error: 0.40625 | utility: 0.93357\n",
      "  batch 003 / 029 | loss: 0.70488 | error: 0.44792 | utility: 0.94137\n",
      "  batch 004 / 029 | loss: 0.69705 | error: 0.45312 | utility: 0.94590\n",
      "  batch 005 / 029 | loss: 0.68295 | error: 0.45312 | utility: 0.94817\n",
      "  batch 006 / 029 | loss: 0.68818 | error: 0.45833 | utility: 0.94646\n",
      "  batch 007 / 029 | loss: 0.70162 | error: 0.46875 | utility: 0.94304\n",
      "  batch 008 / 029 | loss: 0.72023 | error: 0.48047 | utility: 0.93765\n",
      "  batch 009 / 029 | loss: 0.74562 | error: 0.49653 | utility: 0.93913\n",
      "  batch 010 / 029 | loss: 0.74078 | error: 0.49531 | utility: 0.93952\n",
      "  batch 011 / 029 | loss: 0.72702 | error: 0.49006 | utility: 0.94534\n",
      "  batch 012 / 029 | loss: 0.74287 | error: 0.49870 | utility: 0.92815\n",
      "  batch 013 / 029 | loss: 0.73475 | error: 0.49519 | utility: 0.89802\n",
      "  batch 014 / 029 | loss: 0.73637 | error: 0.49888 | utility: 0.91982\n",
      "  batch 015 / 029 | loss: 0.72582 | error: 0.49375 | utility: 0.90620\n",
      "  batch 016 / 029 | loss: 0.72408 | error: 0.49219 | utility: 0.91930\n",
      "  batch 017 / 029 | loss: 0.71938 | error: 0.49265 | utility: 0.87948\n",
      "  batch 018 / 029 | loss: 0.72510 | error: 0.49826 | utility: 0.89794\n",
      "  batch 019 / 029 | loss: 0.72851 | error: 0.50247 | utility: 0.88801\n",
      "  batch 020 / 029 | loss: 0.72886 | error: 0.50469 | utility: 0.87808\n",
      "  batch 021 / 029 | loss: 0.72025 | error: 0.50000 | utility: 0.90394\n",
      "  batch 022 / 029 | loss: 0.70926 | error: 0.49361 | utility: 0.89181\n",
      "  batch 023 / 029 | loss: 0.70618 | error: 0.49253 | utility: 0.81233\n",
      "  batch 024 / 029 | loss: 0.70437 | error: 0.49219 | utility: 0.84750\n",
      "  batch 025 / 029 | loss: 0.70224 | error: 0.49062 | utility: 0.85835\n",
      "  batch 026 / 029 | loss: 0.70098 | error: 0.48858 | utility: 0.86069\n",
      "  batch 027 / 029 | loss: 0.70130 | error: 0.48900 | utility: 0.84398\n",
      "  batch 028 / 029 | loss: 0.69880 | error: 0.48884 | utility: 0.86774\n",
      "  batch 029 / 029 | loss: 0.69525 | error: 0.48922 | utility: 0.89020\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 001 / 010 | time: 026 sec | loss: 0.71150 | error: 0.49688 | utility: 0.88901\n",
      "Saving model to ./Results/utility/utility_0.450_model.pt.\n",
      "Starting epoch 002 / 010.\n",
      "  batch 001 / 029 | loss: 0.74732 | error: 0.51562 | utility: 0.83339\n",
      "  batch 002 / 029 | loss: 0.72215 | error: 0.51562 | utility: 0.83787\n",
      "  batch 003 / 029 | loss: 0.73270 | error: 0.51042 | utility: 0.83031\n",
      "  batch 004 / 029 | loss: 0.71061 | error: 0.49609 | utility: 0.85615\n",
      "  batch 005 / 029 | loss: 0.70371 | error: 0.50000 | utility: 0.84682\n",
      "  batch 006 / 029 | loss: 0.68806 | error: 0.48958 | utility: 0.80508\n",
      "  batch 007 / 029 | loss: 0.69878 | error: 0.50446 | utility: 0.77353\n",
      "  batch 008 / 029 | loss: 0.67208 | error: 0.48828 | utility: 0.85514\n",
      "  batch 009 / 029 | loss: 0.65573 | error: 0.48090 | utility: 0.80186\n",
      "  batch 010 / 029 | loss: 0.64099 | error: 0.46875 | utility: 0.81455\n",
      "  batch 011 / 029 | loss: 0.63807 | error: 0.46733 | utility: 0.87809\n",
      "  batch 012 / 029 | loss: 0.64599 | error: 0.47135 | utility: 0.77667\n",
      "  batch 013 / 029 | loss: 0.64986 | error: 0.46995 | utility: 0.69555\n",
      "  batch 014 / 029 | loss: 0.66305 | error: 0.47433 | utility: 0.82170\n",
      "  batch 015 / 029 | loss: 0.65008 | error: 0.46667 | utility: 0.84865\n",
      "  batch 016 / 029 | loss: 0.64384 | error: 0.45996 | utility: 0.71938\n",
      "  batch 017 / 029 | loss: 0.64289 | error: 0.45956 | utility: 0.81826\n",
      "  batch 018 / 029 | loss: 0.64530 | error: 0.46181 | utility: 0.85090\n",
      "  batch 019 / 029 | loss: 0.65102 | error: 0.46628 | utility: 0.74189\n",
      "  batch 020 / 029 | loss: 0.64707 | error: 0.46250 | utility: 0.71498\n",
      "  batch 021 / 029 | loss: 0.66331 | error: 0.46949 | utility: 0.78507\n",
      "  batch 022 / 029 | loss: 0.66291 | error: 0.46946 | utility: 0.76081\n",
      "  batch 023 / 029 | loss: 0.66037 | error: 0.46875 | utility: 0.82867\n",
      "  batch 024 / 029 | loss: 0.66101 | error: 0.46745 | utility: 0.80408\n",
      "  batch 025 / 029 | loss: 0.66573 | error: 0.47063 | utility: 0.75275\n",
      "  batch 026 / 029 | loss: 0.66223 | error: 0.46815 | utility: 0.75111\n",
      "  batch 027 / 029 | loss: 0.66268 | error: 0.46817 | utility: 0.79542\n",
      "  batch 028 / 029 | loss: 0.66263 | error: 0.46763 | utility: 0.83986\n",
      "  batch 029 / 029 | loss: 0.65953 | error: 0.46875 | utility: 0.81820\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 002 / 010 | time: 030 sec | loss: 0.71955 | error: 0.48854 | utility: 0.84569\n",
      "Validation accuracy improved.\n",
      "Saving model to ./Results/utility/utility_0.450_model.pt.\n",
      "Starting epoch 003 / 010.\n",
      "  batch 001 / 029 | loss: 0.85726 | error: 0.54688 | utility: 0.75139\n",
      "  batch 002 / 029 | loss: 0.74308 | error: 0.48438 | utility: 0.74564\n",
      "  batch 003 / 029 | loss: 0.68585 | error: 0.45833 | utility: 0.75579\n",
      "  batch 004 / 029 | loss: 0.67376 | error: 0.45312 | utility: 0.80090\n",
      "  batch 005 / 029 | loss: 0.66697 | error: 0.45625 | utility: 0.74898\n",
      "  batch 006 / 029 | loss: 0.68766 | error: 0.47135 | utility: 0.75326\n",
      "  batch 007 / 029 | loss: 0.65888 | error: 0.45312 | utility: 0.73422\n",
      "  batch 008 / 029 | loss: 0.67939 | error: 0.46289 | utility: 0.75576\n",
      "  batch 009 / 029 | loss: 0.66229 | error: 0.45139 | utility: 0.65841\n",
      "  batch 010 / 029 | loss: 0.65954 | error: 0.44688 | utility: 0.72953\n",
      "  batch 011 / 029 | loss: 0.66609 | error: 0.45455 | utility: 0.72623\n",
      "  batch 012 / 029 | loss: 0.67245 | error: 0.45573 | utility: 0.69253\n",
      "  batch 013 / 029 | loss: 0.67851 | error: 0.46154 | utility: 0.63616\n",
      "  batch 014 / 029 | loss: 0.66743 | error: 0.45424 | utility: 0.76852\n",
      "  batch 015 / 029 | loss: 0.66760 | error: 0.45312 | utility: 0.70150\n",
      "  batch 016 / 029 | loss: 0.67325 | error: 0.45508 | utility: 0.74118\n",
      "  batch 017 / 029 | loss: 0.67167 | error: 0.45404 | utility: 0.76267\n",
      "  batch 018 / 029 | loss: 0.67563 | error: 0.45312 | utility: 0.61383\n",
      "  batch 019 / 029 | loss: 0.68653 | error: 0.45888 | utility: 0.77117\n",
      "  batch 020 / 029 | loss: 0.68332 | error: 0.45625 | utility: 0.83312\n",
      "  batch 021 / 029 | loss: 0.67777 | error: 0.45610 | utility: 0.69042\n",
      "  batch 022 / 029 | loss: 0.67726 | error: 0.45526 | utility: 0.75345\n",
      "  batch 023 / 029 | loss: 0.67220 | error: 0.45245 | utility: 0.81032\n",
      "  batch 024 / 029 | loss: 0.67565 | error: 0.45508 | utility: 0.73942\n",
      "  batch 025 / 029 | loss: 0.67072 | error: 0.45250 | utility: 0.76984\n",
      "  batch 026 / 029 | loss: 0.67155 | error: 0.45433 | utility: 0.77155\n",
      "  batch 027 / 029 | loss: 0.66841 | error: 0.45139 | utility: 0.72401\n",
      "  batch 028 / 029 | loss: 0.66275 | error: 0.44810 | utility: 0.73308\n",
      "  batch 029 / 029 | loss: 0.65072 | error: 0.44558 | utility: 0.82647\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 003 / 010 | time: 030 sec | loss: 0.72549 | error: 0.47969 | utility: 0.83994\n",
      "Validation accuracy improved.\n",
      "Saving model to ./Results/utility/utility_0.450_model.pt.\n",
      "Starting epoch 004 / 010.\n",
      "  batch 001 / 029 | loss: 0.71458 | error: 0.50000 | utility: 0.74175\n",
      "  batch 002 / 029 | loss: 0.70469 | error: 0.46875 | utility: 0.75189\n",
      "  batch 003 / 029 | loss: 0.63460 | error: 0.43229 | utility: 0.72836\n",
      "  batch 004 / 029 | loss: 0.59770 | error: 0.41406 | utility: 0.77344\n",
      "  batch 005 / 029 | loss: 0.61244 | error: 0.42188 | utility: 0.73055\n",
      "  batch 006 / 029 | loss: 0.61765 | error: 0.41927 | utility: 0.69403\n",
      "  batch 007 / 029 | loss: 0.61928 | error: 0.42411 | utility: 0.76927\n",
      "  batch 008 / 029 | loss: 0.61880 | error: 0.42188 | utility: 0.74807\n",
      "  batch 009 / 029 | loss: 0.64506 | error: 0.43576 | utility: 0.75424\n",
      "  batch 010 / 029 | loss: 0.62517 | error: 0.42969 | utility: 0.78533\n",
      "  batch 011 / 029 | loss: 0.63502 | error: 0.43466 | utility: 0.75978\n",
      "  batch 012 / 029 | loss: 0.64940 | error: 0.44531 | utility: 0.73629\n",
      "  batch 013 / 029 | loss: 0.63748 | error: 0.43990 | utility: 0.77908\n",
      "  batch 014 / 029 | loss: 0.63630 | error: 0.43638 | utility: 0.73035\n",
      "  batch 015 / 029 | loss: 0.63592 | error: 0.43958 | utility: 0.82345\n",
      "  batch 016 / 029 | loss: 0.64592 | error: 0.44531 | utility: 0.79723\n",
      "  batch 017 / 029 | loss: 0.65458 | error: 0.45037 | utility: 0.79388\n",
      "  batch 018 / 029 | loss: 0.65486 | error: 0.45139 | utility: 0.72231\n",
      "  batch 019 / 029 | loss: 0.65727 | error: 0.45395 | utility: 0.78631\n",
      "  batch 020 / 029 | loss: 0.65811 | error: 0.45469 | utility: 0.74670\n",
      "  batch 021 / 029 | loss: 0.65494 | error: 0.45387 | utility: 0.81963\n",
      "  batch 022 / 029 | loss: 0.65686 | error: 0.45312 | utility: 0.77182\n",
      "  batch 023 / 029 | loss: 0.66110 | error: 0.45720 | utility: 0.79370\n",
      "  batch 024 / 029 | loss: 0.66444 | error: 0.46029 | utility: 0.80812\n",
      "  batch 025 / 029 | loss: 0.66108 | error: 0.45875 | utility: 0.83091\n",
      "  batch 026 / 029 | loss: 0.66196 | error: 0.46094 | utility: 0.78186\n",
      "  batch 027 / 029 | loss: 0.66231 | error: 0.46181 | utility: 0.75254\n",
      "  batch 028 / 029 | loss: 0.66163 | error: 0.46205 | utility: 0.71808\n",
      "  batch 029 / 029 | loss: 0.65961 | error: 0.45474 | utility: 0.42027\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 004 / 010 | time: 029 sec | loss: 0.72555 | error: 0.48490 | utility: 0.83850\n",
      "Starting epoch 005 / 010.\n",
      "  batch 001 / 029 | loss: 0.76959 | error: 0.54688 | utility: 0.77684\n",
      "  batch 002 / 029 | loss: 0.73007 | error: 0.50781 | utility: 0.77199\n",
      "  batch 003 / 029 | loss: 0.70884 | error: 0.49479 | utility: 0.78646\n",
      "  batch 004 / 029 | loss: 0.69972 | error: 0.48047 | utility: 0.69967\n",
      "  batch 005 / 029 | loss: 0.71290 | error: 0.48750 | utility: 0.71174\n",
      "  batch 006 / 029 | loss: 0.67083 | error: 0.46875 | utility: 0.76398\n",
      "  batch 007 / 029 | loss: 0.67142 | error: 0.46875 | utility: 0.74136\n",
      "  batch 008 / 029 | loss: 0.66780 | error: 0.46680 | utility: 0.77523\n",
      "  batch 009 / 029 | loss: 0.67516 | error: 0.46875 | utility: 0.80225\n",
      "  batch 010 / 029 | loss: 0.67365 | error: 0.46563 | utility: 0.76090\n",
      "  batch 011 / 029 | loss: 0.67602 | error: 0.47017 | utility: 0.80905\n",
      "  batch 012 / 029 | loss: 0.67029 | error: 0.46615 | utility: 0.75036\n",
      "  batch 013 / 029 | loss: 0.65902 | error: 0.45913 | utility: 0.79464\n",
      "  batch 014 / 029 | loss: 0.67417 | error: 0.46763 | utility: 0.70100\n",
      "  batch 015 / 029 | loss: 0.66723 | error: 0.45937 | utility: 0.73894\n",
      "  batch 016 / 029 | loss: 0.66531 | error: 0.45508 | utility: 0.73887\n",
      "  batch 017 / 029 | loss: 0.66279 | error: 0.45129 | utility: 0.76599\n",
      "  batch 018 / 029 | loss: 0.66349 | error: 0.45312 | utility: 0.71818\n",
      "  batch 019 / 029 | loss: 0.66710 | error: 0.45477 | utility: 0.71300\n",
      "  batch 020 / 029 | loss: 0.66315 | error: 0.45391 | utility: 0.71394\n",
      "  batch 021 / 029 | loss: 0.66332 | error: 0.45536 | utility: 0.76960\n",
      "  batch 022 / 029 | loss: 0.66172 | error: 0.45455 | utility: 0.76175\n",
      "  batch 023 / 029 | loss: 0.65659 | error: 0.45177 | utility: 0.65419\n",
      "  batch 024 / 029 | loss: 0.65971 | error: 0.45312 | utility: 0.77727\n",
      "  batch 025 / 029 | loss: 0.66024 | error: 0.45437 | utility: 0.69845\n",
      "  batch 026 / 029 | loss: 0.66404 | error: 0.45673 | utility: 0.79798\n",
      "  batch 027 / 029 | loss: 0.66276 | error: 0.45602 | utility: 0.74935\n",
      "  batch 028 / 029 | loss: 0.66027 | error: 0.45424 | utility: 0.78613\n",
      "  batch 029 / 029 | loss: 0.66145 | error: 0.45582 | utility: 0.54491\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 005 / 010 | time: 030 sec | loss: 0.72512 | error: 0.47552 | utility: 0.83389\n",
      "Validation accuracy improved.\n",
      "Saving model to ./Results/utility/utility_0.450_model.pt.\n",
      "Starting epoch 006 / 010.\n",
      "  batch 001 / 029 | loss: 0.61585 | error: 0.45312 | utility: 0.75863\n",
      "  batch 002 / 029 | loss: 0.71572 | error: 0.48438 | utility: 0.66578\n",
      "  batch 003 / 029 | loss: 0.69321 | error: 0.46875 | utility: 0.78882\n",
      "  batch 004 / 029 | loss: 0.73770 | error: 0.49219 | utility: 0.71640\n",
      "  batch 005 / 029 | loss: 0.70223 | error: 0.46875 | utility: 0.67702\n",
      "  batch 006 / 029 | loss: 0.68803 | error: 0.46094 | utility: 0.59197\n",
      "  batch 007 / 029 | loss: 0.67657 | error: 0.45312 | utility: 0.69316\n",
      "  batch 008 / 029 | loss: 0.67634 | error: 0.44727 | utility: 0.69325\n",
      "  batch 009 / 029 | loss: 0.66015 | error: 0.43750 | utility: 0.71259\n",
      "  batch 010 / 029 | loss: 0.65475 | error: 0.43906 | utility: 0.80768\n",
      "  batch 011 / 029 | loss: 0.66673 | error: 0.44460 | utility: 0.82864\n",
      "  batch 012 / 029 | loss: 0.65145 | error: 0.43880 | utility: 0.75239\n",
      "  batch 013 / 029 | loss: 0.65643 | error: 0.43750 | utility: 0.66875\n",
      "  batch 014 / 029 | loss: 0.65890 | error: 0.44085 | utility: 0.77704\n",
      "  batch 015 / 029 | loss: 0.65147 | error: 0.43854 | utility: 0.73860\n",
      "  batch 016 / 029 | loss: 0.66476 | error: 0.44434 | utility: 0.67334\n",
      "  batch 017 / 029 | loss: 0.66901 | error: 0.44485 | utility: 0.73993\n",
      "  batch 018 / 029 | loss: 0.66585 | error: 0.44358 | utility: 0.75339\n",
      "  batch 019 / 029 | loss: 0.67032 | error: 0.44243 | utility: 0.61936\n",
      "  batch 020 / 029 | loss: 0.67632 | error: 0.44375 | utility: 0.70898\n",
      "  batch 021 / 029 | loss: 0.66833 | error: 0.43973 | utility: 0.75301\n",
      "  batch 022 / 029 | loss: 0.66200 | error: 0.43537 | utility: 0.71874\n",
      "  batch 023 / 029 | loss: 0.65874 | error: 0.43410 | utility: 0.77941\n",
      "  batch 024 / 029 | loss: 0.65630 | error: 0.43294 | utility: 0.74136\n",
      "  batch 025 / 029 | loss: 0.65681 | error: 0.43312 | utility: 0.77154\n",
      "  batch 026 / 029 | loss: 0.65304 | error: 0.43269 | utility: 0.75538\n",
      "  batch 027 / 029 | loss: 0.65534 | error: 0.43461 | utility: 0.75326\n",
      "  batch 028 / 029 | loss: 0.66122 | error: 0.43694 | utility: 0.62804\n",
      "  batch 029 / 029 | loss: 0.66946 | error: 0.43912 | utility: 0.62455\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 006 / 010 | time: 030 sec | loss: 0.74197 | error: 0.49740 | utility: 0.82434\n",
      "Starting epoch 007 / 010.\n",
      "  batch 001 / 029 | loss: 0.75747 | error: 0.53125 | utility: 0.74439\n",
      "  batch 002 / 029 | loss: 0.78824 | error: 0.55469 | utility: 0.75858\n",
      "  batch 003 / 029 | loss: 0.79930 | error: 0.54688 | utility: 0.78876\n",
      "  batch 004 / 029 | loss: 0.74931 | error: 0.51953 | utility: 0.74020\n",
      "  batch 005 / 029 | loss: 0.69787 | error: 0.49062 | utility: 0.80058\n",
      "  batch 006 / 029 | loss: 0.68753 | error: 0.48177 | utility: 0.75175\n",
      "  batch 007 / 029 | loss: 0.66740 | error: 0.46429 | utility: 0.82631\n",
      "  batch 008 / 029 | loss: 0.67216 | error: 0.47070 | utility: 0.78585\n",
      "  batch 009 / 029 | loss: 0.66784 | error: 0.46701 | utility: 0.79529\n",
      "  batch 010 / 029 | loss: 0.66184 | error: 0.46563 | utility: 0.86300\n",
      "  batch 011 / 029 | loss: 0.66228 | error: 0.46307 | utility: 0.84583\n",
      "  batch 012 / 029 | loss: 0.65533 | error: 0.45833 | utility: 0.76383\n",
      "  batch 013 / 029 | loss: 0.64766 | error: 0.45433 | utility: 0.78202\n",
      "  batch 014 / 029 | loss: 0.64711 | error: 0.45312 | utility: 0.83784\n",
      "  batch 015 / 029 | loss: 0.64401 | error: 0.45312 | utility: 0.84900\n",
      "  batch 016 / 029 | loss: 0.64702 | error: 0.45801 | utility: 0.81022\n",
      "  batch 017 / 029 | loss: 0.64249 | error: 0.45588 | utility: 0.82029\n",
      "  batch 018 / 029 | loss: 0.64556 | error: 0.45833 | utility: 0.83743\n",
      "  batch 019 / 029 | loss: 0.65529 | error: 0.46299 | utility: 0.77461\n",
      "  batch 020 / 029 | loss: 0.65927 | error: 0.46563 | utility: 0.85107\n",
      "  batch 021 / 029 | loss: 0.66426 | error: 0.46875 | utility: 0.81916\n",
      "  batch 022 / 029 | loss: 0.66514 | error: 0.46733 | utility: 0.78862\n",
      "  batch 023 / 029 | loss: 0.66678 | error: 0.46943 | utility: 0.85757\n",
      "  batch 024 / 029 | loss: 0.66876 | error: 0.47070 | utility: 0.87835\n",
      "  batch 025 / 029 | loss: 0.66814 | error: 0.46937 | utility: 0.77105\n",
      "  batch 026 / 029 | loss: 0.66253 | error: 0.46635 | utility: 0.76061\n",
      "  batch 027 / 029 | loss: 0.65941 | error: 0.46528 | utility: 0.89007\n",
      "  batch 028 / 029 | loss: 0.66152 | error: 0.46708 | utility: 0.81203\n",
      "  batch 029 / 029 | loss: 0.66953 | error: 0.47252 | utility: 0.87733\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 007 / 010 | time: 029 sec | loss: 0.69595 | error: 0.48125 | utility: 0.87891\n",
      "Starting epoch 008 / 010.\n",
      "  batch 001 / 029 | loss: 0.71702 | error: 0.53125 | utility: 0.84999\n",
      "  batch 002 / 029 | loss: 0.63094 | error: 0.46875 | utility: 0.84311\n",
      "  batch 003 / 029 | loss: 0.66785 | error: 0.48438 | utility: 0.84885\n",
      "  batch 004 / 029 | loss: 0.59936 | error: 0.43750 | utility: 0.89254\n",
      "  batch 005 / 029 | loss: 0.61868 | error: 0.45312 | utility: 0.71708\n",
      "  batch 006 / 029 | loss: 0.65518 | error: 0.47135 | utility: 0.76677\n",
      "  batch 007 / 029 | loss: 0.67981 | error: 0.48214 | utility: 0.79104\n",
      "  batch 008 / 029 | loss: 0.68311 | error: 0.48633 | utility: 0.83051\n",
      "  batch 009 / 029 | loss: 0.68441 | error: 0.48958 | utility: 0.80768\n",
      "  batch 010 / 029 | loss: 0.68108 | error: 0.48594 | utility: 0.77702\n",
      "  batch 011 / 029 | loss: 0.69615 | error: 0.49148 | utility: 0.78821\n",
      "  batch 012 / 029 | loss: 0.69674 | error: 0.49089 | utility: 0.77584\n",
      "  batch 013 / 029 | loss: 0.68460 | error: 0.47837 | utility: 0.78028\n",
      "  batch 014 / 029 | loss: 0.67541 | error: 0.47433 | utility: 0.84680\n",
      "  batch 015 / 029 | loss: 0.67637 | error: 0.47500 | utility: 0.84236\n",
      "  batch 016 / 029 | loss: 0.67516 | error: 0.47656 | utility: 0.81121\n",
      "  batch 017 / 029 | loss: 0.68445 | error: 0.48254 | utility: 0.82279\n",
      "  batch 018 / 029 | loss: 0.69070 | error: 0.48872 | utility: 0.79659\n",
      "  batch 019 / 029 | loss: 0.68571 | error: 0.48602 | utility: 0.78579\n",
      "  batch 020 / 029 | loss: 0.68494 | error: 0.48594 | utility: 0.82833\n",
      "  batch 021 / 029 | loss: 0.67859 | error: 0.48214 | utility: 0.84637\n",
      "  batch 022 / 029 | loss: 0.66509 | error: 0.47301 | utility: 0.75279\n",
      "  batch 023 / 029 | loss: 0.66268 | error: 0.47215 | utility: 0.79790\n",
      "  batch 024 / 029 | loss: 0.65652 | error: 0.46875 | utility: 0.80892\n",
      "  batch 025 / 029 | loss: 0.65570 | error: 0.46687 | utility: 0.76905\n",
      "  batch 026 / 029 | loss: 0.65346 | error: 0.46635 | utility: 0.81947\n",
      "  batch 027 / 029 | loss: 0.65803 | error: 0.46991 | utility: 0.73747\n",
      "  batch 028 / 029 | loss: 0.66061 | error: 0.47154 | utility: 0.73348\n",
      "  batch 029 / 029 | loss: 0.66520 | error: 0.47252 | utility: 0.68126\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 008 / 010 | time: 030 sec | loss: 0.71556 | error: 0.49010 | utility: 0.84680\n",
      "Starting epoch 009 / 010.\n",
      "  batch 001 / 029 | loss: 0.60881 | error: 0.42188 | utility: 0.72797\n",
      "  batch 002 / 029 | loss: 0.65970 | error: 0.46875 | utility: 0.75406\n",
      "  batch 003 / 029 | loss: 0.64892 | error: 0.45833 | utility: 0.78538\n",
      "  batch 004 / 029 | loss: 0.61844 | error: 0.42969 | utility: 0.76836\n",
      "  batch 005 / 029 | loss: 0.66850 | error: 0.45937 | utility: 0.73649\n",
      "  batch 006 / 029 | loss: 0.64575 | error: 0.44531 | utility: 0.77843\n",
      "  batch 007 / 029 | loss: 0.63492 | error: 0.44420 | utility: 0.75754\n",
      "  batch 008 / 029 | loss: 0.64293 | error: 0.44922 | utility: 0.74109\n",
      "  batch 009 / 029 | loss: 0.63615 | error: 0.45139 | utility: 0.77924\n",
      "  batch 010 / 029 | loss: 0.65429 | error: 0.46250 | utility: 0.81800\n",
      "  batch 011 / 029 | loss: 0.64930 | error: 0.45597 | utility: 0.82039\n",
      "  batch 012 / 029 | loss: 0.64570 | error: 0.45312 | utility: 0.81855\n",
      "  batch 013 / 029 | loss: 0.64711 | error: 0.45192 | utility: 0.79305\n",
      "  batch 014 / 029 | loss: 0.64642 | error: 0.45312 | utility: 0.77280\n",
      "  batch 015 / 029 | loss: 0.63875 | error: 0.44896 | utility: 0.85339\n",
      "  batch 016 / 029 | loss: 0.64891 | error: 0.45605 | utility: 0.73696\n",
      "  batch 017 / 029 | loss: 0.64917 | error: 0.45680 | utility: 0.77850\n",
      "  batch 018 / 029 | loss: 0.65239 | error: 0.46094 | utility: 0.82298\n",
      "  batch 019 / 029 | loss: 0.65375 | error: 0.46299 | utility: 0.78573\n",
      "  batch 020 / 029 | loss: 0.64708 | error: 0.46094 | utility: 0.83493\n",
      "  batch 021 / 029 | loss: 0.64642 | error: 0.45833 | utility: 0.80990\n",
      "  batch 022 / 029 | loss: 0.64875 | error: 0.45881 | utility: 0.73186\n",
      "  batch 023 / 029 | loss: 0.64733 | error: 0.45788 | utility: 0.83029\n",
      "  batch 024 / 029 | loss: 0.64530 | error: 0.45638 | utility: 0.78812\n",
      "  batch 025 / 029 | loss: 0.64699 | error: 0.45750 | utility: 0.87263\n",
      "  batch 026 / 029 | loss: 0.65028 | error: 0.46034 | utility: 0.81497\n",
      "  batch 027 / 029 | loss: 0.65556 | error: 0.46296 | utility: 0.81690\n",
      "  batch 028 / 029 | loss: 0.66455 | error: 0.46819 | utility: 0.80792\n",
      "  batch 029 / 029 | loss: 0.65533 | error: 0.46498 | utility: 0.88285\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 009 / 010 | time: 030 sec | loss: 0.71481 | error: 0.48385 | utility: 0.85073\n",
      "Ending training due to 4 consecutive epochs without improvement in validation accuracy.\n",
      "Total training time: 4 minutes (262.90909123420715 seconds).\n",
      "Loading model from ./Results/utility/utility_0.450_model.pt.\n",
      "---------- Training with lambda=0.5 ----------\n",
      "Starting epoch 001 / 010.\n",
      "  batch 001 / 029 | loss: 0.65381 | error: 0.40625 | utility: 0.93142\n",
      "  batch 002 / 029 | loss: 0.63406 | error: 0.40625 | utility: 0.93357\n",
      "  batch 003 / 029 | loss: 0.68097 | error: 0.44792 | utility: 0.94127\n",
      "  batch 004 / 029 | loss: 0.67227 | error: 0.45312 | utility: 0.94579\n",
      "  batch 005 / 029 | loss: 0.65752 | error: 0.45312 | utility: 0.94815\n",
      "  batch 006 / 029 | loss: 0.66239 | error: 0.45833 | utility: 0.94657\n",
      "  batch 007 / 029 | loss: 0.67576 | error: 0.46875 | utility: 0.94357\n",
      "  batch 008 / 029 | loss: 0.69443 | error: 0.48047 | utility: 0.93866\n",
      "  batch 009 / 029 | loss: 0.72028 | error: 0.49653 | utility: 0.94071\n",
      "  batch 010 / 029 | loss: 0.71539 | error: 0.49531 | utility: 0.94186\n",
      "  batch 011 / 029 | loss: 0.70157 | error: 0.49006 | utility: 0.94757\n",
      "  batch 012 / 029 | loss: 0.71783 | error: 0.49870 | utility: 0.93307\n",
      "  batch 013 / 029 | loss: 0.70969 | error: 0.49519 | utility: 0.90433\n",
      "  batch 014 / 029 | loss: 0.71174 | error: 0.49888 | utility: 0.92769\n",
      "  batch 015 / 029 | loss: 0.70108 | error: 0.49375 | utility: 0.91664\n",
      "  batch 016 / 029 | loss: 0.69937 | error: 0.49219 | utility: 0.92724\n",
      "  batch 017 / 029 | loss: 0.69496 | error: 0.49265 | utility: 0.89484\n",
      "  batch 018 / 029 | loss: 0.70133 | error: 0.49826 | utility: 0.91089\n",
      "  batch 019 / 029 | loss: 0.70518 | error: 0.50247 | utility: 0.90370\n",
      "  batch 020 / 029 | loss: 0.70592 | error: 0.50547 | utility: 0.89978\n",
      "  batch 021 / 029 | loss: 0.69696 | error: 0.50074 | utility: 0.92000\n",
      "  batch 022 / 029 | loss: 0.68549 | error: 0.49432 | utility: 0.91108\n",
      "  batch 023 / 029 | loss: 0.68226 | error: 0.49389 | utility: 0.84935\n",
      "  batch 024 / 029 | loss: 0.68055 | error: 0.49414 | utility: 0.88193\n",
      "  batch 025 / 029 | loss: 0.67821 | error: 0.49250 | utility: 0.88920\n",
      "  batch 026 / 029 | loss: 0.67673 | error: 0.49038 | utility: 0.88677\n",
      "  batch 027 / 029 | loss: 0.67690 | error: 0.49074 | utility: 0.88007\n",
      "  batch 028 / 029 | loss: 0.67448 | error: 0.49051 | utility: 0.89862\n",
      "  batch 029 / 029 | loss: 0.67129 | error: 0.49084 | utility: 0.91280\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 001 / 010 | time: 026 sec | loss: 0.67793 | error: 0.49688 | utility: 0.91091\n",
      "Saving model to ./Results/utility/utility_0.500_model.pt.\n",
      "Starting epoch 002 / 010.\n",
      "  batch 001 / 029 | loss: 0.72305 | error: 0.53125 | utility: 0.87550\n",
      "  batch 002 / 029 | loss: 0.69855 | error: 0.53125 | utility: 0.87781\n",
      "  batch 003 / 029 | loss: 0.70916 | error: 0.52604 | utility: 0.86348\n",
      "  batch 004 / 029 | loss: 0.68606 | error: 0.51172 | utility: 0.89387\n",
      "  batch 005 / 029 | loss: 0.68013 | error: 0.51250 | utility: 0.88905\n",
      "  batch 006 / 029 | loss: 0.66537 | error: 0.50260 | utility: 0.84990\n",
      "  batch 007 / 029 | loss: 0.67753 | error: 0.51339 | utility: 0.84785\n",
      "  batch 008 / 029 | loss: 0.64982 | error: 0.49609 | utility: 0.89369\n",
      "  batch 009 / 029 | loss: 0.63284 | error: 0.48785 | utility: 0.85722\n",
      "  batch 010 / 029 | loss: 0.61710 | error: 0.47500 | utility: 0.86579\n",
      "  batch 011 / 029 | loss: 0.61410 | error: 0.47301 | utility: 0.90929\n",
      "  batch 012 / 029 | loss: 0.62289 | error: 0.48047 | utility: 0.84412\n",
      "  batch 013 / 029 | loss: 0.62715 | error: 0.48077 | utility: 0.76578\n",
      "  batch 014 / 029 | loss: 0.63937 | error: 0.48438 | utility: 0.87491\n",
      "  batch 015 / 029 | loss: 0.62561 | error: 0.47500 | utility: 0.88787\n",
      "  batch 016 / 029 | loss: 0.61984 | error: 0.46777 | utility: 0.77383\n",
      "  batch 017 / 029 | loss: 0.61878 | error: 0.46783 | utility: 0.87136\n",
      "  batch 018 / 029 | loss: 0.62120 | error: 0.46962 | utility: 0.89310\n",
      "  batch 019 / 029 | loss: 0.62759 | error: 0.47451 | utility: 0.82203\n",
      "  batch 020 / 029 | loss: 0.62327 | error: 0.47031 | utility: 0.79155\n",
      "  batch 021 / 029 | loss: 0.63985 | error: 0.47917 | utility: 0.86056\n",
      "  batch 022 / 029 | loss: 0.63942 | error: 0.47940 | utility: 0.83875\n",
      "  batch 023 / 029 | loss: 0.63675 | error: 0.47894 | utility: 0.88918\n",
      "  batch 024 / 029 | loss: 0.63705 | error: 0.47852 | utility: 0.87618\n",
      "  batch 025 / 029 | loss: 0.64222 | error: 0.48187 | utility: 0.84030\n",
      "  batch 026 / 029 | loss: 0.63887 | error: 0.48017 | utility: 0.85110\n",
      "  batch 027 / 029 | loss: 0.63970 | error: 0.48090 | utility: 0.86039\n",
      "  batch 028 / 029 | loss: 0.63951 | error: 0.48103 | utility: 0.89402\n",
      "  batch 029 / 029 | loss: 0.63689 | error: 0.48168 | utility: 0.88415\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 002 / 010 | time: 026 sec | loss: 0.67726 | error: 0.49167 | utility: 0.89190\n",
      "Validation accuracy improved.\n",
      "Saving model to ./Results/utility/utility_0.500_model.pt.\n",
      "Starting epoch 003 / 010.\n",
      "  batch 001 / 029 | loss: 0.84296 | error: 0.56250 | utility: 0.83493\n",
      "  batch 002 / 029 | loss: 0.72565 | error: 0.50781 | utility: 0.83190\n",
      "  batch 003 / 029 | loss: 0.66884 | error: 0.48438 | utility: 0.83696\n",
      "  batch 004 / 029 | loss: 0.65354 | error: 0.47656 | utility: 0.87291\n",
      "  batch 005 / 029 | loss: 0.64749 | error: 0.47500 | utility: 0.82089\n",
      "  batch 006 / 029 | loss: 0.66903 | error: 0.48958 | utility: 0.83755\n",
      "  batch 007 / 029 | loss: 0.63979 | error: 0.47098 | utility: 0.81857\n",
      "  batch 008 / 029 | loss: 0.66039 | error: 0.48438 | utility: 0.83994\n",
      "  batch 009 / 029 | loss: 0.64396 | error: 0.47917 | utility: 0.78529\n",
      "  batch 010 / 029 | loss: 0.64111 | error: 0.47656 | utility: 0.81097\n",
      "  batch 011 / 029 | loss: 0.64852 | error: 0.48153 | utility: 0.80848\n",
      "  batch 012 / 029 | loss: 0.65420 | error: 0.48307 | utility: 0.81221\n",
      "  batch 013 / 029 | loss: 0.66111 | error: 0.48798 | utility: 0.75679\n",
      "  batch 014 / 029 | loss: 0.64888 | error: 0.48103 | utility: 0.84531\n",
      "  batch 015 / 029 | loss: 0.64786 | error: 0.48021 | utility: 0.80271\n",
      "  batch 016 / 029 | loss: 0.65337 | error: 0.48145 | utility: 0.81953\n",
      "  batch 017 / 029 | loss: 0.65133 | error: 0.47978 | utility: 0.82642\n",
      "  batch 018 / 029 | loss: 0.65484 | error: 0.48090 | utility: 0.75001\n",
      "  batch 019 / 029 | loss: 0.66559 | error: 0.48602 | utility: 0.85123\n",
      "  batch 020 / 029 | loss: 0.66171 | error: 0.48359 | utility: 0.88472\n",
      "  batch 021 / 029 | loss: 0.65628 | error: 0.48140 | utility: 0.79319\n",
      "  batch 022 / 029 | loss: 0.65545 | error: 0.47940 | utility: 0.83684\n",
      "  batch 023 / 029 | loss: 0.64982 | error: 0.47690 | utility: 0.88051\n",
      "  batch 024 / 029 | loss: 0.65338 | error: 0.47982 | utility: 0.84061\n",
      "  batch 025 / 029 | loss: 0.64763 | error: 0.47563 | utility: 0.86273\n",
      "  batch 026 / 029 | loss: 0.64869 | error: 0.47716 | utility: 0.84598\n",
      "  batch 027 / 029 | loss: 0.64579 | error: 0.47627 | utility: 0.84443\n",
      "  batch 028 / 029 | loss: 0.64018 | error: 0.47433 | utility: 0.84795\n",
      "  batch 029 / 029 | loss: 0.62877 | error: 0.47091 | utility: 0.89138\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 003 / 010 | time: 027 sec | loss: 0.67322 | error: 0.48125 | utility: 0.89337\n",
      "Validation accuracy improved.\n",
      "Saving model to ./Results/utility/utility_0.500_model.pt.\n",
      "Starting epoch 004 / 010.\n",
      "  batch 001 / 029 | loss: 0.69823 | error: 0.51562 | utility: 0.83913\n",
      "  batch 002 / 029 | loss: 0.67878 | error: 0.47656 | utility: 0.84596\n",
      "  batch 003 / 029 | loss: 0.60949 | error: 0.45312 | utility: 0.83895\n",
      "  batch 004 / 029 | loss: 0.57121 | error: 0.42969 | utility: 0.84288\n",
      "  batch 005 / 029 | loss: 0.58566 | error: 0.43750 | utility: 0.83613\n",
      "  batch 006 / 029 | loss: 0.59233 | error: 0.44531 | utility: 0.81304\n",
      "  batch 007 / 029 | loss: 0.59563 | error: 0.45089 | utility: 0.85085\n",
      "  batch 008 / 029 | loss: 0.59493 | error: 0.44727 | utility: 0.82489\n",
      "  batch 009 / 029 | loss: 0.62099 | error: 0.45660 | utility: 0.83338\n",
      "  batch 010 / 029 | loss: 0.60129 | error: 0.44844 | utility: 0.87056\n",
      "  batch 011 / 029 | loss: 0.61058 | error: 0.45312 | utility: 0.85416\n",
      "  batch 012 / 029 | loss: 0.62660 | error: 0.46094 | utility: 0.84330\n",
      "  batch 013 / 029 | loss: 0.61559 | error: 0.45913 | utility: 0.87083\n",
      "  batch 014 / 029 | loss: 0.61455 | error: 0.45871 | utility: 0.82558\n",
      "  batch 015 / 029 | loss: 0.61439 | error: 0.46042 | utility: 0.89793\n",
      "  batch 016 / 029 | loss: 0.62447 | error: 0.46582 | utility: 0.86147\n",
      "  batch 017 / 029 | loss: 0.63406 | error: 0.47151 | utility: 0.87120\n",
      "  batch 018 / 029 | loss: 0.63455 | error: 0.47222 | utility: 0.82778\n",
      "  batch 019 / 029 | loss: 0.63682 | error: 0.47368 | utility: 0.85858\n",
      "  batch 020 / 029 | loss: 0.63698 | error: 0.47266 | utility: 0.83635\n",
      "  batch 021 / 029 | loss: 0.63381 | error: 0.47173 | utility: 0.88699\n",
      "  batch 022 / 029 | loss: 0.63540 | error: 0.47159 | utility: 0.84769\n",
      "  batch 023 / 029 | loss: 0.63972 | error: 0.47486 | utility: 0.86389\n",
      "  batch 024 / 029 | loss: 0.64301 | error: 0.47721 | utility: 0.88345\n",
      "  batch 025 / 029 | loss: 0.63932 | error: 0.47563 | utility: 0.89497\n",
      "  batch 026 / 029 | loss: 0.64072 | error: 0.47837 | utility: 0.87171\n",
      "  batch 027 / 029 | loss: 0.64104 | error: 0.47801 | utility: 0.84867\n",
      "  batch 028 / 029 | loss: 0.64048 | error: 0.47768 | utility: 0.82328\n",
      "  batch 029 / 029 | loss: 0.63890 | error: 0.46983 | utility: 0.52055\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 004 / 010 | time: 027 sec | loss: 0.67811 | error: 0.48906 | utility: 0.88941\n",
      "Starting epoch 005 / 010.\n",
      "  batch 001 / 029 | loss: 0.74449 | error: 0.54688 | utility: 0.85506\n",
      "  batch 002 / 029 | loss: 0.70278 | error: 0.51562 | utility: 0.85833\n",
      "  batch 003 / 029 | loss: 0.68410 | error: 0.51042 | utility: 0.87205\n",
      "  batch 004 / 029 | loss: 0.67631 | error: 0.50000 | utility: 0.79540\n",
      "  batch 005 / 029 | loss: 0.69361 | error: 0.51562 | utility: 0.83088\n",
      "  batch 006 / 029 | loss: 0.65157 | error: 0.49219 | utility: 0.84850\n",
      "  batch 007 / 029 | loss: 0.65236 | error: 0.49107 | utility: 0.84890\n",
      "  batch 008 / 029 | loss: 0.64936 | error: 0.49219 | utility: 0.86019\n",
      "  batch 009 / 029 | loss: 0.65588 | error: 0.49479 | utility: 0.88403\n",
      "  batch 010 / 029 | loss: 0.65441 | error: 0.49531 | utility: 0.85242\n",
      "  batch 011 / 029 | loss: 0.65608 | error: 0.49574 | utility: 0.88260\n",
      "  batch 012 / 029 | loss: 0.65031 | error: 0.48958 | utility: 0.84047\n",
      "  batch 013 / 029 | loss: 0.63810 | error: 0.48197 | utility: 0.85771\n",
      "  batch 014 / 029 | loss: 0.65463 | error: 0.49107 | utility: 0.80401\n",
      "  batch 015 / 029 | loss: 0.64643 | error: 0.48333 | utility: 0.82777\n",
      "  batch 016 / 029 | loss: 0.64372 | error: 0.47949 | utility: 0.83246\n",
      "  batch 017 / 029 | loss: 0.64089 | error: 0.47702 | utility: 0.84791\n",
      "  batch 018 / 029 | loss: 0.64190 | error: 0.47830 | utility: 0.82183\n",
      "  batch 019 / 029 | loss: 0.64577 | error: 0.48191 | utility: 0.81752\n",
      "  batch 020 / 029 | loss: 0.64212 | error: 0.47969 | utility: 0.81698\n",
      "  batch 021 / 029 | loss: 0.64248 | error: 0.48065 | utility: 0.85468\n",
      "  batch 022 / 029 | loss: 0.64042 | error: 0.47940 | utility: 0.85677\n",
      "  batch 023 / 029 | loss: 0.63546 | error: 0.47622 | utility: 0.77032\n",
      "  batch 024 / 029 | loss: 0.63862 | error: 0.47721 | utility: 0.83550\n",
      "  batch 025 / 029 | loss: 0.63932 | error: 0.47750 | utility: 0.81929\n",
      "  batch 026 / 029 | loss: 0.64320 | error: 0.47957 | utility: 0.88062\n",
      "  batch 027 / 029 | loss: 0.64184 | error: 0.47917 | utility: 0.85319\n",
      "  batch 028 / 029 | loss: 0.63894 | error: 0.47712 | utility: 0.86890\n",
      "  batch 029 / 029 | loss: 0.64168 | error: 0.48222 | utility: 0.74020\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 005 / 010 | time: 028 sec | loss: 0.66849 | error: 0.47865 | utility: 0.88834\n",
      "Validation accuracy improved.\n",
      "Saving model to ./Results/utility/utility_0.500_model.pt.\n",
      "Starting epoch 006 / 010.\n",
      "  batch 001 / 029 | loss: 0.60546 | error: 0.50000 | utility: 0.85825\n",
      "  batch 002 / 029 | loss: 0.70347 | error: 0.53125 | utility: 0.78847\n",
      "  batch 003 / 029 | loss: 0.67600 | error: 0.51042 | utility: 0.86763\n",
      "  batch 004 / 029 | loss: 0.71987 | error: 0.52734 | utility: 0.79796\n",
      "  batch 005 / 029 | loss: 0.68487 | error: 0.50938 | utility: 0.80880\n",
      "  batch 006 / 029 | loss: 0.66919 | error: 0.50000 | utility: 0.75287\n",
      "  batch 007 / 029 | loss: 0.65746 | error: 0.48884 | utility: 0.79066\n",
      "  batch 008 / 029 | loss: 0.65710 | error: 0.48438 | utility: 0.80238\n",
      "  batch 009 / 029 | loss: 0.64046 | error: 0.47396 | utility: 0.80279\n",
      "  batch 010 / 029 | loss: 0.63504 | error: 0.47187 | utility: 0.87228\n",
      "  batch 011 / 029 | loss: 0.64642 | error: 0.47727 | utility: 0.88669\n",
      "  batch 012 / 029 | loss: 0.63013 | error: 0.46745 | utility: 0.83450\n",
      "  batch 013 / 029 | loss: 0.63574 | error: 0.46995 | utility: 0.78300\n",
      "  batch 014 / 029 | loss: 0.63839 | error: 0.47321 | utility: 0.84594\n",
      "  batch 015 / 029 | loss: 0.63157 | error: 0.47187 | utility: 0.84236\n",
      "  batch 016 / 029 | loss: 0.64442 | error: 0.47852 | utility: 0.79817\n",
      "  batch 017 / 029 | loss: 0.64867 | error: 0.48070 | utility: 0.82788\n",
      "  batch 018 / 029 | loss: 0.64615 | error: 0.48003 | utility: 0.83212\n",
      "  batch 019 / 029 | loss: 0.65052 | error: 0.48026 | utility: 0.74003\n",
      "  batch 020 / 029 | loss: 0.65659 | error: 0.48281 | utility: 0.79863\n",
      "  batch 021 / 029 | loss: 0.64889 | error: 0.47917 | utility: 0.84275\n",
      "  batch 022 / 029 | loss: 0.64192 | error: 0.47301 | utility: 0.81410\n",
      "  batch 023 / 029 | loss: 0.63829 | error: 0.47079 | utility: 0.84436\n",
      "  batch 024 / 029 | loss: 0.63567 | error: 0.46875 | utility: 0.82861\n",
      "  batch 025 / 029 | loss: 0.63562 | error: 0.46813 | utility: 0.86267\n",
      "  batch 026 / 029 | loss: 0.63162 | error: 0.46635 | utility: 0.85533\n",
      "  batch 027 / 029 | loss: 0.63395 | error: 0.46817 | utility: 0.85316\n",
      "  batch 028 / 029 | loss: 0.64018 | error: 0.47266 | utility: 0.76290\n",
      "  batch 029 / 029 | loss: 0.64571 | error: 0.46929 | utility: 0.75851\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 006 / 010 | time: 029 sec | loss: 0.68659 | error: 0.50208 | utility: 0.88850\n",
      "Starting epoch 007 / 010.\n",
      "  batch 001 / 029 | loss: 0.72944 | error: 0.51562 | utility: 0.85762\n",
      "  batch 002 / 029 | loss: 0.76984 | error: 0.55469 | utility: 0.86481\n",
      "  batch 003 / 029 | loss: 0.78126 | error: 0.56250 | utility: 0.87937\n",
      "  batch 004 / 029 | loss: 0.73163 | error: 0.53125 | utility: 0.84556\n",
      "  batch 005 / 029 | loss: 0.67885 | error: 0.50313 | utility: 0.87933\n",
      "  batch 006 / 029 | loss: 0.66812 | error: 0.49740 | utility: 0.87159\n",
      "  batch 007 / 029 | loss: 0.64454 | error: 0.47991 | utility: 0.88774\n",
      "  batch 008 / 029 | loss: 0.65185 | error: 0.48828 | utility: 0.89257\n",
      "  batch 009 / 029 | loss: 0.64655 | error: 0.48438 | utility: 0.87463\n",
      "  batch 010 / 029 | loss: 0.63985 | error: 0.48125 | utility: 0.92402\n",
      "  batch 011 / 029 | loss: 0.63858 | error: 0.47869 | utility: 0.91149\n",
      "  batch 012 / 029 | loss: 0.63199 | error: 0.47526 | utility: 0.86757\n",
      "  batch 013 / 029 | loss: 0.62472 | error: 0.47115 | utility: 0.86011\n",
      "  batch 014 / 029 | loss: 0.62351 | error: 0.46987 | utility: 0.91316\n",
      "  batch 015 / 029 | loss: 0.62049 | error: 0.46875 | utility: 0.91798\n",
      "  batch 016 / 029 | loss: 0.62471 | error: 0.47363 | utility: 0.90215\n",
      "  batch 017 / 029 | loss: 0.62005 | error: 0.47059 | utility: 0.89036\n",
      "  batch 018 / 029 | loss: 0.62260 | error: 0.47222 | utility: 0.90406\n",
      "  batch 019 / 029 | loss: 0.63336 | error: 0.47862 | utility: 0.87672\n",
      "  batch 020 / 029 | loss: 0.63722 | error: 0.48047 | utility: 0.91891\n",
      "  batch 021 / 029 | loss: 0.64290 | error: 0.48438 | utility: 0.90110\n",
      "  batch 022 / 029 | loss: 0.64371 | error: 0.48509 | utility: 0.88979\n",
      "  batch 023 / 029 | loss: 0.64538 | error: 0.48641 | utility: 0.92230\n",
      "  batch 024 / 029 | loss: 0.64737 | error: 0.48763 | utility: 0.92749\n",
      "  batch 025 / 029 | loss: 0.64656 | error: 0.48625 | utility: 0.86243\n",
      "  batch 026 / 029 | loss: 0.64112 | error: 0.48317 | utility: 0.84626\n",
      "  batch 027 / 029 | loss: 0.63778 | error: 0.48148 | utility: 0.93254\n",
      "  batch 028 / 029 | loss: 0.63982 | error: 0.48326 | utility: 0.88509\n",
      "  batch 029 / 029 | loss: 0.64790 | error: 0.48815 | utility: 0.91954\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 007 / 010 | time: 027 sec | loss: 0.65061 | error: 0.47865 | utility: 0.92278\n",
      "Starting epoch 008 / 010.\n",
      "  batch 001 / 029 | loss: 0.69739 | error: 0.53125 | utility: 0.91285\n",
      "  batch 002 / 029 | loss: 0.60779 | error: 0.46875 | utility: 0.90245\n",
      "  batch 003 / 029 | loss: 0.64194 | error: 0.47917 | utility: 0.90618\n",
      "  batch 004 / 029 | loss: 0.56896 | error: 0.43359 | utility: 0.92969\n",
      "  batch 005 / 029 | loss: 0.59330 | error: 0.45000 | utility: 0.81904\n",
      "  batch 006 / 029 | loss: 0.63311 | error: 0.47135 | utility: 0.85072\n",
      "  batch 007 / 029 | loss: 0.65915 | error: 0.48661 | utility: 0.86217\n",
      "  batch 008 / 029 | loss: 0.66237 | error: 0.49023 | utility: 0.89656\n",
      "  batch 009 / 029 | loss: 0.66435 | error: 0.49479 | utility: 0.88412\n",
      "  batch 010 / 029 | loss: 0.66036 | error: 0.49062 | utility: 0.86334\n",
      "  batch 011 / 029 | loss: 0.67580 | error: 0.50000 | utility: 0.86849\n",
      "  batch 012 / 029 | loss: 0.67676 | error: 0.50260 | utility: 0.86428\n",
      "  batch 013 / 029 | loss: 0.66374 | error: 0.49279 | utility: 0.86283\n",
      "  batch 014 / 029 | loss: 0.65459 | error: 0.48884 | utility: 0.89806\n",
      "  batch 015 / 029 | loss: 0.65496 | error: 0.48854 | utility: 0.89631\n",
      "  batch 016 / 029 | loss: 0.65424 | error: 0.48926 | utility: 0.87888\n",
      "  batch 017 / 029 | loss: 0.66395 | error: 0.49449 | utility: 0.88337\n",
      "  batch 018 / 029 | loss: 0.67101 | error: 0.50000 | utility: 0.87194\n",
      "  batch 019 / 029 | loss: 0.66622 | error: 0.49753 | utility: 0.85910\n",
      "  batch 020 / 029 | loss: 0.66490 | error: 0.49609 | utility: 0.88942\n",
      "  batch 021 / 029 | loss: 0.65812 | error: 0.49256 | utility: 0.90097\n",
      "  batch 022 / 029 | loss: 0.64445 | error: 0.48509 | utility: 0.83274\n",
      "  batch 023 / 029 | loss: 0.64211 | error: 0.48370 | utility: 0.86247\n",
      "  batch 024 / 029 | loss: 0.63570 | error: 0.48047 | utility: 0.87873\n",
      "  batch 025 / 029 | loss: 0.63470 | error: 0.47937 | utility: 0.84280\n",
      "  batch 026 / 029 | loss: 0.63236 | error: 0.47837 | utility: 0.87124\n",
      "  batch 027 / 029 | loss: 0.63677 | error: 0.48148 | utility: 0.83367\n",
      "  batch 028 / 029 | loss: 0.63920 | error: 0.48270 | utility: 0.79495\n",
      "  batch 029 / 029 | loss: 0.64319 | error: 0.48330 | utility: 0.80919\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 008 / 010 | time: 027 sec | loss: 0.67236 | error: 0.49167 | utility: 0.89228\n",
      "Starting epoch 009 / 010.\n",
      "  batch 001 / 029 | loss: 0.58973 | error: 0.45312 | utility: 0.81620\n",
      "  batch 002 / 029 | loss: 0.64593 | error: 0.49219 | utility: 0.82272\n",
      "  batch 003 / 029 | loss: 0.62868 | error: 0.47396 | utility: 0.84574\n",
      "  batch 004 / 029 | loss: 0.59471 | error: 0.44922 | utility: 0.84554\n",
      "  batch 005 / 029 | loss: 0.64773 | error: 0.48438 | utility: 0.84464\n",
      "  batch 006 / 029 | loss: 0.62497 | error: 0.47396 | utility: 0.86000\n",
      "  batch 007 / 029 | loss: 0.61221 | error: 0.46429 | utility: 0.85031\n",
      "  batch 008 / 029 | loss: 0.62141 | error: 0.46875 | utility: 0.82714\n",
      "  batch 009 / 029 | loss: 0.61491 | error: 0.46875 | utility: 0.87395\n",
      "  batch 010 / 029 | loss: 0.63249 | error: 0.47656 | utility: 0.89151\n",
      "  batch 011 / 029 | loss: 0.62526 | error: 0.46875 | utility: 0.89259\n",
      "  batch 012 / 029 | loss: 0.62141 | error: 0.46615 | utility: 0.87215\n",
      "  batch 013 / 029 | loss: 0.62188 | error: 0.46635 | utility: 0.86991\n",
      "  batch 014 / 029 | loss: 0.62106 | error: 0.46763 | utility: 0.85458\n",
      "  batch 015 / 029 | loss: 0.61298 | error: 0.46354 | utility: 0.90893\n",
      "  batch 016 / 029 | loss: 0.62419 | error: 0.47168 | utility: 0.85754\n",
      "  batch 017 / 029 | loss: 0.62539 | error: 0.47243 | utility: 0.85666\n",
      "  batch 018 / 029 | loss: 0.62871 | error: 0.47483 | utility: 0.89835\n",
      "  batch 019 / 029 | loss: 0.63077 | error: 0.47697 | utility: 0.86850\n",
      "  batch 020 / 029 | loss: 0.62392 | error: 0.47422 | utility: 0.90898\n",
      "  batch 021 / 029 | loss: 0.62250 | error: 0.47247 | utility: 0.89420\n",
      "  batch 022 / 029 | loss: 0.62508 | error: 0.47301 | utility: 0.82317\n",
      "  batch 023 / 029 | loss: 0.62370 | error: 0.47283 | utility: 0.89840\n",
      "  batch 024 / 029 | loss: 0.62155 | error: 0.47005 | utility: 0.85663\n",
      "  batch 025 / 029 | loss: 0.62322 | error: 0.47125 | utility: 0.91838\n",
      "  batch 026 / 029 | loss: 0.62678 | error: 0.47416 | utility: 0.89244\n",
      "  batch 027 / 029 | loss: 0.63208 | error: 0.47685 | utility: 0.89118\n",
      "  batch 028 / 029 | loss: 0.64149 | error: 0.48270 | utility: 0.88876\n",
      "  batch 029 / 029 | loss: 0.63235 | error: 0.47899 | utility: 0.92619\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 009 / 010 | time: 026 sec | loss: 0.66039 | error: 0.48385 | utility: 0.90150\n",
      "Ending training due to 4 consecutive epochs without improvement in validation accuracy.\n",
      "Total training time: 4 minutes (244.0323097705841 seconds).\n",
      "Loading model from ./Results/utility/utility_0.500_model.pt.\n",
      "---------- Training with lambda=0.55 ----------\n",
      "Starting epoch 001 / 010.\n",
      "  batch 001 / 029 | loss: 0.63175 | error: 0.40625 | utility: 0.93142\n",
      "  batch 002 / 029 | loss: 0.61110 | error: 0.40625 | utility: 0.93357\n",
      "  batch 003 / 029 | loss: 0.65707 | error: 0.44792 | utility: 0.94117\n",
      "  batch 004 / 029 | loss: 0.64747 | error: 0.45312 | utility: 0.94568\n",
      "  batch 005 / 029 | loss: 0.63204 | error: 0.45312 | utility: 0.94809\n",
      "  batch 006 / 029 | loss: 0.63650 | error: 0.45833 | utility: 0.94661\n",
      "  batch 007 / 029 | loss: 0.64974 | error: 0.46875 | utility: 0.94395\n",
      "  batch 008 / 029 | loss: 0.66838 | error: 0.48047 | utility: 0.93943\n",
      "  batch 009 / 029 | loss: 0.69450 | error: 0.49653 | utility: 0.94194\n",
      "  batch 010 / 029 | loss: 0.68941 | error: 0.49531 | utility: 0.94365\n",
      "  batch 011 / 029 | loss: 0.67543 | error: 0.49006 | utility: 0.94925\n",
      "  batch 012 / 029 | loss: 0.69197 | error: 0.49870 | utility: 0.93652\n",
      "  batch 013 / 029 | loss: 0.68381 | error: 0.49519 | utility: 0.90948\n",
      "  batch 014 / 029 | loss: 0.68613 | error: 0.49888 | utility: 0.93294\n",
      "  batch 015 / 029 | loss: 0.67531 | error: 0.49375 | utility: 0.92378\n",
      "  batch 016 / 029 | loss: 0.67358 | error: 0.49219 | utility: 0.93357\n",
      "  batch 017 / 029 | loss: 0.66939 | error: 0.49265 | utility: 0.90674\n",
      "  batch 018 / 029 | loss: 0.67631 | error: 0.49826 | utility: 0.92083\n",
      "  batch 019 / 029 | loss: 0.68054 | error: 0.50247 | utility: 0.91579\n",
      "  batch 020 / 029 | loss: 0.68171 | error: 0.50547 | utility: 0.91474\n",
      "  batch 021 / 029 | loss: 0.67237 | error: 0.50074 | utility: 0.93161\n",
      "  batch 022 / 029 | loss: 0.66031 | error: 0.49432 | utility: 0.92471\n",
      "  batch 023 / 029 | loss: 0.65692 | error: 0.49389 | utility: 0.87727\n",
      "  batch 024 / 029 | loss: 0.65525 | error: 0.49414 | utility: 0.90663\n",
      "  batch 025 / 029 | loss: 0.65272 | error: 0.49250 | utility: 0.91231\n",
      "  batch 026 / 029 | loss: 0.65096 | error: 0.49038 | utility: 0.90747\n",
      "  batch 027 / 029 | loss: 0.65101 | error: 0.49016 | utility: 0.90665\n",
      "  batch 028 / 029 | loss: 0.64866 | error: 0.48996 | utility: 0.92080\n",
      "  batch 029 / 029 | loss: 0.64587 | error: 0.49030 | utility: 0.93000\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 001 / 010 | time: 026 sec | loss: 0.64399 | error: 0.49688 | utility: 0.93150\n",
      "Saving model to ./Results/utility/utility_0.550_model.pt.\n",
      "Starting epoch 002 / 010.\n",
      "  batch 001 / 029 | loss: 0.69982 | error: 0.53125 | utility: 0.90731\n",
      "  batch 002 / 029 | loss: 0.67527 | error: 0.52344 | utility: 0.90863\n",
      "  batch 003 / 029 | loss: 0.68529 | error: 0.52083 | utility: 0.88932\n",
      "  batch 004 / 029 | loss: 0.66141 | error: 0.50781 | utility: 0.92076\n",
      "  batch 005 / 029 | loss: 0.65630 | error: 0.50938 | utility: 0.91710\n",
      "  batch 006 / 029 | loss: 0.64218 | error: 0.50260 | utility: 0.88470\n",
      "  batch 007 / 029 | loss: 0.65546 | error: 0.51339 | utility: 0.89436\n",
      "  batch 008 / 029 | loss: 0.62694 | error: 0.49805 | utility: 0.92130\n",
      "  batch 009 / 029 | loss: 0.60959 | error: 0.48958 | utility: 0.89539\n",
      "  batch 010 / 029 | loss: 0.59280 | error: 0.47813 | utility: 0.90241\n",
      "  batch 011 / 029 | loss: 0.58955 | error: 0.47585 | utility: 0.93020\n",
      "  batch 012 / 029 | loss: 0.59907 | error: 0.48307 | utility: 0.89148\n",
      "  batch 013 / 029 | loss: 0.60386 | error: 0.48317 | utility: 0.82396\n",
      "  batch 014 / 029 | loss: 0.61555 | error: 0.48661 | utility: 0.90928\n",
      "  batch 015 / 029 | loss: 0.60092 | error: 0.47708 | utility: 0.91975\n",
      "  batch 016 / 029 | loss: 0.59511 | error: 0.47266 | utility: 0.82329\n",
      "  batch 017 / 029 | loss: 0.59402 | error: 0.47243 | utility: 0.90969\n",
      "  batch 018 / 029 | loss: 0.59654 | error: 0.47396 | utility: 0.92343\n",
      "  batch 019 / 029 | loss: 0.60350 | error: 0.47862 | utility: 0.86991\n",
      "  batch 020 / 029 | loss: 0.59866 | error: 0.47422 | utility: 0.85022\n",
      "  batch 021 / 029 | loss: 0.61545 | error: 0.48289 | utility: 0.90722\n",
      "  batch 022 / 029 | loss: 0.61547 | error: 0.48366 | utility: 0.89219\n",
      "  batch 023 / 029 | loss: 0.61296 | error: 0.48302 | utility: 0.92467\n",
      "  batch 024 / 029 | loss: 0.61283 | error: 0.48242 | utility: 0.91773\n",
      "  batch 025 / 029 | loss: 0.61825 | error: 0.48562 | utility: 0.88915\n",
      "  batch 026 / 029 | loss: 0.61502 | error: 0.48438 | utility: 0.90525\n",
      "  batch 027 / 029 | loss: 0.61606 | error: 0.48495 | utility: 0.89646\n",
      "  batch 028 / 029 | loss: 0.61584 | error: 0.48493 | utility: 0.92684\n",
      "  batch 029 / 029 | loss: 0.61378 | error: 0.48545 | utility: 0.92284\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 002 / 010 | time: 026 sec | loss: 0.63048 | error: 0.49167 | utility: 0.92716\n",
      "Validation accuracy improved.\n",
      "Saving model to ./Results/utility/utility_0.550_model.pt.\n",
      "Starting epoch 003 / 010.\n",
      "  batch 001 / 029 | loss: 0.82511 | error: 0.60938 | utility: 0.89685\n",
      "  batch 002 / 029 | loss: 0.70312 | error: 0.53906 | utility: 0.89174\n",
      "  batch 003 / 029 | loss: 0.64745 | error: 0.51562 | utility: 0.89861\n",
      "  batch 004 / 029 | loss: 0.62927 | error: 0.50000 | utility: 0.91710\n",
      "  batch 005 / 029 | loss: 0.62441 | error: 0.49375 | utility: 0.86956\n",
      "  batch 006 / 029 | loss: 0.64690 | error: 0.50521 | utility: 0.89118\n",
      "  batch 007 / 029 | loss: 0.61691 | error: 0.48884 | utility: 0.87480\n",
      "  batch 008 / 029 | loss: 0.63816 | error: 0.50000 | utility: 0.89358\n",
      "  batch 009 / 029 | loss: 0.62255 | error: 0.49306 | utility: 0.86016\n",
      "  batch 010 / 029 | loss: 0.61938 | error: 0.48906 | utility: 0.86495\n",
      "  batch 011 / 029 | loss: 0.62780 | error: 0.49290 | utility: 0.85990\n",
      "  batch 012 / 029 | loss: 0.63307 | error: 0.49479 | utility: 0.88418\n",
      "  batch 013 / 029 | loss: 0.64133 | error: 0.50000 | utility: 0.83007\n",
      "  batch 014 / 029 | loss: 0.62850 | error: 0.49219 | utility: 0.89693\n",
      "  batch 015 / 029 | loss: 0.62640 | error: 0.49062 | utility: 0.86525\n",
      "  batch 016 / 029 | loss: 0.63174 | error: 0.49219 | utility: 0.87425\n",
      "  batch 017 / 029 | loss: 0.62937 | error: 0.49173 | utility: 0.88326\n",
      "  batch 018 / 029 | loss: 0.63242 | error: 0.49219 | utility: 0.84844\n",
      "  batch 019 / 029 | loss: 0.64310 | error: 0.49753 | utility: 0.90126\n",
      "  batch 020 / 029 | loss: 0.63864 | error: 0.49453 | utility: 0.92203\n",
      "  batch 021 / 029 | loss: 0.63325 | error: 0.49330 | utility: 0.86792\n",
      "  batch 022 / 029 | loss: 0.63236 | error: 0.49290 | utility: 0.89724\n",
      "  batch 023 / 029 | loss: 0.62641 | error: 0.48981 | utility: 0.92195\n",
      "  batch 024 / 029 | loss: 0.63006 | error: 0.49219 | utility: 0.90070\n",
      "  batch 025 / 029 | loss: 0.62357 | error: 0.48750 | utility: 0.91339\n",
      "  batch 026 / 029 | loss: 0.62500 | error: 0.48858 | utility: 0.89013\n",
      "  batch 027 / 029 | loss: 0.62201 | error: 0.48727 | utility: 0.90946\n",
      "  batch 028 / 029 | loss: 0.61638 | error: 0.48493 | utility: 0.90822\n",
      "  batch 029 / 029 | loss: 0.60549 | error: 0.48114 | utility: 0.92476\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 003 / 010 | time: 026 sec | loss: 0.62346 | error: 0.48125 | utility: 0.93168\n",
      "Validation accuracy improved.\n",
      "Saving model to ./Results/utility/utility_0.550_model.pt.\n",
      "Starting epoch 004 / 010.\n",
      "  batch 001 / 029 | loss: 0.68027 | error: 0.51562 | utility: 0.89114\n",
      "  batch 002 / 029 | loss: 0.65221 | error: 0.49219 | utility: 0.90621\n",
      "  batch 003 / 029 | loss: 0.58273 | error: 0.46354 | utility: 0.90482\n",
      "  batch 004 / 029 | loss: 0.54389 | error: 0.43750 | utility: 0.88763\n",
      "  batch 005 / 029 | loss: 0.55729 | error: 0.44375 | utility: 0.90736\n",
      "  batch 006 / 029 | loss: 0.56548 | error: 0.45312 | utility: 0.89445\n",
      "  batch 007 / 029 | loss: 0.57073 | error: 0.45982 | utility: 0.90989\n",
      "  batch 008 / 029 | loss: 0.56967 | error: 0.45508 | utility: 0.87398\n",
      "  batch 009 / 029 | loss: 0.59547 | error: 0.46528 | utility: 0.88409\n",
      "  batch 010 / 029 | loss: 0.57596 | error: 0.45781 | utility: 0.92121\n",
      "  batch 011 / 029 | loss: 0.58451 | error: 0.46307 | utility: 0.91175\n",
      "  batch 012 / 029 | loss: 0.60114 | error: 0.47266 | utility: 0.90956\n",
      "  batch 013 / 029 | loss: 0.59084 | error: 0.46995 | utility: 0.92285\n",
      "  batch 014 / 029 | loss: 0.59008 | error: 0.46987 | utility: 0.88994\n",
      "  batch 015 / 029 | loss: 0.58992 | error: 0.47083 | utility: 0.93285\n",
      "  batch 016 / 029 | loss: 0.60019 | error: 0.47559 | utility: 0.89880\n",
      "  batch 017 / 029 | loss: 0.61068 | error: 0.48162 | utility: 0.91839\n",
      "  batch 018 / 029 | loss: 0.61124 | error: 0.48264 | utility: 0.89411\n",
      "  batch 019 / 029 | loss: 0.61357 | error: 0.48355 | utility: 0.90603\n",
      "  batch 020 / 029 | loss: 0.61315 | error: 0.48203 | utility: 0.89041\n",
      "  batch 021 / 029 | loss: 0.60999 | error: 0.48065 | utility: 0.92690\n",
      "  batch 022 / 029 | loss: 0.61132 | error: 0.48011 | utility: 0.89192\n",
      "  batch 023 / 029 | loss: 0.61563 | error: 0.48302 | utility: 0.90290\n",
      "  batch 024 / 029 | loss: 0.61889 | error: 0.48503 | utility: 0.92317\n",
      "  batch 025 / 029 | loss: 0.61498 | error: 0.48313 | utility: 0.92990\n",
      "  batch 026 / 029 | loss: 0.61688 | error: 0.48558 | utility: 0.92172\n",
      "  batch 027 / 029 | loss: 0.61722 | error: 0.48553 | utility: 0.90589\n",
      "  batch 028 / 029 | loss: 0.61682 | error: 0.48493 | utility: 0.88328\n",
      "  batch 029 / 029 | loss: 0.61561 | error: 0.48114 | utility: 0.65368\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 004 / 010 | time: 026 sec | loss: 0.63380 | error: 0.48646 | utility: 0.92709\n",
      "Starting epoch 005 / 010.\n",
      "  batch 001 / 029 | loss: 0.71714 | error: 0.54688 | utility: 0.90253\n",
      "  batch 002 / 029 | loss: 0.67347 | error: 0.51562 | utility: 0.91167\n",
      "  batch 003 / 029 | loss: 0.65674 | error: 0.51042 | utility: 0.91755\n",
      "  batch 004 / 029 | loss: 0.65007 | error: 0.50000 | utility: 0.86717\n",
      "  batch 005 / 029 | loss: 0.67128 | error: 0.51875 | utility: 0.89997\n",
      "  batch 006 / 029 | loss: 0.62894 | error: 0.49479 | utility: 0.89497\n",
      "  batch 007 / 029 | loss: 0.63003 | error: 0.49554 | utility: 0.90901\n",
      "  batch 008 / 029 | loss: 0.62775 | error: 0.49609 | utility: 0.91480\n",
      "  batch 009 / 029 | loss: 0.63388 | error: 0.49826 | utility: 0.92691\n",
      "  batch 010 / 029 | loss: 0.63239 | error: 0.49844 | utility: 0.90990\n",
      "  batch 011 / 029 | loss: 0.63352 | error: 0.49858 | utility: 0.92455\n",
      "  batch 012 / 029 | loss: 0.62780 | error: 0.49609 | utility: 0.89968\n",
      "  batch 013 / 029 | loss: 0.61523 | error: 0.48798 | utility: 0.89387\n",
      "  batch 014 / 029 | loss: 0.63261 | error: 0.49777 | utility: 0.86487\n",
      "  batch 015 / 029 | loss: 0.62337 | error: 0.48958 | utility: 0.88067\n",
      "  batch 016 / 029 | loss: 0.61986 | error: 0.48535 | utility: 0.88403\n",
      "  batch 017 / 029 | loss: 0.61660 | error: 0.48346 | utility: 0.90422\n",
      "  batch 018 / 029 | loss: 0.61788 | error: 0.48524 | utility: 0.88872\n",
      "  batch 019 / 029 | loss: 0.62189 | error: 0.48849 | utility: 0.88520\n",
      "  batch 020 / 029 | loss: 0.61835 | error: 0.48672 | utility: 0.87652\n",
      "  batch 021 / 029 | loss: 0.61909 | error: 0.48810 | utility: 0.90765\n",
      "  batch 022 / 029 | loss: 0.61661 | error: 0.48651 | utility: 0.91244\n",
      "  batch 023 / 029 | loss: 0.61189 | error: 0.48370 | utility: 0.83952\n",
      "  batch 024 / 029 | loss: 0.61510 | error: 0.48438 | utility: 0.87887\n",
      "  batch 025 / 029 | loss: 0.61589 | error: 0.48562 | utility: 0.89308\n",
      "  batch 026 / 029 | loss: 0.61967 | error: 0.48738 | utility: 0.92084\n",
      "  batch 027 / 029 | loss: 0.61819 | error: 0.48669 | utility: 0.90966\n",
      "  batch 028 / 029 | loss: 0.61523 | error: 0.48438 | utility: 0.91541\n",
      "  batch 029 / 029 | loss: 0.61922 | error: 0.48922 | utility: 0.85384\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 005 / 010 | time: 027 sec | loss: 0.62015 | error: 0.47708 | utility: 0.92414\n",
      "Validation accuracy improved.\n",
      "Saving model to ./Results/utility/utility_0.550_model.pt.\n",
      "Starting epoch 006 / 010.\n",
      "  batch 001 / 029 | loss: 0.59154 | error: 0.50000 | utility: 0.91223\n",
      "  batch 002 / 029 | loss: 0.68923 | error: 0.53906 | utility: 0.86014\n",
      "  batch 003 / 029 | loss: 0.65664 | error: 0.51562 | utility: 0.91532\n",
      "  batch 004 / 029 | loss: 0.69983 | error: 0.53516 | utility: 0.85884\n",
      "  batch 005 / 029 | loss: 0.66437 | error: 0.51875 | utility: 0.88700\n",
      "  batch 006 / 029 | loss: 0.64729 | error: 0.50781 | utility: 0.85836\n",
      "  batch 007 / 029 | loss: 0.63611 | error: 0.49777 | utility: 0.85745\n",
      "  batch 008 / 029 | loss: 0.63538 | error: 0.49805 | utility: 0.87980\n",
      "  batch 009 / 029 | loss: 0.61863 | error: 0.48611 | utility: 0.85415\n",
      "  batch 010 / 029 | loss: 0.61291 | error: 0.48438 | utility: 0.91476\n",
      "  batch 011 / 029 | loss: 0.62349 | error: 0.48864 | utility: 0.92163\n",
      "  batch 012 / 029 | loss: 0.60639 | error: 0.47786 | utility: 0.88322\n",
      "  batch 013 / 029 | loss: 0.61220 | error: 0.48077 | utility: 0.86135\n",
      "  batch 014 / 029 | loss: 0.61523 | error: 0.48326 | utility: 0.88671\n",
      "  batch 015 / 029 | loss: 0.60887 | error: 0.48229 | utility: 0.90212\n",
      "  batch 016 / 029 | loss: 0.62103 | error: 0.48730 | utility: 0.88007\n",
      "  batch 017 / 029 | loss: 0.62523 | error: 0.48989 | utility: 0.89312\n",
      "  batch 018 / 029 | loss: 0.62309 | error: 0.48958 | utility: 0.88604\n",
      "  batch 019 / 029 | loss: 0.62732 | error: 0.49095 | utility: 0.83892\n",
      "  batch 020 / 029 | loss: 0.63335 | error: 0.49375 | utility: 0.86481\n",
      "  batch 021 / 029 | loss: 0.62528 | error: 0.49033 | utility: 0.90378\n",
      "  batch 022 / 029 | loss: 0.61774 | error: 0.48580 | utility: 0.88628\n",
      "  batch 023 / 029 | loss: 0.61416 | error: 0.48370 | utility: 0.88750\n",
      "  batch 024 / 029 | loss: 0.61150 | error: 0.48177 | utility: 0.88764\n",
      "  batch 025 / 029 | loss: 0.61100 | error: 0.48063 | utility: 0.91062\n",
      "  batch 026 / 029 | loss: 0.60680 | error: 0.47837 | utility: 0.90853\n",
      "  batch 027 / 029 | loss: 0.60907 | error: 0.47975 | utility: 0.90519\n",
      "  batch 028 / 029 | loss: 0.61552 | error: 0.48382 | utility: 0.84030\n",
      "  batch 029 / 029 | loss: 0.61886 | error: 0.48006 | utility: 0.85197\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 006 / 010 | time: 027 sec | loss: 0.64823 | error: 0.50208 | utility: 0.92491\n",
      "Starting epoch 007 / 010.\n",
      "  batch 001 / 029 | loss: 0.69386 | error: 0.51562 | utility: 0.91174\n",
      "  batch 002 / 029 | loss: 0.74069 | error: 0.55469 | utility: 0.91757\n",
      "  batch 003 / 029 | loss: 0.75344 | error: 0.56250 | utility: 0.92860\n",
      "  batch 004 / 029 | loss: 0.70692 | error: 0.53516 | utility: 0.89876\n",
      "  batch 005 / 029 | loss: 0.65462 | error: 0.50625 | utility: 0.92156\n",
      "  batch 006 / 029 | loss: 0.64418 | error: 0.50260 | utility: 0.92907\n",
      "  batch 007 / 029 | loss: 0.61795 | error: 0.48438 | utility: 0.91948\n",
      "  batch 008 / 029 | loss: 0.62763 | error: 0.49219 | utility: 0.94001\n",
      "  batch 009 / 029 | loss: 0.62166 | error: 0.48785 | utility: 0.92058\n",
      "  batch 010 / 029 | loss: 0.61465 | error: 0.48438 | utility: 0.95082\n",
      "  batch 011 / 029 | loss: 0.61210 | error: 0.48153 | utility: 0.94684\n",
      "  batch 012 / 029 | loss: 0.60560 | error: 0.47917 | utility: 0.92711\n",
      "  batch 013 / 029 | loss: 0.59885 | error: 0.47476 | utility: 0.91585\n",
      "  batch 014 / 029 | loss: 0.59730 | error: 0.47321 | utility: 0.94698\n",
      "  batch 015 / 029 | loss: 0.59445 | error: 0.47187 | utility: 0.94750\n",
      "  batch 016 / 029 | loss: 0.59976 | error: 0.47656 | utility: 0.94174\n",
      "  batch 017 / 029 | loss: 0.59517 | error: 0.47335 | utility: 0.92969\n",
      "  batch 018 / 029 | loss: 0.59732 | error: 0.47396 | utility: 0.94024\n",
      "  batch 019 / 029 | loss: 0.60892 | error: 0.48109 | utility: 0.93091\n",
      "  batch 020 / 029 | loss: 0.61270 | error: 0.48281 | utility: 0.94796\n",
      "  batch 021 / 029 | loss: 0.61879 | error: 0.48661 | utility: 0.94025\n",
      "  batch 022 / 029 | loss: 0.61956 | error: 0.48722 | utility: 0.93628\n",
      "  batch 023 / 029 | loss: 0.62132 | error: 0.48845 | utility: 0.94647\n",
      "  batch 024 / 029 | loss: 0.62332 | error: 0.48958 | utility: 0.94878\n",
      "  batch 025 / 029 | loss: 0.62237 | error: 0.48812 | utility: 0.91017\n",
      "  batch 026 / 029 | loss: 0.61716 | error: 0.48498 | utility: 0.89624\n",
      "  batch 027 / 029 | loss: 0.61370 | error: 0.48322 | utility: 0.94922\n",
      "  batch 028 / 029 | loss: 0.61573 | error: 0.48438 | utility: 0.92291\n",
      "  batch 029 / 029 | loss: 0.62407 | error: 0.48922 | utility: 0.93933\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 007 / 010 | time: 025 sec | loss: 0.61144 | error: 0.47865 | utility: 0.94394\n",
      "Starting epoch 008 / 010.\n",
      "  batch 001 / 029 | loss: 0.67808 | error: 0.53125 | utility: 0.93751\n",
      "  batch 002 / 029 | loss: 0.58479 | error: 0.47656 | utility: 0.93037\n",
      "  batch 003 / 029 | loss: 0.61719 | error: 0.48438 | utility: 0.93076\n",
      "  batch 004 / 029 | loss: 0.54150 | error: 0.43750 | utility: 0.94373\n",
      "  batch 005 / 029 | loss: 0.56823 | error: 0.45312 | utility: 0.86891\n",
      "  batch 006 / 029 | loss: 0.60932 | error: 0.47656 | utility: 0.89037\n",
      "  batch 007 / 029 | loss: 0.63616 | error: 0.49107 | utility: 0.89605\n",
      "  batch 008 / 029 | loss: 0.63927 | error: 0.49414 | utility: 0.92086\n",
      "  batch 009 / 029 | loss: 0.64173 | error: 0.49826 | utility: 0.91340\n",
      "  batch 010 / 029 | loss: 0.63743 | error: 0.49531 | utility: 0.90070\n",
      "  batch 011 / 029 | loss: 0.65324 | error: 0.50426 | utility: 0.90414\n",
      "  batch 012 / 029 | loss: 0.65444 | error: 0.50651 | utility: 0.90236\n",
      "  batch 013 / 029 | loss: 0.64053 | error: 0.49639 | utility: 0.89961\n",
      "  batch 014 / 029 | loss: 0.63127 | error: 0.49219 | utility: 0.92112\n",
      "  batch 015 / 029 | loss: 0.63133 | error: 0.49167 | utility: 0.92012\n",
      "  batch 016 / 029 | loss: 0.63093 | error: 0.49316 | utility: 0.90952\n",
      "  batch 017 / 029 | loss: 0.64069 | error: 0.49908 | utility: 0.91065\n",
      "  batch 018 / 029 | loss: 0.64808 | error: 0.50434 | utility: 0.90570\n",
      "  batch 019 / 029 | loss: 0.64328 | error: 0.50164 | utility: 0.89549\n",
      "  batch 020 / 029 | loss: 0.64160 | error: 0.50000 | utility: 0.91772\n",
      "  batch 021 / 029 | loss: 0.63456 | error: 0.49628 | utility: 0.92514\n",
      "  batch 022 / 029 | loss: 0.62084 | error: 0.48864 | utility: 0.87449\n",
      "  batch 023 / 029 | loss: 0.61851 | error: 0.48709 | utility: 0.89134\n",
      "  batch 024 / 029 | loss: 0.61194 | error: 0.48372 | utility: 0.91415\n",
      "  batch 025 / 029 | loss: 0.61083 | error: 0.48250 | utility: 0.88125\n",
      "  batch 026 / 029 | loss: 0.60853 | error: 0.48137 | utility: 0.89692\n",
      "  batch 027 / 029 | loss: 0.61302 | error: 0.48380 | utility: 0.88493\n",
      "  batch 028 / 029 | loss: 0.61561 | error: 0.48493 | utility: 0.83149\n",
      "  batch 029 / 029 | loss: 0.61906 | error: 0.48545 | utility: 0.87316\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 008 / 010 | time: 027 sec | loss: 0.63263 | error: 0.49167 | utility: 0.92338\n",
      "Starting epoch 009 / 010.\n",
      "  batch 001 / 029 | loss: 0.57227 | error: 0.46875 | utility: 0.87658\n",
      "  batch 002 / 029 | loss: 0.63160 | error: 0.50000 | utility: 0.86544\n",
      "  batch 003 / 029 | loss: 0.60771 | error: 0.47396 | utility: 0.88478\n",
      "  batch 004 / 029 | loss: 0.57004 | error: 0.44922 | utility: 0.88734\n",
      "  batch 005 / 029 | loss: 0.62580 | error: 0.48438 | utility: 0.89835\n",
      "  batch 006 / 029 | loss: 0.60326 | error: 0.47656 | utility: 0.90686\n",
      "  batch 007 / 029 | loss: 0.58926 | error: 0.46875 | utility: 0.90295\n",
      "  batch 008 / 029 | loss: 0.59954 | error: 0.47266 | utility: 0.87232\n",
      "  batch 009 / 029 | loss: 0.59325 | error: 0.47222 | utility: 0.91652\n",
      "  batch 010 / 029 | loss: 0.60991 | error: 0.47969 | utility: 0.92403\n",
      "  batch 011 / 029 | loss: 0.60084 | error: 0.47159 | utility: 0.92674\n",
      "  batch 012 / 029 | loss: 0.59666 | error: 0.46875 | utility: 0.90342\n",
      "  batch 013 / 029 | loss: 0.59628 | error: 0.46755 | utility: 0.91467\n",
      "  batch 014 / 029 | loss: 0.59543 | error: 0.46875 | utility: 0.90337\n",
      "  batch 015 / 029 | loss: 0.58707 | error: 0.46458 | utility: 0.93876\n",
      "  batch 016 / 029 | loss: 0.59913 | error: 0.47266 | utility: 0.91546\n",
      "  batch 017 / 029 | loss: 0.60101 | error: 0.47426 | utility: 0.90147\n",
      "  batch 018 / 029 | loss: 0.60443 | error: 0.47656 | utility: 0.93551\n",
      "  batch 019 / 029 | loss: 0.60697 | error: 0.47862 | utility: 0.91263\n",
      "  batch 020 / 029 | loss: 0.60025 | error: 0.47578 | utility: 0.94098\n",
      "  batch 021 / 029 | loss: 0.59818 | error: 0.47396 | utility: 0.93443\n",
      "  batch 022 / 029 | loss: 0.60089 | error: 0.47443 | utility: 0.87993\n",
      "  batch 023 / 029 | loss: 0.59940 | error: 0.47418 | utility: 0.93494\n",
      "  batch 024 / 029 | loss: 0.59687 | error: 0.47201 | utility: 0.90065\n",
      "  batch 025 / 029 | loss: 0.59850 | error: 0.47313 | utility: 0.94474\n",
      "  batch 026 / 029 | loss: 0.60235 | error: 0.47596 | utility: 0.93211\n",
      "  batch 027 / 029 | loss: 0.60763 | error: 0.47859 | utility: 0.93095\n",
      "  batch 028 / 029 | loss: 0.61746 | error: 0.48438 | utility: 0.93001\n",
      "  batch 029 / 029 | loss: 0.60851 | error: 0.48060 | utility: 0.94746\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 009 / 010 | time: 026 sec | loss: 0.62203 | error: 0.48646 | utility: 0.93599\n",
      "Ending training due to 4 consecutive epochs without improvement in validation accuracy.\n",
      "Total training time: 4 minutes (235.5605273246765 seconds).\n",
      "Loading model from ./Results/utility/utility_0.550_model.pt.\n",
      "---------- Training with lambda=0.6000000000000001 ----------\n",
      "Starting epoch 001 / 010.\n",
      "  batch 001 / 029 | loss: 0.60968 | error: 0.40625 | utility: 0.93142\n",
      "  batch 002 / 029 | loss: 0.58814 | error: 0.40625 | utility: 0.93357\n",
      "  batch 003 / 029 | loss: 0.63317 | error: 0.44792 | utility: 0.94109\n",
      "  batch 004 / 029 | loss: 0.62266 | error: 0.45312 | utility: 0.94557\n",
      "  batch 005 / 029 | loss: 0.60651 | error: 0.45312 | utility: 0.94801\n",
      "  batch 006 / 029 | loss: 0.61052 | error: 0.45833 | utility: 0.94660\n",
      "  batch 007 / 029 | loss: 0.62360 | error: 0.46875 | utility: 0.94421\n",
      "  batch 008 / 029 | loss: 0.64218 | error: 0.48047 | utility: 0.94001\n",
      "  batch 009 / 029 | loss: 0.66856 | error: 0.49653 | utility: 0.94294\n",
      "  batch 010 / 029 | loss: 0.66327 | error: 0.49531 | utility: 0.94513\n",
      "  batch 011 / 029 | loss: 0.64910 | error: 0.49006 | utility: 0.95077\n",
      "  batch 012 / 029 | loss: 0.66587 | error: 0.49870 | utility: 0.93986\n",
      "  batch 013 / 029 | loss: 0.65763 | error: 0.49519 | utility: 0.91462\n",
      "  batch 014 / 029 | loss: 0.66025 | error: 0.49888 | utility: 0.93799\n",
      "  batch 015 / 029 | loss: 0.64925 | error: 0.49375 | utility: 0.93026\n",
      "  batch 016 / 029 | loss: 0.64748 | error: 0.49219 | utility: 0.93954\n",
      "  batch 017 / 029 | loss: 0.64353 | error: 0.49265 | utility: 0.91701\n",
      "  batch 018 / 029 | loss: 0.65090 | error: 0.49826 | utility: 0.92957\n",
      "  batch 019 / 029 | loss: 0.65550 | error: 0.50247 | utility: 0.92631\n",
      "  batch 020 / 029 | loss: 0.65704 | error: 0.50547 | utility: 0.92836\n",
      "  batch 021 / 029 | loss: 0.64738 | error: 0.50074 | utility: 0.94121\n",
      "  batch 022 / 029 | loss: 0.63481 | error: 0.49432 | utility: 0.93571\n",
      "  batch 023 / 029 | loss: 0.63123 | error: 0.49389 | utility: 0.90089\n",
      "  batch 024 / 029 | loss: 0.62961 | error: 0.49414 | utility: 0.92693\n",
      "  batch 025 / 029 | loss: 0.62683 | error: 0.49250 | utility: 0.93017\n",
      "  batch 026 / 029 | loss: 0.62480 | error: 0.49099 | utility: 0.92694\n",
      "  batch 027 / 029 | loss: 0.62458 | error: 0.49074 | utility: 0.92786\n",
      "  batch 028 / 029 | loss: 0.62220 | error: 0.49051 | utility: 0.93765\n",
      "  batch 029 / 029 | loss: 0.61997 | error: 0.49084 | utility: 0.94158\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 001 / 010 | time: 026 sec | loss: 0.60995 | error: 0.49688 | utility: 0.94745\n",
      "Saving model to ./Results/utility/utility_0.600_model.pt.\n",
      "Starting epoch 002 / 010.\n",
      "  batch 001 / 029 | loss: 0.67360 | error: 0.53125 | utility: 0.93035\n",
      "  batch 002 / 029 | loss: 0.65024 | error: 0.52344 | utility: 0.93242\n",
      "  batch 003 / 029 | loss: 0.65964 | error: 0.52083 | utility: 0.91204\n",
      "  batch 004 / 029 | loss: 0.63621 | error: 0.50781 | utility: 0.94080\n",
      "  batch 005 / 029 | loss: 0.63243 | error: 0.50938 | utility: 0.93627\n",
      "  batch 006 / 029 | loss: 0.61936 | error: 0.50260 | utility: 0.91378\n",
      "  batch 007 / 029 | loss: 0.63440 | error: 0.51339 | utility: 0.92493\n",
      "  batch 008 / 029 | loss: 0.60498 | error: 0.49805 | utility: 0.93989\n",
      "  batch 009 / 029 | loss: 0.58634 | error: 0.48785 | utility: 0.92470\n",
      "  batch 010 / 029 | loss: 0.56809 | error: 0.47656 | utility: 0.93033\n",
      "  batch 011 / 029 | loss: 0.56432 | error: 0.47443 | utility: 0.94589\n",
      "  batch 012 / 029 | loss: 0.57447 | error: 0.48177 | utility: 0.92315\n",
      "  batch 013 / 029 | loss: 0.57932 | error: 0.48317 | utility: 0.87807\n",
      "  batch 014 / 029 | loss: 0.59010 | error: 0.48661 | utility: 0.93124\n",
      "  batch 015 / 029 | loss: 0.57480 | error: 0.47708 | utility: 0.94105\n",
      "  batch 016 / 029 | loss: 0.56928 | error: 0.47266 | utility: 0.86836\n",
      "  batch 017 / 029 | loss: 0.56807 | error: 0.47243 | utility: 0.93449\n",
      "  batch 018 / 029 | loss: 0.57058 | error: 0.47396 | utility: 0.94208\n",
      "  batch 019 / 029 | loss: 0.57822 | error: 0.47862 | utility: 0.90370\n",
      "  batch 020 / 029 | loss: 0.57275 | error: 0.47422 | utility: 0.89816\n",
      "  batch 021 / 029 | loss: 0.59007 | error: 0.48289 | utility: 0.93536\n",
      "  batch 022 / 029 | loss: 0.59000 | error: 0.48366 | utility: 0.92748\n",
      "  batch 023 / 029 | loss: 0.58751 | error: 0.48302 | utility: 0.94668\n",
      "  batch 024 / 029 | loss: 0.58707 | error: 0.48242 | utility: 0.94262\n",
      "  batch 025 / 029 | loss: 0.59279 | error: 0.48562 | utility: 0.92180\n",
      "  batch 026 / 029 | loss: 0.58967 | error: 0.48438 | utility: 0.93760\n",
      "  batch 027 / 029 | loss: 0.59088 | error: 0.48495 | utility: 0.92257\n",
      "  batch 028 / 029 | loss: 0.59069 | error: 0.48493 | utility: 0.94790\n",
      "  batch 029 / 029 | loss: 0.58932 | error: 0.48545 | utility: 0.94405\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 002 / 010 | time: 026 sec | loss: 0.59745 | error: 0.49167 | utility: 0.94866\n",
      "Validation accuracy improved.\n",
      "Saving model to ./Results/utility/utility_0.600_model.pt.\n",
      "Starting epoch 003 / 010.\n",
      "  batch 001 / 029 | loss: 0.80055 | error: 0.60938 | utility: 0.93300\n",
      "  batch 002 / 029 | loss: 0.67618 | error: 0.53906 | utility: 0.92838\n",
      "  batch 003 / 029 | loss: 0.62253 | error: 0.51562 | utility: 0.93227\n",
      "  batch 004 / 029 | loss: 0.60276 | error: 0.50000 | utility: 0.94090\n",
      "  batch 005 / 029 | loss: 0.59878 | error: 0.49375 | utility: 0.90602\n",
      "  batch 006 / 029 | loss: 0.62235 | error: 0.50781 | utility: 0.92403\n",
      "  batch 007 / 029 | loss: 0.59197 | error: 0.49107 | utility: 0.90982\n",
      "  batch 008 / 029 | loss: 0.61426 | error: 0.50195 | utility: 0.92673\n",
      "  batch 009 / 029 | loss: 0.59893 | error: 0.49479 | utility: 0.89620\n",
      "  batch 010 / 029 | loss: 0.59576 | error: 0.49219 | utility: 0.89513\n",
      "  batch 011 / 029 | loss: 0.60535 | error: 0.49574 | utility: 0.89266\n",
      "  batch 012 / 029 | loss: 0.61010 | error: 0.49740 | utility: 0.91823\n",
      "  batch 013 / 029 | loss: 0.61930 | error: 0.50240 | utility: 0.86970\n",
      "  batch 014 / 029 | loss: 0.60552 | error: 0.49554 | utility: 0.92419\n",
      "  batch 015 / 029 | loss: 0.60256 | error: 0.49375 | utility: 0.89789\n",
      "  batch 016 / 029 | loss: 0.60777 | error: 0.49512 | utility: 0.90732\n",
      "  batch 017 / 029 | loss: 0.60514 | error: 0.49357 | utility: 0.91787\n",
      "  batch 018 / 029 | loss: 0.60779 | error: 0.49392 | utility: 0.89663\n",
      "  batch 019 / 029 | loss: 0.61824 | error: 0.49918 | utility: 0.92724\n",
      "  batch 020 / 029 | loss: 0.61331 | error: 0.49609 | utility: 0.94065\n",
      "  batch 021 / 029 | loss: 0.60823 | error: 0.49405 | utility: 0.90925\n",
      "  batch 022 / 029 | loss: 0.60743 | error: 0.49361 | utility: 0.92766\n",
      "  batch 023 / 029 | loss: 0.60128 | error: 0.49049 | utility: 0.94205\n",
      "  batch 024 / 029 | loss: 0.60507 | error: 0.49284 | utility: 0.93040\n",
      "  batch 025 / 029 | loss: 0.59786 | error: 0.48812 | utility: 0.93712\n",
      "  batch 026 / 029 | loss: 0.59967 | error: 0.48918 | utility: 0.91405\n",
      "  batch 027 / 029 | loss: 0.59659 | error: 0.48785 | utility: 0.93566\n",
      "  batch 028 / 029 | loss: 0.59087 | error: 0.48549 | utility: 0.93557\n",
      "  batch 029 / 029 | loss: 0.58036 | error: 0.48168 | utility: 0.94358\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 003 / 010 | time: 025 sec | loss: 0.57673 | error: 0.48125 | utility: 0.95300\n",
      "Validation accuracy improved.\n",
      "Saving model to ./Results/utility/utility_0.600_model.pt.\n",
      "Starting epoch 004 / 010.\n",
      "  batch 001 / 029 | loss: 0.66228 | error: 0.51562 | utility: 0.91882\n",
      "  batch 002 / 029 | loss: 0.62740 | error: 0.49219 | utility: 0.93510\n",
      "  batch 003 / 029 | loss: 0.55630 | error: 0.46354 | utility: 0.93481\n",
      "  batch 004 / 029 | loss: 0.51640 | error: 0.44141 | utility: 0.91384\n",
      "  batch 005 / 029 | loss: 0.52988 | error: 0.44688 | utility: 0.93730\n",
      "  batch 006 / 029 | loss: 0.53918 | error: 0.45573 | utility: 0.93006\n",
      "  batch 007 / 029 | loss: 0.54596 | error: 0.46205 | utility: 0.93762\n",
      "  batch 008 / 029 | loss: 0.54422 | error: 0.45703 | utility: 0.90457\n",
      "  batch 009 / 029 | loss: 0.56950 | error: 0.46701 | utility: 0.91444\n",
      "  batch 010 / 029 | loss: 0.55031 | error: 0.45937 | utility: 0.94459\n",
      "  batch 011 / 029 | loss: 0.55879 | error: 0.46449 | utility: 0.93998\n",
      "  batch 012 / 029 | loss: 0.57578 | error: 0.47396 | utility: 0.93854\n",
      "  batch 013 / 029 | loss: 0.56624 | error: 0.47115 | utility: 0.94538\n",
      "  batch 014 / 029 | loss: 0.56562 | error: 0.47210 | utility: 0.92710\n",
      "  batch 015 / 029 | loss: 0.56548 | error: 0.47292 | utility: 0.94889\n",
      "  batch 016 / 029 | loss: 0.57563 | error: 0.47754 | utility: 0.91918\n",
      "  batch 017 / 029 | loss: 0.58650 | error: 0.48346 | utility: 0.94115\n",
      "  batch 018 / 029 | loss: 0.58690 | error: 0.48351 | utility: 0.92846\n",
      "  batch 019 / 029 | loss: 0.58927 | error: 0.48520 | utility: 0.93233\n",
      "  batch 020 / 029 | loss: 0.58849 | error: 0.48359 | utility: 0.91858\n",
      "  batch 021 / 029 | loss: 0.58534 | error: 0.48214 | utility: 0.94472\n",
      "  batch 022 / 029 | loss: 0.58638 | error: 0.48153 | utility: 0.91244\n",
      "  batch 023 / 029 | loss: 0.59075 | error: 0.48438 | utility: 0.92489\n",
      "  batch 024 / 029 | loss: 0.59402 | error: 0.48633 | utility: 0.94129\n",
      "  batch 025 / 029 | loss: 0.58995 | error: 0.48438 | utility: 0.94538\n",
      "  batch 026 / 029 | loss: 0.59220 | error: 0.48678 | utility: 0.94182\n",
      "  batch 027 / 029 | loss: 0.59227 | error: 0.48669 | utility: 0.93175\n",
      "  batch 028 / 029 | loss: 0.59191 | error: 0.48605 | utility: 0.91099\n",
      "  batch 029 / 029 | loss: 0.59126 | error: 0.48222 | utility: 0.77071\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 004 / 010 | time: 026 sec | loss: 0.59925 | error: 0.48646 | utility: 0.94528\n",
      "Starting epoch 005 / 010.\n",
      "  batch 001 / 029 | loss: 0.68988 | error: 0.53125 | utility: 0.92735\n",
      "  batch 002 / 029 | loss: 0.64452 | error: 0.50781 | utility: 0.93536\n",
      "  batch 003 / 029 | loss: 0.62918 | error: 0.50521 | utility: 0.93818\n",
      "  batch 004 / 029 | loss: 0.62301 | error: 0.50000 | utility: 0.91026\n",
      "  batch 005 / 029 | loss: 0.64696 | error: 0.51875 | utility: 0.92904\n",
      "  batch 006 / 029 | loss: 0.60464 | error: 0.49479 | utility: 0.91958\n",
      "  batch 007 / 029 | loss: 0.60602 | error: 0.49554 | utility: 0.93390\n",
      "  batch 008 / 029 | loss: 0.60433 | error: 0.49609 | utility: 0.93815\n",
      "  batch 009 / 029 | loss: 0.61052 | error: 0.49826 | utility: 0.94519\n",
      "  batch 010 / 029 | loss: 0.60897 | error: 0.49844 | utility: 0.93506\n",
      "  batch 011 / 029 | loss: 0.60978 | error: 0.49858 | utility: 0.94380\n",
      "  batch 012 / 029 | loss: 0.60370 | error: 0.49609 | utility: 0.92921\n",
      "  batch 013 / 029 | loss: 0.59065 | error: 0.48798 | utility: 0.91218\n",
      "  batch 014 / 029 | loss: 0.60872 | error: 0.49777 | utility: 0.90049\n",
      "  batch 015 / 029 | loss: 0.59879 | error: 0.48958 | utility: 0.91263\n",
      "  batch 016 / 029 | loss: 0.59472 | error: 0.48535 | utility: 0.91341\n",
      "  batch 017 / 029 | loss: 0.59108 | error: 0.48346 | utility: 0.93054\n",
      "  batch 018 / 029 | loss: 0.59248 | error: 0.48524 | utility: 0.92045\n",
      "  batch 019 / 029 | loss: 0.59662 | error: 0.48766 | utility: 0.91760\n",
      "  batch 020 / 029 | loss: 0.59326 | error: 0.48594 | utility: 0.90643\n",
      "  batch 021 / 029 | loss: 0.59416 | error: 0.48735 | utility: 0.93221\n",
      "  batch 022 / 029 | loss: 0.59145 | error: 0.48580 | utility: 0.93611\n",
      "  batch 023 / 029 | loss: 0.58687 | error: 0.48302 | utility: 0.87144\n",
      "  batch 024 / 029 | loss: 0.59014 | error: 0.48438 | utility: 0.90805\n",
      "  batch 025 / 029 | loss: 0.59111 | error: 0.48562 | utility: 0.92569\n",
      "  batch 026 / 029 | loss: 0.59490 | error: 0.48738 | utility: 0.93992\n",
      "  batch 027 / 029 | loss: 0.59333 | error: 0.48669 | utility: 0.93420\n",
      "  batch 028 / 029 | loss: 0.58997 | error: 0.48438 | utility: 0.93593\n",
      "  batch 029 / 029 | loss: 0.59474 | error: 0.48922 | utility: 0.90347\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 005 / 010 | time: 025 sec | loss: 0.58263 | error: 0.47865 | utility: 0.94398\n",
      "Validation accuracy improved.\n",
      "Saving model to ./Results/utility/utility_0.600_model.pt.\n",
      "Starting epoch 006 / 010.\n",
      "  batch 001 / 029 | loss: 0.57105 | error: 0.50000 | utility: 0.93485\n",
      "  batch 002 / 029 | loss: 0.66953 | error: 0.53906 | utility: 0.89271\n",
      "  batch 003 / 029 | loss: 0.63395 | error: 0.51562 | utility: 0.93592\n",
      "  batch 004 / 029 | loss: 0.67630 | error: 0.53906 | utility: 0.89582\n",
      "  batch 005 / 029 | loss: 0.64136 | error: 0.52187 | utility: 0.91813\n",
      "  batch 006 / 029 | loss: 0.62365 | error: 0.51042 | utility: 0.90190\n",
      "  batch 007 / 029 | loss: 0.61211 | error: 0.50223 | utility: 0.89299\n",
      "  batch 008 / 029 | loss: 0.61141 | error: 0.50195 | utility: 0.91468\n",
      "  batch 009 / 029 | loss: 0.59435 | error: 0.48958 | utility: 0.87981\n",
      "  batch 010 / 029 | loss: 0.58863 | error: 0.48750 | utility: 0.93493\n",
      "  batch 011 / 029 | loss: 0.59897 | error: 0.49148 | utility: 0.93864\n",
      "  batch 012 / 029 | loss: 0.58115 | error: 0.48047 | utility: 0.90768\n",
      "  batch 013 / 029 | loss: 0.58719 | error: 0.48317 | utility: 0.89557\n",
      "  batch 014 / 029 | loss: 0.59068 | error: 0.48549 | utility: 0.90774\n",
      "  batch 015 / 029 | loss: 0.58468 | error: 0.48438 | utility: 0.92744\n",
      "  batch 016 / 029 | loss: 0.59687 | error: 0.48926 | utility: 0.91298\n",
      "  batch 017 / 029 | loss: 0.60124 | error: 0.49173 | utility: 0.91981\n",
      "  batch 018 / 029 | loss: 0.59943 | error: 0.49132 | utility: 0.91450\n",
      "  batch 019 / 029 | loss: 0.60365 | error: 0.49342 | utility: 0.89123\n",
      "  batch 020 / 029 | loss: 0.60981 | error: 0.49609 | utility: 0.89620\n",
      "  batch 021 / 029 | loss: 0.60205 | error: 0.49256 | utility: 0.92853\n",
      "  batch 022 / 029 | loss: 0.59395 | error: 0.48793 | utility: 0.91692\n",
      "  batch 023 / 029 | loss: 0.59006 | error: 0.48573 | utility: 0.90855\n",
      "  batch 024 / 029 | loss: 0.58710 | error: 0.48438 | utility: 0.91633\n",
      "  batch 025 / 029 | loss: 0.58622 | error: 0.48313 | utility: 0.93281\n",
      "  batch 026 / 029 | loss: 0.58186 | error: 0.48077 | utility: 0.93287\n",
      "  batch 027 / 029 | loss: 0.58413 | error: 0.48206 | utility: 0.93112\n",
      "  batch 028 / 029 | loss: 0.59093 | error: 0.48549 | utility: 0.88166\n",
      "  batch 029 / 029 | loss: 0.59233 | error: 0.48168 | utility: 0.90269\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 006 / 010 | time: 025 sec | loss: 0.60972 | error: 0.50208 | utility: 0.94822\n",
      "Starting epoch 007 / 010.\n",
      "  batch 001 / 029 | loss: 0.66385 | error: 0.51562 | utility: 0.93821\n",
      "  batch 002 / 029 | loss: 0.71899 | error: 0.55469 | utility: 0.94273\n",
      "  batch 003 / 029 | loss: 0.73299 | error: 0.56250 | utility: 0.95003\n",
      "  batch 004 / 029 | loss: 0.68491 | error: 0.53516 | utility: 0.92698\n",
      "  batch 005 / 029 | loss: 0.63063 | error: 0.50938 | utility: 0.94691\n",
      "  batch 006 / 029 | loss: 0.62011 | error: 0.50521 | utility: 0.95169\n",
      "  batch 007 / 029 | loss: 0.59223 | error: 0.48661 | utility: 0.93973\n",
      "  batch 008 / 029 | loss: 0.60313 | error: 0.49414 | utility: 0.95757\n",
      "  batch 009 / 029 | loss: 0.59684 | error: 0.49132 | utility: 0.94866\n",
      "  batch 010 / 029 | loss: 0.58933 | error: 0.48750 | utility: 0.96299\n",
      "  batch 011 / 029 | loss: 0.58567 | error: 0.48438 | utility: 0.96152\n",
      "  batch 012 / 029 | loss: 0.57918 | error: 0.48177 | utility: 0.95319\n",
      "  batch 013 / 029 | loss: 0.57262 | error: 0.47957 | utility: 0.94900\n",
      "  batch 014 / 029 | loss: 0.57044 | error: 0.47768 | utility: 0.96108\n",
      "  batch 015 / 029 | loss: 0.56745 | error: 0.47604 | utility: 0.96082\n",
      "  batch 016 / 029 | loss: 0.57353 | error: 0.48047 | utility: 0.95769\n",
      "  batch 017 / 029 | loss: 0.56876 | error: 0.47794 | utility: 0.95206\n",
      "  batch 018 / 029 | loss: 0.57059 | error: 0.47830 | utility: 0.95683\n",
      "  batch 019 / 029 | loss: 0.58273 | error: 0.48520 | utility: 0.95177\n",
      "  batch 020 / 029 | loss: 0.58641 | error: 0.48672 | utility: 0.95921\n",
      "  batch 021 / 029 | loss: 0.59271 | error: 0.49033 | utility: 0.95425\n",
      "  batch 022 / 029 | loss: 0.59345 | error: 0.49077 | utility: 0.95206\n",
      "  batch 023 / 029 | loss: 0.59522 | error: 0.49185 | utility: 0.95616\n",
      "  batch 024 / 029 | loss: 0.59725 | error: 0.49284 | utility: 0.95714\n",
      "  batch 025 / 029 | loss: 0.59629 | error: 0.49125 | utility: 0.93216\n",
      "  batch 026 / 029 | loss: 0.59130 | error: 0.48858 | utility: 0.92299\n",
      "  batch 027 / 029 | loss: 0.58770 | error: 0.48669 | utility: 0.95694\n",
      "  batch 028 / 029 | loss: 0.58976 | error: 0.48772 | utility: 0.93958\n",
      "  batch 029 / 029 | loss: 0.59821 | error: 0.49246 | utility: 0.94843\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 007 / 010 | time: 025 sec | loss: 0.57556 | error: 0.47865 | utility: 0.95414\n",
      "Starting epoch 008 / 010.\n",
      "  batch 001 / 029 | loss: 0.65282 | error: 0.53125 | utility: 0.94765\n",
      "  batch 002 / 029 | loss: 0.55836 | error: 0.47656 | utility: 0.94432\n",
      "  batch 003 / 029 | loss: 0.58969 | error: 0.48438 | utility: 0.94355\n",
      "  batch 004 / 029 | loss: 0.51087 | error: 0.43750 | utility: 0.95197\n",
      "  batch 005 / 029 | loss: 0.53998 | error: 0.45312 | utility: 0.89957\n",
      "  batch 006 / 029 | loss: 0.58228 | error: 0.47656 | utility: 0.91627\n",
      "  batch 007 / 029 | loss: 0.61004 | error: 0.49107 | utility: 0.91842\n",
      "  batch 008 / 029 | loss: 0.61340 | error: 0.49414 | utility: 0.93655\n",
      "  batch 009 / 029 | loss: 0.61631 | error: 0.49826 | utility: 0.93351\n",
      "  batch 010 / 029 | loss: 0.61167 | error: 0.49531 | utility: 0.92493\n",
      "  batch 011 / 029 | loss: 0.62774 | error: 0.50426 | utility: 0.92827\n",
      "  batch 012 / 029 | loss: 0.62939 | error: 0.50651 | utility: 0.92759\n",
      "  batch 013 / 029 | loss: 0.61429 | error: 0.49639 | utility: 0.92633\n",
      "  batch 014 / 029 | loss: 0.60476 | error: 0.49219 | utility: 0.93910\n",
      "  batch 015 / 029 | loss: 0.60462 | error: 0.49167 | utility: 0.93770\n",
      "  batch 016 / 029 | loss: 0.60460 | error: 0.49316 | utility: 0.93234\n",
      "  batch 017 / 029 | loss: 0.61447 | error: 0.49908 | utility: 0.93284\n",
      "  batch 018 / 029 | loss: 0.62226 | error: 0.50434 | utility: 0.93030\n",
      "  batch 019 / 029 | loss: 0.61731 | error: 0.50164 | utility: 0.91971\n",
      "  batch 020 / 029 | loss: 0.61561 | error: 0.50000 | utility: 0.93595\n",
      "  batch 021 / 029 | loss: 0.60850 | error: 0.49628 | utility: 0.94102\n",
      "  batch 022 / 029 | loss: 0.59470 | error: 0.48864 | utility: 0.90112\n",
      "  batch 023 / 029 | loss: 0.59234 | error: 0.48709 | utility: 0.90964\n",
      "  batch 024 / 029 | loss: 0.58565 | error: 0.48372 | utility: 0.93476\n",
      "  batch 025 / 029 | loss: 0.58443 | error: 0.48250 | utility: 0.90548\n",
      "  batch 026 / 029 | loss: 0.58224 | error: 0.48137 | utility: 0.91449\n",
      "  batch 027 / 029 | loss: 0.58691 | error: 0.48380 | utility: 0.91505\n",
      "  batch 028 / 029 | loss: 0.58966 | error: 0.48493 | utility: 0.85853\n",
      "  batch 029 / 029 | loss: 0.59245 | error: 0.48545 | utility: 0.90853\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 008 / 010 | time: 026 sec | loss: 0.59614 | error: 0.49167 | utility: 0.94347\n",
      "Starting epoch 009 / 010.\n",
      "  batch 001 / 029 | loss: 0.55624 | error: 0.48438 | utility: 0.91418\n",
      "  batch 002 / 029 | loss: 0.61784 | error: 0.50781 | utility: 0.89729\n",
      "  batch 003 / 029 | loss: 0.58764 | error: 0.47917 | utility: 0.91263\n",
      "  batch 004 / 029 | loss: 0.54544 | error: 0.45312 | utility: 0.91174\n",
      "  batch 005 / 029 | loss: 0.60387 | error: 0.48750 | utility: 0.92490\n",
      "  batch 006 / 029 | loss: 0.58159 | error: 0.47917 | utility: 0.93192\n",
      "  batch 007 / 029 | loss: 0.56661 | error: 0.47098 | utility: 0.93151\n",
      "  batch 008 / 029 | loss: 0.57796 | error: 0.47656 | utility: 0.90322\n",
      "  batch 009 / 029 | loss: 0.57191 | error: 0.47569 | utility: 0.93789\n",
      "  batch 010 / 029 | loss: 0.58720 | error: 0.48281 | utility: 0.94056\n",
      "  batch 011 / 029 | loss: 0.57661 | error: 0.47443 | utility: 0.94450\n",
      "  batch 012 / 029 | loss: 0.57206 | error: 0.47135 | utility: 0.92255\n",
      "  batch 013 / 029 | loss: 0.57078 | error: 0.46995 | utility: 0.93952\n",
      "  batch 014 / 029 | loss: 0.57001 | error: 0.46987 | utility: 0.93318\n",
      "  batch 015 / 029 | loss: 0.56137 | error: 0.46563 | utility: 0.95469\n",
      "  batch 016 / 029 | loss: 0.57407 | error: 0.47363 | utility: 0.94222\n",
      "  batch 017 / 029 | loss: 0.57641 | error: 0.47518 | utility: 0.92801\n",
      "  batch 018 / 029 | loss: 0.57987 | error: 0.47743 | utility: 0.95283\n",
      "  batch 019 / 029 | loss: 0.58280 | error: 0.48026 | utility: 0.93890\n",
      "  batch 020 / 029 | loss: 0.57602 | error: 0.47734 | utility: 0.95579\n",
      "  batch 021 / 029 | loss: 0.57340 | error: 0.47545 | utility: 0.95246\n",
      "  batch 022 / 029 | loss: 0.57619 | error: 0.47656 | utility: 0.91716\n",
      "  batch 023 / 029 | loss: 0.57477 | error: 0.47622 | utility: 0.95187\n",
      "  batch 024 / 029 | loss: 0.57219 | error: 0.47396 | utility: 0.92731\n",
      "  batch 025 / 029 | loss: 0.57375 | error: 0.47500 | utility: 0.95689\n",
      "  batch 026 / 029 | loss: 0.57762 | error: 0.47776 | utility: 0.94954\n",
      "  batch 027 / 029 | loss: 0.58275 | error: 0.48032 | utility: 0.94880\n",
      "  batch 028 / 029 | loss: 0.59269 | error: 0.48605 | utility: 0.94774\n",
      "  batch 029 / 029 | loss: 0.58373 | error: 0.48222 | utility: 0.95820\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 009 / 010 | time: 026 sec | loss: 0.58524 | error: 0.48646 | utility: 0.95220\n",
      "Ending training due to 4 consecutive epochs without improvement in validation accuracy.\n",
      "Total training time: 4 minutes (229.72568154335022 seconds).\n",
      "Loading model from ./Results/utility/utility_0.600_model.pt.\n",
      "---------- Training with lambda=0.6500000000000001 ----------\n",
      "Starting epoch 001 / 010.\n",
      "  batch 001 / 029 | loss: 0.58762 | error: 0.40625 | utility: 0.93142\n",
      "  batch 002 / 029 | loss: 0.56518 | error: 0.40625 | utility: 0.93357\n",
      "  batch 003 / 029 | loss: 0.60927 | error: 0.44792 | utility: 0.94100\n",
      "  batch 004 / 029 | loss: 0.59783 | error: 0.45312 | utility: 0.94547\n",
      "  batch 005 / 029 | loss: 0.58093 | error: 0.45312 | utility: 0.94792\n",
      "  batch 006 / 029 | loss: 0.58447 | error: 0.45833 | utility: 0.94655\n",
      "  batch 007 / 029 | loss: 0.59734 | error: 0.46875 | utility: 0.94439\n",
      "  batch 008 / 029 | loss: 0.61581 | error: 0.48047 | utility: 0.94044\n",
      "  batch 009 / 029 | loss: 0.64234 | error: 0.49653 | utility: 0.94375\n",
      "  batch 010 / 029 | loss: 0.63679 | error: 0.49531 | utility: 0.94628\n",
      "  batch 011 / 029 | loss: 0.62240 | error: 0.49006 | utility: 0.95199\n",
      "  batch 012 / 029 | loss: 0.63930 | error: 0.49870 | utility: 0.94251\n",
      "  batch 013 / 029 | loss: 0.63098 | error: 0.49519 | utility: 0.91918\n",
      "  batch 014 / 029 | loss: 0.63379 | error: 0.49888 | utility: 0.94179\n",
      "  batch 015 / 029 | loss: 0.62256 | error: 0.49375 | utility: 0.93522\n",
      "  batch 016 / 029 | loss: 0.62072 | error: 0.49219 | utility: 0.94422\n",
      "  batch 017 / 029 | loss: 0.61692 | error: 0.49265 | utility: 0.92506\n",
      "  batch 018 / 029 | loss: 0.62455 | error: 0.49826 | utility: 0.93601\n",
      "  batch 019 / 029 | loss: 0.62937 | error: 0.50247 | utility: 0.93412\n",
      "  batch 020 / 029 | loss: 0.63113 | error: 0.50547 | utility: 0.93734\n",
      "  batch 021 / 029 | loss: 0.62122 | error: 0.50074 | utility: 0.94754\n",
      "  batch 022 / 029 | loss: 0.60828 | error: 0.49432 | utility: 0.94335\n",
      "  batch 023 / 029 | loss: 0.60467 | error: 0.49321 | utility: 0.91749\n",
      "  batch 024 / 029 | loss: 0.60310 | error: 0.49349 | utility: 0.93855\n",
      "  batch 025 / 029 | loss: 0.60015 | error: 0.49188 | utility: 0.94131\n",
      "  batch 026 / 029 | loss: 0.59794 | error: 0.49038 | utility: 0.94054\n",
      "  batch 027 / 029 | loss: 0.59761 | error: 0.49016 | utility: 0.94112\n",
      "  batch 028 / 029 | loss: 0.59530 | error: 0.48996 | utility: 0.94843\n",
      "  batch 029 / 029 | loss: 0.59385 | error: 0.49030 | utility: 0.95036\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 001 / 010 | time: 025 sec | loss: 0.58207 | error: 0.49688 | utility: 0.95752\n",
      "Saving model to ./Results/utility/utility_0.650_model.pt.\n",
      "Starting epoch 002 / 010.\n",
      "  batch 001 / 029 | loss: 0.64658 | error: 0.53125 | utility: 0.94367\n",
      "  batch 002 / 029 | loss: 0.62301 | error: 0.52344 | utility: 0.94623\n",
      "  batch 003 / 029 | loss: 0.63192 | error: 0.52604 | utility: 0.93237\n",
      "  batch 004 / 029 | loss: 0.60806 | error: 0.51172 | utility: 0.95237\n",
      "  batch 005 / 029 | loss: 0.60527 | error: 0.51250 | utility: 0.94846\n",
      "  batch 006 / 029 | loss: 0.59284 | error: 0.50781 | utility: 0.93567\n",
      "  batch 007 / 029 | loss: 0.60900 | error: 0.51786 | utility: 0.94079\n",
      "  batch 008 / 029 | loss: 0.57887 | error: 0.50195 | utility: 0.95213\n",
      "  batch 009 / 029 | loss: 0.55992 | error: 0.49132 | utility: 0.94205\n",
      "  batch 010 / 029 | loss: 0.54031 | error: 0.47969 | utility: 0.94545\n",
      "  batch 011 / 029 | loss: 0.53659 | error: 0.47727 | utility: 0.95551\n",
      "  batch 012 / 029 | loss: 0.54748 | error: 0.48438 | utility: 0.94021\n",
      "  batch 013 / 029 | loss: 0.55300 | error: 0.48678 | utility: 0.90892\n",
      "  batch 014 / 029 | loss: 0.56362 | error: 0.48996 | utility: 0.94509\n",
      "  batch 015 / 029 | loss: 0.54733 | error: 0.48021 | utility: 0.95314\n",
      "  batch 016 / 029 | loss: 0.54146 | error: 0.47559 | utility: 0.89912\n",
      "  batch 017 / 029 | loss: 0.54022 | error: 0.47518 | utility: 0.94824\n",
      "  batch 018 / 029 | loss: 0.54283 | error: 0.47656 | utility: 0.95342\n",
      "  batch 019 / 029 | loss: 0.55080 | error: 0.48109 | utility: 0.92492\n",
      "  batch 020 / 029 | loss: 0.54483 | error: 0.47734 | utility: 0.92981\n",
      "  batch 021 / 029 | loss: 0.56218 | error: 0.48586 | utility: 0.94949\n",
      "  batch 022 / 029 | loss: 0.56262 | error: 0.48651 | utility: 0.94656\n",
      "  batch 023 / 029 | loss: 0.56025 | error: 0.48573 | utility: 0.95760\n",
      "  batch 024 / 029 | loss: 0.55945 | error: 0.48503 | utility: 0.95483\n",
      "  batch 025 / 029 | loss: 0.56535 | error: 0.48875 | utility: 0.94444\n",
      "  batch 026 / 029 | loss: 0.56223 | error: 0.48738 | utility: 0.95258\n",
      "  batch 027 / 029 | loss: 0.56356 | error: 0.48785 | utility: 0.94164\n",
      "  batch 028 / 029 | loss: 0.56328 | error: 0.48772 | utility: 0.95908\n",
      "  batch 029 / 029 | loss: 0.56229 | error: 0.48815 | utility: 0.95611\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 002 / 010 | time: 026 sec | loss: 0.56228 | error: 0.49167 | utility: 0.96176\n",
      "Validation accuracy improved.\n",
      "Saving model to ./Results/utility/utility_0.650_model.pt.\n",
      "Starting epoch 003 / 010.\n",
      "  batch 001 / 029 | loss: 0.78056 | error: 0.60938 | utility: 0.95027\n",
      "  batch 002 / 029 | loss: 0.65189 | error: 0.53906 | utility: 0.94676\n",
      "  batch 003 / 029 | loss: 0.59839 | error: 0.51562 | utility: 0.94928\n",
      "  batch 004 / 029 | loss: 0.57677 | error: 0.50000 | utility: 0.95344\n",
      "  batch 005 / 029 | loss: 0.57314 | error: 0.50000 | utility: 0.93245\n",
      "  batch 006 / 029 | loss: 0.59694 | error: 0.51302 | utility: 0.94272\n",
      "  batch 007 / 029 | loss: 0.56616 | error: 0.49777 | utility: 0.93355\n",
      "  batch 008 / 029 | loss: 0.58804 | error: 0.50781 | utility: 0.94445\n",
      "  batch 009 / 029 | loss: 0.57320 | error: 0.50000 | utility: 0.91898\n",
      "  batch 010 / 029 | loss: 0.56988 | error: 0.49688 | utility: 0.91720\n",
      "  batch 011 / 029 | loss: 0.57958 | error: 0.50142 | utility: 0.91758\n",
      "  batch 012 / 029 | loss: 0.58405 | error: 0.50260 | utility: 0.93512\n",
      "  batch 013 / 029 | loss: 0.59385 | error: 0.50841 | utility: 0.89295\n",
      "  batch 014 / 029 | loss: 0.57972 | error: 0.50112 | utility: 0.93950\n",
      "  batch 015 / 029 | loss: 0.57634 | error: 0.49896 | utility: 0.91785\n",
      "  batch 016 / 029 | loss: 0.58146 | error: 0.50098 | utility: 0.92588\n",
      "  batch 017 / 029 | loss: 0.57857 | error: 0.49908 | utility: 0.93555\n",
      "  batch 018 / 029 | loss: 0.58093 | error: 0.49913 | utility: 0.92025\n",
      "  batch 019 / 029 | loss: 0.59163 | error: 0.50411 | utility: 0.94125\n",
      "  batch 020 / 029 | loss: 0.58628 | error: 0.50078 | utility: 0.95046\n",
      "  batch 021 / 029 | loss: 0.58113 | error: 0.49851 | utility: 0.93151\n",
      "  batch 022 / 029 | loss: 0.58036 | error: 0.49787 | utility: 0.94224\n",
      "  batch 023 / 029 | loss: 0.57406 | error: 0.49457 | utility: 0.95212\n",
      "  batch 024 / 029 | loss: 0.57796 | error: 0.49674 | utility: 0.94399\n",
      "  batch 025 / 029 | loss: 0.57032 | error: 0.49188 | utility: 0.94877\n",
      "  batch 026 / 029 | loss: 0.57240 | error: 0.49279 | utility: 0.93070\n",
      "  batch 027 / 029 | loss: 0.56913 | error: 0.49132 | utility: 0.94895\n",
      "  batch 028 / 029 | loss: 0.56345 | error: 0.48884 | utility: 0.94878\n",
      "  batch 029 / 029 | loss: 0.55338 | error: 0.48491 | utility: 0.95226\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 003 / 010 | time: 025 sec | loss: 0.54658 | error: 0.48125 | utility: 0.96308\n",
      "Validation accuracy improved.\n",
      "Saving model to ./Results/utility/utility_0.650_model.pt.\n",
      "Starting epoch 004 / 010.\n",
      "  batch 001 / 029 | loss: 0.63380 | error: 0.53125 | utility: 0.93841\n",
      "  batch 002 / 029 | loss: 0.59380 | error: 0.50000 | utility: 0.95010\n",
      "  batch 003 / 029 | loss: 0.52472 | error: 0.46875 | utility: 0.94896\n",
      "  batch 004 / 029 | loss: 0.48469 | error: 0.44531 | utility: 0.93631\n",
      "  batch 005 / 029 | loss: 0.49769 | error: 0.45000 | utility: 0.95138\n",
      "  batch 006 / 029 | loss: 0.50779 | error: 0.45833 | utility: 0.94754\n",
      "  batch 007 / 029 | loss: 0.51574 | error: 0.46429 | utility: 0.95267\n",
      "  batch 008 / 029 | loss: 0.51396 | error: 0.46289 | utility: 0.93123\n",
      "  batch 009 / 029 | loss: 0.53964 | error: 0.47222 | utility: 0.93497\n",
      "  batch 010 / 029 | loss: 0.52052 | error: 0.46406 | utility: 0.95559\n",
      "  batch 011 / 029 | loss: 0.52869 | error: 0.46875 | utility: 0.95221\n",
      "  batch 012 / 029 | loss: 0.54647 | error: 0.47786 | utility: 0.95191\n",
      "  batch 013 / 029 | loss: 0.53742 | error: 0.47476 | utility: 0.95606\n",
      "  batch 014 / 029 | loss: 0.53714 | error: 0.47545 | utility: 0.94573\n",
      "  batch 015 / 029 | loss: 0.53711 | error: 0.47604 | utility: 0.95762\n",
      "  batch 016 / 029 | loss: 0.54747 | error: 0.48047 | utility: 0.93398\n",
      "  batch 017 / 029 | loss: 0.55886 | error: 0.48621 | utility: 0.95163\n",
      "  batch 018 / 029 | loss: 0.55928 | error: 0.48611 | utility: 0.94482\n",
      "  batch 019 / 029 | loss: 0.56162 | error: 0.48766 | utility: 0.94646\n",
      "  batch 020 / 029 | loss: 0.56064 | error: 0.48672 | utility: 0.93612\n",
      "  batch 021 / 029 | loss: 0.55743 | error: 0.48512 | utility: 0.95356\n",
      "  batch 022 / 029 | loss: 0.55835 | error: 0.48438 | utility: 0.92735\n",
      "  batch 023 / 029 | loss: 0.56271 | error: 0.48641 | utility: 0.94024\n",
      "  batch 024 / 029 | loss: 0.56605 | error: 0.48828 | utility: 0.95035\n",
      "  batch 025 / 029 | loss: 0.56189 | error: 0.48625 | utility: 0.95363\n",
      "  batch 026 / 029 | loss: 0.56451 | error: 0.48858 | utility: 0.95167\n",
      "  batch 027 / 029 | loss: 0.56467 | error: 0.48843 | utility: 0.94453\n",
      "  batch 028 / 029 | loss: 0.56437 | error: 0.48828 | utility: 0.93052\n",
      "  batch 029 / 029 | loss: 0.56379 | error: 0.48869 | utility: 0.84765\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 004 / 010 | time: 026 sec | loss: 0.57031 | error: 0.48646 | utility: 0.95532\n",
      "Starting epoch 005 / 010.\n",
      "  batch 001 / 029 | loss: 0.66278 | error: 0.53125 | utility: 0.94235\n",
      "  batch 002 / 029 | loss: 0.61655 | error: 0.50781 | utility: 0.94680\n",
      "  batch 003 / 029 | loss: 0.60206 | error: 0.50521 | utility: 0.94770\n",
      "  batch 004 / 029 | loss: 0.59634 | error: 0.50391 | utility: 0.93457\n",
      "  batch 005 / 029 | loss: 0.62204 | error: 0.52187 | utility: 0.94419\n",
      "  batch 006 / 029 | loss: 0.57864 | error: 0.50000 | utility: 0.93562\n",
      "  batch 007 / 029 | loss: 0.57974 | error: 0.50000 | utility: 0.94683\n",
      "  batch 008 / 029 | loss: 0.57826 | error: 0.50000 | utility: 0.95001\n",
      "  batch 009 / 029 | loss: 0.58429 | error: 0.50174 | utility: 0.95418\n",
      "  batch 010 / 029 | loss: 0.58286 | error: 0.50156 | utility: 0.94773\n",
      "  batch 011 / 029 | loss: 0.58345 | error: 0.50142 | utility: 0.95312\n",
      "  batch 012 / 029 | loss: 0.57730 | error: 0.49870 | utility: 0.94436\n",
      "  batch 013 / 029 | loss: 0.56381 | error: 0.49038 | utility: 0.92486\n",
      "  batch 014 / 029 | loss: 0.58257 | error: 0.50000 | utility: 0.92231\n",
      "  batch 015 / 029 | loss: 0.57181 | error: 0.49271 | utility: 0.93257\n",
      "  batch 016 / 029 | loss: 0.56726 | error: 0.48926 | utility: 0.93204\n",
      "  batch 017 / 029 | loss: 0.56344 | error: 0.48713 | utility: 0.94550\n",
      "  batch 018 / 029 | loss: 0.56506 | error: 0.48872 | utility: 0.93985\n",
      "  batch 019 / 029 | loss: 0.56919 | error: 0.49095 | utility: 0.93807\n",
      "  batch 020 / 029 | loss: 0.56589 | error: 0.48906 | utility: 0.92645\n",
      "  batch 021 / 029 | loss: 0.56699 | error: 0.49033 | utility: 0.94756\n",
      "  batch 022 / 029 | loss: 0.56412 | error: 0.48864 | utility: 0.94906\n",
      "  batch 023 / 029 | loss: 0.55969 | error: 0.48573 | utility: 0.89458\n",
      "  batch 024 / 029 | loss: 0.56294 | error: 0.48763 | utility: 0.93124\n",
      "  batch 025 / 029 | loss: 0.56404 | error: 0.48875 | utility: 0.94321\n",
      "  batch 026 / 029 | loss: 0.56776 | error: 0.49038 | utility: 0.95137\n",
      "  batch 027 / 029 | loss: 0.56612 | error: 0.48958 | utility: 0.94849\n",
      "  batch 028 / 029 | loss: 0.56254 | error: 0.48717 | utility: 0.94886\n",
      "  batch 029 / 029 | loss: 0.56809 | error: 0.49192 | utility: 0.92914\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 005 / 010 | time: 025 sec | loss: 0.54839 | error: 0.47865 | utility: 0.95628\n",
      "Validation accuracy improved.\n",
      "Saving model to ./Results/utility/utility_0.650_model.pt.\n",
      "Starting epoch 006 / 010.\n",
      "  batch 001 / 029 | loss: 0.54995 | error: 0.50000 | utility: 0.94870\n",
      "  batch 002 / 029 | loss: 0.64818 | error: 0.53906 | utility: 0.91445\n",
      "  batch 003 / 029 | loss: 0.61039 | error: 0.51562 | utility: 0.94813\n",
      "  batch 004 / 029 | loss: 0.65201 | error: 0.53516 | utility: 0.92032\n",
      "  batch 005 / 029 | loss: 0.61695 | error: 0.51875 | utility: 0.93600\n",
      "  batch 006 / 029 | loss: 0.59839 | error: 0.50781 | utility: 0.92568\n",
      "  batch 007 / 029 | loss: 0.58658 | error: 0.50000 | utility: 0.91938\n",
      "  batch 008 / 029 | loss: 0.58585 | error: 0.50000 | utility: 0.93524\n",
      "  batch 009 / 029 | loss: 0.56876 | error: 0.48785 | utility: 0.90428\n",
      "  batch 010 / 029 | loss: 0.56289 | error: 0.48594 | utility: 0.94722\n",
      "  batch 011 / 029 | loss: 0.57292 | error: 0.49006 | utility: 0.94907\n",
      "  batch 012 / 029 | loss: 0.55457 | error: 0.47917 | utility: 0.92747\n",
      "  batch 013 / 029 | loss: 0.56075 | error: 0.48197 | utility: 0.92134\n",
      "  batch 014 / 029 | loss: 0.56449 | error: 0.48438 | utility: 0.92082\n",
      "  batch 015 / 029 | loss: 0.55878 | error: 0.48333 | utility: 0.94377\n",
      "  batch 016 / 029 | loss: 0.57058 | error: 0.48828 | utility: 0.93509\n",
      "  batch 017 / 029 | loss: 0.57475 | error: 0.49081 | utility: 0.94021\n",
      "  batch 018 / 029 | loss: 0.57312 | error: 0.49132 | utility: 0.93584\n",
      "  batch 019 / 029 | loss: 0.57727 | error: 0.49342 | utility: 0.92398\n",
      "  batch 020 / 029 | loss: 0.58346 | error: 0.49609 | utility: 0.92072\n",
      "  batch 021 / 029 | loss: 0.57555 | error: 0.49256 | utility: 0.94578\n",
      "  batch 022 / 029 | loss: 0.56716 | error: 0.48793 | utility: 0.93928\n",
      "  batch 023 / 029 | loss: 0.56319 | error: 0.48573 | utility: 0.92476\n",
      "  batch 024 / 029 | loss: 0.56021 | error: 0.48438 | utility: 0.93810\n",
      "  batch 025 / 029 | loss: 0.55901 | error: 0.48313 | utility: 0.94713\n",
      "  batch 026 / 029 | loss: 0.55459 | error: 0.48077 | utility: 0.94795\n",
      "  batch 027 / 029 | loss: 0.55695 | error: 0.48206 | utility: 0.94679\n",
      "  batch 028 / 029 | loss: 0.56408 | error: 0.48549 | utility: 0.90980\n",
      "  batch 029 / 029 | loss: 0.56381 | error: 0.48168 | utility: 0.93172\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 006 / 010 | time: 025 sec | loss: 0.57859 | error: 0.50208 | utility: 0.96224\n",
      "Starting epoch 007 / 010.\n",
      "  batch 001 / 029 | loss: 0.63425 | error: 0.51562 | utility: 0.95319\n",
      "  batch 002 / 029 | loss: 0.69562 | error: 0.55469 | utility: 0.95690\n",
      "  batch 003 / 029 | loss: 0.71041 | error: 0.56250 | utility: 0.96205\n",
      "  batch 004 / 029 | loss: 0.66137 | error: 0.53906 | utility: 0.95046\n",
      "  batch 005 / 029 | loss: 0.60645 | error: 0.51250 | utility: 0.96302\n",
      "  batch 006 / 029 | loss: 0.59595 | error: 0.50781 | utility: 0.96407\n",
      "  batch 007 / 029 | loss: 0.56625 | error: 0.49107 | utility: 0.96009\n",
      "  batch 008 / 029 | loss: 0.57815 | error: 0.49805 | utility: 0.96732\n",
      "  batch 009 / 029 | loss: 0.57164 | error: 0.49479 | utility: 0.96471\n",
      "  batch 010 / 029 | loss: 0.56364 | error: 0.49062 | utility: 0.97045\n",
      "  batch 011 / 029 | loss: 0.55909 | error: 0.48722 | utility: 0.96975\n",
      "  batch 012 / 029 | loss: 0.55253 | error: 0.48438 | utility: 0.96493\n",
      "  batch 013 / 029 | loss: 0.54621 | error: 0.48197 | utility: 0.96543\n",
      "  batch 014 / 029 | loss: 0.54378 | error: 0.47991 | utility: 0.96866\n",
      "  batch 015 / 029 | loss: 0.54065 | error: 0.47813 | utility: 0.96791\n",
      "  batch 016 / 029 | loss: 0.54721 | error: 0.48242 | utility: 0.96577\n",
      "  batch 017 / 029 | loss: 0.54231 | error: 0.47978 | utility: 0.96419\n",
      "  batch 018 / 029 | loss: 0.54389 | error: 0.48003 | utility: 0.96429\n",
      "  batch 019 / 029 | loss: 0.55645 | error: 0.48684 | utility: 0.96067\n",
      "  batch 020 / 029 | loss: 0.56011 | error: 0.48828 | utility: 0.96493\n",
      "  batch 021 / 029 | loss: 0.56659 | error: 0.49182 | utility: 0.96093\n",
      "  batch 022 / 029 | loss: 0.56726 | error: 0.49219 | utility: 0.95914\n",
      "  batch 023 / 029 | loss: 0.56897 | error: 0.49321 | utility: 0.96124\n",
      "  batch 024 / 029 | loss: 0.57091 | error: 0.49414 | utility: 0.96154\n",
      "  batch 025 / 029 | loss: 0.56985 | error: 0.49312 | utility: 0.94316\n",
      "  batch 026 / 029 | loss: 0.56500 | error: 0.49099 | utility: 0.93769\n",
      "  batch 027 / 029 | loss: 0.56129 | error: 0.48900 | utility: 0.96072\n",
      "  batch 028 / 029 | loss: 0.56333 | error: 0.48996 | utility: 0.94798\n",
      "  batch 029 / 029 | loss: 0.57175 | error: 0.49461 | utility: 0.95305\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 007 / 010 | time: 025 sec | loss: 0.54947 | error: 0.47865 | utility: 0.95876\n",
      "Starting epoch 008 / 010.\n",
      "  batch 001 / 029 | loss: 0.62474 | error: 0.53125 | utility: 0.95257\n",
      "  batch 002 / 029 | loss: 0.53039 | error: 0.47656 | utility: 0.95064\n",
      "  batch 003 / 029 | loss: 0.56076 | error: 0.48438 | utility: 0.94938\n",
      "  batch 004 / 029 | loss: 0.48090 | error: 0.43750 | utility: 0.95598\n",
      "  batch 005 / 029 | loss: 0.51153 | error: 0.45937 | utility: 0.91516\n",
      "  batch 006 / 029 | loss: 0.55523 | error: 0.48438 | utility: 0.92864\n",
      "  batch 007 / 029 | loss: 0.58374 | error: 0.50000 | utility: 0.93010\n",
      "  batch 008 / 029 | loss: 0.58701 | error: 0.50195 | utility: 0.94461\n",
      "  batch 009 / 029 | loss: 0.59030 | error: 0.50521 | utility: 0.94272\n",
      "  batch 010 / 029 | loss: 0.58539 | error: 0.50156 | utility: 0.93722\n",
      "  batch 011 / 029 | loss: 0.60158 | error: 0.50994 | utility: 0.94010\n",
      "  batch 012 / 029 | loss: 0.60349 | error: 0.51172 | utility: 0.94008\n",
      "  batch 013 / 029 | loss: 0.58774 | error: 0.50120 | utility: 0.93980\n",
      "  batch 014 / 029 | loss: 0.57820 | error: 0.49665 | utility: 0.94881\n",
      "  batch 015 / 029 | loss: 0.57779 | error: 0.49583 | utility: 0.94817\n",
      "  batch 016 / 029 | loss: 0.57812 | error: 0.49707 | utility: 0.94564\n",
      "  batch 017 / 029 | loss: 0.58837 | error: 0.50276 | utility: 0.94589\n",
      "  batch 018 / 029 | loss: 0.59676 | error: 0.50781 | utility: 0.94447\n",
      "  batch 019 / 029 | loss: 0.59190 | error: 0.50576 | utility: 0.93740\n",
      "  batch 020 / 029 | loss: 0.58995 | error: 0.50391 | utility: 0.94791\n",
      "  batch 021 / 029 | loss: 0.58258 | error: 0.50000 | utility: 0.95176\n",
      "  batch 022 / 029 | loss: 0.56856 | error: 0.49219 | utility: 0.91882\n",
      "  batch 023 / 029 | loss: 0.56619 | error: 0.49049 | utility: 0.92435\n",
      "  batch 024 / 029 | loss: 0.55926 | error: 0.48698 | utility: 0.94738\n",
      "  batch 025 / 029 | loss: 0.55774 | error: 0.48562 | utility: 0.92478\n",
      "  batch 026 / 029 | loss: 0.55545 | error: 0.48438 | utility: 0.92780\n",
      "  batch 027 / 029 | loss: 0.56023 | error: 0.48669 | utility: 0.93419\n",
      "  batch 028 / 029 | loss: 0.56300 | error: 0.48717 | utility: 0.88181\n",
      "  batch 029 / 029 | loss: 0.56512 | error: 0.48761 | utility: 0.92982\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 008 / 010 | time: 025 sec | loss: 0.56460 | error: 0.49167 | utility: 0.95693\n",
      "Starting epoch 009 / 010.\n",
      "  batch 001 / 029 | loss: 0.53563 | error: 0.48438 | utility: 0.93694\n",
      "  batch 002 / 029 | loss: 0.59973 | error: 0.52344 | utility: 0.92446\n",
      "  batch 003 / 029 | loss: 0.56474 | error: 0.49479 | utility: 0.93520\n",
      "  batch 004 / 029 | loss: 0.51886 | error: 0.46484 | utility: 0.93075\n",
      "  batch 005 / 029 | loss: 0.58005 | error: 0.49688 | utility: 0.94205\n",
      "  batch 006 / 029 | loss: 0.55724 | error: 0.48698 | utility: 0.94820\n",
      "  batch 007 / 029 | loss: 0.54084 | error: 0.47768 | utility: 0.94807\n",
      "  batch 008 / 029 | loss: 0.55265 | error: 0.48438 | utility: 0.93063\n",
      "  batch 009 / 029 | loss: 0.54664 | error: 0.48264 | utility: 0.95141\n",
      "  batch 010 / 029 | loss: 0.56152 | error: 0.48906 | utility: 0.95315\n",
      "  batch 011 / 029 | loss: 0.54960 | error: 0.48011 | utility: 0.95561\n",
      "  batch 012 / 029 | loss: 0.54478 | error: 0.47656 | utility: 0.94242\n",
      "  batch 013 / 029 | loss: 0.54297 | error: 0.47476 | utility: 0.95493\n",
      "  batch 014 / 029 | loss: 0.54204 | error: 0.47433 | utility: 0.95268\n",
      "  batch 015 / 029 | loss: 0.53318 | error: 0.46979 | utility: 0.96375\n",
      "  batch 016 / 029 | loss: 0.54651 | error: 0.47754 | utility: 0.95731\n",
      "  batch 017 / 029 | loss: 0.54930 | error: 0.47978 | utility: 0.95157\n",
      "  batch 018 / 029 | loss: 0.55284 | error: 0.48177 | utility: 0.96324\n",
      "  batch 019 / 029 | loss: 0.55620 | error: 0.48438 | utility: 0.95743\n",
      "  batch 020 / 029 | loss: 0.54940 | error: 0.48125 | utility: 0.96438\n",
      "  batch 021 / 029 | loss: 0.54640 | error: 0.47917 | utility: 0.96203\n",
      "  batch 022 / 029 | loss: 0.54926 | error: 0.48082 | utility: 0.94407\n",
      "  batch 023 / 029 | loss: 0.54772 | error: 0.48030 | utility: 0.96044\n",
      "  batch 024 / 029 | loss: 0.54498 | error: 0.47852 | utility: 0.94488\n",
      "  batch 025 / 029 | loss: 0.54654 | error: 0.47937 | utility: 0.96301\n",
      "  batch 026 / 029 | loss: 0.55055 | error: 0.48197 | utility: 0.95693\n",
      "  batch 027 / 029 | loss: 0.55585 | error: 0.48438 | utility: 0.95681\n",
      "  batch 028 / 029 | loss: 0.56610 | error: 0.48996 | utility: 0.95583\n",
      "  batch 029 / 029 | loss: 0.55728 | error: 0.48599 | utility: 0.96261\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 009 / 010 | time: 026 sec | loss: 0.55802 | error: 0.48646 | utility: 0.96068\n",
      "Ending training due to 4 consecutive epochs without improvement in validation accuracy.\n",
      "Total training time: 4 minutes (228.56119084358215 seconds).\n",
      "Loading model from ./Results/utility/utility_0.650_model.pt.\n",
      "---------- Training with lambda=0.7000000000000001 ----------\n",
      "Starting epoch 001 / 010.\n",
      "  batch 001 / 029 | loss: 0.56556 | error: 0.40625 | utility: 0.93142\n",
      "  batch 002 / 029 | loss: 0.54222 | error: 0.40625 | utility: 0.93357\n",
      "  batch 003 / 029 | loss: 0.58537 | error: 0.44792 | utility: 0.94093\n",
      "  batch 004 / 029 | loss: 0.57298 | error: 0.45312 | utility: 0.94538\n",
      "  batch 005 / 029 | loss: 0.55533 | error: 0.45312 | utility: 0.94783\n",
      "  batch 006 / 029 | loss: 0.55837 | error: 0.45833 | utility: 0.94647\n",
      "  batch 007 / 029 | loss: 0.57097 | error: 0.46875 | utility: 0.94443\n",
      "  batch 008 / 029 | loss: 0.58927 | error: 0.48047 | utility: 0.94063\n",
      "  batch 009 / 029 | loss: 0.61586 | error: 0.49653 | utility: 0.94419\n",
      "  batch 010 / 029 | loss: 0.61002 | error: 0.49531 | utility: 0.94694\n",
      "  batch 011 / 029 | loss: 0.59536 | error: 0.49006 | utility: 0.95280\n",
      "  batch 012 / 029 | loss: 0.61232 | error: 0.49870 | utility: 0.94442\n",
      "  batch 013 / 029 | loss: 0.60389 | error: 0.49519 | utility: 0.92266\n",
      "  batch 014 / 029 | loss: 0.60681 | error: 0.49888 | utility: 0.94458\n",
      "  batch 015 / 029 | loss: 0.59538 | error: 0.49375 | utility: 0.93873\n",
      "  batch 016 / 029 | loss: 0.59346 | error: 0.49219 | utility: 0.94746\n",
      "  batch 017 / 029 | loss: 0.58976 | error: 0.49265 | utility: 0.93044\n",
      "  batch 018 / 029 | loss: 0.59765 | error: 0.49826 | utility: 0.94047\n",
      "  batch 019 / 029 | loss: 0.60270 | error: 0.50247 | utility: 0.93942\n",
      "  batch 020 / 029 | loss: 0.60470 | error: 0.50547 | utility: 0.94373\n",
      "  batch 021 / 029 | loss: 0.59459 | error: 0.50074 | utility: 0.95215\n",
      "  batch 022 / 029 | loss: 0.58130 | error: 0.49432 | utility: 0.94878\n",
      "  batch 023 / 029 | loss: 0.57765 | error: 0.49321 | utility: 0.92907\n",
      "  batch 024 / 029 | loss: 0.57613 | error: 0.49349 | utility: 0.94631\n",
      "  batch 025 / 029 | loss: 0.57299 | error: 0.49188 | utility: 0.94907\n",
      "  batch 026 / 029 | loss: 0.57050 | error: 0.49038 | utility: 0.94950\n",
      "  batch 027 / 029 | loss: 0.57004 | error: 0.49016 | utility: 0.95001\n",
      "  batch 028 / 029 | loss: 0.56778 | error: 0.48996 | utility: 0.95596\n",
      "  batch 029 / 029 | loss: 0.56654 | error: 0.49030 | utility: 0.95733\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 001 / 010 | time: 025 sec | loss: 0.55397 | error: 0.49688 | utility: 0.96437\n",
      "Saving model to ./Results/utility/utility_0.700_model.pt.\n",
      "Starting epoch 002 / 010.\n",
      "  batch 001 / 029 | loss: 0.62014 | error: 0.53125 | utility: 0.95304\n",
      "  batch 002 / 029 | loss: 0.59637 | error: 0.52344 | utility: 0.95570\n",
      "  batch 003 / 029 | loss: 0.60460 | error: 0.52604 | utility: 0.94939\n",
      "  batch 004 / 029 | loss: 0.57969 | error: 0.51172 | utility: 0.96006\n",
      "  batch 005 / 029 | loss: 0.57752 | error: 0.51250 | utility: 0.95698\n",
      "  batch 006 / 029 | loss: 0.56539 | error: 0.50781 | utility: 0.95206\n",
      "  batch 007 / 029 | loss: 0.58191 | error: 0.51786 | utility: 0.95187\n",
      "  batch 008 / 029 | loss: 0.55163 | error: 0.50195 | utility: 0.96019\n",
      "  batch 009 / 029 | loss: 0.53241 | error: 0.49132 | utility: 0.95425\n",
      "  batch 010 / 029 | loss: 0.51212 | error: 0.47969 | utility: 0.95544\n",
      "  batch 011 / 029 | loss: 0.50817 | error: 0.47727 | utility: 0.96195\n",
      "  batch 012 / 029 | loss: 0.51956 | error: 0.48438 | utility: 0.95075\n",
      "  batch 013 / 029 | loss: 0.52548 | error: 0.48798 | utility: 0.93231\n",
      "  batch 014 / 029 | loss: 0.53591 | error: 0.49107 | utility: 0.95401\n",
      "  batch 015 / 029 | loss: 0.51889 | error: 0.48125 | utility: 0.96051\n",
      "  batch 016 / 029 | loss: 0.51280 | error: 0.47754 | utility: 0.92080\n",
      "  batch 017 / 029 | loss: 0.51156 | error: 0.47702 | utility: 0.95660\n",
      "  batch 018 / 029 | loss: 0.51432 | error: 0.47830 | utility: 0.96044\n",
      "  batch 019 / 029 | loss: 0.52277 | error: 0.48273 | utility: 0.93926\n",
      "  batch 020 / 029 | loss: 0.51637 | error: 0.47891 | utility: 0.94633\n",
      "  batch 021 / 029 | loss: 0.53415 | error: 0.48735 | utility: 0.95743\n",
      "  batch 022 / 029 | loss: 0.53490 | error: 0.48793 | utility: 0.95571\n",
      "  batch 023 / 029 | loss: 0.53276 | error: 0.48709 | utility: 0.96349\n",
      "  batch 024 / 029 | loss: 0.53171 | error: 0.48633 | utility: 0.96129\n",
      "  batch 025 / 029 | loss: 0.53776 | error: 0.49000 | utility: 0.95705\n",
      "  batch 026 / 029 | loss: 0.53465 | error: 0.48858 | utility: 0.95951\n",
      "  batch 027 / 029 | loss: 0.53606 | error: 0.48958 | utility: 0.95442\n",
      "  batch 028 / 029 | loss: 0.53579 | error: 0.48940 | utility: 0.96447\n",
      "  batch 029 / 029 | loss: 0.53510 | error: 0.48976 | utility: 0.96192\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 002 / 010 | time: 025 sec | loss: 0.53419 | error: 0.49167 | utility: 0.96770\n",
      "Validation accuracy improved.\n",
      "Saving model to ./Results/utility/utility_0.700_model.pt.\n",
      "Starting epoch 003 / 010.\n",
      "  batch 001 / 029 | loss: 0.75491 | error: 0.60938 | utility: 0.95846\n",
      "  batch 002 / 029 | loss: 0.62412 | error: 0.53906 | utility: 0.95573\n",
      "  batch 003 / 029 | loss: 0.57195 | error: 0.51562 | utility: 0.95749\n",
      "  batch 004 / 029 | loss: 0.54877 | error: 0.50000 | utility: 0.95969\n",
      "  batch 005 / 029 | loss: 0.54572 | error: 0.50000 | utility: 0.94699\n",
      "  batch 006 / 029 | loss: 0.56996 | error: 0.51302 | utility: 0.95296\n",
      "  batch 007 / 029 | loss: 0.53939 | error: 0.49777 | utility: 0.94633\n",
      "  batch 008 / 029 | loss: 0.56167 | error: 0.50781 | utility: 0.95311\n",
      "  batch 009 / 029 | loss: 0.54689 | error: 0.50000 | utility: 0.93331\n",
      "  batch 010 / 029 | loss: 0.54352 | error: 0.49688 | utility: 0.93115\n",
      "  batch 011 / 029 | loss: 0.55375 | error: 0.50284 | utility: 0.93290\n",
      "  batch 012 / 029 | loss: 0.55796 | error: 0.50391 | utility: 0.94462\n",
      "  batch 013 / 029 | loss: 0.56829 | error: 0.50962 | utility: 0.90862\n",
      "  batch 014 / 029 | loss: 0.55374 | error: 0.50223 | utility: 0.94870\n",
      "  batch 015 / 029 | loss: 0.54982 | error: 0.49896 | utility: 0.93101\n",
      "  batch 016 / 029 | loss: 0.55486 | error: 0.50098 | utility: 0.93968\n",
      "  batch 017 / 029 | loss: 0.55183 | error: 0.49908 | utility: 0.94646\n",
      "  batch 018 / 029 | loss: 0.55401 | error: 0.49913 | utility: 0.93342\n",
      "  batch 019 / 029 | loss: 0.56471 | error: 0.50411 | utility: 0.94925\n",
      "  batch 020 / 029 | loss: 0.55901 | error: 0.50078 | utility: 0.95732\n",
      "  batch 021 / 029 | loss: 0.55396 | error: 0.49851 | utility: 0.94344\n",
      "  batch 022 / 029 | loss: 0.55328 | error: 0.49787 | utility: 0.95190\n",
      "  batch 023 / 029 | loss: 0.54687 | error: 0.49457 | utility: 0.95896\n",
      "  batch 024 / 029 | loss: 0.55091 | error: 0.49674 | utility: 0.95369\n",
      "  batch 025 / 029 | loss: 0.54272 | error: 0.49188 | utility: 0.95703\n",
      "  batch 026 / 029 | loss: 0.54506 | error: 0.49279 | utility: 0.94344\n",
      "  batch 027 / 029 | loss: 0.54155 | error: 0.49132 | utility: 0.95776\n",
      "  batch 028 / 029 | loss: 0.53583 | error: 0.48884 | utility: 0.95799\n",
      "  batch 029 / 029 | loss: 0.52604 | error: 0.48491 | utility: 0.95975\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 003 / 010 | time: 025 sec | loss: 0.51560 | error: 0.48125 | utility: 0.97029\n",
      "Validation accuracy improved.\n",
      "Saving model to ./Results/utility/utility_0.700_model.pt.\n",
      "Starting epoch 004 / 010.\n",
      "  batch 001 / 029 | loss: 0.60757 | error: 0.53125 | utility: 0.95210\n",
      "  batch 002 / 029 | loss: 0.56248 | error: 0.50000 | utility: 0.95947\n",
      "  batch 003 / 029 | loss: 0.49372 | error: 0.46875 | utility: 0.95836\n",
      "  batch 004 / 029 | loss: 0.45292 | error: 0.44922 | utility: 0.95083\n",
      "  batch 005 / 029 | loss: 0.46618 | error: 0.45312 | utility: 0.96026\n",
      "  batch 006 / 029 | loss: 0.47738 | error: 0.46094 | utility: 0.95772\n",
      "  batch 007 / 029 | loss: 0.48668 | error: 0.46652 | utility: 0.96151\n",
      "  batch 008 / 029 | loss: 0.48490 | error: 0.46484 | utility: 0.94804\n",
      "  batch 009 / 029 | loss: 0.51113 | error: 0.47569 | utility: 0.94877\n",
      "  batch 010 / 029 | loss: 0.49186 | error: 0.46719 | utility: 0.96322\n",
      "  batch 011 / 029 | loss: 0.50013 | error: 0.47159 | utility: 0.96058\n",
      "  batch 012 / 029 | loss: 0.51846 | error: 0.48047 | utility: 0.96055\n",
      "  batch 013 / 029 | loss: 0.50962 | error: 0.47716 | utility: 0.96323\n",
      "  batch 014 / 029 | loss: 0.50947 | error: 0.47768 | utility: 0.95742\n",
      "  batch 015 / 029 | loss: 0.50947 | error: 0.47813 | utility: 0.96352\n",
      "  batch 016 / 029 | loss: 0.51980 | error: 0.48340 | utility: 0.94853\n",
      "  batch 017 / 029 | loss: 0.53118 | error: 0.48897 | utility: 0.95867\n",
      "  batch 018 / 029 | loss: 0.53154 | error: 0.48872 | utility: 0.95420\n",
      "  batch 019 / 029 | loss: 0.53379 | error: 0.49013 | utility: 0.95508\n",
      "  batch 020 / 029 | loss: 0.53272 | error: 0.48906 | utility: 0.94838\n",
      "  batch 021 / 029 | loss: 0.52934 | error: 0.48735 | utility: 0.95883\n",
      "  batch 022 / 029 | loss: 0.53018 | error: 0.48651 | utility: 0.94043\n",
      "  batch 023 / 029 | loss: 0.53455 | error: 0.48845 | utility: 0.94974\n",
      "  batch 024 / 029 | loss: 0.53801 | error: 0.49023 | utility: 0.95589\n",
      "  batch 025 / 029 | loss: 0.53380 | error: 0.48812 | utility: 0.95833\n",
      "  batch 026 / 029 | loss: 0.53676 | error: 0.49038 | utility: 0.95745\n",
      "  batch 027 / 029 | loss: 0.53689 | error: 0.49016 | utility: 0.95165\n",
      "  batch 028 / 029 | loss: 0.53659 | error: 0.48996 | utility: 0.94174\n",
      "  batch 029 / 029 | loss: 0.53616 | error: 0.49030 | utility: 0.88845\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 004 / 010 | time: 025 sec | loss: 0.53305 | error: 0.48646 | utility: 0.96254\n",
      "Starting epoch 005 / 010.\n",
      "  batch 001 / 029 | loss: 0.63729 | error: 0.53125 | utility: 0.95066\n",
      "  batch 002 / 029 | loss: 0.58970 | error: 0.50781 | utility: 0.95429\n",
      "  batch 003 / 029 | loss: 0.57504 | error: 0.50521 | utility: 0.95498\n",
      "  batch 004 / 029 | loss: 0.56914 | error: 0.50391 | utility: 0.94827\n",
      "  batch 005 / 029 | loss: 0.59617 | error: 0.52187 | utility: 0.95337\n",
      "  batch 006 / 029 | loss: 0.55241 | error: 0.50000 | utility: 0.94850\n",
      "  batch 007 / 029 | loss: 0.55327 | error: 0.50000 | utility: 0.95506\n",
      "  batch 008 / 029 | loss: 0.55168 | error: 0.50000 | utility: 0.95773\n",
      "  batch 009 / 029 | loss: 0.55737 | error: 0.50174 | utility: 0.96068\n",
      "  batch 010 / 029 | loss: 0.55588 | error: 0.50156 | utility: 0.95635\n",
      "  batch 011 / 029 | loss: 0.55616 | error: 0.50142 | utility: 0.96025\n",
      "  batch 012 / 029 | loss: 0.54984 | error: 0.49870 | utility: 0.95443\n",
      "  batch 013 / 029 | loss: 0.53601 | error: 0.49038 | utility: 0.93637\n",
      "  batch 014 / 029 | loss: 0.55551 | error: 0.50112 | utility: 0.94021\n",
      "  batch 015 / 029 | loss: 0.54397 | error: 0.49375 | utility: 0.94751\n",
      "  batch 016 / 029 | loss: 0.53888 | error: 0.49023 | utility: 0.94721\n",
      "  batch 017 / 029 | loss: 0.53494 | error: 0.48805 | utility: 0.95463\n",
      "  batch 018 / 029 | loss: 0.53696 | error: 0.48958 | utility: 0.95113\n",
      "  batch 019 / 029 | loss: 0.54134 | error: 0.49178 | utility: 0.95020\n",
      "  batch 020 / 029 | loss: 0.53820 | error: 0.49062 | utility: 0.94282\n",
      "  batch 021 / 029 | loss: 0.53940 | error: 0.49182 | utility: 0.95670\n",
      "  batch 022 / 029 | loss: 0.53638 | error: 0.49006 | utility: 0.95748\n",
      "  batch 023 / 029 | loss: 0.53207 | error: 0.48709 | utility: 0.91577\n",
      "  batch 024 / 029 | loss: 0.53532 | error: 0.48893 | utility: 0.94704\n",
      "  batch 025 / 029 | loss: 0.53657 | error: 0.49000 | utility: 0.95318\n",
      "  batch 026 / 029 | loss: 0.54023 | error: 0.49159 | utility: 0.95901\n",
      "  batch 027 / 029 | loss: 0.53857 | error: 0.49074 | utility: 0.95670\n",
      "  batch 028 / 029 | loss: 0.53461 | error: 0.48828 | utility: 0.95638\n",
      "  batch 029 / 029 | loss: 0.54059 | error: 0.49300 | utility: 0.94382\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 005 / 010 | time: 025 sec | loss: 0.51493 | error: 0.47865 | utility: 0.96383\n",
      "Validation accuracy improved.\n",
      "Saving model to ./Results/utility/utility_0.700_model.pt.\n",
      "Starting epoch 006 / 010.\n",
      "  batch 001 / 029 | loss: 0.52510 | error: 0.50000 | utility: 0.95628\n",
      "  batch 002 / 029 | loss: 0.62478 | error: 0.54688 | utility: 0.93288\n",
      "  batch 003 / 029 | loss: 0.58419 | error: 0.52083 | utility: 0.95555\n",
      "  batch 004 / 029 | loss: 0.62573 | error: 0.53906 | utility: 0.93795\n",
      "  batch 005 / 029 | loss: 0.59053 | error: 0.52187 | utility: 0.94603\n",
      "  batch 006 / 029 | loss: 0.57153 | error: 0.51042 | utility: 0.93865\n",
      "  batch 007 / 029 | loss: 0.55981 | error: 0.50446 | utility: 0.93656\n",
      "  batch 008 / 029 | loss: 0.55873 | error: 0.50391 | utility: 0.94676\n",
      "  batch 009 / 029 | loss: 0.54145 | error: 0.49306 | utility: 0.92534\n",
      "  batch 010 / 029 | loss: 0.53559 | error: 0.49062 | utility: 0.95505\n",
      "  batch 011 / 029 | loss: 0.54512 | error: 0.49432 | utility: 0.95652\n",
      "  batch 012 / 029 | loss: 0.52640 | error: 0.48438 | utility: 0.94220\n",
      "  batch 013 / 029 | loss: 0.53264 | error: 0.48798 | utility: 0.93853\n",
      "  batch 014 / 029 | loss: 0.53663 | error: 0.48996 | utility: 0.93166\n",
      "  batch 015 / 029 | loss: 0.53117 | error: 0.48854 | utility: 0.95329\n",
      "  batch 016 / 029 | loss: 0.54291 | error: 0.49316 | utility: 0.94703\n",
      "  batch 017 / 029 | loss: 0.54714 | error: 0.49540 | utility: 0.95131\n",
      "  batch 018 / 029 | loss: 0.54569 | error: 0.49566 | utility: 0.94848\n",
      "  batch 019 / 029 | loss: 0.54970 | error: 0.49753 | utility: 0.94108\n",
      "  batch 020 / 029 | loss: 0.55591 | error: 0.50078 | utility: 0.93715\n",
      "  batch 021 / 029 | loss: 0.54789 | error: 0.49702 | utility: 0.95544\n",
      "  batch 022 / 029 | loss: 0.53905 | error: 0.49219 | utility: 0.95149\n",
      "  batch 023 / 029 | loss: 0.53506 | error: 0.48981 | utility: 0.93811\n",
      "  batch 024 / 029 | loss: 0.53198 | error: 0.48828 | utility: 0.95035\n",
      "  batch 025 / 029 | loss: 0.53055 | error: 0.48688 | utility: 0.95611\n",
      "  batch 026 / 029 | loss: 0.52599 | error: 0.48438 | utility: 0.95705\n",
      "  batch 027 / 029 | loss: 0.52830 | error: 0.48553 | utility: 0.95648\n",
      "  batch 028 / 029 | loss: 0.53552 | error: 0.48884 | utility: 0.92991\n",
      "  batch 029 / 029 | loss: 0.53404 | error: 0.48491 | utility: 0.94699\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 006 / 010 | time: 025 sec | loss: 0.55013 | error: 0.50208 | utility: 0.96955\n",
      "Starting epoch 007 / 010.\n",
      "  batch 001 / 029 | loss: 0.59933 | error: 0.51562 | utility: 0.96211\n",
      "  batch 002 / 029 | loss: 0.66456 | error: 0.55469 | utility: 0.96520\n",
      "  batch 003 / 029 | loss: 0.67968 | error: 0.56250 | utility: 0.96879\n",
      "  batch 004 / 029 | loss: 0.63215 | error: 0.53906 | utility: 0.96488\n",
      "  batch 005 / 029 | loss: 0.57821 | error: 0.51250 | utility: 0.97041\n",
      "  batch 006 / 029 | loss: 0.56786 | error: 0.50781 | utility: 0.97079\n",
      "  batch 007 / 029 | loss: 0.53684 | error: 0.49107 | utility: 0.97106\n",
      "  batch 008 / 029 | loss: 0.54970 | error: 0.49805 | utility: 0.97312\n",
      "  batch 009 / 029 | loss: 0.54318 | error: 0.49479 | utility: 0.97185\n",
      "  batch 010 / 029 | loss: 0.53513 | error: 0.49062 | utility: 0.97475\n",
      "  batch 011 / 029 | loss: 0.53006 | error: 0.48722 | utility: 0.97413\n",
      "  batch 012 / 029 | loss: 0.52368 | error: 0.48438 | utility: 0.97087\n",
      "  batch 013 / 029 | loss: 0.51766 | error: 0.48197 | utility: 0.97145\n",
      "  batch 014 / 029 | loss: 0.51493 | error: 0.47991 | utility: 0.97266\n",
      "  batch 015 / 029 | loss: 0.51163 | error: 0.47813 | utility: 0.97178\n",
      "  batch 016 / 029 | loss: 0.51831 | error: 0.48242 | utility: 0.96980\n",
      "  batch 017 / 029 | loss: 0.51330 | error: 0.47978 | utility: 0.96904\n",
      "  batch 018 / 029 | loss: 0.51474 | error: 0.48003 | utility: 0.96773\n",
      "  batch 019 / 029 | loss: 0.52730 | error: 0.48684 | utility: 0.96460\n",
      "  batch 020 / 029 | loss: 0.53081 | error: 0.48828 | utility: 0.96772\n",
      "  batch 021 / 029 | loss: 0.53733 | error: 0.49182 | utility: 0.96392\n",
      "  batch 022 / 029 | loss: 0.53797 | error: 0.49219 | utility: 0.96221\n",
      "  batch 023 / 029 | loss: 0.53974 | error: 0.49321 | utility: 0.96341\n",
      "  batch 024 / 029 | loss: 0.54168 | error: 0.49414 | utility: 0.96328\n",
      "  batch 025 / 029 | loss: 0.54064 | error: 0.49312 | utility: 0.94849\n",
      "  batch 026 / 029 | loss: 0.53589 | error: 0.49099 | utility: 0.94387\n",
      "  batch 027 / 029 | loss: 0.53217 | error: 0.48900 | utility: 0.96258\n",
      "  batch 028 / 029 | loss: 0.53429 | error: 0.48996 | utility: 0.95214\n",
      "  batch 029 / 029 | loss: 0.54289 | error: 0.49461 | utility: 0.95595\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 007 / 010 | time: 025 sec | loss: 0.51850 | error: 0.47865 | utility: 0.96236\n",
      "Starting epoch 008 / 010.\n",
      "  batch 001 / 029 | loss: 0.59886 | error: 0.53125 | utility: 0.95597\n",
      "  batch 002 / 029 | loss: 0.50304 | error: 0.47656 | utility: 0.95488\n",
      "  batch 003 / 029 | loss: 0.53290 | error: 0.48438 | utility: 0.95376\n",
      "  batch 004 / 029 | loss: 0.45091 | error: 0.43750 | utility: 0.95948\n",
      "  batch 005 / 029 | loss: 0.48298 | error: 0.45937 | utility: 0.92710\n",
      "  batch 006 / 029 | loss: 0.52784 | error: 0.48438 | utility: 0.93847\n",
      "  batch 007 / 029 | loss: 0.55712 | error: 0.50000 | utility: 0.94025\n",
      "  batch 008 / 029 | loss: 0.56010 | error: 0.50195 | utility: 0.95130\n",
      "  batch 009 / 029 | loss: 0.56378 | error: 0.50521 | utility: 0.95033\n",
      "  batch 010 / 029 | loss: 0.55831 | error: 0.50156 | utility: 0.94796\n",
      "  batch 011 / 029 | loss: 0.57454 | error: 0.50994 | utility: 0.94979\n",
      "  batch 012 / 029 | loss: 0.57663 | error: 0.51172 | utility: 0.95006\n",
      "  batch 013 / 029 | loss: 0.56022 | error: 0.50120 | utility: 0.95061\n",
      "  batch 014 / 029 | loss: 0.55066 | error: 0.49665 | utility: 0.95715\n",
      "  batch 015 / 029 | loss: 0.54995 | error: 0.49583 | utility: 0.95711\n",
      "  batch 016 / 029 | loss: 0.55067 | error: 0.49707 | utility: 0.95629\n",
      "  batch 017 / 029 | loss: 0.56121 | error: 0.50276 | utility: 0.95636\n",
      "  batch 018 / 029 | loss: 0.57028 | error: 0.50781 | utility: 0.95551\n",
      "  batch 019 / 029 | loss: 0.56545 | error: 0.50576 | utility: 0.95133\n",
      "  batch 020 / 029 | loss: 0.56318 | error: 0.50391 | utility: 0.95764\n",
      "  batch 021 / 029 | loss: 0.55547 | error: 0.50000 | utility: 0.96034\n",
      "  batch 022 / 029 | loss: 0.54105 | error: 0.49219 | utility: 0.93490\n",
      "  batch 023 / 029 | loss: 0.53870 | error: 0.49049 | utility: 0.93896\n",
      "  batch 024 / 029 | loss: 0.53152 | error: 0.48698 | utility: 0.95732\n",
      "  batch 025 / 029 | loss: 0.52980 | error: 0.48625 | utility: 0.94331\n",
      "  batch 026 / 029 | loss: 0.52743 | error: 0.48498 | utility: 0.94044\n",
      "  batch 027 / 029 | loss: 0.53225 | error: 0.48727 | utility: 0.94757\n",
      "  batch 028 / 029 | loss: 0.53498 | error: 0.48828 | utility: 0.90816\n",
      "  batch 029 / 029 | loss: 0.53676 | error: 0.48869 | utility: 0.94414\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 008 / 010 | time: 026 sec | loss: 0.53484 | error: 0.49167 | utility: 0.96499\n",
      "Starting epoch 009 / 010.\n",
      "  batch 001 / 029 | loss: 0.50789 | error: 0.48438 | utility: 0.95066\n",
      "  batch 002 / 029 | loss: 0.57341 | error: 0.52344 | utility: 0.94453\n",
      "  batch 003 / 029 | loss: 0.53545 | error: 0.49479 | utility: 0.95029\n",
      "  batch 004 / 029 | loss: 0.48902 | error: 0.46875 | utility: 0.94630\n",
      "  batch 005 / 029 | loss: 0.54985 | error: 0.50000 | utility: 0.95211\n",
      "  batch 006 / 029 | loss: 0.52717 | error: 0.48958 | utility: 0.95683\n",
      "  batch 007 / 029 | loss: 0.51036 | error: 0.47991 | utility: 0.95636\n",
      "  batch 008 / 029 | loss: 0.52202 | error: 0.48633 | utility: 0.94706\n",
      "  batch 009 / 029 | loss: 0.51613 | error: 0.48438 | utility: 0.95814\n",
      "  batch 010 / 029 | loss: 0.53133 | error: 0.49062 | utility: 0.95967\n",
      "  batch 011 / 029 | loss: 0.51876 | error: 0.48153 | utility: 0.96130\n",
      "  batch 012 / 029 | loss: 0.51403 | error: 0.47917 | utility: 0.95640\n",
      "  batch 013 / 029 | loss: 0.51222 | error: 0.47716 | utility: 0.96144\n",
      "  batch 014 / 029 | loss: 0.51132 | error: 0.47656 | utility: 0.96085\n",
      "  batch 015 / 029 | loss: 0.50242 | error: 0.47187 | utility: 0.96825\n",
      "  batch 016 / 029 | loss: 0.51614 | error: 0.47949 | utility: 0.96359\n",
      "  batch 017 / 029 | loss: 0.51919 | error: 0.48162 | utility: 0.96256\n",
      "  batch 018 / 029 | loss: 0.52277 | error: 0.48351 | utility: 0.96821\n",
      "  batch 019 / 029 | loss: 0.52649 | error: 0.48602 | utility: 0.96540\n",
      "  batch 020 / 029 | loss: 0.51956 | error: 0.48281 | utility: 0.96913\n",
      "  batch 021 / 029 | loss: 0.51631 | error: 0.48065 | utility: 0.96686\n",
      "  batch 022 / 029 | loss: 0.51926 | error: 0.48224 | utility: 0.95523\n",
      "  batch 023 / 029 | loss: 0.51781 | error: 0.48166 | utility: 0.96520\n",
      "  batch 024 / 029 | loss: 0.51496 | error: 0.47982 | utility: 0.95578\n",
      "  batch 025 / 029 | loss: 0.51670 | error: 0.48063 | utility: 0.96731\n",
      "  batch 026 / 029 | loss: 0.52087 | error: 0.48317 | utility: 0.96242\n",
      "  batch 027 / 029 | loss: 0.52631 | error: 0.48553 | utility: 0.96307\n",
      "  batch 028 / 029 | loss: 0.53686 | error: 0.49107 | utility: 0.96157\n",
      "  batch 029 / 029 | loss: 0.52823 | error: 0.48707 | utility: 0.96636\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 009 / 010 | time: 026 sec | loss: 0.52609 | error: 0.48646 | utility: 0.96625\n",
      "Ending training due to 4 consecutive epochs without improvement in validation accuracy.\n",
      "Total training time: 4 minutes (226.56023168563843 seconds).\n",
      "Loading model from ./Results/utility/utility_0.700_model.pt.\n",
      "---------- Training with lambda=0.7500000000000001 ----------\n",
      "Starting epoch 001 / 010.\n",
      "  batch 001 / 029 | loss: 0.54350 | error: 0.40625 | utility: 0.93142\n",
      "  batch 002 / 029 | loss: 0.51926 | error: 0.40625 | utility: 0.93357\n",
      "  batch 003 / 029 | loss: 0.56148 | error: 0.44792 | utility: 0.94086\n",
      "  batch 004 / 029 | loss: 0.54813 | error: 0.45312 | utility: 0.94529\n",
      "  batch 005 / 029 | loss: 0.52969 | error: 0.45312 | utility: 0.94772\n",
      "  batch 006 / 029 | loss: 0.53222 | error: 0.45833 | utility: 0.94637\n",
      "  batch 007 / 029 | loss: 0.54454 | error: 0.46875 | utility: 0.94449\n",
      "  batch 008 / 029 | loss: 0.56265 | error: 0.48047 | utility: 0.94086\n",
      "  batch 009 / 029 | loss: 0.58927 | error: 0.49653 | utility: 0.94471\n",
      "  batch 010 / 029 | loss: 0.58309 | error: 0.49531 | utility: 0.94761\n",
      "  batch 011 / 029 | loss: 0.56815 | error: 0.49006 | utility: 0.95352\n",
      "  batch 012 / 029 | loss: 0.58512 | error: 0.49870 | utility: 0.94603\n",
      "  batch 013 / 029 | loss: 0.57658 | error: 0.49519 | utility: 0.92604\n",
      "  batch 014 / 029 | loss: 0.57964 | error: 0.49888 | utility: 0.94697\n",
      "  batch 015 / 029 | loss: 0.56806 | error: 0.49375 | utility: 0.94159\n",
      "  batch 016 / 029 | loss: 0.56605 | error: 0.49219 | utility: 0.95021\n",
      "  batch 017 / 029 | loss: 0.56247 | error: 0.49265 | utility: 0.93489\n",
      "  batch 018 / 029 | loss: 0.57065 | error: 0.49826 | utility: 0.94442\n",
      "  batch 019 / 029 | loss: 0.57598 | error: 0.50247 | utility: 0.94394\n",
      "  batch 020 / 029 | loss: 0.57828 | error: 0.50547 | utility: 0.94921\n",
      "  batch 021 / 029 | loss: 0.56795 | error: 0.50074 | utility: 0.95636\n",
      "  batch 022 / 029 | loss: 0.55426 | error: 0.49432 | utility: 0.95360\n",
      "  batch 023 / 029 | loss: 0.55048 | error: 0.49321 | utility: 0.93823\n",
      "  batch 024 / 029 | loss: 0.54905 | error: 0.49349 | utility: 0.95306\n",
      "  batch 025 / 029 | loss: 0.54576 | error: 0.49188 | utility: 0.95562\n",
      "  batch 026 / 029 | loss: 0.54297 | error: 0.49038 | utility: 0.95647\n",
      "  batch 027 / 029 | loss: 0.54229 | error: 0.49016 | utility: 0.95713\n",
      "  batch 028 / 029 | loss: 0.54000 | error: 0.48996 | utility: 0.96222\n",
      "  batch 029 / 029 | loss: 0.53851 | error: 0.49030 | utility: 0.96314\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 001 / 010 | time: 026 sec | loss: 0.52239 | error: 0.49688 | utility: 0.96988\n",
      "Saving model to ./Results/utility/utility_0.750_model.pt.\n",
      "Starting epoch 002 / 010.\n",
      "  batch 001 / 029 | loss: 0.59177 | error: 0.53125 | utility: 0.96015\n",
      "  batch 002 / 029 | loss: 0.56816 | error: 0.52344 | utility: 0.96288\n",
      "  batch 003 / 029 | loss: 0.57573 | error: 0.52604 | utility: 0.96050\n",
      "  batch 004 / 029 | loss: 0.55002 | error: 0.51172 | utility: 0.96622\n",
      "  batch 005 / 029 | loss: 0.54901 | error: 0.51250 | utility: 0.96431\n",
      "  batch 006 / 029 | loss: 0.53716 | error: 0.50781 | utility: 0.96303\n",
      "  batch 007 / 029 | loss: 0.55393 | error: 0.51786 | utility: 0.96055\n",
      "  batch 008 / 029 | loss: 0.52303 | error: 0.50195 | utility: 0.96678\n",
      "  batch 009 / 029 | loss: 0.50365 | error: 0.49132 | utility: 0.96288\n",
      "  batch 010 / 029 | loss: 0.48270 | error: 0.47969 | utility: 0.96270\n",
      "  batch 011 / 029 | loss: 0.47874 | error: 0.47727 | utility: 0.96718\n",
      "  batch 012 / 029 | loss: 0.49053 | error: 0.48438 | utility: 0.95903\n",
      "  batch 013 / 029 | loss: 0.49670 | error: 0.48798 | utility: 0.94880\n",
      "  batch 014 / 029 | loss: 0.50659 | error: 0.49107 | utility: 0.96133\n",
      "  batch 015 / 029 | loss: 0.48896 | error: 0.48125 | utility: 0.96585\n",
      "  batch 016 / 029 | loss: 0.48268 | error: 0.47852 | utility: 0.93644\n",
      "  batch 017 / 029 | loss: 0.48147 | error: 0.47794 | utility: 0.96269\n",
      "  batch 018 / 029 | loss: 0.48435 | error: 0.47917 | utility: 0.96578\n",
      "  batch 019 / 029 | loss: 0.49338 | error: 0.48438 | utility: 0.94981\n",
      "  batch 020 / 029 | loss: 0.48679 | error: 0.48047 | utility: 0.95634\n",
      "  batch 021 / 029 | loss: 0.50518 | error: 0.48884 | utility: 0.96355\n",
      "  batch 022 / 029 | loss: 0.50584 | error: 0.48935 | utility: 0.96229\n",
      "  batch 023 / 029 | loss: 0.50384 | error: 0.48845 | utility: 0.96853\n",
      "  batch 024 / 029 | loss: 0.50263 | error: 0.48763 | utility: 0.96665\n",
      "  batch 025 / 029 | loss: 0.50891 | error: 0.49125 | utility: 0.96415\n",
      "  batch 026 / 029 | loss: 0.50568 | error: 0.48978 | utility: 0.96503\n",
      "  batch 027 / 029 | loss: 0.50712 | error: 0.49074 | utility: 0.96258\n",
      "  batch 028 / 029 | loss: 0.50679 | error: 0.49051 | utility: 0.96874\n",
      "  batch 029 / 029 | loss: 0.50610 | error: 0.49084 | utility: 0.96637\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 002 / 010 | time: 025 sec | loss: 0.50724 | error: 0.49167 | utility: 0.97140\n",
      "Validation accuracy improved.\n",
      "Saving model to ./Results/utility/utility_0.750_model.pt.\n",
      "Starting epoch 003 / 010.\n",
      "  batch 001 / 029 | loss: 0.72849 | error: 0.60938 | utility: 0.96361\n",
      "  batch 002 / 029 | loss: 0.59769 | error: 0.53906 | utility: 0.96195\n",
      "  batch 003 / 029 | loss: 0.54543 | error: 0.51562 | utility: 0.96319\n",
      "  batch 004 / 029 | loss: 0.52097 | error: 0.50000 | utility: 0.96386\n",
      "  batch 005 / 029 | loss: 0.51860 | error: 0.50000 | utility: 0.95716\n",
      "  batch 006 / 029 | loss: 0.54291 | error: 0.51302 | utility: 0.95835\n",
      "  batch 007 / 029 | loss: 0.51170 | error: 0.49777 | utility: 0.95609\n",
      "  batch 008 / 029 | loss: 0.53391 | error: 0.50781 | utility: 0.95773\n",
      "  batch 009 / 029 | loss: 0.51937 | error: 0.50174 | utility: 0.94417\n",
      "  batch 010 / 029 | loss: 0.51586 | error: 0.50000 | utility: 0.94208\n",
      "  batch 011 / 029 | loss: 0.52635 | error: 0.50568 | utility: 0.94353\n",
      "  batch 012 / 029 | loss: 0.53046 | error: 0.50651 | utility: 0.95061\n",
      "  batch 013 / 029 | loss: 0.54127 | error: 0.51202 | utility: 0.92008\n",
      "  batch 014 / 029 | loss: 0.52632 | error: 0.50446 | utility: 0.95464\n",
      "  batch 015 / 029 | loss: 0.52197 | error: 0.50104 | utility: 0.94084\n",
      "  batch 016 / 029 | loss: 0.52691 | error: 0.50293 | utility: 0.94876\n",
      "  batch 017 / 029 | loss: 0.52370 | error: 0.50092 | utility: 0.95404\n",
      "  batch 018 / 029 | loss: 0.52571 | error: 0.50087 | utility: 0.94320\n",
      "  batch 019 / 029 | loss: 0.53635 | error: 0.50576 | utility: 0.95559\n",
      "  batch 020 / 029 | loss: 0.53043 | error: 0.50234 | utility: 0.96245\n",
      "  batch 021 / 029 | loss: 0.52537 | error: 0.50000 | utility: 0.95306\n",
      "  batch 022 / 029 | loss: 0.52455 | error: 0.49929 | utility: 0.95917\n",
      "  batch 023 / 029 | loss: 0.51801 | error: 0.49592 | utility: 0.96465\n",
      "  batch 024 / 029 | loss: 0.52206 | error: 0.49805 | utility: 0.96084\n",
      "  batch 025 / 029 | loss: 0.51359 | error: 0.49312 | utility: 0.96344\n",
      "  batch 026 / 029 | loss: 0.51599 | error: 0.49459 | utility: 0.95768\n",
      "  batch 027 / 029 | loss: 0.51255 | error: 0.49306 | utility: 0.96468\n",
      "  batch 028 / 029 | loss: 0.50684 | error: 0.49051 | utility: 0.96492\n",
      "  batch 029 / 029 | loss: 0.49729 | error: 0.48653 | utility: 0.96590\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 003 / 010 | time: 025 sec | loss: 0.48682 | error: 0.48125 | utility: 0.97468\n",
      "Validation accuracy improved.\n",
      "Saving model to ./Results/utility/utility_0.750_model.pt.\n",
      "Starting epoch 004 / 010.\n",
      "  batch 001 / 029 | loss: 0.58205 | error: 0.53125 | utility: 0.96233\n",
      "  batch 002 / 029 | loss: 0.53320 | error: 0.50000 | utility: 0.96578\n",
      "  batch 003 / 029 | loss: 0.46359 | error: 0.46875 | utility: 0.96496\n",
      "  batch 004 / 029 | loss: 0.42217 | error: 0.44922 | utility: 0.96102\n",
      "  batch 005 / 029 | loss: 0.43534 | error: 0.45312 | utility: 0.96614\n",
      "  batch 006 / 029 | loss: 0.44748 | error: 0.46094 | utility: 0.96411\n",
      "  batch 007 / 029 | loss: 0.45746 | error: 0.46652 | utility: 0.96694\n",
      "  batch 008 / 029 | loss: 0.45560 | error: 0.46484 | utility: 0.95832\n",
      "  batch 009 / 029 | loss: 0.48210 | error: 0.47569 | utility: 0.95774\n",
      "  batch 010 / 029 | loss: 0.46263 | error: 0.46719 | utility: 0.96761\n",
      "  batch 011 / 029 | loss: 0.47090 | error: 0.47159 | utility: 0.96510\n",
      "  batch 012 / 029 | loss: 0.48961 | error: 0.48047 | utility: 0.96490\n",
      "  batch 013 / 029 | loss: 0.48072 | error: 0.47716 | utility: 0.96711\n",
      "  batch 014 / 029 | loss: 0.48060 | error: 0.47768 | utility: 0.96276\n",
      "  batch 015 / 029 | loss: 0.48055 | error: 0.47813 | utility: 0.96683\n",
      "  batch 016 / 029 | loss: 0.49100 | error: 0.48340 | utility: 0.95663\n",
      "  batch 017 / 029 | loss: 0.50254 | error: 0.48897 | utility: 0.96156\n",
      "  batch 018 / 029 | loss: 0.50297 | error: 0.48872 | utility: 0.95826\n",
      "  batch 019 / 029 | loss: 0.50535 | error: 0.49013 | utility: 0.95880\n",
      "  batch 020 / 029 | loss: 0.50427 | error: 0.48906 | utility: 0.95508\n",
      "  batch 021 / 029 | loss: 0.50078 | error: 0.48735 | utility: 0.96143\n",
      "  batch 022 / 029 | loss: 0.50167 | error: 0.48722 | utility: 0.94866\n",
      "  batch 023 / 029 | loss: 0.50588 | error: 0.48913 | utility: 0.95499\n",
      "  batch 024 / 029 | loss: 0.50934 | error: 0.49089 | utility: 0.95881\n",
      "  batch 025 / 029 | loss: 0.50512 | error: 0.48875 | utility: 0.96115\n",
      "  batch 026 / 029 | loss: 0.50817 | error: 0.49099 | utility: 0.96084\n",
      "  batch 027 / 029 | loss: 0.50838 | error: 0.49074 | utility: 0.95612\n",
      "  batch 028 / 029 | loss: 0.50811 | error: 0.49051 | utility: 0.95128\n",
      "  batch 029 / 029 | loss: 0.50769 | error: 0.49084 | utility: 0.91753\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 004 / 010 | time: 025 sec | loss: 0.50326 | error: 0.48646 | utility: 0.96749\n",
      "Starting epoch 005 / 010.\n",
      "  batch 001 / 029 | loss: 0.60887 | error: 0.53125 | utility: 0.95700\n",
      "  batch 002 / 029 | loss: 0.56111 | error: 0.50781 | utility: 0.95976\n",
      "  batch 003 / 029 | loss: 0.54689 | error: 0.50521 | utility: 0.96015\n",
      "  batch 004 / 029 | loss: 0.54111 | error: 0.50391 | utility: 0.95731\n",
      "  batch 005 / 029 | loss: 0.57055 | error: 0.52187 | utility: 0.96048\n",
      "  batch 006 / 029 | loss: 0.52540 | error: 0.50000 | utility: 0.95720\n",
      "  batch 007 / 029 | loss: 0.52640 | error: 0.50000 | utility: 0.96187\n",
      "  batch 008 / 029 | loss: 0.52530 | error: 0.50000 | utility: 0.96391\n",
      "  batch 009 / 029 | loss: 0.53132 | error: 0.50174 | utility: 0.96601\n",
      "  batch 010 / 029 | loss: 0.52971 | error: 0.50156 | utility: 0.96311\n",
      "  batch 011 / 029 | loss: 0.52981 | error: 0.50142 | utility: 0.96582\n",
      "  batch 012 / 029 | loss: 0.52338 | error: 0.49870 | utility: 0.96241\n",
      "  batch 013 / 029 | loss: 0.50914 | error: 0.49038 | utility: 0.94824\n",
      "  batch 014 / 029 | loss: 0.52889 | error: 0.50112 | utility: 0.95356\n",
      "  batch 015 / 029 | loss: 0.51661 | error: 0.49375 | utility: 0.95794\n",
      "  batch 016 / 029 | loss: 0.51108 | error: 0.49023 | utility: 0.95740\n",
      "  batch 017 / 029 | loss: 0.50682 | error: 0.48805 | utility: 0.96240\n",
      "  batch 018 / 029 | loss: 0.50890 | error: 0.48958 | utility: 0.95998\n",
      "  batch 019 / 029 | loss: 0.51310 | error: 0.49178 | utility: 0.95935\n",
      "  batch 020 / 029 | loss: 0.51003 | error: 0.49062 | utility: 0.95553\n",
      "  batch 021 / 029 | loss: 0.51140 | error: 0.49182 | utility: 0.96348\n",
      "  batch 022 / 029 | loss: 0.50826 | error: 0.49006 | utility: 0.96342\n",
      "  batch 023 / 029 | loss: 0.50397 | error: 0.48845 | utility: 0.93479\n",
      "  batch 024 / 029 | loss: 0.50724 | error: 0.49023 | utility: 0.95697\n",
      "  batch 025 / 029 | loss: 0.50859 | error: 0.49125 | utility: 0.95964\n",
      "  batch 026 / 029 | loss: 0.51222 | error: 0.49279 | utility: 0.96394\n",
      "  batch 027 / 029 | loss: 0.51054 | error: 0.49190 | utility: 0.96208\n",
      "  batch 028 / 029 | loss: 0.50627 | error: 0.48940 | utility: 0.96114\n",
      "  batch 029 / 029 | loss: 0.51261 | error: 0.49407 | utility: 0.95176\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 005 / 010 | time: 026 sec | loss: 0.48234 | error: 0.47865 | utility: 0.96864\n",
      "Validation accuracy improved.\n",
      "Saving model to ./Results/utility/utility_0.750_model.pt.\n",
      "Starting epoch 006 / 010.\n",
      "  batch 001 / 029 | loss: 0.49902 | error: 0.50000 | utility: 0.96105\n",
      "  batch 002 / 029 | loss: 0.59959 | error: 0.54688 | utility: 0.94302\n",
      "  batch 003 / 029 | loss: 0.55710 | error: 0.52083 | utility: 0.95997\n",
      "  batch 004 / 029 | loss: 0.59925 | error: 0.53906 | utility: 0.94668\n",
      "  batch 005 / 029 | loss: 0.56416 | error: 0.52187 | utility: 0.95223\n",
      "  batch 006 / 029 | loss: 0.54401 | error: 0.51042 | utility: 0.94668\n",
      "  batch 007 / 029 | loss: 0.53111 | error: 0.50446 | utility: 0.94849\n",
      "  batch 008 / 029 | loss: 0.53038 | error: 0.50391 | utility: 0.95419\n",
      "  batch 009 / 029 | loss: 0.51272 | error: 0.49479 | utility: 0.94261\n",
      "  batch 010 / 029 | loss: 0.50711 | error: 0.49219 | utility: 0.96045\n",
      "  batch 011 / 029 | loss: 0.51646 | error: 0.49574 | utility: 0.96203\n",
      "  batch 012 / 029 | loss: 0.49708 | error: 0.48568 | utility: 0.95372\n",
      "  batch 013 / 029 | loss: 0.50336 | error: 0.48918 | utility: 0.95118\n",
      "  batch 014 / 029 | loss: 0.50775 | error: 0.49107 | utility: 0.94147\n",
      "  batch 015 / 029 | loss: 0.50265 | error: 0.48958 | utility: 0.96048\n",
      "  batch 016 / 029 | loss: 0.51443 | error: 0.49414 | utility: 0.95573\n",
      "  batch 017 / 029 | loss: 0.51879 | error: 0.49632 | utility: 0.95936\n",
      "  batch 018 / 029 | loss: 0.51765 | error: 0.49653 | utility: 0.95774\n",
      "  batch 019 / 029 | loss: 0.52165 | error: 0.49836 | utility: 0.95325\n",
      "  batch 020 / 029 | loss: 0.52784 | error: 0.50156 | utility: 0.95069\n",
      "  batch 021 / 029 | loss: 0.51998 | error: 0.49777 | utility: 0.96251\n",
      "  batch 022 / 029 | loss: 0.51072 | error: 0.49290 | utility: 0.95997\n",
      "  batch 023 / 029 | loss: 0.50679 | error: 0.49117 | utility: 0.95111\n",
      "  batch 024 / 029 | loss: 0.50366 | error: 0.48958 | utility: 0.95890\n",
      "  batch 025 / 029 | loss: 0.50201 | error: 0.48812 | utility: 0.96238\n",
      "  batch 026 / 029 | loss: 0.49730 | error: 0.48558 | utility: 0.96328\n",
      "  batch 027 / 029 | loss: 0.49955 | error: 0.48669 | utility: 0.96292\n",
      "  batch 028 / 029 | loss: 0.50680 | error: 0.49051 | utility: 0.94596\n",
      "  batch 029 / 029 | loss: 0.50475 | error: 0.48653 | utility: 0.95566\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 006 / 010 | time: 025 sec | loss: 0.52296 | error: 0.50208 | utility: 0.97360\n",
      "Starting epoch 007 / 010.\n",
      "  batch 001 / 029 | loss: 0.56935 | error: 0.51562 | utility: 0.96745\n",
      "  batch 002 / 029 | loss: 0.63767 | error: 0.55469 | utility: 0.97031\n",
      "  batch 003 / 029 | loss: 0.65247 | error: 0.56250 | utility: 0.97317\n",
      "  batch 004 / 029 | loss: 0.60444 | error: 0.53906 | utility: 0.97144\n",
      "  batch 005 / 029 | loss: 0.55027 | error: 0.51250 | utility: 0.97438\n",
      "  batch 006 / 029 | loss: 0.54034 | error: 0.50781 | utility: 0.97453\n",
      "  batch 007 / 029 | loss: 0.50867 | error: 0.49107 | utility: 0.97545\n",
      "  batch 008 / 029 | loss: 0.52200 | error: 0.49805 | utility: 0.97614\n",
      "  batch 009 / 029 | loss: 0.51515 | error: 0.49479 | utility: 0.97531\n",
      "  batch 010 / 029 | loss: 0.50691 | error: 0.49062 | utility: 0.97714\n",
      "  batch 011 / 029 | loss: 0.50143 | error: 0.48722 | utility: 0.97647\n",
      "  batch 012 / 029 | loss: 0.49510 | error: 0.48438 | utility: 0.97328\n",
      "  batch 013 / 029 | loss: 0.48915 | error: 0.48197 | utility: 0.97368\n",
      "  batch 014 / 029 | loss: 0.48625 | error: 0.47991 | utility: 0.97396\n",
      "  batch 015 / 029 | loss: 0.48282 | error: 0.47813 | utility: 0.97281\n",
      "  batch 016 / 029 | loss: 0.48953 | error: 0.48242 | utility: 0.97069\n",
      "  batch 017 / 029 | loss: 0.48432 | error: 0.47978 | utility: 0.96986\n",
      "  batch 018 / 029 | loss: 0.48575 | error: 0.48003 | utility: 0.96846\n",
      "  batch 019 / 029 | loss: 0.49840 | error: 0.48684 | utility: 0.96527\n",
      "  batch 020 / 029 | loss: 0.50193 | error: 0.48828 | utility: 0.96788\n",
      "  batch 021 / 029 | loss: 0.50843 | error: 0.49182 | utility: 0.96446\n",
      "  batch 022 / 029 | loss: 0.50921 | error: 0.49219 | utility: 0.96315\n",
      "  batch 023 / 029 | loss: 0.51103 | error: 0.49321 | utility: 0.96440\n",
      "  batch 024 / 029 | loss: 0.51290 | error: 0.49414 | utility: 0.96431\n",
      "  batch 025 / 029 | loss: 0.51185 | error: 0.49312 | utility: 0.95243\n",
      "  batch 026 / 029 | loss: 0.50712 | error: 0.49099 | utility: 0.94789\n",
      "  batch 027 / 029 | loss: 0.50328 | error: 0.48900 | utility: 0.96435\n",
      "  batch 028 / 029 | loss: 0.50551 | error: 0.48996 | utility: 0.95595\n",
      "  batch 029 / 029 | loss: 0.51427 | error: 0.49461 | utility: 0.95847\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 007 / 010 | time: 025 sec | loss: 0.49032 | error: 0.47865 | utility: 0.96547\n",
      "Starting epoch 008 / 010.\n",
      "  batch 001 / 029 | loss: 0.57086 | error: 0.53125 | utility: 0.95906\n",
      "  batch 002 / 029 | loss: 0.47437 | error: 0.47656 | utility: 0.95946\n",
      "  batch 003 / 029 | loss: 0.50260 | error: 0.48438 | utility: 0.95869\n",
      "  batch 004 / 029 | loss: 0.41850 | error: 0.43750 | utility: 0.96348\n",
      "  batch 005 / 029 | loss: 0.45220 | error: 0.45937 | utility: 0.94109\n",
      "  batch 006 / 029 | loss: 0.49874 | error: 0.48438 | utility: 0.94910\n",
      "  batch 007 / 029 | loss: 0.52876 | error: 0.50000 | utility: 0.95121\n",
      "  batch 008 / 029 | loss: 0.53168 | error: 0.50195 | utility: 0.95847\n",
      "  batch 009 / 029 | loss: 0.53559 | error: 0.50521 | utility: 0.95779\n",
      "  batch 010 / 029 | loss: 0.52972 | error: 0.50156 | utility: 0.95666\n",
      "  batch 011 / 029 | loss: 0.54638 | error: 0.50994 | utility: 0.95842\n",
      "  batch 012 / 029 | loss: 0.54891 | error: 0.51172 | utility: 0.95877\n",
      "  batch 013 / 029 | loss: 0.53166 | error: 0.50120 | utility: 0.95975\n",
      "  batch 014 / 029 | loss: 0.52232 | error: 0.49665 | utility: 0.96370\n",
      "  batch 015 / 029 | loss: 0.52121 | error: 0.49583 | utility: 0.96459\n",
      "  batch 016 / 029 | loss: 0.52228 | error: 0.49707 | utility: 0.96457\n",
      "  batch 017 / 029 | loss: 0.53311 | error: 0.50276 | utility: 0.96414\n",
      "  batch 018 / 029 | loss: 0.54269 | error: 0.50781 | utility: 0.96381\n",
      "  batch 019 / 029 | loss: 0.53793 | error: 0.50576 | utility: 0.96224\n",
      "  batch 020 / 029 | loss: 0.53535 | error: 0.50391 | utility: 0.96516\n",
      "  batch 021 / 029 | loss: 0.52738 | error: 0.50000 | utility: 0.96667\n",
      "  batch 022 / 029 | loss: 0.51267 | error: 0.49290 | utility: 0.94985\n",
      "  batch 023 / 029 | loss: 0.51030 | error: 0.49185 | utility: 0.95184\n",
      "  batch 024 / 029 | loss: 0.50299 | error: 0.48828 | utility: 0.96425\n",
      "  batch 025 / 029 | loss: 0.50120 | error: 0.48750 | utility: 0.95572\n",
      "  batch 026 / 029 | loss: 0.49887 | error: 0.48678 | utility: 0.95155\n",
      "  batch 027 / 029 | loss: 0.50368 | error: 0.48900 | utility: 0.95565\n",
      "  batch 028 / 029 | loss: 0.50640 | error: 0.48996 | utility: 0.92971\n",
      "  batch 029 / 029 | loss: 0.50813 | error: 0.49030 | utility: 0.95127\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 008 / 010 | time: 026 sec | loss: 0.50546 | error: 0.49167 | utility: 0.96918\n",
      "Starting epoch 009 / 010.\n",
      "  batch 001 / 029 | loss: 0.47918 | error: 0.48438 | utility: 0.95787\n",
      "  batch 002 / 029 | loss: 0.54610 | error: 0.52344 | utility: 0.95378\n",
      "  batch 003 / 029 | loss: 0.50623 | error: 0.49479 | utility: 0.95758\n",
      "  batch 004 / 029 | loss: 0.45974 | error: 0.46875 | utility: 0.95532\n",
      "  batch 005 / 029 | loss: 0.52071 | error: 0.50000 | utility: 0.95709\n",
      "  batch 006 / 029 | loss: 0.49821 | error: 0.48958 | utility: 0.96119\n",
      "  batch 007 / 029 | loss: 0.48116 | error: 0.47991 | utility: 0.96082\n",
      "  batch 008 / 029 | loss: 0.49297 | error: 0.48633 | utility: 0.95555\n",
      "  batch 009 / 029 | loss: 0.48717 | error: 0.48438 | utility: 0.96205\n",
      "  batch 010 / 029 | loss: 0.50233 | error: 0.49062 | utility: 0.96299\n",
      "  batch 011 / 029 | loss: 0.48928 | error: 0.48153 | utility: 0.96465\n",
      "  batch 012 / 029 | loss: 0.48450 | error: 0.47917 | utility: 0.96350\n",
      "  batch 013 / 029 | loss: 0.48255 | error: 0.47716 | utility: 0.96543\n",
      "  batch 014 / 029 | loss: 0.48168 | error: 0.47656 | utility: 0.96572\n",
      "  batch 015 / 029 | loss: 0.47269 | error: 0.47187 | utility: 0.97154\n",
      "  batch 016 / 029 | loss: 0.48669 | error: 0.47949 | utility: 0.96801\n",
      "  batch 017 / 029 | loss: 0.48981 | error: 0.48162 | utility: 0.96867\n",
      "  batch 018 / 029 | loss: 0.49333 | error: 0.48351 | utility: 0.97186\n",
      "  batch 019 / 029 | loss: 0.49737 | error: 0.48602 | utility: 0.97032\n",
      "  batch 020 / 029 | loss: 0.49028 | error: 0.48281 | utility: 0.97267\n",
      "  batch 021 / 029 | loss: 0.48673 | error: 0.48065 | utility: 0.97050\n",
      "  batch 022 / 029 | loss: 0.48983 | error: 0.48224 | utility: 0.96277\n",
      "  batch 023 / 029 | loss: 0.48830 | error: 0.48166 | utility: 0.96893\n",
      "  batch 024 / 029 | loss: 0.48535 | error: 0.47982 | utility: 0.96292\n",
      "  batch 025 / 029 | loss: 0.48716 | error: 0.48063 | utility: 0.97034\n",
      "  batch 026 / 029 | loss: 0.49142 | error: 0.48317 | utility: 0.96599\n",
      "  batch 027 / 029 | loss: 0.49683 | error: 0.48553 | utility: 0.96622\n",
      "  batch 028 / 029 | loss: 0.50737 | error: 0.49107 | utility: 0.96463\n",
      "  batch 029 / 029 | loss: 0.49868 | error: 0.48707 | utility: 0.96839\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 009 / 010 | time: 025 sec | loss: 0.49877 | error: 0.48646 | utility: 0.96788\n",
      "Ending training due to 4 consecutive epochs without improvement in validation accuracy.\n",
      "Total training time: 4 minutes (228.2567596435547 seconds).\n",
      "Loading model from ./Results/utility/utility_0.750_model.pt.\n",
      "---------- Training with lambda=0.8 ----------\n",
      "Starting epoch 001 / 010.\n",
      "  batch 001 / 029 | loss: 0.52144 | error: 0.40625 | utility: 0.93142\n",
      "  batch 002 / 029 | loss: 0.49630 | error: 0.40625 | utility: 0.93357\n",
      "  batch 003 / 029 | loss: 0.53758 | error: 0.44792 | utility: 0.94080\n",
      "  batch 004 / 029 | loss: 0.52327 | error: 0.45312 | utility: 0.94520\n",
      "  batch 005 / 029 | loss: 0.50398 | error: 0.45312 | utility: 0.94767\n",
      "  batch 006 / 029 | loss: 0.50593 | error: 0.45833 | utility: 0.94628\n",
      "  batch 007 / 029 | loss: 0.51785 | error: 0.46875 | utility: 0.94452\n",
      "  batch 008 / 029 | loss: 0.53570 | error: 0.48047 | utility: 0.94101\n",
      "  batch 009 / 029 | loss: 0.56223 | error: 0.49653 | utility: 0.94503\n",
      "  batch 010 / 029 | loss: 0.55567 | error: 0.49531 | utility: 0.94809\n",
      "  batch 011 / 029 | loss: 0.54040 | error: 0.49006 | utility: 0.95411\n",
      "  batch 012 / 029 | loss: 0.55731 | error: 0.49870 | utility: 0.94730\n",
      "  batch 013 / 029 | loss: 0.54862 | error: 0.49519 | utility: 0.92883\n",
      "  batch 014 / 029 | loss: 0.55174 | error: 0.49888 | utility: 0.94894\n",
      "  batch 015 / 029 | loss: 0.53996 | error: 0.49375 | utility: 0.94401\n",
      "  batch 016 / 029 | loss: 0.53783 | error: 0.49219 | utility: 0.95260\n",
      "  batch 017 / 029 | loss: 0.53437 | error: 0.49265 | utility: 0.93852\n",
      "  batch 018 / 029 | loss: 0.54276 | error: 0.49826 | utility: 0.94771\n",
      "  batch 019 / 029 | loss: 0.54832 | error: 0.50247 | utility: 0.94767\n",
      "  batch 020 / 029 | loss: 0.55091 | error: 0.50547 | utility: 0.95350\n",
      "  batch 021 / 029 | loss: 0.54037 | error: 0.50074 | utility: 0.95974\n",
      "  batch 022 / 029 | loss: 0.52628 | error: 0.49432 | utility: 0.95753\n",
      "  batch 023 / 029 | loss: 0.52235 | error: 0.49321 | utility: 0.94520\n",
      "  batch 024 / 029 | loss: 0.52102 | error: 0.49349 | utility: 0.95822\n",
      "  batch 025 / 029 | loss: 0.51758 | error: 0.49188 | utility: 0.96065\n",
      "  batch 026 / 029 | loss: 0.51456 | error: 0.49038 | utility: 0.96176\n",
      "  batch 027 / 029 | loss: 0.51379 | error: 0.49016 | utility: 0.96266\n",
      "  batch 028 / 029 | loss: 0.51151 | error: 0.48996 | utility: 0.96711\n",
      "  batch 029 / 029 | loss: 0.50987 | error: 0.49030 | utility: 0.96829\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 001 / 010 | time: 025 sec | loss: 0.48898 | error: 0.49688 | utility: 0.97405\n",
      "Saving model to ./Results/utility/utility_0.800_model.pt.\n",
      "Starting epoch 002 / 010.\n",
      "  batch 001 / 029 | loss: 0.56402 | error: 0.53125 | utility: 0.96583\n",
      "  batch 002 / 029 | loss: 0.54023 | error: 0.52344 | utility: 0.96817\n",
      "  batch 003 / 029 | loss: 0.54776 | error: 0.52604 | utility: 0.96691\n",
      "  batch 004 / 029 | loss: 0.52130 | error: 0.51172 | utility: 0.97045\n",
      "  batch 005 / 029 | loss: 0.52131 | error: 0.51250 | utility: 0.96908\n",
      "  batch 006 / 029 | loss: 0.50983 | error: 0.50781 | utility: 0.96885\n",
      "  batch 007 / 029 | loss: 0.52702 | error: 0.51786 | utility: 0.96685\n",
      "  batch 008 / 029 | loss: 0.49636 | error: 0.50195 | utility: 0.97058\n",
      "  batch 009 / 029 | loss: 0.47649 | error: 0.49132 | utility: 0.96842\n",
      "  batch 010 / 029 | loss: 0.45512 | error: 0.47969 | utility: 0.96785\n",
      "  batch 011 / 029 | loss: 0.45074 | error: 0.47727 | utility: 0.97076\n",
      "  batch 012 / 029 | loss: 0.46282 | error: 0.48438 | utility: 0.96484\n",
      "  batch 013 / 029 | loss: 0.46891 | error: 0.48798 | utility: 0.95997\n",
      "  batch 014 / 029 | loss: 0.47834 | error: 0.49107 | utility: 0.96593\n",
      "  batch 015 / 029 | loss: 0.46015 | error: 0.48125 | utility: 0.96963\n",
      "  batch 016 / 029 | loss: 0.45385 | error: 0.47852 | utility: 0.95127\n",
      "  batch 017 / 029 | loss: 0.45249 | error: 0.47794 | utility: 0.96710\n",
      "  batch 018 / 029 | loss: 0.45528 | error: 0.47917 | utility: 0.96941\n",
      "  batch 019 / 029 | loss: 0.46457 | error: 0.48438 | utility: 0.95854\n",
      "  batch 020 / 029 | loss: 0.45769 | error: 0.48047 | utility: 0.96275\n",
      "  batch 021 / 029 | loss: 0.47625 | error: 0.48884 | utility: 0.96745\n",
      "  batch 022 / 029 | loss: 0.47693 | error: 0.48935 | utility: 0.96650\n",
      "  batch 023 / 029 | loss: 0.47494 | error: 0.48845 | utility: 0.97177\n",
      "  batch 024 / 029 | loss: 0.47365 | error: 0.48763 | utility: 0.97008\n",
      "  batch 025 / 029 | loss: 0.48011 | error: 0.49125 | utility: 0.96805\n",
      "  batch 026 / 029 | loss: 0.47682 | error: 0.48978 | utility: 0.96856\n",
      "  batch 027 / 029 | loss: 0.47828 | error: 0.49074 | utility: 0.96753\n",
      "  batch 028 / 029 | loss: 0.47790 | error: 0.49051 | utility: 0.97145\n",
      "  batch 029 / 029 | loss: 0.47741 | error: 0.49084 | utility: 0.96950\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 002 / 010 | time: 025 sec | loss: 0.47660 | error: 0.49167 | utility: 0.97391\n",
      "Validation accuracy improved.\n",
      "Saving model to ./Results/utility/utility_0.800_model.pt.\n",
      "Starting epoch 003 / 010.\n",
      "  batch 001 / 029 | loss: 0.70149 | error: 0.60938 | utility: 0.96702\n",
      "  batch 002 / 029 | loss: 0.56763 | error: 0.53906 | utility: 0.96552\n",
      "  batch 003 / 029 | loss: 0.51584 | error: 0.51562 | utility: 0.96655\n",
      "  batch 004 / 029 | loss: 0.49054 | error: 0.50000 | utility: 0.96678\n",
      "  batch 005 / 029 | loss: 0.48896 | error: 0.50000 | utility: 0.96205\n",
      "  batch 006 / 029 | loss: 0.51342 | error: 0.51302 | utility: 0.96239\n",
      "  batch 007 / 029 | loss: 0.48201 | error: 0.49777 | utility: 0.96178\n",
      "  batch 008 / 029 | loss: 0.50449 | error: 0.50781 | utility: 0.96106\n",
      "  batch 009 / 029 | loss: 0.49024 | error: 0.50174 | utility: 0.95279\n",
      "  batch 010 / 029 | loss: 0.48659 | error: 0.50000 | utility: 0.95025\n",
      "  batch 011 / 029 | loss: 0.49758 | error: 0.50568 | utility: 0.95161\n",
      "  batch 012 / 029 | loss: 0.50161 | error: 0.50651 | utility: 0.95503\n",
      "  batch 013 / 029 | loss: 0.51298 | error: 0.51202 | utility: 0.92964\n",
      "  batch 014 / 029 | loss: 0.49774 | error: 0.50446 | utility: 0.95896\n",
      "  batch 015 / 029 | loss: 0.49313 | error: 0.50104 | utility: 0.94845\n",
      "  batch 016 / 029 | loss: 0.49809 | error: 0.50293 | utility: 0.95579\n",
      "  batch 017 / 029 | loss: 0.49484 | error: 0.50092 | utility: 0.95959\n",
      "  batch 018 / 029 | loss: 0.49663 | error: 0.50087 | utility: 0.95012\n",
      "  batch 019 / 029 | loss: 0.50729 | error: 0.50576 | utility: 0.96043\n",
      "  batch 020 / 029 | loss: 0.50112 | error: 0.50234 | utility: 0.96633\n",
      "  batch 021 / 029 | loss: 0.49613 | error: 0.50000 | utility: 0.95943\n",
      "  batch 022 / 029 | loss: 0.49525 | error: 0.49929 | utility: 0.96414\n",
      "  batch 023 / 029 | loss: 0.48858 | error: 0.49592 | utility: 0.96852\n",
      "  batch 024 / 029 | loss: 0.49265 | error: 0.49805 | utility: 0.96562\n",
      "  batch 025 / 029 | loss: 0.48400 | error: 0.49312 | utility: 0.96754\n",
      "  batch 026 / 029 | loss: 0.48644 | error: 0.49459 | utility: 0.96614\n",
      "  batch 027 / 029 | loss: 0.48317 | error: 0.49306 | utility: 0.96887\n",
      "  batch 028 / 029 | loss: 0.47748 | error: 0.49051 | utility: 0.96903\n",
      "  batch 029 / 029 | loss: 0.46809 | error: 0.48653 | utility: 0.96989\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 003 / 010 | time: 029 sec | loss: 0.45832 | error: 0.48125 | utility: 0.97696\n",
      "Validation accuracy improved.\n",
      "Saving model to ./Results/utility/utility_0.800_model.pt.\n",
      "Starting epoch 004 / 010.\n",
      "  batch 001 / 029 | loss: 0.55656 | error: 0.53125 | utility: 0.96805\n",
      "  batch 002 / 029 | loss: 0.50483 | error: 0.50000 | utility: 0.96938\n",
      "  batch 003 / 029 | loss: 0.43423 | error: 0.46875 | utility: 0.96893\n",
      "  batch 004 / 029 | loss: 0.39274 | error: 0.44922 | utility: 0.96759\n",
      "  batch 005 / 029 | loss: 0.40539 | error: 0.45312 | utility: 0.96980\n",
      "  batch 006 / 029 | loss: 0.41791 | error: 0.46094 | utility: 0.96811\n",
      "  batch 007 / 029 | loss: 0.42805 | error: 0.46652 | utility: 0.97027\n",
      "  batch 008 / 029 | loss: 0.42595 | error: 0.46484 | utility: 0.96429\n",
      "  batch 009 / 029 | loss: 0.45259 | error: 0.47569 | utility: 0.96343\n",
      "  batch 010 / 029 | loss: 0.43284 | error: 0.46719 | utility: 0.97027\n",
      "  batch 011 / 029 | loss: 0.44111 | error: 0.47159 | utility: 0.96772\n",
      "  batch 012 / 029 | loss: 0.46015 | error: 0.48047 | utility: 0.96739\n",
      "  batch 013 / 029 | loss: 0.45115 | error: 0.47716 | utility: 0.96941\n",
      "  batch 014 / 029 | loss: 0.45115 | error: 0.47768 | utility: 0.96583\n",
      "  batch 015 / 029 | loss: 0.45115 | error: 0.47813 | utility: 0.96911\n",
      "  batch 016 / 029 | loss: 0.46177 | error: 0.48340 | utility: 0.96111\n",
      "  batch 017 / 029 | loss: 0.47315 | error: 0.48897 | utility: 0.96443\n",
      "  batch 018 / 029 | loss: 0.47342 | error: 0.48872 | utility: 0.96131\n",
      "  batch 019 / 029 | loss: 0.47580 | error: 0.49013 | utility: 0.96177\n",
      "  batch 020 / 029 | loss: 0.47461 | error: 0.48906 | utility: 0.95924\n",
      "  batch 021 / 029 | loss: 0.47110 | error: 0.48735 | utility: 0.96390\n",
      "  batch 022 / 029 | loss: 0.47206 | error: 0.48722 | utility: 0.95503\n",
      "  batch 023 / 029 | loss: 0.47625 | error: 0.48913 | utility: 0.95902\n",
      "  batch 024 / 029 | loss: 0.47972 | error: 0.49089 | utility: 0.96226\n",
      "  batch 025 / 029 | loss: 0.47550 | error: 0.48875 | utility: 0.96456\n",
      "  batch 026 / 029 | loss: 0.47860 | error: 0.49099 | utility: 0.96487\n",
      "  batch 027 / 029 | loss: 0.47878 | error: 0.49074 | utility: 0.96124\n",
      "  batch 028 / 029 | loss: 0.47853 | error: 0.49051 | utility: 0.95883\n",
      "  batch 029 / 029 | loss: 0.47843 | error: 0.49084 | utility: 0.94051\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 004 / 010 | time: 031 sec | loss: 0.47328 | error: 0.48646 | utility: 0.97143\n",
      "Starting epoch 005 / 010.\n",
      "  batch 001 / 029 | loss: 0.57690 | error: 0.53125 | utility: 0.96302\n",
      "  batch 002 / 029 | loss: 0.52886 | error: 0.50781 | utility: 0.96519\n",
      "  batch 003 / 029 | loss: 0.51593 | error: 0.50521 | utility: 0.96545\n",
      "  batch 004 / 029 | loss: 0.51066 | error: 0.50391 | utility: 0.96442\n",
      "  batch 005 / 029 | loss: 0.54184 | error: 0.52187 | utility: 0.96648\n",
      "  batch 006 / 029 | loss: 0.49611 | error: 0.50000 | utility: 0.96453\n",
      "  batch 007 / 029 | loss: 0.49723 | error: 0.50000 | utility: 0.96731\n",
      "  batch 008 / 029 | loss: 0.49653 | error: 0.50000 | utility: 0.96880\n",
      "  batch 009 / 029 | loss: 0.50271 | error: 0.50174 | utility: 0.97034\n",
      "  batch 010 / 029 | loss: 0.50123 | error: 0.50156 | utility: 0.96811\n",
      "  batch 011 / 029 | loss: 0.50149 | error: 0.50142 | utility: 0.97002\n",
      "  batch 012 / 029 | loss: 0.49511 | error: 0.49870 | utility: 0.96732\n",
      "  batch 013 / 029 | loss: 0.48040 | error: 0.49159 | utility: 0.95643\n",
      "  batch 014 / 029 | loss: 0.50103 | error: 0.50223 | utility: 0.96094\n",
      "  batch 015 / 029 | loss: 0.48806 | error: 0.49479 | utility: 0.96368\n",
      "  batch 016 / 029 | loss: 0.48244 | error: 0.49121 | utility: 0.96276\n",
      "  batch 017 / 029 | loss: 0.47806 | error: 0.48897 | utility: 0.96625\n",
      "  batch 018 / 029 | loss: 0.48024 | error: 0.49045 | utility: 0.96443\n",
      "  batch 019 / 029 | loss: 0.48451 | error: 0.49260 | utility: 0.96390\n",
      "  batch 020 / 029 | loss: 0.48141 | error: 0.49141 | utility: 0.96232\n",
      "  batch 021 / 029 | loss: 0.48265 | error: 0.49256 | utility: 0.96709\n",
      "  batch 022 / 029 | loss: 0.47930 | error: 0.49077 | utility: 0.96727\n",
      "  batch 023 / 029 | loss: 0.47510 | error: 0.48913 | utility: 0.95047\n",
      "  batch 024 / 029 | loss: 0.47828 | error: 0.49089 | utility: 0.96322\n",
      "  batch 025 / 029 | loss: 0.47963 | error: 0.49188 | utility: 0.96404\n",
      "  batch 026 / 029 | loss: 0.48316 | error: 0.49339 | utility: 0.96659\n",
      "  batch 027 / 029 | loss: 0.48138 | error: 0.49248 | utility: 0.96550\n",
      "  batch 028 / 029 | loss: 0.47700 | error: 0.48996 | utility: 0.96447\n",
      "  batch 029 / 029 | loss: 0.48365 | error: 0.49461 | utility: 0.95683\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 005 / 010 | time: 030 sec | loss: 0.45272 | error: 0.47865 | utility: 0.97146\n",
      "Validation accuracy improved.\n",
      "Saving model to ./Results/utility/utility_0.800_model.pt.\n",
      "Starting epoch 006 / 010.\n",
      "  batch 001 / 029 | loss: 0.47216 | error: 0.50000 | utility: 0.96441\n",
      "  batch 002 / 029 | loss: 0.57331 | error: 0.54688 | utility: 0.95070\n",
      "  batch 003 / 029 | loss: 0.52930 | error: 0.52083 | utility: 0.96330\n",
      "  batch 004 / 029 | loss: 0.57180 | error: 0.53906 | utility: 0.95306\n",
      "  batch 005 / 029 | loss: 0.53615 | error: 0.52187 | utility: 0.95681\n",
      "  batch 006 / 029 | loss: 0.51559 | error: 0.51042 | utility: 0.95224\n",
      "  batch 007 / 029 | loss: 0.50278 | error: 0.50446 | utility: 0.95507\n",
      "  batch 008 / 029 | loss: 0.50194 | error: 0.50391 | utility: 0.95916\n",
      "  batch 009 / 029 | loss: 0.48385 | error: 0.49479 | utility: 0.95180\n",
      "  batch 010 / 029 | loss: 0.47815 | error: 0.49219 | utility: 0.96465\n",
      "  batch 011 / 029 | loss: 0.48750 | error: 0.49574 | utility: 0.96598\n",
      "  batch 012 / 029 | loss: 0.46745 | error: 0.48568 | utility: 0.96079\n",
      "  batch 013 / 029 | loss: 0.47379 | error: 0.48918 | utility: 0.95874\n",
      "  batch 014 / 029 | loss: 0.47860 | error: 0.49107 | utility: 0.94958\n",
      "  batch 015 / 029 | loss: 0.47377 | error: 0.48958 | utility: 0.96510\n",
      "  batch 016 / 029 | loss: 0.48549 | error: 0.49414 | utility: 0.96109\n",
      "  batch 017 / 029 | loss: 0.49011 | error: 0.49632 | utility: 0.96371\n",
      "  batch 018 / 029 | loss: 0.48923 | error: 0.49653 | utility: 0.96401\n",
      "  batch 019 / 029 | loss: 0.49325 | error: 0.49836 | utility: 0.95945\n",
      "  batch 020 / 029 | loss: 0.49958 | error: 0.50156 | utility: 0.95890\n",
      "  batch 021 / 029 | loss: 0.49157 | error: 0.49777 | utility: 0.96669\n",
      "  batch 022 / 029 | loss: 0.48201 | error: 0.49290 | utility: 0.96468\n",
      "  batch 023 / 029 | loss: 0.47802 | error: 0.49117 | utility: 0.96010\n",
      "  batch 024 / 029 | loss: 0.47483 | error: 0.48958 | utility: 0.96360\n",
      "  batch 025 / 029 | loss: 0.47299 | error: 0.48812 | utility: 0.96644\n",
      "  batch 026 / 029 | loss: 0.46822 | error: 0.48558 | utility: 0.96718\n",
      "  batch 027 / 029 | loss: 0.47044 | error: 0.48669 | utility: 0.96682\n",
      "  batch 028 / 029 | loss: 0.47777 | error: 0.49051 | utility: 0.95655\n",
      "  batch 029 / 029 | loss: 0.47503 | error: 0.48653 | utility: 0.96120\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 006 / 010 | time: 030 sec | loss: 0.49532 | error: 0.50208 | utility: 0.97599\n",
      "Starting epoch 007 / 010.\n",
      "  batch 001 / 029 | loss: 0.53898 | error: 0.51562 | utility: 0.97093\n",
      "  batch 002 / 029 | loss: 0.60935 | error: 0.55469 | utility: 0.97351\n",
      "  batch 003 / 029 | loss: 0.62475 | error: 0.56250 | utility: 0.97596\n",
      "  batch 004 / 029 | loss: 0.57635 | error: 0.53906 | utility: 0.97519\n",
      "  batch 005 / 029 | loss: 0.52185 | error: 0.51250 | utility: 0.97689\n",
      "  batch 006 / 029 | loss: 0.51212 | error: 0.50781 | utility: 0.97695\n",
      "  batch 007 / 029 | loss: 0.47989 | error: 0.49107 | utility: 0.97760\n",
      "  batch 008 / 029 | loss: 0.49341 | error: 0.49805 | utility: 0.97786\n",
      "  batch 009 / 029 | loss: 0.48642 | error: 0.49479 | utility: 0.97715\n",
      "  batch 010 / 029 | loss: 0.47803 | error: 0.49062 | utility: 0.97842\n",
      "  batch 011 / 029 | loss: 0.47222 | error: 0.48722 | utility: 0.97772\n",
      "  batch 012 / 029 | loss: 0.46595 | error: 0.48438 | utility: 0.97489\n",
      "  batch 013 / 029 | loss: 0.46002 | error: 0.48197 | utility: 0.97521\n",
      "  batch 014 / 029 | loss: 0.45702 | error: 0.47991 | utility: 0.97506\n",
      "  batch 015 / 029 | loss: 0.45346 | error: 0.47813 | utility: 0.97404\n",
      "  batch 016 / 029 | loss: 0.46046 | error: 0.48242 | utility: 0.97210\n",
      "  batch 017 / 029 | loss: 0.45503 | error: 0.47978 | utility: 0.97154\n",
      "  batch 018 / 029 | loss: 0.45639 | error: 0.48003 | utility: 0.97034\n",
      "  batch 019 / 029 | loss: 0.46934 | error: 0.48684 | utility: 0.96729\n",
      "  batch 020 / 029 | loss: 0.47297 | error: 0.48828 | utility: 0.96972\n",
      "  batch 021 / 029 | loss: 0.47971 | error: 0.49182 | utility: 0.96672\n",
      "  batch 022 / 029 | loss: 0.48053 | error: 0.49219 | utility: 0.96589\n",
      "  batch 023 / 029 | loss: 0.48240 | error: 0.49321 | utility: 0.96727\n",
      "  batch 024 / 029 | loss: 0.48431 | error: 0.49414 | utility: 0.96740\n",
      "  batch 025 / 029 | loss: 0.48319 | error: 0.49312 | utility: 0.95805\n",
      "  batch 026 / 029 | loss: 0.47824 | error: 0.49099 | utility: 0.95458\n",
      "  batch 027 / 029 | loss: 0.47428 | error: 0.48900 | utility: 0.96774\n",
      "  batch 028 / 029 | loss: 0.47656 | error: 0.48996 | utility: 0.96136\n",
      "  batch 029 / 029 | loss: 0.48558 | error: 0.49461 | utility: 0.96277\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 007 / 010 | time: 033 sec | loss: 0.46135 | error: 0.47865 | utility: 0.96955\n",
      "Starting epoch 008 / 010.\n",
      "  batch 001 / 029 | loss: 0.54519 | error: 0.53125 | utility: 0.96314\n",
      "  batch 002 / 029 | loss: 0.44655 | error: 0.47656 | utility: 0.96459\n",
      "  batch 003 / 029 | loss: 0.47214 | error: 0.48438 | utility: 0.96396\n",
      "  batch 004 / 029 | loss: 0.38552 | error: 0.43750 | utility: 0.96746\n",
      "  batch 005 / 029 | loss: 0.42073 | error: 0.45937 | utility: 0.95357\n",
      "  batch 006 / 029 | loss: 0.46834 | error: 0.48438 | utility: 0.95840\n",
      "  batch 007 / 029 | loss: 0.49898 | error: 0.50000 | utility: 0.96018\n",
      "  batch 008 / 029 | loss: 0.50172 | error: 0.50195 | utility: 0.96436\n",
      "  batch 009 / 029 | loss: 0.50608 | error: 0.50521 | utility: 0.96373\n",
      "  batch 010 / 029 | loss: 0.49983 | error: 0.50156 | utility: 0.96346\n",
      "  batch 011 / 029 | loss: 0.51693 | error: 0.50994 | utility: 0.96462\n",
      "  batch 012 / 029 | loss: 0.51980 | error: 0.51172 | utility: 0.96459\n",
      "  batch 013 / 029 | loss: 0.50144 | error: 0.50120 | utility: 0.96551\n",
      "  batch 014 / 029 | loss: 0.49205 | error: 0.49665 | utility: 0.96831\n",
      "  batch 015 / 029 | loss: 0.49069 | error: 0.49583 | utility: 0.96931\n",
      "  batch 016 / 029 | loss: 0.49206 | error: 0.49707 | utility: 0.96938\n",
      "  batch 017 / 029 | loss: 0.50321 | error: 0.50276 | utility: 0.96864\n",
      "  batch 018 / 029 | loss: 0.51314 | error: 0.50781 | utility: 0.96812\n",
      "  batch 019 / 029 | loss: 0.50847 | error: 0.50576 | utility: 0.96766\n",
      "  batch 020 / 029 | loss: 0.50574 | error: 0.50391 | utility: 0.96896\n",
      "  batch 021 / 029 | loss: 0.49768 | error: 0.50000 | utility: 0.96995\n",
      "  batch 022 / 029 | loss: 0.48296 | error: 0.49290 | utility: 0.95951\n",
      "  batch 023 / 029 | loss: 0.48054 | error: 0.49185 | utility: 0.96027\n",
      "  batch 024 / 029 | loss: 0.47320 | error: 0.48828 | utility: 0.96758\n",
      "  batch 025 / 029 | loss: 0.47142 | error: 0.48750 | utility: 0.96186\n",
      "  batch 026 / 029 | loss: 0.46910 | error: 0.48678 | utility: 0.95978\n",
      "  batch 027 / 029 | loss: 0.47391 | error: 0.48900 | utility: 0.95989\n",
      "  batch 028 / 029 | loss: 0.47668 | error: 0.49051 | utility: 0.94402\n",
      "  batch 029 / 029 | loss: 0.47847 | error: 0.49084 | utility: 0.95525\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 008 / 010 | time: 030 sec | loss: 0.47642 | error: 0.49167 | utility: 0.97181\n",
      "Starting epoch 009 / 010.\n",
      "  batch 001 / 029 | loss: 0.45002 | error: 0.48438 | utility: 0.96225\n",
      "  batch 002 / 029 | loss: 0.51821 | error: 0.52344 | utility: 0.95927\n",
      "  batch 003 / 029 | loss: 0.47693 | error: 0.49479 | utility: 0.96242\n",
      "  batch 004 / 029 | loss: 0.42978 | error: 0.46875 | utility: 0.96098\n",
      "  batch 005 / 029 | loss: 0.49184 | error: 0.50000 | utility: 0.96124\n",
      "  batch 006 / 029 | loss: 0.46939 | error: 0.48958 | utility: 0.96510\n",
      "  batch 007 / 029 | loss: 0.45188 | error: 0.47991 | utility: 0.96526\n",
      "  batch 008 / 029 | loss: 0.46408 | error: 0.48633 | utility: 0.96209\n",
      "  batch 009 / 029 | loss: 0.45832 | error: 0.48438 | utility: 0.96638\n",
      "  batch 010 / 029 | loss: 0.47317 | error: 0.49062 | utility: 0.96688\n",
      "  batch 011 / 029 | loss: 0.45931 | error: 0.48153 | utility: 0.96864\n",
      "  batch 012 / 029 | loss: 0.45436 | error: 0.47917 | utility: 0.96860\n",
      "  batch 013 / 029 | loss: 0.45209 | error: 0.47716 | utility: 0.96951\n",
      "  batch 014 / 029 | loss: 0.45127 | error: 0.47656 | utility: 0.97001\n",
      "  batch 015 / 029 | loss: 0.44220 | error: 0.47187 | utility: 0.97443\n",
      "  batch 016 / 029 | loss: 0.45655 | error: 0.47949 | utility: 0.97188\n",
      "  batch 017 / 029 | loss: 0.45984 | error: 0.48162 | utility: 0.97282\n",
      "  batch 018 / 029 | loss: 0.46338 | error: 0.48351 | utility: 0.97462\n",
      "  batch 019 / 029 | loss: 0.46779 | error: 0.48602 | utility: 0.97367\n",
      "  batch 020 / 029 | loss: 0.46067 | error: 0.48281 | utility: 0.97492\n",
      "  batch 021 / 029 | loss: 0.45703 | error: 0.48065 | utility: 0.97307\n",
      "  batch 022 / 029 | loss: 0.46020 | error: 0.48224 | utility: 0.96792\n",
      "  batch 023 / 029 | loss: 0.45857 | error: 0.48166 | utility: 0.97168\n",
      "  batch 024 / 029 | loss: 0.45560 | error: 0.47982 | utility: 0.96753\n",
      "  batch 025 / 029 | loss: 0.45734 | error: 0.48063 | utility: 0.97259\n",
      "  batch 026 / 029 | loss: 0.46166 | error: 0.48317 | utility: 0.96863\n",
      "  batch 027 / 029 | loss: 0.46700 | error: 0.48553 | utility: 0.96883\n",
      "  batch 028 / 029 | loss: 0.47767 | error: 0.49107 | utility: 0.96714\n",
      "  batch 029 / 029 | loss: 0.46885 | error: 0.48707 | utility: 0.97047\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 009 / 010 | time: 030 sec | loss: 0.46722 | error: 0.48646 | utility: 0.97029\n",
      "Ending training due to 4 consecutive epochs without improvement in validation accuracy.\n",
      "Total training time: 4 minutes (262.85542583465576 seconds).\n",
      "Loading model from ./Results/utility/utility_0.800_model.pt.\n",
      "---------- Training with lambda=0.8500000000000001 ----------\n",
      "Starting epoch 001 / 010.\n",
      "  batch 001 / 029 | loss: 0.49938 | error: 0.40625 | utility: 0.93142\n",
      "  batch 002 / 029 | loss: 0.47335 | error: 0.40625 | utility: 0.93357\n",
      "  batch 003 / 029 | loss: 0.51369 | error: 0.44792 | utility: 0.94074\n",
      "  batch 004 / 029 | loss: 0.49841 | error: 0.45312 | utility: 0.94512\n",
      "  batch 005 / 029 | loss: 0.47830 | error: 0.45312 | utility: 0.94757\n",
      "  batch 006 / 029 | loss: 0.47970 | error: 0.45833 | utility: 0.94617\n",
      "  batch 007 / 029 | loss: 0.49129 | error: 0.46875 | utility: 0.94454\n",
      "  batch 008 / 029 | loss: 0.50889 | error: 0.48047 | utility: 0.94116\n",
      "  batch 009 / 029 | loss: 0.53530 | error: 0.49653 | utility: 0.94544\n",
      "  batch 010 / 029 | loss: 0.52832 | error: 0.49531 | utility: 0.94858\n",
      "  batch 011 / 029 | loss: 0.51269 | error: 0.49006 | utility: 0.95465\n",
      "  batch 012 / 029 | loss: 0.52949 | error: 0.49870 | utility: 0.94857\n",
      "  batch 013 / 029 | loss: 0.52058 | error: 0.49519 | utility: 0.93175\n",
      "  batch 014 / 029 | loss: 0.52367 | error: 0.49888 | utility: 0.95064\n",
      "  batch 015 / 029 | loss: 0.51163 | error: 0.49375 | utility: 0.94619\n",
      "  batch 016 / 029 | loss: 0.50930 | error: 0.49219 | utility: 0.95477\n",
      "  batch 017 / 029 | loss: 0.50590 | error: 0.49265 | utility: 0.94174\n",
      "  batch 018 / 029 | loss: 0.51444 | error: 0.49826 | utility: 0.95061\n",
      "  batch 019 / 029 | loss: 0.52015 | error: 0.50247 | utility: 0.95092\n",
      "  batch 020 / 029 | loss: 0.52296 | error: 0.50547 | utility: 0.95696\n",
      "  batch 021 / 029 | loss: 0.51220 | error: 0.50074 | utility: 0.96266\n",
      "  batch 022 / 029 | loss: 0.49772 | error: 0.49432 | utility: 0.96087\n",
      "  batch 023 / 029 | loss: 0.49366 | error: 0.49321 | utility: 0.95082\n",
      "  batch 024 / 029 | loss: 0.49237 | error: 0.49349 | utility: 0.96226\n",
      "  batch 025 / 029 | loss: 0.48875 | error: 0.49188 | utility: 0.96464\n",
      "  batch 026 / 029 | loss: 0.48551 | error: 0.49038 | utility: 0.96573\n",
      "  batch 027 / 029 | loss: 0.48470 | error: 0.49016 | utility: 0.96687\n",
      "  batch 028 / 029 | loss: 0.48244 | error: 0.48996 | utility: 0.97085\n",
      "  batch 029 / 029 | loss: 0.48079 | error: 0.49030 | utility: 0.97205\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 001 / 010 | time: 030 sec | loss: 0.45804 | error: 0.49688 | utility: 0.97732\n",
      "Saving model to ./Results/utility/utility_0.850_model.pt.\n",
      "Starting epoch 002 / 010.\n",
      "  batch 001 / 029 | loss: 0.53585 | error: 0.53125 | utility: 0.97010\n",
      "  batch 002 / 029 | loss: 0.51262 | error: 0.52344 | utility: 0.97218\n",
      "  batch 003 / 029 | loss: 0.52012 | error: 0.52604 | utility: 0.97127\n",
      "  batch 004 / 029 | loss: 0.49281 | error: 0.51172 | utility: 0.97399\n",
      "  batch 005 / 029 | loss: 0.49284 | error: 0.51250 | utility: 0.97291\n",
      "  batch 006 / 029 | loss: 0.48123 | error: 0.50781 | utility: 0.97299\n",
      "  batch 007 / 029 | loss: 0.49917 | error: 0.51786 | utility: 0.97142\n",
      "  batch 008 / 029 | loss: 0.46796 | error: 0.50195 | utility: 0.97382\n",
      "  batch 009 / 029 | loss: 0.44758 | error: 0.49132 | utility: 0.97222\n",
      "  batch 010 / 029 | loss: 0.42544 | error: 0.47969 | utility: 0.97171\n",
      "  batch 011 / 029 | loss: 0.42078 | error: 0.47727 | utility: 0.97359\n",
      "  batch 012 / 029 | loss: 0.43328 | error: 0.48438 | utility: 0.96922\n",
      "  batch 013 / 029 | loss: 0.43948 | error: 0.48798 | utility: 0.96734\n",
      "  batch 014 / 029 | loss: 0.44857 | error: 0.49107 | utility: 0.96963\n",
      "  batch 015 / 029 | loss: 0.42998 | error: 0.48125 | utility: 0.97267\n",
      "  batch 016 / 029 | loss: 0.42380 | error: 0.47852 | utility: 0.96297\n",
      "  batch 017 / 029 | loss: 0.42239 | error: 0.47794 | utility: 0.97074\n",
      "  batch 018 / 029 | loss: 0.42499 | error: 0.47917 | utility: 0.97242\n",
      "  batch 019 / 029 | loss: 0.43434 | error: 0.48438 | utility: 0.96627\n",
      "  batch 020 / 029 | loss: 0.42725 | error: 0.48047 | utility: 0.96780\n",
      "  batch 021 / 029 | loss: 0.44562 | error: 0.48884 | utility: 0.97054\n",
      "  batch 022 / 029 | loss: 0.44632 | error: 0.48935 | utility: 0.96976\n",
      "  batch 023 / 029 | loss: 0.44427 | error: 0.48845 | utility: 0.97399\n",
      "  batch 024 / 029 | loss: 0.44291 | error: 0.48763 | utility: 0.97240\n",
      "  batch 025 / 029 | loss: 0.44947 | error: 0.49125 | utility: 0.97078\n",
      "  batch 026 / 029 | loss: 0.44617 | error: 0.48978 | utility: 0.97089\n",
      "  batch 027 / 029 | loss: 0.44772 | error: 0.49074 | utility: 0.97043\n",
      "  batch 028 / 029 | loss: 0.44732 | error: 0.49051 | utility: 0.97306\n",
      "  batch 029 / 029 | loss: 0.44686 | error: 0.49084 | utility: 0.97126\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 002 / 010 | time: 031 sec | loss: 0.44616 | error: 0.49167 | utility: 0.97530\n",
      "Validation accuracy improved.\n",
      "Saving model to ./Results/utility/utility_0.850_model.pt.\n",
      "Starting epoch 003 / 010.\n",
      "  batch 001 / 029 | loss: 0.67376 | error: 0.60938 | utility: 0.96875\n",
      "  batch 002 / 029 | loss: 0.53784 | error: 0.53906 | utility: 0.96716\n",
      "  batch 003 / 029 | loss: 0.48605 | error: 0.51562 | utility: 0.96810\n",
      "  batch 004 / 029 | loss: 0.46025 | error: 0.50000 | utility: 0.96800\n",
      "  batch 005 / 029 | loss: 0.45911 | error: 0.50000 | utility: 0.96398\n",
      "  batch 006 / 029 | loss: 0.48363 | error: 0.51302 | utility: 0.96419\n",
      "  batch 007 / 029 | loss: 0.45190 | error: 0.49777 | utility: 0.96413\n",
      "  batch 008 / 029 | loss: 0.47480 | error: 0.50781 | utility: 0.96259\n",
      "  batch 009 / 029 | loss: 0.46066 | error: 0.50174 | utility: 0.95686\n",
      "  batch 010 / 029 | loss: 0.45688 | error: 0.50000 | utility: 0.95468\n",
      "  batch 011 / 029 | loss: 0.46828 | error: 0.50568 | utility: 0.95601\n",
      "  batch 012 / 029 | loss: 0.47224 | error: 0.50651 | utility: 0.95750\n",
      "  batch 013 / 029 | loss: 0.48395 | error: 0.51202 | utility: 0.93665\n",
      "  batch 014 / 029 | loss: 0.46855 | error: 0.50446 | utility: 0.96220\n",
      "  batch 015 / 029 | loss: 0.46382 | error: 0.50104 | utility: 0.95400\n",
      "  batch 016 / 029 | loss: 0.46874 | error: 0.50293 | utility: 0.95979\n",
      "  batch 017 / 029 | loss: 0.46540 | error: 0.50092 | utility: 0.96326\n",
      "  batch 018 / 029 | loss: 0.46708 | error: 0.50087 | utility: 0.95571\n",
      "  batch 019 / 029 | loss: 0.47775 | error: 0.50576 | utility: 0.96447\n",
      "  batch 020 / 029 | loss: 0.47142 | error: 0.50234 | utility: 0.96950\n",
      "  batch 021 / 029 | loss: 0.46645 | error: 0.50000 | utility: 0.96418\n",
      "  batch 022 / 029 | loss: 0.46551 | error: 0.49929 | utility: 0.96820\n",
      "  batch 023 / 029 | loss: 0.45874 | error: 0.49592 | utility: 0.97160\n",
      "  batch 024 / 029 | loss: 0.46287 | error: 0.49805 | utility: 0.96968\n",
      "  batch 025 / 029 | loss: 0.45395 | error: 0.49312 | utility: 0.97114\n",
      "  batch 026 / 029 | loss: 0.45651 | error: 0.49459 | utility: 0.97108\n",
      "  batch 027 / 029 | loss: 0.45315 | error: 0.49306 | utility: 0.97276\n",
      "  batch 028 / 029 | loss: 0.44747 | error: 0.49051 | utility: 0.97299\n",
      "  batch 029 / 029 | loss: 0.43829 | error: 0.48653 | utility: 0.97368\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 003 / 010 | time: 037 sec | loss: 0.42692 | error: 0.48125 | utility: 0.97938\n",
      "Validation accuracy improved.\n",
      "Saving model to ./Results/utility/utility_0.850_model.pt.\n",
      "Starting epoch 004 / 010.\n",
      "  batch 001 / 029 | loss: 0.52806 | error: 0.53125 | utility: 0.97270\n",
      "  batch 002 / 029 | loss: 0.47249 | error: 0.50000 | utility: 0.97325\n",
      "  batch 003 / 029 | loss: 0.40168 | error: 0.46875 | utility: 0.97279\n",
      "  batch 004 / 029 | loss: 0.36041 | error: 0.44922 | utility: 0.97226\n",
      "  batch 005 / 029 | loss: 0.37293 | error: 0.45312 | utility: 0.97299\n",
      "  batch 006 / 029 | loss: 0.38604 | error: 0.46094 | utility: 0.97136\n",
      "  batch 007 / 029 | loss: 0.39649 | error: 0.46652 | utility: 0.97303\n",
      "  batch 008 / 029 | loss: 0.39436 | error: 0.46484 | utility: 0.96852\n",
      "  batch 009 / 029 | loss: 0.42114 | error: 0.47569 | utility: 0.96747\n",
      "  batch 010 / 029 | loss: 0.40122 | error: 0.46719 | utility: 0.97217\n",
      "  batch 011 / 029 | loss: 0.40973 | error: 0.47159 | utility: 0.96961\n",
      "  batch 012 / 029 | loss: 0.42898 | error: 0.48047 | utility: 0.96907\n",
      "  batch 013 / 029 | loss: 0.41986 | error: 0.47716 | utility: 0.97094\n",
      "  batch 014 / 029 | loss: 0.41999 | error: 0.47768 | utility: 0.96785\n",
      "  batch 015 / 029 | loss: 0.42004 | error: 0.47813 | utility: 0.97046\n",
      "  batch 016 / 029 | loss: 0.43102 | error: 0.48340 | utility: 0.96427\n",
      "  batch 017 / 029 | loss: 0.44254 | error: 0.48897 | utility: 0.96581\n",
      "  batch 018 / 029 | loss: 0.44285 | error: 0.48872 | utility: 0.96297\n",
      "  batch 019 / 029 | loss: 0.44531 | error: 0.49013 | utility: 0.96341\n",
      "  batch 020 / 029 | loss: 0.44403 | error: 0.48906 | utility: 0.96186\n",
      "  batch 021 / 029 | loss: 0.44056 | error: 0.48735 | utility: 0.96550\n",
      "  batch 022 / 029 | loss: 0.44163 | error: 0.48722 | utility: 0.95803\n",
      "  batch 023 / 029 | loss: 0.44593 | error: 0.48913 | utility: 0.96121\n",
      "  batch 024 / 029 | loss: 0.44952 | error: 0.49089 | utility: 0.96485\n",
      "  batch 025 / 029 | loss: 0.44532 | error: 0.48875 | utility: 0.96709\n",
      "  batch 026 / 029 | loss: 0.44857 | error: 0.49099 | utility: 0.96810\n",
      "  batch 027 / 029 | loss: 0.44865 | error: 0.49074 | utility: 0.96513\n",
      "  batch 028 / 029 | loss: 0.44840 | error: 0.49051 | utility: 0.96368\n",
      "  batch 029 / 029 | loss: 0.44837 | error: 0.49084 | utility: 0.95160\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 004 / 010 | time: 029 sec | loss: 0.44254 | error: 0.48646 | utility: 0.97488\n",
      "Starting epoch 005 / 010.\n",
      "  batch 001 / 029 | loss: 0.54679 | error: 0.53125 | utility: 0.96741\n",
      "  batch 002 / 029 | loss: 0.49758 | error: 0.50781 | utility: 0.96933\n",
      "  batch 003 / 029 | loss: 0.48513 | error: 0.50521 | utility: 0.96955\n",
      "  batch 004 / 029 | loss: 0.48000 | error: 0.50391 | utility: 0.96928\n",
      "  batch 005 / 029 | loss: 0.51351 | error: 0.52187 | utility: 0.97080\n",
      "  batch 006 / 029 | loss: 0.46660 | error: 0.50000 | utility: 0.96928\n",
      "  batch 007 / 029 | loss: 0.46801 | error: 0.50000 | utility: 0.97139\n",
      "  batch 008 / 029 | loss: 0.46786 | error: 0.50000 | utility: 0.97254\n",
      "  batch 009 / 029 | loss: 0.47467 | error: 0.50174 | utility: 0.97386\n",
      "  batch 010 / 029 | loss: 0.47331 | error: 0.50156 | utility: 0.97202\n",
      "  batch 011 / 029 | loss: 0.47381 | error: 0.50142 | utility: 0.97361\n",
      "  batch 012 / 029 | loss: 0.46719 | error: 0.49870 | utility: 0.97106\n",
      "  batch 013 / 029 | loss: 0.45208 | error: 0.49159 | utility: 0.96341\n",
      "  batch 014 / 029 | loss: 0.47333 | error: 0.50223 | utility: 0.96543\n",
      "  batch 015 / 029 | loss: 0.45972 | error: 0.49479 | utility: 0.96757\n",
      "  batch 016 / 029 | loss: 0.45381 | error: 0.49121 | utility: 0.96648\n",
      "  batch 017 / 029 | loss: 0.44926 | error: 0.48897 | utility: 0.96919\n",
      "  batch 018 / 029 | loss: 0.45154 | error: 0.49045 | utility: 0.96734\n",
      "  batch 019 / 029 | loss: 0.45588 | error: 0.49260 | utility: 0.96668\n",
      "  batch 020 / 029 | loss: 0.45278 | error: 0.49141 | utility: 0.96620\n",
      "  batch 021 / 029 | loss: 0.45401 | error: 0.49256 | utility: 0.96918\n",
      "  batch 022 / 029 | loss: 0.45054 | error: 0.49077 | utility: 0.96949\n",
      "  batch 023 / 029 | loss: 0.44639 | error: 0.48913 | utility: 0.95974\n",
      "  batch 024 / 029 | loss: 0.44955 | error: 0.49089 | utility: 0.96652\n",
      "  batch 025 / 029 | loss: 0.45087 | error: 0.49188 | utility: 0.96663\n",
      "  batch 026 / 029 | loss: 0.45429 | error: 0.49339 | utility: 0.96842\n",
      "  batch 027 / 029 | loss: 0.45243 | error: 0.49248 | utility: 0.96772\n",
      "  batch 028 / 029 | loss: 0.44795 | error: 0.48996 | utility: 0.96670\n",
      "  batch 029 / 029 | loss: 0.45477 | error: 0.49461 | utility: 0.96065\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 005 / 010 | time: 027 sec | loss: 0.42258 | error: 0.47865 | utility: 0.97369\n",
      "Validation accuracy improved.\n",
      "Saving model to ./Results/utility/utility_0.850_model.pt.\n",
      "Starting epoch 006 / 010.\n",
      "  batch 001 / 029 | loss: 0.44407 | error: 0.50000 | utility: 0.96693\n",
      "  batch 002 / 029 | loss: 0.54665 | error: 0.54688 | utility: 0.95668\n",
      "  batch 003 / 029 | loss: 0.50081 | error: 0.52083 | utility: 0.96604\n",
      "  batch 004 / 029 | loss: 0.54378 | error: 0.53906 | utility: 0.95801\n",
      "  batch 005 / 029 | loss: 0.50765 | error: 0.52187 | utility: 0.96052\n",
      "  batch 006 / 029 | loss: 0.48640 | error: 0.51042 | utility: 0.95682\n",
      "  batch 007 / 029 | loss: 0.47327 | error: 0.50446 | utility: 0.96048\n",
      "  batch 008 / 029 | loss: 0.47228 | error: 0.50391 | utility: 0.96334\n",
      "  batch 009 / 029 | loss: 0.45380 | error: 0.49479 | utility: 0.95950\n",
      "  batch 010 / 029 | loss: 0.44815 | error: 0.49219 | utility: 0.96809\n",
      "  batch 011 / 029 | loss: 0.45742 | error: 0.49574 | utility: 0.96950\n",
      "  batch 012 / 029 | loss: 0.43684 | error: 0.48568 | utility: 0.96591\n",
      "  batch 013 / 029 | loss: 0.44326 | error: 0.48918 | utility: 0.96383\n",
      "  batch 014 / 029 | loss: 0.44854 | error: 0.49219 | utility: 0.95630\n",
      "  batch 015 / 029 | loss: 0.44390 | error: 0.49062 | utility: 0.96867\n",
      "  batch 016 / 029 | loss: 0.45549 | error: 0.49512 | utility: 0.96536\n",
      "  batch 017 / 029 | loss: 0.46025 | error: 0.49724 | utility: 0.96749\n",
      "  batch 018 / 029 | loss: 0.45954 | error: 0.49740 | utility: 0.96869\n",
      "  batch 019 / 029 | loss: 0.46359 | error: 0.49918 | utility: 0.96433\n",
      "  batch 020 / 029 | loss: 0.47004 | error: 0.50234 | utility: 0.96502\n",
      "  batch 021 / 029 | loss: 0.46185 | error: 0.49851 | utility: 0.97035\n",
      "  batch 022 / 029 | loss: 0.45213 | error: 0.49361 | utility: 0.96853\n",
      "  batch 023 / 029 | loss: 0.44813 | error: 0.49185 | utility: 0.96709\n",
      "  batch 024 / 029 | loss: 0.44490 | error: 0.49023 | utility: 0.96718\n",
      "  batch 025 / 029 | loss: 0.44298 | error: 0.48875 | utility: 0.96957\n",
      "  batch 026 / 029 | loss: 0.43815 | error: 0.48618 | utility: 0.97008\n",
      "  batch 027 / 029 | loss: 0.44036 | error: 0.48727 | utility: 0.96945\n",
      "  batch 028 / 029 | loss: 0.44772 | error: 0.49107 | utility: 0.96269\n",
      "  batch 029 / 029 | loss: 0.44448 | error: 0.48707 | utility: 0.96499\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 006 / 010 | time: 026 sec | loss: 0.46673 | error: 0.50208 | utility: 0.97722\n",
      "Starting epoch 007 / 010.\n",
      "  batch 001 / 029 | loss: 0.50705 | error: 0.51562 | utility: 0.97327\n",
      "  batch 002 / 029 | loss: 0.57765 | error: 0.55469 | utility: 0.97563\n",
      "  batch 003 / 029 | loss: 0.59352 | error: 0.56250 | utility: 0.97762\n",
      "  batch 004 / 029 | loss: 0.54603 | error: 0.53906 | utility: 0.97732\n",
      "  batch 005 / 029 | loss: 0.49206 | error: 0.51250 | utility: 0.97843\n",
      "  batch 006 / 029 | loss: 0.48264 | error: 0.50781 | utility: 0.97864\n",
      "  batch 007 / 029 | loss: 0.45007 | error: 0.49107 | utility: 0.97920\n",
      "  batch 008 / 029 | loss: 0.46380 | error: 0.49805 | utility: 0.97937\n",
      "  batch 009 / 029 | loss: 0.45660 | error: 0.49479 | utility: 0.97849\n",
      "  batch 010 / 029 | loss: 0.44803 | error: 0.49062 | utility: 0.97928\n",
      "  batch 011 / 029 | loss: 0.44194 | error: 0.48722 | utility: 0.97833\n",
      "  batch 012 / 029 | loss: 0.43571 | error: 0.48438 | utility: 0.97559\n",
      "  batch 013 / 029 | loss: 0.42981 | error: 0.48197 | utility: 0.97596\n",
      "  batch 014 / 029 | loss: 0.42679 | error: 0.47991 | utility: 0.97560\n",
      "  batch 015 / 029 | loss: 0.42314 | error: 0.47813 | utility: 0.97462\n",
      "  batch 016 / 029 | loss: 0.43005 | error: 0.48242 | utility: 0.97274\n",
      "  batch 017 / 029 | loss: 0.42462 | error: 0.47978 | utility: 0.97259\n",
      "  batch 018 / 029 | loss: 0.42587 | error: 0.48003 | utility: 0.97115\n",
      "  batch 019 / 029 | loss: 0.43905 | error: 0.48684 | utility: 0.96835\n",
      "  batch 020 / 029 | loss: 0.44276 | error: 0.48828 | utility: 0.97102\n",
      "  batch 021 / 029 | loss: 0.44961 | error: 0.49182 | utility: 0.96817\n",
      "  batch 022 / 029 | loss: 0.45040 | error: 0.49219 | utility: 0.96766\n",
      "  batch 023 / 029 | loss: 0.45236 | error: 0.49321 | utility: 0.96897\n",
      "  batch 024 / 029 | loss: 0.45429 | error: 0.49414 | utility: 0.96912\n",
      "  batch 025 / 029 | loss: 0.45314 | error: 0.49312 | utility: 0.96208\n",
      "  batch 026 / 029 | loss: 0.44815 | error: 0.49099 | utility: 0.95939\n",
      "  batch 027 / 029 | loss: 0.44419 | error: 0.48900 | utility: 0.96988\n",
      "  batch 028 / 029 | loss: 0.44647 | error: 0.48996 | utility: 0.96506\n",
      "  batch 029 / 029 | loss: 0.45561 | error: 0.49461 | utility: 0.96628\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 007 / 010 | time: 027 sec | loss: 0.42811 | error: 0.47865 | utility: 0.97266\n",
      "Starting epoch 008 / 010.\n",
      "  batch 001 / 029 | loss: 0.51649 | error: 0.53125 | utility: 0.96689\n",
      "  batch 002 / 029 | loss: 0.41545 | error: 0.47656 | utility: 0.96793\n",
      "  batch 003 / 029 | loss: 0.44061 | error: 0.48438 | utility: 0.96729\n",
      "  batch 004 / 029 | loss: 0.35246 | error: 0.43750 | utility: 0.97005\n",
      "  batch 005 / 029 | loss: 0.38907 | error: 0.45937 | utility: 0.96086\n",
      "  batch 006 / 029 | loss: 0.43770 | error: 0.48438 | utility: 0.96407\n",
      "  batch 007 / 029 | loss: 0.46862 | error: 0.50000 | utility: 0.96560\n",
      "  batch 008 / 029 | loss: 0.47144 | error: 0.50195 | utility: 0.96819\n",
      "  batch 009 / 029 | loss: 0.47616 | error: 0.50521 | utility: 0.96765\n",
      "  batch 010 / 029 | loss: 0.46974 | error: 0.50156 | utility: 0.96785\n",
      "  batch 011 / 029 | loss: 0.48695 | error: 0.50994 | utility: 0.96868\n",
      "  batch 012 / 029 | loss: 0.49000 | error: 0.51172 | utility: 0.96837\n",
      "  batch 013 / 029 | loss: 0.47102 | error: 0.50120 | utility: 0.96922\n",
      "  batch 014 / 029 | loss: 0.46148 | error: 0.49665 | utility: 0.97147\n",
      "  batch 015 / 029 | loss: 0.46003 | error: 0.49583 | utility: 0.97220\n",
      "  batch 016 / 029 | loss: 0.46158 | error: 0.49707 | utility: 0.97230\n",
      "  batch 017 / 029 | loss: 0.47298 | error: 0.50276 | utility: 0.97177\n",
      "  batch 018 / 029 | loss: 0.48309 | error: 0.50781 | utility: 0.97125\n",
      "  batch 019 / 029 | loss: 0.47854 | error: 0.50576 | utility: 0.97097\n",
      "  batch 020 / 029 | loss: 0.47572 | error: 0.50391 | utility: 0.97162\n",
      "  batch 021 / 029 | loss: 0.46763 | error: 0.50000 | utility: 0.97233\n",
      "  batch 022 / 029 | loss: 0.45278 | error: 0.49290 | utility: 0.96458\n",
      "  batch 023 / 029 | loss: 0.45031 | error: 0.49185 | utility: 0.96522\n",
      "  batch 024 / 029 | loss: 0.44288 | error: 0.48828 | utility: 0.96986\n",
      "  batch 025 / 029 | loss: 0.44113 | error: 0.48750 | utility: 0.96529\n",
      "  batch 026 / 029 | loss: 0.43889 | error: 0.48678 | utility: 0.96472\n",
      "  batch 027 / 029 | loss: 0.44381 | error: 0.48900 | utility: 0.96261\n",
      "  batch 028 / 029 | loss: 0.44669 | error: 0.49051 | utility: 0.95023\n",
      "  batch 029 / 029 | loss: 0.44842 | error: 0.49084 | utility: 0.95798\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 008 / 010 | time: 028 sec | loss: 0.44611 | error: 0.49167 | utility: 0.97388\n",
      "Starting epoch 009 / 010.\n",
      "  batch 001 / 029 | loss: 0.42229 | error: 0.48438 | utility: 0.96478\n",
      "  batch 002 / 029 | loss: 0.49139 | error: 0.52344 | utility: 0.96268\n",
      "  batch 003 / 029 | loss: 0.44838 | error: 0.49479 | utility: 0.96552\n",
      "  batch 004 / 029 | loss: 0.39932 | error: 0.46875 | utility: 0.96463\n",
      "  batch 005 / 029 | loss: 0.46295 | error: 0.50000 | utility: 0.96420\n",
      "  batch 006 / 029 | loss: 0.44027 | error: 0.48958 | utility: 0.96794\n",
      "  batch 007 / 029 | loss: 0.42218 | error: 0.47991 | utility: 0.96827\n",
      "  batch 008 / 029 | loss: 0.43479 | error: 0.48633 | utility: 0.96622\n",
      "  batch 009 / 029 | loss: 0.42892 | error: 0.48438 | utility: 0.96962\n",
      "  batch 010 / 029 | loss: 0.44376 | error: 0.49062 | utility: 0.97000\n",
      "  batch 011 / 029 | loss: 0.42912 | error: 0.48153 | utility: 0.97176\n",
      "  batch 012 / 029 | loss: 0.42393 | error: 0.47917 | utility: 0.97241\n",
      "  batch 013 / 029 | loss: 0.42128 | error: 0.47716 | utility: 0.97293\n",
      "  batch 014 / 029 | loss: 0.42039 | error: 0.47656 | utility: 0.97362\n",
      "  batch 015 / 029 | loss: 0.41111 | error: 0.47187 | utility: 0.97717\n",
      "  batch 016 / 029 | loss: 0.42591 | error: 0.47949 | utility: 0.97529\n",
      "  batch 017 / 029 | loss: 0.42945 | error: 0.48162 | utility: 0.97616\n",
      "  batch 018 / 029 | loss: 0.43316 | error: 0.48351 | utility: 0.97717\n",
      "  batch 019 / 029 | loss: 0.43768 | error: 0.48602 | utility: 0.97605\n",
      "  batch 020 / 029 | loss: 0.43051 | error: 0.48281 | utility: 0.97680\n",
      "  batch 021 / 029 | loss: 0.42682 | error: 0.48065 | utility: 0.97467\n",
      "  batch 022 / 029 | loss: 0.43002 | error: 0.48224 | utility: 0.97024\n",
      "  batch 023 / 029 | loss: 0.42849 | error: 0.48166 | utility: 0.97271\n",
      "  batch 024 / 029 | loss: 0.42546 | error: 0.47982 | utility: 0.96907\n",
      "  batch 025 / 029 | loss: 0.42716 | error: 0.48063 | utility: 0.97324\n",
      "  batch 026 / 029 | loss: 0.43148 | error: 0.48317 | utility: 0.96900\n",
      "  batch 027 / 029 | loss: 0.43684 | error: 0.48553 | utility: 0.96955\n",
      "  batch 028 / 029 | loss: 0.44754 | error: 0.49107 | utility: 0.96761\n",
      "  batch 029 / 029 | loss: 0.43870 | error: 0.48707 | utility: 0.97139\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 009 / 010 | time: 029 sec | loss: 0.43952 | error: 0.48646 | utility: 0.97096\n",
      "Ending training due to 4 consecutive epochs without improvement in validation accuracy.\n",
      "Total training time: 4 minutes (264.6761064529419 seconds).\n",
      "Loading model from ./Results/utility/utility_0.850_model.pt.\n",
      "---------- Training with lambda=0.9000000000000001 ----------\n",
      "Starting epoch 001 / 010.\n",
      "  batch 001 / 029 | loss: 0.47732 | error: 0.40625 | utility: 0.93142\n",
      "  batch 002 / 029 | loss: 0.45039 | error: 0.40625 | utility: 0.93357\n",
      "  batch 003 / 029 | loss: 0.48981 | error: 0.44792 | utility: 0.94069\n",
      "  batch 004 / 029 | loss: 0.47354 | error: 0.45312 | utility: 0.94505\n",
      "  batch 005 / 029 | loss: 0.45260 | error: 0.45312 | utility: 0.94746\n",
      "  batch 006 / 029 | loss: 0.45343 | error: 0.45833 | utility: 0.94604\n",
      "  batch 007 / 029 | loss: 0.46466 | error: 0.46875 | utility: 0.94450\n",
      "  batch 008 / 029 | loss: 0.48201 | error: 0.48047 | utility: 0.94120\n",
      "  batch 009 / 029 | loss: 0.50828 | error: 0.49653 | utility: 0.94567\n",
      "  batch 010 / 029 | loss: 0.50089 | error: 0.49531 | utility: 0.94885\n",
      "  batch 011 / 029 | loss: 0.48489 | error: 0.49006 | utility: 0.95498\n",
      "  batch 012 / 029 | loss: 0.50154 | error: 0.49870 | utility: 0.94944\n",
      "  batch 013 / 029 | loss: 0.49240 | error: 0.49639 | utility: 0.93411\n",
      "  batch 014 / 029 | loss: 0.49546 | error: 0.50000 | utility: 0.95186\n",
      "  batch 015 / 029 | loss: 0.48318 | error: 0.49479 | utility: 0.94767\n",
      "  batch 016 / 029 | loss: 0.48063 | error: 0.49316 | utility: 0.95621\n",
      "  batch 017 / 029 | loss: 0.47725 | error: 0.49357 | utility: 0.94382\n",
      "  batch 018 / 029 | loss: 0.48586 | error: 0.49913 | utility: 0.95248\n",
      "  batch 019 / 029 | loss: 0.49168 | error: 0.50329 | utility: 0.95303\n",
      "  batch 020 / 029 | loss: 0.49464 | error: 0.50625 | utility: 0.95923\n",
      "  batch 021 / 029 | loss: 0.48365 | error: 0.50149 | utility: 0.96461\n",
      "  batch 022 / 029 | loss: 0.46885 | error: 0.49503 | utility: 0.96304\n",
      "  batch 023 / 029 | loss: 0.46468 | error: 0.49389 | utility: 0.95437\n",
      "  batch 024 / 029 | loss: 0.46342 | error: 0.49414 | utility: 0.96498\n",
      "  batch 025 / 029 | loss: 0.45965 | error: 0.49250 | utility: 0.96733\n",
      "  batch 026 / 029 | loss: 0.45621 | error: 0.49099 | utility: 0.96842\n",
      "  batch 027 / 029 | loss: 0.45529 | error: 0.49074 | utility: 0.96961\n",
      "  batch 028 / 029 | loss: 0.45299 | error: 0.49051 | utility: 0.97329\n",
      "  batch 029 / 029 | loss: 0.45134 | error: 0.49084 | utility: 0.97434\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 001 / 010 | time: 036 sec | loss: 0.42734 | error: 0.49688 | utility: 0.97944\n",
      "Saving model to ./Results/utility/utility_0.900_model.pt.\n",
      "Starting epoch 002 / 010.\n",
      "  batch 001 / 029 | loss: 0.50629 | error: 0.53125 | utility: 0.97283\n",
      "  batch 002 / 029 | loss: 0.48373 | error: 0.52344 | utility: 0.97477\n",
      "  batch 003 / 029 | loss: 0.49140 | error: 0.52604 | utility: 0.97407\n",
      "  batch 004 / 029 | loss: 0.46370 | error: 0.51172 | utility: 0.97643\n",
      "  batch 005 / 029 | loss: 0.46344 | error: 0.51250 | utility: 0.97543\n",
      "  batch 006 / 029 | loss: 0.45200 | error: 0.50781 | utility: 0.97577\n",
      "  batch 007 / 029 | loss: 0.47066 | error: 0.51786 | utility: 0.97446\n",
      "  batch 008 / 029 | loss: 0.43845 | error: 0.50195 | utility: 0.97616\n",
      "  batch 009 / 029 | loss: 0.41724 | error: 0.49132 | utility: 0.97510\n",
      "  batch 010 / 029 | loss: 0.39455 | error: 0.47969 | utility: 0.97414\n",
      "  batch 011 / 029 | loss: 0.38991 | error: 0.47727 | utility: 0.97562\n",
      "  batch 012 / 029 | loss: 0.40283 | error: 0.48438 | utility: 0.97209\n",
      "  batch 013 / 029 | loss: 0.40923 | error: 0.48798 | utility: 0.97094\n",
      "  batch 014 / 029 | loss: 0.41811 | error: 0.49107 | utility: 0.97209\n",
      "  batch 015 / 029 | loss: 0.39915 | error: 0.48125 | utility: 0.97479\n",
      "  batch 016 / 029 | loss: 0.39299 | error: 0.47852 | utility: 0.96853\n",
      "  batch 017 / 029 | loss: 0.39152 | error: 0.47794 | utility: 0.97322\n",
      "  batch 018 / 029 | loss: 0.39412 | error: 0.47917 | utility: 0.97458\n",
      "  batch 019 / 029 | loss: 0.40371 | error: 0.48438 | utility: 0.97052\n",
      "  batch 020 / 029 | loss: 0.39644 | error: 0.48047 | utility: 0.97115\n",
      "  batch 021 / 029 | loss: 0.41489 | error: 0.48884 | utility: 0.97305\n",
      "  batch 022 / 029 | loss: 0.41564 | error: 0.48935 | utility: 0.97245\n",
      "  batch 023 / 029 | loss: 0.41361 | error: 0.48845 | utility: 0.97603\n",
      "  batch 024 / 029 | loss: 0.41219 | error: 0.48763 | utility: 0.97452\n",
      "  batch 025 / 029 | loss: 0.41892 | error: 0.49125 | utility: 0.97326\n",
      "  batch 026 / 029 | loss: 0.41556 | error: 0.48978 | utility: 0.97319\n",
      "  batch 027 / 029 | loss: 0.41715 | error: 0.49074 | utility: 0.97296\n",
      "  batch 028 / 029 | loss: 0.41675 | error: 0.49051 | utility: 0.97481\n",
      "  batch 029 / 029 | loss: 0.41630 | error: 0.49084 | utility: 0.97291\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 002 / 010 | time: 025 sec | loss: 0.41474 | error: 0.49167 | utility: 0.97691\n",
      "Validation accuracy improved.\n",
      "Saving model to ./Results/utility/utility_0.900_model.pt.\n",
      "Starting epoch 003 / 010.\n",
      "  batch 001 / 029 | loss: 0.64606 | error: 0.60938 | utility: 0.97050\n",
      "  batch 002 / 029 | loss: 0.50790 | error: 0.53906 | utility: 0.96904\n",
      "  batch 003 / 029 | loss: 0.45578 | error: 0.51562 | utility: 0.96996\n",
      "  batch 004 / 029 | loss: 0.42925 | error: 0.50000 | utility: 0.96954\n",
      "  batch 005 / 029 | loss: 0.42844 | error: 0.50000 | utility: 0.96595\n",
      "  batch 006 / 029 | loss: 0.45335 | error: 0.51302 | utility: 0.96600\n",
      "  batch 007 / 029 | loss: 0.42159 | error: 0.49777 | utility: 0.96640\n",
      "  batch 008 / 029 | loss: 0.44468 | error: 0.50781 | utility: 0.96440\n",
      "  batch 009 / 029 | loss: 0.43055 | error: 0.50174 | utility: 0.96036\n",
      "  batch 010 / 029 | loss: 0.42690 | error: 0.50000 | utility: 0.95948\n",
      "  batch 011 / 029 | loss: 0.43856 | error: 0.50568 | utility: 0.95998\n",
      "  batch 012 / 029 | loss: 0.44242 | error: 0.50651 | utility: 0.95986\n",
      "  batch 013 / 029 | loss: 0.45445 | error: 0.51322 | utility: 0.94416\n",
      "  batch 014 / 029 | loss: 0.43889 | error: 0.50558 | utility: 0.96501\n",
      "  batch 015 / 029 | loss: 0.43395 | error: 0.50208 | utility: 0.95860\n",
      "  batch 016 / 029 | loss: 0.43884 | error: 0.50391 | utility: 0.96326\n",
      "  batch 017 / 029 | loss: 0.43545 | error: 0.50184 | utility: 0.96628\n",
      "  batch 018 / 029 | loss: 0.43706 | error: 0.50174 | utility: 0.95994\n",
      "  batch 019 / 029 | loss: 0.44776 | error: 0.50658 | utility: 0.96771\n",
      "  batch 020 / 029 | loss: 0.44128 | error: 0.50313 | utility: 0.97217\n",
      "  batch 021 / 029 | loss: 0.43626 | error: 0.50074 | utility: 0.96787\n",
      "  batch 022 / 029 | loss: 0.43519 | error: 0.50000 | utility: 0.97128\n",
      "  batch 023 / 029 | loss: 0.42829 | error: 0.49660 | utility: 0.97410\n",
      "  batch 024 / 029 | loss: 0.43248 | error: 0.49870 | utility: 0.97255\n",
      "  batch 025 / 029 | loss: 0.42327 | error: 0.49375 | utility: 0.97369\n",
      "  batch 026 / 029 | loss: 0.42590 | error: 0.49519 | utility: 0.97406\n",
      "  batch 027 / 029 | loss: 0.42254 | error: 0.49363 | utility: 0.97527\n",
      "  batch 028 / 029 | loss: 0.41683 | error: 0.49107 | utility: 0.97541\n",
      "  batch 029 / 029 | loss: 0.40770 | error: 0.48707 | utility: 0.97623\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 003 / 010 | time: 025 sec | loss: 0.39616 | error: 0.48125 | utility: 0.98081\n",
      "Validation accuracy improved.\n",
      "Saving model to ./Results/utility/utility_0.900_model.pt.\n",
      "Starting epoch 004 / 010.\n",
      "  batch 001 / 029 | loss: 0.49971 | error: 0.53125 | utility: 0.97538\n",
      "  batch 002 / 029 | loss: 0.44152 | error: 0.50000 | utility: 0.97551\n",
      "  batch 003 / 029 | loss: 0.37054 | error: 0.46875 | utility: 0.97514\n",
      "  batch 004 / 029 | loss: 0.32918 | error: 0.44922 | utility: 0.97508\n",
      "  batch 005 / 029 | loss: 0.34133 | error: 0.45312 | utility: 0.97495\n",
      "  batch 006 / 029 | loss: 0.35478 | error: 0.46094 | utility: 0.97334\n",
      "  batch 007 / 029 | loss: 0.36535 | error: 0.46652 | utility: 0.97465\n",
      "  batch 008 / 029 | loss: 0.36316 | error: 0.46484 | utility: 0.97087\n",
      "  batch 009 / 029 | loss: 0.39005 | error: 0.47569 | utility: 0.96981\n",
      "  batch 010 / 029 | loss: 0.36988 | error: 0.46719 | utility: 0.97335\n",
      "  batch 011 / 029 | loss: 0.37860 | error: 0.47159 | utility: 0.97076\n",
      "  batch 012 / 029 | loss: 0.39799 | error: 0.48047 | utility: 0.97034\n",
      "  batch 013 / 029 | loss: 0.38881 | error: 0.47716 | utility: 0.97224\n",
      "  batch 014 / 029 | loss: 0.38905 | error: 0.47768 | utility: 0.96967\n",
      "  batch 015 / 029 | loss: 0.38911 | error: 0.47813 | utility: 0.97187\n",
      "  batch 016 / 029 | loss: 0.40038 | error: 0.48340 | utility: 0.96699\n",
      "  batch 017 / 029 | loss: 0.41196 | error: 0.48897 | utility: 0.96796\n",
      "  batch 018 / 029 | loss: 0.41228 | error: 0.48872 | utility: 0.96559\n",
      "  batch 019 / 029 | loss: 0.41481 | error: 0.49013 | utility: 0.96605\n",
      "  batch 020 / 029 | loss: 0.41336 | error: 0.48906 | utility: 0.96488\n",
      "  batch 021 / 029 | loss: 0.40988 | error: 0.48735 | utility: 0.96810\n",
      "  batch 022 / 029 | loss: 0.41083 | error: 0.48722 | utility: 0.96210\n",
      "  batch 023 / 029 | loss: 0.41517 | error: 0.48913 | utility: 0.96467\n",
      "  batch 024 / 029 | loss: 0.41880 | error: 0.49089 | utility: 0.96798\n",
      "  batch 025 / 029 | loss: 0.41463 | error: 0.48875 | utility: 0.97000\n",
      "  batch 026 / 029 | loss: 0.41801 | error: 0.49099 | utility: 0.97135\n",
      "  batch 027 / 029 | loss: 0.41795 | error: 0.49074 | utility: 0.96903\n",
      "  batch 028 / 029 | loss: 0.41767 | error: 0.49051 | utility: 0.96815\n",
      "  batch 029 / 029 | loss: 0.41797 | error: 0.49084 | utility: 0.96047\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 004 / 010 | time: 025 sec | loss: 0.41069 | error: 0.48646 | utility: 0.97729\n",
      "Starting epoch 005 / 010.\n",
      "  batch 001 / 029 | loss: 0.51365 | error: 0.53125 | utility: 0.97142\n",
      "  batch 002 / 029 | loss: 0.46403 | error: 0.50781 | utility: 0.97305\n",
      "  batch 003 / 029 | loss: 0.45257 | error: 0.50521 | utility: 0.97334\n",
      "  batch 004 / 029 | loss: 0.44771 | error: 0.50391 | utility: 0.97332\n",
      "  batch 005 / 029 | loss: 0.48259 | error: 0.52187 | utility: 0.97430\n",
      "  batch 006 / 029 | loss: 0.43525 | error: 0.50000 | utility: 0.97311\n",
      "  batch 007 / 029 | loss: 0.43677 | error: 0.50000 | utility: 0.97424\n",
      "  batch 008 / 029 | loss: 0.43681 | error: 0.50000 | utility: 0.97493\n",
      "  batch 009 / 029 | loss: 0.44374 | error: 0.50174 | utility: 0.97592\n",
      "  batch 010 / 029 | loss: 0.44236 | error: 0.50156 | utility: 0.97410\n",
      "  batch 011 / 029 | loss: 0.44293 | error: 0.50142 | utility: 0.97550\n",
      "  batch 012 / 029 | loss: 0.43615 | error: 0.49870 | utility: 0.97281\n",
      "  batch 013 / 029 | loss: 0.42099 | error: 0.49159 | utility: 0.96726\n",
      "  batch 014 / 029 | loss: 0.44243 | error: 0.50223 | utility: 0.96744\n",
      "  batch 015 / 029 | loss: 0.42873 | error: 0.49479 | utility: 0.96940\n",
      "  batch 016 / 029 | loss: 0.42280 | error: 0.49121 | utility: 0.96833\n",
      "  batch 017 / 029 | loss: 0.41829 | error: 0.48897 | utility: 0.97075\n",
      "  batch 018 / 029 | loss: 0.42052 | error: 0.49045 | utility: 0.96904\n",
      "  batch 019 / 029 | loss: 0.42487 | error: 0.49260 | utility: 0.96840\n",
      "  batch 020 / 029 | loss: 0.42173 | error: 0.49141 | utility: 0.96821\n",
      "  batch 021 / 029 | loss: 0.42302 | error: 0.49256 | utility: 0.97058\n",
      "  batch 022 / 029 | loss: 0.41953 | error: 0.49077 | utility: 0.97119\n",
      "  batch 023 / 029 | loss: 0.41542 | error: 0.48913 | utility: 0.96416\n",
      "  batch 024 / 029 | loss: 0.41866 | error: 0.49089 | utility: 0.96897\n",
      "  batch 025 / 029 | loss: 0.41995 | error: 0.49188 | utility: 0.96897\n",
      "  batch 026 / 029 | loss: 0.42343 | error: 0.49339 | utility: 0.97041\n",
      "  batch 027 / 029 | loss: 0.42147 | error: 0.49248 | utility: 0.97021\n",
      "  batch 028 / 029 | loss: 0.41703 | error: 0.48996 | utility: 0.96923\n",
      "  batch 029 / 029 | loss: 0.42433 | error: 0.49461 | utility: 0.96473\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 005 / 010 | time: 025 sec | loss: 0.39161 | error: 0.47865 | utility: 0.97563\n",
      "Validation accuracy improved.\n",
      "Saving model to ./Results/utility/utility_0.900_model.pt.\n",
      "Starting epoch 006 / 010.\n",
      "  batch 001 / 029 | loss: 0.41516 | error: 0.50000 | utility: 0.96982\n",
      "  batch 002 / 029 | loss: 0.51715 | error: 0.54688 | utility: 0.96181\n",
      "  batch 003 / 029 | loss: 0.47039 | error: 0.52083 | utility: 0.96906\n",
      "  batch 004 / 029 | loss: 0.51329 | error: 0.53906 | utility: 0.96297\n",
      "  batch 005 / 029 | loss: 0.47727 | error: 0.52187 | utility: 0.96474\n",
      "  batch 006 / 029 | loss: 0.45522 | error: 0.51042 | utility: 0.96188\n",
      "  batch 007 / 029 | loss: 0.44155 | error: 0.50446 | utility: 0.96553\n",
      "  batch 008 / 029 | loss: 0.44079 | error: 0.50391 | utility: 0.96751\n",
      "  batch 009 / 029 | loss: 0.42189 | error: 0.49479 | utility: 0.96529\n",
      "  batch 010 / 029 | loss: 0.41644 | error: 0.49219 | utility: 0.97147\n",
      "  batch 011 / 029 | loss: 0.42604 | error: 0.49574 | utility: 0.97256\n",
      "  batch 012 / 029 | loss: 0.40505 | error: 0.48568 | utility: 0.96980\n",
      "  batch 013 / 029 | loss: 0.41167 | error: 0.48918 | utility: 0.96788\n",
      "  batch 014 / 029 | loss: 0.41731 | error: 0.49219 | utility: 0.96339\n",
      "  batch 015 / 029 | loss: 0.41281 | error: 0.49062 | utility: 0.97166\n",
      "  batch 016 / 029 | loss: 0.42434 | error: 0.49512 | utility: 0.96859\n",
      "  batch 017 / 029 | loss: 0.42925 | error: 0.49724 | utility: 0.97028\n",
      "  batch 018 / 029 | loss: 0.42865 | error: 0.49740 | utility: 0.97173\n",
      "  batch 019 / 029 | loss: 0.43275 | error: 0.49918 | utility: 0.96755\n",
      "  batch 020 / 029 | loss: 0.43936 | error: 0.50234 | utility: 0.96866\n",
      "  batch 021 / 029 | loss: 0.43110 | error: 0.49851 | utility: 0.97275\n",
      "  batch 022 / 029 | loss: 0.42126 | error: 0.49361 | utility: 0.97106\n",
      "  batch 023 / 029 | loss: 0.41727 | error: 0.49185 | utility: 0.97081\n",
      "  batch 024 / 029 | loss: 0.41399 | error: 0.49023 | utility: 0.96954\n",
      "  batch 025 / 029 | loss: 0.41198 | error: 0.48875 | utility: 0.97164\n",
      "  batch 026 / 029 | loss: 0.40709 | error: 0.48618 | utility: 0.97220\n",
      "  batch 027 / 029 | loss: 0.40936 | error: 0.48727 | utility: 0.97163\n",
      "  batch 028 / 029 | loss: 0.41687 | error: 0.49107 | utility: 0.96727\n",
      "  batch 029 / 029 | loss: 0.41310 | error: 0.48707 | utility: 0.96736\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 006 / 010 | time: 024 sec | loss: 0.43680 | error: 0.50208 | utility: 0.97870\n",
      "Starting epoch 007 / 010.\n",
      "  batch 001 / 029 | loss: 0.47663 | error: 0.51562 | utility: 0.97517\n",
      "  batch 002 / 029 | loss: 0.54953 | error: 0.55469 | utility: 0.97731\n",
      "  batch 003 / 029 | loss: 0.56579 | error: 0.56250 | utility: 0.97921\n",
      "  batch 004 / 029 | loss: 0.51751 | error: 0.53906 | utility: 0.97900\n",
      "  batch 005 / 029 | loss: 0.46283 | error: 0.51250 | utility: 0.97980\n",
      "  batch 006 / 029 | loss: 0.45360 | error: 0.50781 | utility: 0.97984\n",
      "  batch 007 / 029 | loss: 0.42042 | error: 0.49107 | utility: 0.98019\n",
      "  batch 008 / 029 | loss: 0.43402 | error: 0.49805 | utility: 0.98005\n",
      "  batch 009 / 029 | loss: 0.42682 | error: 0.49479 | utility: 0.97921\n",
      "  batch 010 / 029 | loss: 0.41809 | error: 0.49062 | utility: 0.97992\n",
      "  batch 011 / 029 | loss: 0.41189 | error: 0.48722 | utility: 0.97917\n",
      "  batch 012 / 029 | loss: 0.40565 | error: 0.48438 | utility: 0.97633\n",
      "  batch 013 / 029 | loss: 0.39980 | error: 0.48197 | utility: 0.97672\n",
      "  batch 014 / 029 | loss: 0.39674 | error: 0.47991 | utility: 0.97614\n",
      "  batch 015 / 029 | loss: 0.39296 | error: 0.47813 | utility: 0.97518\n",
      "  batch 016 / 029 | loss: 0.39994 | error: 0.48242 | utility: 0.97343\n",
      "  batch 017 / 029 | loss: 0.39437 | error: 0.47978 | utility: 0.97333\n",
      "  batch 018 / 029 | loss: 0.39556 | error: 0.48003 | utility: 0.97198\n",
      "  batch 019 / 029 | loss: 0.40885 | error: 0.48684 | utility: 0.96936\n",
      "  batch 020 / 029 | loss: 0.41255 | error: 0.48828 | utility: 0.97180\n",
      "  batch 021 / 029 | loss: 0.41946 | error: 0.49182 | utility: 0.96931\n",
      "  batch 022 / 029 | loss: 0.42030 | error: 0.49219 | utility: 0.96911\n",
      "  batch 023 / 029 | loss: 0.42230 | error: 0.49321 | utility: 0.97055\n",
      "  batch 024 / 029 | loss: 0.42422 | error: 0.49414 | utility: 0.97089\n",
      "  batch 025 / 029 | loss: 0.42302 | error: 0.49312 | utility: 0.96557\n",
      "  batch 026 / 029 | loss: 0.41791 | error: 0.49099 | utility: 0.96336\n",
      "  batch 027 / 029 | loss: 0.41386 | error: 0.48900 | utility: 0.97223\n",
      "  batch 028 / 029 | loss: 0.41617 | error: 0.48996 | utility: 0.96843\n",
      "  batch 029 / 029 | loss: 0.42548 | error: 0.49461 | utility: 0.96954\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 007 / 010 | time: 025 sec | loss: 0.39376 | error: 0.47865 | utility: 0.97596\n",
      "Starting epoch 008 / 010.\n",
      "  batch 001 / 029 | loss: 0.48902 | error: 0.53125 | utility: 0.97050\n",
      "  batch 002 / 029 | loss: 0.38416 | error: 0.47656 | utility: 0.97143\n",
      "  batch 003 / 029 | loss: 0.40901 | error: 0.48438 | utility: 0.97088\n",
      "  batch 004 / 029 | loss: 0.31762 | error: 0.43750 | utility: 0.97336\n",
      "  batch 005 / 029 | loss: 0.35598 | error: 0.45937 | utility: 0.96624\n",
      "  batch 006 / 029 | loss: 0.40610 | error: 0.48438 | utility: 0.96876\n",
      "  batch 007 / 029 | loss: 0.43772 | error: 0.50000 | utility: 0.96987\n",
      "  batch 008 / 029 | loss: 0.44056 | error: 0.50195 | utility: 0.97182\n",
      "  batch 009 / 029 | loss: 0.44562 | error: 0.50521 | utility: 0.97127\n",
      "  batch 010 / 029 | loss: 0.43897 | error: 0.50156 | utility: 0.97132\n",
      "  batch 011 / 029 | loss: 0.45654 | error: 0.50994 | utility: 0.97188\n",
      "  batch 012 / 029 | loss: 0.45982 | error: 0.51172 | utility: 0.97128\n",
      "  batch 013 / 029 | loss: 0.44044 | error: 0.50120 | utility: 0.97175\n",
      "  batch 014 / 029 | loss: 0.43092 | error: 0.49665 | utility: 0.97337\n",
      "  batch 015 / 029 | loss: 0.42938 | error: 0.49583 | utility: 0.97397\n",
      "  batch 016 / 029 | loss: 0.43091 | error: 0.49707 | utility: 0.97417\n",
      "  batch 017 / 029 | loss: 0.44219 | error: 0.50276 | utility: 0.97330\n",
      "  batch 018 / 029 | loss: 0.45224 | error: 0.50781 | utility: 0.97264\n",
      "  batch 019 / 029 | loss: 0.44768 | error: 0.50576 | utility: 0.97268\n",
      "  batch 020 / 029 | loss: 0.44485 | error: 0.50391 | utility: 0.97271\n",
      "  batch 021 / 029 | loss: 0.43669 | error: 0.50000 | utility: 0.97354\n",
      "  batch 022 / 029 | loss: 0.42182 | error: 0.49290 | utility: 0.96716\n",
      "  batch 023 / 029 | loss: 0.41943 | error: 0.49185 | utility: 0.96801\n",
      "  batch 024 / 029 | loss: 0.41189 | error: 0.48828 | utility: 0.97118\n",
      "  batch 025 / 029 | loss: 0.41015 | error: 0.48750 | utility: 0.96726\n",
      "  batch 026 / 029 | loss: 0.40794 | error: 0.48678 | utility: 0.96726\n",
      "  batch 027 / 029 | loss: 0.41296 | error: 0.48900 | utility: 0.96473\n",
      "  batch 028 / 029 | loss: 0.41593 | error: 0.49051 | utility: 0.95602\n",
      "  batch 029 / 029 | loss: 0.41765 | error: 0.49084 | utility: 0.96004\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 008 / 010 | time: 025 sec | loss: 0.41466 | error: 0.49167 | utility: 0.97613\n",
      "Starting epoch 009 / 010.\n",
      "  batch 001 / 029 | loss: 0.39309 | error: 0.48438 | utility: 0.96756\n",
      "  batch 002 / 029 | loss: 0.46360 | error: 0.52344 | utility: 0.96546\n",
      "  batch 003 / 029 | loss: 0.41833 | error: 0.49479 | utility: 0.96838\n",
      "  batch 004 / 029 | loss: 0.36748 | error: 0.46875 | utility: 0.96787\n",
      "  batch 005 / 029 | loss: 0.43258 | error: 0.50000 | utility: 0.96753\n",
      "  batch 006 / 029 | loss: 0.40957 | error: 0.48958 | utility: 0.97079\n",
      "  batch 007 / 029 | loss: 0.39101 | error: 0.47991 | utility: 0.97121\n",
      "  batch 008 / 029 | loss: 0.40392 | error: 0.48633 | utility: 0.96961\n",
      "  batch 009 / 029 | loss: 0.39790 | error: 0.48438 | utility: 0.97250\n",
      "  batch 010 / 029 | loss: 0.41322 | error: 0.49062 | utility: 0.97300\n",
      "  batch 011 / 029 | loss: 0.39796 | error: 0.48153 | utility: 0.97445\n",
      "  batch 012 / 029 | loss: 0.39262 | error: 0.47917 | utility: 0.97546\n",
      "  batch 013 / 029 | loss: 0.38974 | error: 0.47716 | utility: 0.97560\n",
      "  batch 014 / 029 | loss: 0.38874 | error: 0.47656 | utility: 0.97622\n",
      "  batch 015 / 029 | loss: 0.37919 | error: 0.47187 | utility: 0.97905\n",
      "  batch 016 / 029 | loss: 0.39445 | error: 0.47949 | utility: 0.97733\n",
      "  batch 017 / 029 | loss: 0.39819 | error: 0.48162 | utility: 0.97793\n",
      "  batch 018 / 029 | loss: 0.40209 | error: 0.48351 | utility: 0.97854\n",
      "  batch 019 / 029 | loss: 0.40668 | error: 0.48602 | utility: 0.97724\n",
      "  batch 020 / 029 | loss: 0.39947 | error: 0.48281 | utility: 0.97762\n",
      "  batch 021 / 029 | loss: 0.39582 | error: 0.48065 | utility: 0.97544\n",
      "  batch 022 / 029 | loss: 0.39911 | error: 0.48224 | utility: 0.97145\n",
      "  batch 023 / 029 | loss: 0.39769 | error: 0.48166 | utility: 0.97324\n",
      "  batch 024 / 029 | loss: 0.39478 | error: 0.47982 | utility: 0.96980\n",
      "  batch 025 / 029 | loss: 0.39648 | error: 0.48063 | utility: 0.97368\n",
      "  batch 026 / 029 | loss: 0.40085 | error: 0.48317 | utility: 0.96924\n",
      "  batch 027 / 029 | loss: 0.40629 | error: 0.48553 | utility: 0.97030\n",
      "  batch 028 / 029 | loss: 0.41712 | error: 0.49107 | utility: 0.96822\n",
      "  batch 029 / 029 | loss: 0.40821 | error: 0.48707 | utility: 0.97220\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 009 / 010 | time: 025 sec | loss: 0.40963 | error: 0.48646 | utility: 0.97220\n",
      "Ending training due to 4 consecutive epochs without improvement in validation accuracy.\n",
      "Total training time: 4 minutes (235.0701401233673 seconds).\n",
      "Loading model from ./Results/utility/utility_0.900_model.pt.\n",
      "---------- Training with lambda=0.9500000000000001 ----------\n",
      "Starting epoch 001 / 010.\n",
      "  batch 001 / 029 | loss: 0.45525 | error: 0.40625 | utility: 0.93142\n",
      "  batch 002 / 029 | loss: 0.42743 | error: 0.40625 | utility: 0.93357\n",
      "  batch 003 / 029 | loss: 0.46593 | error: 0.44792 | utility: 0.94064\n",
      "  batch 004 / 029 | loss: 0.44867 | error: 0.45312 | utility: 0.94506\n",
      "  batch 005 / 029 | loss: 0.42680 | error: 0.45312 | utility: 0.94744\n",
      "  batch 006 / 029 | loss: 0.42690 | error: 0.45833 | utility: 0.94606\n",
      "  batch 007 / 029 | loss: 0.43777 | error: 0.46875 | utility: 0.94456\n",
      "  batch 008 / 029 | loss: 0.45485 | error: 0.48047 | utility: 0.94139\n",
      "  batch 009 / 029 | loss: 0.48086 | error: 0.49653 | utility: 0.94594\n",
      "  batch 010 / 029 | loss: 0.47306 | error: 0.49531 | utility: 0.94919\n",
      "  batch 011 / 029 | loss: 0.45670 | error: 0.49006 | utility: 0.95539\n",
      "  batch 012 / 029 | loss: 0.47313 | error: 0.49870 | utility: 0.95040\n",
      "  batch 013 / 029 | loss: 0.46375 | error: 0.49639 | utility: 0.93647\n",
      "  batch 014 / 029 | loss: 0.46673 | error: 0.50000 | utility: 0.95311\n",
      "  batch 015 / 029 | loss: 0.45423 | error: 0.49479 | utility: 0.94911\n",
      "  batch 016 / 029 | loss: 0.45142 | error: 0.49316 | utility: 0.95766\n",
      "  batch 017 / 029 | loss: 0.44803 | error: 0.49357 | utility: 0.94600\n",
      "  batch 018 / 029 | loss: 0.45669 | error: 0.49913 | utility: 0.95443\n",
      "  batch 019 / 029 | loss: 0.46262 | error: 0.50329 | utility: 0.95511\n",
      "  batch 020 / 029 | loss: 0.46568 | error: 0.50625 | utility: 0.96141\n",
      "  batch 021 / 029 | loss: 0.45443 | error: 0.50149 | utility: 0.96649\n",
      "  batch 022 / 029 | loss: 0.43932 | error: 0.49503 | utility: 0.96508\n",
      "  batch 023 / 029 | loss: 0.43505 | error: 0.49389 | utility: 0.95755\n",
      "  batch 024 / 029 | loss: 0.43381 | error: 0.49414 | utility: 0.96737\n",
      "  batch 025 / 029 | loss: 0.42986 | error: 0.49250 | utility: 0.96966\n",
      "  batch 026 / 029 | loss: 0.42624 | error: 0.49099 | utility: 0.97069\n",
      "  batch 027 / 029 | loss: 0.42522 | error: 0.49074 | utility: 0.97189\n",
      "  batch 028 / 029 | loss: 0.42291 | error: 0.49051 | utility: 0.97531\n",
      "  batch 029 / 029 | loss: 0.42119 | error: 0.49084 | utility: 0.97619\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 001 / 010 | time: 025 sec | loss: 0.39630 | error: 0.49688 | utility: 0.98108\n",
      "Saving model to ./Results/utility/utility_0.950_model.pt.\n",
      "Starting epoch 002 / 010.\n",
      "  batch 001 / 029 | loss: 0.47617 | error: 0.53125 | utility: 0.97490\n",
      "  batch 002 / 029 | loss: 0.45385 | error: 0.52344 | utility: 0.97665\n",
      "  batch 003 / 029 | loss: 0.46138 | error: 0.52604 | utility: 0.97586\n",
      "  batch 004 / 029 | loss: 0.43348 | error: 0.51172 | utility: 0.97806\n",
      "  batch 005 / 029 | loss: 0.43303 | error: 0.51250 | utility: 0.97691\n",
      "  batch 006 / 029 | loss: 0.42174 | error: 0.50781 | utility: 0.97738\n",
      "  batch 007 / 029 | loss: 0.44078 | error: 0.51786 | utility: 0.97604\n",
      "  batch 008 / 029 | loss: 0.40792 | error: 0.50195 | utility: 0.97749\n",
      "  batch 009 / 029 | loss: 0.38622 | error: 0.49132 | utility: 0.97657\n",
      "  batch 010 / 029 | loss: 0.36321 | error: 0.47969 | utility: 0.97542\n",
      "  batch 011 / 029 | loss: 0.35844 | error: 0.47727 | utility: 0.97672\n",
      "  batch 012 / 029 | loss: 0.37157 | error: 0.48438 | utility: 0.97337\n",
      "  batch 013 / 029 | loss: 0.37822 | error: 0.48798 | utility: 0.97287\n",
      "  batch 014 / 029 | loss: 0.38728 | error: 0.49107 | utility: 0.97321\n",
      "  batch 015 / 029 | loss: 0.36794 | error: 0.48125 | utility: 0.97614\n",
      "  batch 016 / 029 | loss: 0.36176 | error: 0.47852 | utility: 0.97145\n",
      "  batch 017 / 029 | loss: 0.36024 | error: 0.47794 | utility: 0.97471\n",
      "  batch 018 / 029 | loss: 0.36282 | error: 0.47917 | utility: 0.97590\n",
      "  batch 019 / 029 | loss: 0.37257 | error: 0.48438 | utility: 0.97292\n",
      "  batch 020 / 029 | loss: 0.36514 | error: 0.48047 | utility: 0.97329\n",
      "  batch 021 / 029 | loss: 0.38365 | error: 0.48884 | utility: 0.97471\n",
      "  batch 022 / 029 | loss: 0.38441 | error: 0.48935 | utility: 0.97435\n",
      "  batch 023 / 029 | loss: 0.38235 | error: 0.48845 | utility: 0.97757\n",
      "  batch 024 / 029 | loss: 0.38090 | error: 0.48763 | utility: 0.97618\n",
      "  batch 025 / 029 | loss: 0.38778 | error: 0.49125 | utility: 0.97525\n",
      "  batch 026 / 029 | loss: 0.38439 | error: 0.48978 | utility: 0.97522\n",
      "  batch 027 / 029 | loss: 0.38607 | error: 0.49074 | utility: 0.97521\n",
      "  batch 028 / 029 | loss: 0.38564 | error: 0.49051 | utility: 0.97654\n",
      "  batch 029 / 029 | loss: 0.38529 | error: 0.49084 | utility: 0.97490\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 002 / 010 | time: 026 sec | loss: 0.38267 | error: 0.49167 | utility: 0.97862\n",
      "Validation accuracy improved.\n",
      "Saving model to ./Results/utility/utility_0.950_model.pt.\n",
      "Starting epoch 003 / 010.\n",
      "  batch 001 / 029 | loss: 0.61911 | error: 0.60938 | utility: 0.97271\n",
      "  batch 002 / 029 | loss: 0.47778 | error: 0.53906 | utility: 0.97122\n",
      "  batch 003 / 029 | loss: 0.42550 | error: 0.51562 | utility: 0.97215\n",
      "  batch 004 / 029 | loss: 0.39819 | error: 0.50000 | utility: 0.97165\n",
      "  batch 005 / 029 | loss: 0.39714 | error: 0.50000 | utility: 0.96827\n",
      "  batch 006 / 029 | loss: 0.42254 | error: 0.51302 | utility: 0.96833\n",
      "  batch 007 / 029 | loss: 0.39078 | error: 0.49777 | utility: 0.96881\n",
      "  batch 008 / 029 | loss: 0.41407 | error: 0.50781 | utility: 0.96696\n",
      "  batch 009 / 029 | loss: 0.39971 | error: 0.50174 | utility: 0.96342\n",
      "  batch 010 / 029 | loss: 0.39615 | error: 0.50000 | utility: 0.96327\n",
      "  batch 011 / 029 | loss: 0.40807 | error: 0.50568 | utility: 0.96348\n",
      "  batch 012 / 029 | loss: 0.41185 | error: 0.50651 | utility: 0.96253\n",
      "  batch 013 / 029 | loss: 0.42418 | error: 0.51322 | utility: 0.95102\n",
      "  batch 014 / 029 | loss: 0.40841 | error: 0.50558 | utility: 0.96775\n",
      "  batch 015 / 029 | loss: 0.40327 | error: 0.50208 | utility: 0.96254\n",
      "  batch 016 / 029 | loss: 0.40811 | error: 0.50391 | utility: 0.96621\n",
      "  batch 017 / 029 | loss: 0.40470 | error: 0.50184 | utility: 0.96888\n",
      "  batch 018 / 029 | loss: 0.40621 | error: 0.50174 | utility: 0.96326\n",
      "  batch 019 / 029 | loss: 0.41692 | error: 0.50658 | utility: 0.97012\n",
      "  batch 020 / 029 | loss: 0.41034 | error: 0.50313 | utility: 0.97419\n",
      "  batch 021 / 029 | loss: 0.40539 | error: 0.50074 | utility: 0.97051\n",
      "  batch 022 / 029 | loss: 0.40433 | error: 0.50000 | utility: 0.97364\n",
      "  batch 023 / 029 | loss: 0.39736 | error: 0.49660 | utility: 0.97594\n",
      "  batch 024 / 029 | loss: 0.40159 | error: 0.49870 | utility: 0.97480\n",
      "  batch 025 / 029 | loss: 0.39215 | error: 0.49375 | utility: 0.97557\n",
      "  batch 026 / 029 | loss: 0.39487 | error: 0.49519 | utility: 0.97617\n",
      "  batch 027 / 029 | loss: 0.39150 | error: 0.49363 | utility: 0.97698\n",
      "  batch 028 / 029 | loss: 0.38577 | error: 0.49107 | utility: 0.97695\n",
      "  batch 029 / 029 | loss: 0.37661 | error: 0.48707 | utility: 0.97763\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 003 / 010 | time: 024 sec | loss: 0.36514 | error: 0.48125 | utility: 0.98164\n",
      "Validation accuracy improved.\n",
      "Saving model to ./Results/utility/utility_0.950_model.pt.\n",
      "Starting epoch 004 / 010.\n",
      "  batch 001 / 029 | loss: 0.47008 | error: 0.53125 | utility: 0.97674\n",
      "  batch 002 / 029 | loss: 0.41106 | error: 0.50000 | utility: 0.97646\n",
      "  batch 003 / 029 | loss: 0.33925 | error: 0.46875 | utility: 0.97606\n",
      "  batch 004 / 029 | loss: 0.29770 | error: 0.44922 | utility: 0.97613\n",
      "  batch 005 / 029 | loss: 0.30958 | error: 0.45312 | utility: 0.97574\n",
      "  batch 006 / 029 | loss: 0.32325 | error: 0.46094 | utility: 0.97400\n",
      "  batch 007 / 029 | loss: 0.33383 | error: 0.46652 | utility: 0.97538\n",
      "  batch 008 / 029 | loss: 0.33157 | error: 0.46484 | utility: 0.97205\n",
      "  batch 009 / 029 | loss: 0.35872 | error: 0.47569 | utility: 0.97107\n",
      "  batch 010 / 029 | loss: 0.33823 | error: 0.46719 | utility: 0.97422\n",
      "  batch 011 / 029 | loss: 0.34712 | error: 0.47159 | utility: 0.97164\n",
      "  batch 012 / 029 | loss: 0.36669 | error: 0.48047 | utility: 0.97155\n",
      "  batch 013 / 029 | loss: 0.35739 | error: 0.47716 | utility: 0.97367\n",
      "  batch 014 / 029 | loss: 0.35767 | error: 0.47768 | utility: 0.97130\n",
      "  batch 015 / 029 | loss: 0.35773 | error: 0.47813 | utility: 0.97337\n",
      "  batch 016 / 029 | loss: 0.36935 | error: 0.48340 | utility: 0.96955\n",
      "  batch 017 / 029 | loss: 0.38126 | error: 0.48897 | utility: 0.96994\n",
      "  batch 018 / 029 | loss: 0.38156 | error: 0.48872 | utility: 0.96829\n",
      "  batch 019 / 029 | loss: 0.38413 | error: 0.49013 | utility: 0.96882\n",
      "  batch 020 / 029 | loss: 0.38251 | error: 0.48906 | utility: 0.96795\n",
      "  batch 021 / 029 | loss: 0.37893 | error: 0.48735 | utility: 0.97086\n",
      "  batch 022 / 029 | loss: 0.37963 | error: 0.48722 | utility: 0.96647\n",
      "  batch 023 / 029 | loss: 0.38395 | error: 0.48913 | utility: 0.96822\n",
      "  batch 024 / 029 | loss: 0.38753 | error: 0.49089 | utility: 0.97087\n",
      "  batch 025 / 029 | loss: 0.38327 | error: 0.48875 | utility: 0.97259\n",
      "  batch 026 / 029 | loss: 0.38687 | error: 0.49099 | utility: 0.97397\n",
      "  batch 027 / 029 | loss: 0.38672 | error: 0.49074 | utility: 0.97214\n",
      "  batch 028 / 029 | loss: 0.38645 | error: 0.49051 | utility: 0.97168\n",
      "  batch 029 / 029 | loss: 0.38692 | error: 0.49084 | utility: 0.96636\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 004 / 010 | time: 029 sec | loss: 0.37827 | error: 0.48646 | utility: 0.97913\n",
      "Starting epoch 005 / 010.\n",
      "  batch 001 / 029 | loss: 0.48079 | error: 0.53125 | utility: 0.97458\n",
      "  batch 002 / 029 | loss: 0.43021 | error: 0.50781 | utility: 0.97599\n",
      "  batch 003 / 029 | loss: 0.41988 | error: 0.50521 | utility: 0.97640\n",
      "  batch 004 / 029 | loss: 0.41556 | error: 0.50391 | utility: 0.97642\n",
      "  batch 005 / 029 | loss: 0.45150 | error: 0.52187 | utility: 0.97695\n",
      "  batch 006 / 029 | loss: 0.40415 | error: 0.50000 | utility: 0.97598\n",
      "  batch 007 / 029 | loss: 0.40553 | error: 0.50000 | utility: 0.97646\n",
      "  batch 008 / 029 | loss: 0.40559 | error: 0.50000 | utility: 0.97683\n",
      "  batch 009 / 029 | loss: 0.41242 | error: 0.50174 | utility: 0.97740\n",
      "  batch 010 / 029 | loss: 0.41095 | error: 0.50156 | utility: 0.97548\n",
      "  batch 011 / 029 | loss: 0.41150 | error: 0.50142 | utility: 0.97665\n",
      "  batch 012 / 029 | loss: 0.40465 | error: 0.49870 | utility: 0.97385\n",
      "  batch 013 / 029 | loss: 0.38945 | error: 0.49159 | utility: 0.96938\n",
      "  batch 014 / 029 | loss: 0.41109 | error: 0.50223 | utility: 0.96850\n",
      "  batch 015 / 029 | loss: 0.39730 | error: 0.49479 | utility: 0.97036\n",
      "  batch 016 / 029 | loss: 0.39145 | error: 0.49121 | utility: 0.96916\n",
      "  batch 017 / 029 | loss: 0.38698 | error: 0.48897 | utility: 0.97168\n",
      "  batch 018 / 029 | loss: 0.38923 | error: 0.49045 | utility: 0.97006\n",
      "  batch 019 / 029 | loss: 0.39355 | error: 0.49260 | utility: 0.96949\n",
      "  batch 020 / 029 | loss: 0.39030 | error: 0.49141 | utility: 0.96943\n",
      "  batch 021 / 029 | loss: 0.39170 | error: 0.49256 | utility: 0.97165\n",
      "  batch 022 / 029 | loss: 0.38818 | error: 0.49077 | utility: 0.97241\n",
      "  batch 023 / 029 | loss: 0.38406 | error: 0.48913 | utility: 0.96705\n",
      "  batch 024 / 029 | loss: 0.38743 | error: 0.49089 | utility: 0.97102\n",
      "  batch 025 / 029 | loss: 0.38870 | error: 0.49188 | utility: 0.97104\n",
      "  batch 026 / 029 | loss: 0.39225 | error: 0.49339 | utility: 0.97276\n",
      "  batch 027 / 029 | loss: 0.39024 | error: 0.49248 | utility: 0.97271\n",
      "  batch 028 / 029 | loss: 0.38571 | error: 0.48996 | utility: 0.97182\n",
      "  batch 029 / 029 | loss: 0.39339 | error: 0.49461 | utility: 0.96892\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 005 / 010 | time: 034 sec | loss: 0.35809 | error: 0.47865 | utility: 0.97797\n",
      "Validation accuracy improved.\n",
      "Saving model to ./Results/utility/utility_0.950_model.pt.\n",
      "Starting epoch 006 / 010.\n",
      "  batch 001 / 029 | loss: 0.38540 | error: 0.50000 | utility: 0.97292\n",
      "  batch 002 / 029 | loss: 0.48775 | error: 0.54688 | utility: 0.96672\n",
      "  batch 003 / 029 | loss: 0.43974 | error: 0.52083 | utility: 0.97235\n",
      "  batch 004 / 029 | loss: 0.48272 | error: 0.53906 | utility: 0.96768\n",
      "  batch 005 / 029 | loss: 0.44636 | error: 0.52187 | utility: 0.96882\n",
      "  batch 006 / 029 | loss: 0.42359 | error: 0.51042 | utility: 0.96647\n",
      "  batch 007 / 029 | loss: 0.40956 | error: 0.50446 | utility: 0.96962\n",
      "  batch 008 / 029 | loss: 0.40882 | error: 0.50391 | utility: 0.97110\n",
      "  batch 009 / 029 | loss: 0.38969 | error: 0.49479 | utility: 0.96962\n",
      "  batch 010 / 029 | loss: 0.38435 | error: 0.49219 | utility: 0.97414\n",
      "  batch 011 / 029 | loss: 0.39404 | error: 0.49574 | utility: 0.97490\n",
      "  batch 012 / 029 | loss: 0.37284 | error: 0.48568 | utility: 0.97248\n",
      "  batch 013 / 029 | loss: 0.37956 | error: 0.48918 | utility: 0.97053\n",
      "  batch 014 / 029 | loss: 0.38534 | error: 0.49219 | utility: 0.96805\n",
      "  batch 015 / 029 | loss: 0.38083 | error: 0.49062 | utility: 0.97340\n",
      "  batch 016 / 029 | loss: 0.39236 | error: 0.49512 | utility: 0.97023\n",
      "  batch 017 / 029 | loss: 0.39724 | error: 0.49724 | utility: 0.97165\n",
      "  batch 018 / 029 | loss: 0.39657 | error: 0.49740 | utility: 0.97296\n",
      "  batch 019 / 029 | loss: 0.40081 | error: 0.49918 | utility: 0.96881\n",
      "  batch 020 / 029 | loss: 0.40760 | error: 0.50234 | utility: 0.96999\n",
      "  batch 021 / 029 | loss: 0.39925 | error: 0.49851 | utility: 0.97371\n",
      "  batch 022 / 029 | loss: 0.38941 | error: 0.49361 | utility: 0.97208\n",
      "  batch 023 / 029 | loss: 0.38545 | error: 0.49185 | utility: 0.97246\n",
      "  batch 024 / 029 | loss: 0.38221 | error: 0.49023 | utility: 0.97065\n",
      "  batch 025 / 029 | loss: 0.38017 | error: 0.48875 | utility: 0.97279\n",
      "  batch 026 / 029 | loss: 0.37525 | error: 0.48618 | utility: 0.97361\n",
      "  batch 027 / 029 | loss: 0.37758 | error: 0.48727 | utility: 0.97317\n",
      "  batch 028 / 029 | loss: 0.38527 | error: 0.49107 | utility: 0.97001\n",
      "  batch 029 / 029 | loss: 0.38096 | error: 0.48707 | utility: 0.96963\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 006 / 010 | time: 033 sec | loss: 0.40571 | error: 0.50208 | utility: 0.98031\n",
      "Starting epoch 007 / 010.\n",
      "  batch 001 / 029 | loss: 0.44637 | error: 0.51562 | utility: 0.97705\n",
      "  batch 002 / 029 | loss: 0.52148 | error: 0.55469 | utility: 0.97916\n",
      "  batch 003 / 029 | loss: 0.53857 | error: 0.56250 | utility: 0.98095\n",
      "  batch 004 / 029 | loss: 0.48934 | error: 0.53906 | utility: 0.98081\n",
      "  batch 005 / 029 | loss: 0.43378 | error: 0.51250 | utility: 0.98153\n",
      "  batch 006 / 029 | loss: 0.42439 | error: 0.50781 | utility: 0.98140\n",
      "  batch 007 / 029 | loss: 0.39059 | error: 0.49107 | utility: 0.98152\n",
      "  batch 008 / 029 | loss: 0.40414 | error: 0.49805 | utility: 0.98110\n",
      "  batch 009 / 029 | loss: 0.39669 | error: 0.49479 | utility: 0.97993\n",
      "  batch 010 / 029 | loss: 0.38770 | error: 0.49062 | utility: 0.98045\n",
      "  batch 011 / 029 | loss: 0.38142 | error: 0.48722 | utility: 0.97941\n",
      "  batch 012 / 029 | loss: 0.37499 | error: 0.48438 | utility: 0.97572\n",
      "  batch 013 / 029 | loss: 0.36897 | error: 0.48197 | utility: 0.97605\n",
      "  batch 014 / 029 | loss: 0.36596 | error: 0.47991 | utility: 0.97519\n",
      "  batch 015 / 029 | loss: 0.36210 | error: 0.47813 | utility: 0.97398\n",
      "  batch 016 / 029 | loss: 0.36893 | error: 0.48242 | utility: 0.97186\n",
      "  batch 017 / 029 | loss: 0.36332 | error: 0.47978 | utility: 0.97210\n",
      "  batch 018 / 029 | loss: 0.36454 | error: 0.48003 | utility: 0.97091\n",
      "  batch 019 / 029 | loss: 0.37793 | error: 0.48684 | utility: 0.96833\n",
      "  batch 020 / 029 | loss: 0.38167 | error: 0.48828 | utility: 0.97134\n",
      "  batch 021 / 029 | loss: 0.38868 | error: 0.49182 | utility: 0.96921\n",
      "  batch 022 / 029 | loss: 0.38955 | error: 0.49219 | utility: 0.96955\n",
      "  batch 023 / 029 | loss: 0.39157 | error: 0.49321 | utility: 0.97136\n",
      "  batch 024 / 029 | loss: 0.39346 | error: 0.49414 | utility: 0.97209\n",
      "  batch 025 / 029 | loss: 0.39218 | error: 0.49312 | utility: 0.96798\n",
      "  batch 026 / 029 | loss: 0.38699 | error: 0.49099 | utility: 0.96651\n",
      "  batch 027 / 029 | loss: 0.38287 | error: 0.48900 | utility: 0.97424\n",
      "  batch 028 / 029 | loss: 0.38517 | error: 0.48996 | utility: 0.97133\n",
      "  batch 029 / 029 | loss: 0.39459 | error: 0.49461 | utility: 0.97241\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 007 / 010 | time: 034 sec | loss: 0.36116 | error: 0.47865 | utility: 0.97831\n",
      "Starting epoch 008 / 010.\n",
      "  batch 001 / 029 | loss: 0.46065 | error: 0.53125 | utility: 0.97354\n",
      "  batch 002 / 029 | loss: 0.35228 | error: 0.47656 | utility: 0.97424\n",
      "  batch 003 / 029 | loss: 0.37676 | error: 0.48438 | utility: 0.97372\n",
      "  batch 004 / 029 | loss: 0.28275 | error: 0.43750 | utility: 0.97590\n",
      "  batch 005 / 029 | loss: 0.32263 | error: 0.45937 | utility: 0.97071\n",
      "  batch 006 / 029 | loss: 0.37410 | error: 0.48438 | utility: 0.97237\n",
      "  batch 007 / 029 | loss: 0.40624 | error: 0.50000 | utility: 0.97297\n",
      "  batch 008 / 029 | loss: 0.40947 | error: 0.50195 | utility: 0.97447\n",
      "  batch 009 / 029 | loss: 0.41466 | error: 0.50521 | utility: 0.97393\n",
      "  batch 010 / 029 | loss: 0.40797 | error: 0.50156 | utility: 0.97345\n",
      "  batch 011 / 029 | loss: 0.42581 | error: 0.50994 | utility: 0.97400\n",
      "  batch 012 / 029 | loss: 0.42911 | error: 0.51172 | utility: 0.97341\n",
      "  batch 013 / 029 | loss: 0.40929 | error: 0.50120 | utility: 0.97350\n",
      "  batch 014 / 029 | loss: 0.39959 | error: 0.49665 | utility: 0.97499\n",
      "  batch 015 / 029 | loss: 0.39803 | error: 0.49583 | utility: 0.97516\n",
      "  batch 016 / 029 | loss: 0.39954 | error: 0.49707 | utility: 0.97545\n",
      "  batch 017 / 029 | loss: 0.41089 | error: 0.50276 | utility: 0.97452\n",
      "  batch 018 / 029 | loss: 0.42094 | error: 0.50781 | utility: 0.97388\n",
      "  batch 019 / 029 | loss: 0.41640 | error: 0.50576 | utility: 0.97406\n",
      "  batch 020 / 029 | loss: 0.41346 | error: 0.50391 | utility: 0.97374\n",
      "  batch 021 / 029 | loss: 0.40525 | error: 0.50000 | utility: 0.97462\n",
      "  batch 022 / 029 | loss: 0.39027 | error: 0.49290 | utility: 0.96935\n",
      "  batch 023 / 029 | loss: 0.38782 | error: 0.49185 | utility: 0.97008\n",
      "  batch 024 / 029 | loss: 0.38020 | error: 0.48828 | utility: 0.97224\n",
      "  batch 025 / 029 | loss: 0.37848 | error: 0.48750 | utility: 0.96916\n",
      "  batch 026 / 029 | loss: 0.37632 | error: 0.48678 | utility: 0.97109\n",
      "  batch 027 / 029 | loss: 0.38145 | error: 0.48900 | utility: 0.96695\n",
      "  batch 028 / 029 | loss: 0.38451 | error: 0.49051 | utility: 0.96137\n",
      "  batch 029 / 029 | loss: 0.38605 | error: 0.49084 | utility: 0.96348\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 008 / 010 | time: 038 sec | loss: 0.38375 | error: 0.49167 | utility: 0.97801\n",
      "Starting epoch 009 / 010.\n",
      "  batch 001 / 029 | loss: 0.36380 | error: 0.48438 | utility: 0.97012\n",
      "  batch 002 / 029 | loss: 0.43528 | error: 0.52344 | utility: 0.96885\n",
      "  batch 003 / 029 | loss: 0.38788 | error: 0.49479 | utility: 0.97140\n",
      "  batch 004 / 029 | loss: 0.33507 | error: 0.46875 | utility: 0.97135\n",
      "  batch 005 / 029 | loss: 0.40137 | error: 0.50000 | utility: 0.97084\n",
      "  batch 006 / 029 | loss: 0.37828 | error: 0.48958 | utility: 0.97374\n",
      "  batch 007 / 029 | loss: 0.35934 | error: 0.47991 | utility: 0.97415\n",
      "  batch 008 / 029 | loss: 0.37257 | error: 0.48633 | utility: 0.97301\n",
      "  batch 009 / 029 | loss: 0.36650 | error: 0.48438 | utility: 0.97522\n",
      "  batch 010 / 029 | loss: 0.38196 | error: 0.49062 | utility: 0.97541\n",
      "  batch 011 / 029 | loss: 0.36616 | error: 0.48153 | utility: 0.97641\n",
      "  batch 012 / 029 | loss: 0.36070 | error: 0.47917 | utility: 0.97730\n",
      "  batch 013 / 029 | loss: 0.35766 | error: 0.47716 | utility: 0.97697\n",
      "  batch 014 / 029 | loss: 0.35663 | error: 0.47656 | utility: 0.97732\n",
      "  batch 015 / 029 | loss: 0.34694 | error: 0.47187 | utility: 0.97972\n",
      "  batch 016 / 029 | loss: 0.36251 | error: 0.47949 | utility: 0.97799\n",
      "  batch 017 / 029 | loss: 0.36630 | error: 0.48162 | utility: 0.97850\n",
      "  batch 018 / 029 | loss: 0.37032 | error: 0.48351 | utility: 0.97901\n",
      "  batch 019 / 029 | loss: 0.37493 | error: 0.48602 | utility: 0.97768\n",
      "  batch 020 / 029 | loss: 0.36765 | error: 0.48281 | utility: 0.97806\n",
      "  batch 021 / 029 | loss: 0.36403 | error: 0.48065 | utility: 0.97588\n",
      "  batch 022 / 029 | loss: 0.36743 | error: 0.48224 | utility: 0.97218\n",
      "  batch 023 / 029 | loss: 0.36611 | error: 0.48166 | utility: 0.97379\n",
      "  batch 024 / 029 | loss: 0.36316 | error: 0.47982 | utility: 0.97063\n",
      "  batch 025 / 029 | loss: 0.36493 | error: 0.48063 | utility: 0.97457\n",
      "  batch 026 / 029 | loss: 0.36943 | error: 0.48317 | utility: 0.97018\n",
      "  batch 027 / 029 | loss: 0.37499 | error: 0.48553 | utility: 0.97158\n",
      "  batch 028 / 029 | loss: 0.38607 | error: 0.49107 | utility: 0.96960\n",
      "  batch 029 / 029 | loss: 0.37717 | error: 0.48707 | utility: 0.97375\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 009 / 010 | time: 039 sec | loss: 0.37840 | error: 0.48646 | utility: 0.97422\n",
      "Ending training due to 4 consecutive epochs without improvement in validation accuracy.\n",
      "Total training time: 5 minutes (280.758353471756 seconds).\n",
      "Loading model from ./Results/utility/utility_0.950_model.pt.\n",
      "---------- Training with lambda=1.0 ----------\n",
      "Starting epoch 001 / 010.\n",
      "  batch 001 / 029 | loss: 0.43319 | error: 0.40625 | utility: 0.93142\n",
      "  batch 002 / 029 | loss: 0.40447 | error: 0.40625 | utility: 0.93357\n",
      "  batch 003 / 029 | loss: 0.44205 | error: 0.44792 | utility: 0.94059\n",
      "  batch 004 / 029 | loss: 0.42380 | error: 0.45312 | utility: 0.94499\n",
      "  batch 005 / 029 | loss: 0.40108 | error: 0.45312 | utility: 0.94734\n",
      "  batch 006 / 029 | loss: 0.40059 | error: 0.45833 | utility: 0.94591\n",
      "  batch 007 / 029 | loss: 0.41108 | error: 0.46875 | utility: 0.94447\n",
      "  batch 008 / 029 | loss: 0.42786 | error: 0.48047 | utility: 0.94135\n",
      "  batch 009 / 029 | loss: 0.45369 | error: 0.49653 | utility: 0.94611\n",
      "  batch 010 / 029 | loss: 0.44544 | error: 0.49531 | utility: 0.94934\n",
      "  batch 011 / 029 | loss: 0.42867 | error: 0.49006 | utility: 0.95560\n",
      "  batch 012 / 029 | loss: 0.44490 | error: 0.49870 | utility: 0.95111\n",
      "  batch 013 / 029 | loss: 0.43524 | error: 0.49639 | utility: 0.93848\n",
      "  batch 014 / 029 | loss: 0.43810 | error: 0.50000 | utility: 0.95404\n",
      "  batch 015 / 029 | loss: 0.42532 | error: 0.49479 | utility: 0.95031\n",
      "  batch 016 / 029 | loss: 0.42224 | error: 0.49316 | utility: 0.95885\n",
      "  batch 017 / 029 | loss: 0.41884 | error: 0.49357 | utility: 0.94761\n",
      "  batch 018 / 029 | loss: 0.42755 | error: 0.49913 | utility: 0.95592\n",
      "  batch 019 / 029 | loss: 0.43356 | error: 0.50329 | utility: 0.95679\n",
      "  batch 020 / 029 | loss: 0.43672 | error: 0.50625 | utility: 0.96319\n",
      "  batch 021 / 029 | loss: 0.42521 | error: 0.50149 | utility: 0.96809\n",
      "  batch 022 / 029 | loss: 0.40976 | error: 0.49503 | utility: 0.96688\n",
      "  batch 023 / 029 | loss: 0.40536 | error: 0.49389 | utility: 0.96015\n",
      "  batch 024 / 029 | loss: 0.40412 | error: 0.49414 | utility: 0.96947\n",
      "  batch 025 / 029 | loss: 0.40004 | error: 0.49250 | utility: 0.97174\n",
      "  batch 026 / 029 | loss: 0.39623 | error: 0.49099 | utility: 0.97271\n",
      "  batch 027 / 029 | loss: 0.39512 | error: 0.49074 | utility: 0.97387\n",
      "  batch 028 / 029 | loss: 0.39278 | error: 0.49051 | utility: 0.97703\n",
      "  batch 029 / 029 | loss: 0.39101 | error: 0.49084 | utility: 0.97777\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 001 / 010 | time: 038 sec | loss: 0.36443 | error: 0.49688 | utility: 0.98244\n",
      "Saving model to ./Results/utility/utility_1.000_model.pt.\n",
      "Starting epoch 002 / 010.\n",
      "  batch 001 / 029 | loss: 0.44494 | error: 0.53125 | utility: 0.97661\n",
      "  batch 002 / 029 | loss: 0.42325 | error: 0.52344 | utility: 0.97826\n",
      "  batch 003 / 029 | loss: 0.43079 | error: 0.52604 | utility: 0.97745\n",
      "  batch 004 / 029 | loss: 0.40256 | error: 0.51172 | utility: 0.97947\n",
      "  batch 005 / 029 | loss: 0.40191 | error: 0.51250 | utility: 0.97830\n",
      "  batch 006 / 029 | loss: 0.39064 | error: 0.50781 | utility: 0.97885\n",
      "  batch 007 / 029 | loss: 0.41009 | error: 0.51786 | utility: 0.97750\n",
      "  batch 008 / 029 | loss: 0.37652 | error: 0.50195 | utility: 0.97877\n",
      "  batch 009 / 029 | loss: 0.35439 | error: 0.49132 | utility: 0.97794\n",
      "  batch 010 / 029 | loss: 0.33102 | error: 0.47969 | utility: 0.97659\n",
      "  batch 011 / 029 | loss: 0.32618 | error: 0.47727 | utility: 0.97773\n",
      "  batch 012 / 029 | loss: 0.33951 | error: 0.48438 | utility: 0.97442\n",
      "  batch 013 / 029 | loss: 0.34636 | error: 0.48798 | utility: 0.97426\n",
      "  batch 014 / 029 | loss: 0.35549 | error: 0.49107 | utility: 0.97407\n",
      "  batch 015 / 029 | loss: 0.33583 | error: 0.48125 | utility: 0.97708\n",
      "  batch 016 / 029 | loss: 0.32967 | error: 0.47852 | utility: 0.97317\n",
      "  batch 017 / 029 | loss: 0.32808 | error: 0.47794 | utility: 0.97568\n",
      "  batch 018 / 029 | loss: 0.33064 | error: 0.47917 | utility: 0.97677\n",
      "  batch 019 / 029 | loss: 0.34057 | error: 0.48438 | utility: 0.97451\n",
      "  batch 020 / 029 | loss: 0.33307 | error: 0.48047 | utility: 0.97488\n",
      "  batch 021 / 029 | loss: 0.35170 | error: 0.48884 | utility: 0.97591\n",
      "  batch 022 / 029 | loss: 0.35243 | error: 0.48935 | utility: 0.97576\n",
      "  batch 023 / 029 | loss: 0.35033 | error: 0.48845 | utility: 0.97881\n",
      "  batch 024 / 029 | loss: 0.34886 | error: 0.48763 | utility: 0.97749\n",
      "  batch 025 / 029 | loss: 0.35588 | error: 0.49125 | utility: 0.97663\n",
      "  batch 026 / 029 | loss: 0.35246 | error: 0.48978 | utility: 0.97659\n",
      "  batch 027 / 029 | loss: 0.35419 | error: 0.49074 | utility: 0.97664\n",
      "  batch 028 / 029 | loss: 0.35373 | error: 0.49051 | utility: 0.97765\n",
      "  batch 029 / 029 | loss: 0.35339 | error: 0.49084 | utility: 0.97614\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 002 / 010 | time: 039 sec | loss: 0.35078 | error: 0.49167 | utility: 0.97971\n",
      "Validation accuracy improved.\n",
      "Saving model to ./Results/utility/utility_1.000_model.pt.\n",
      "Starting epoch 003 / 010.\n",
      "  batch 001 / 029 | loss: 0.59101 | error: 0.60938 | utility: 0.97396\n",
      "  batch 002 / 029 | loss: 0.44730 | error: 0.53906 | utility: 0.97255\n",
      "  batch 003 / 029 | loss: 0.39454 | error: 0.51562 | utility: 0.97357\n",
      "  batch 004 / 029 | loss: 0.36677 | error: 0.50000 | utility: 0.97311\n",
      "  batch 005 / 029 | loss: 0.36579 | error: 0.50000 | utility: 0.97007\n",
      "  batch 006 / 029 | loss: 0.39161 | error: 0.51302 | utility: 0.97007\n",
      "  batch 007 / 029 | loss: 0.35951 | error: 0.49777 | utility: 0.97080\n",
      "  batch 008 / 029 | loss: 0.38305 | error: 0.50781 | utility: 0.96894\n",
      "  batch 009 / 029 | loss: 0.36850 | error: 0.50174 | utility: 0.96595\n",
      "  batch 010 / 029 | loss: 0.36489 | error: 0.50000 | utility: 0.96629\n",
      "  batch 011 / 029 | loss: 0.37710 | error: 0.50568 | utility: 0.96628\n",
      "  batch 012 / 029 | loss: 0.38075 | error: 0.50651 | utility: 0.96510\n",
      "  batch 013 / 029 | loss: 0.39339 | error: 0.51322 | utility: 0.95654\n",
      "  batch 014 / 029 | loss: 0.37741 | error: 0.50558 | utility: 0.97008\n",
      "  batch 015 / 029 | loss: 0.37206 | error: 0.50208 | utility: 0.96597\n",
      "  batch 016 / 029 | loss: 0.37683 | error: 0.50391 | utility: 0.96900\n",
      "  batch 017 / 029 | loss: 0.37335 | error: 0.50184 | utility: 0.97143\n",
      "  batch 018 / 029 | loss: 0.37471 | error: 0.50174 | utility: 0.96672\n",
      "  batch 019 / 029 | loss: 0.38546 | error: 0.50658 | utility: 0.97273\n",
      "  batch 020 / 029 | loss: 0.37876 | error: 0.50313 | utility: 0.97619\n",
      "  batch 021 / 029 | loss: 0.37382 | error: 0.50074 | utility: 0.97326\n",
      "  batch 022 / 029 | loss: 0.37273 | error: 0.50000 | utility: 0.97585\n",
      "  batch 023 / 029 | loss: 0.36567 | error: 0.49660 | utility: 0.97772\n",
      "  batch 024 / 029 | loss: 0.36995 | error: 0.49870 | utility: 0.97680\n",
      "  batch 025 / 029 | loss: 0.36026 | error: 0.49375 | utility: 0.97731\n",
      "  batch 026 / 029 | loss: 0.36304 | error: 0.49519 | utility: 0.97796\n",
      "  batch 027 / 029 | loss: 0.35971 | error: 0.49363 | utility: 0.97850\n",
      "  batch 028 / 029 | loss: 0.35399 | error: 0.49107 | utility: 0.97830\n",
      "  batch 029 / 029 | loss: 0.34478 | error: 0.48707 | utility: 0.97894\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 003 / 010 | time: 044 sec | loss: 0.33338 | error: 0.48125 | utility: 0.98225\n",
      "Validation accuracy improved.\n",
      "Saving model to ./Results/utility/utility_1.000_model.pt.\n",
      "Starting epoch 004 / 010.\n",
      "  batch 001 / 029 | loss: 0.43953 | error: 0.53125 | utility: 0.97781\n",
      "  batch 002 / 029 | loss: 0.38003 | error: 0.50000 | utility: 0.97721\n",
      "  batch 003 / 029 | loss: 0.30743 | error: 0.46875 | utility: 0.97676\n",
      "  batch 004 / 029 | loss: 0.26567 | error: 0.44922 | utility: 0.97681\n",
      "  batch 005 / 029 | loss: 0.27733 | error: 0.45312 | utility: 0.97612\n",
      "  batch 006 / 029 | loss: 0.29116 | error: 0.46094 | utility: 0.97418\n",
      "  batch 007 / 029 | loss: 0.30148 | error: 0.46652 | utility: 0.97559\n",
      "  batch 008 / 029 | loss: 0.29915 | error: 0.46484 | utility: 0.97253\n",
      "  batch 009 / 029 | loss: 0.32651 | error: 0.47569 | utility: 0.97150\n",
      "  batch 010 / 029 | loss: 0.30571 | error: 0.46719 | utility: 0.97434\n",
      "  batch 011 / 029 | loss: 0.31481 | error: 0.47159 | utility: 0.97177\n",
      "  batch 012 / 029 | loss: 0.33448 | error: 0.48047 | utility: 0.97196\n",
      "  batch 013 / 029 | loss: 0.32506 | error: 0.47716 | utility: 0.97431\n",
      "  batch 014 / 029 | loss: 0.32543 | error: 0.47768 | utility: 0.97232\n",
      "  batch 015 / 029 | loss: 0.32548 | error: 0.47813 | utility: 0.97433\n",
      "  batch 016 / 029 | loss: 0.33741 | error: 0.48340 | utility: 0.97132\n",
      "  batch 017 / 029 | loss: 0.34959 | error: 0.48897 | utility: 0.97151\n",
      "  batch 018 / 029 | loss: 0.34990 | error: 0.48872 | utility: 0.97045\n",
      "  batch 019 / 029 | loss: 0.35253 | error: 0.49013 | utility: 0.97113\n",
      "  batch 020 / 029 | loss: 0.35080 | error: 0.48906 | utility: 0.97051\n",
      "  batch 021 / 029 | loss: 0.34714 | error: 0.48735 | utility: 0.97324\n",
      "  batch 022 / 029 | loss: 0.34769 | error: 0.48722 | utility: 0.97010\n",
      "  batch 023 / 029 | loss: 0.35200 | error: 0.48913 | utility: 0.97128\n",
      "  batch 024 / 029 | loss: 0.35556 | error: 0.49089 | utility: 0.97332\n",
      "  batch 025 / 029 | loss: 0.35116 | error: 0.48875 | utility: 0.97481\n",
      "  batch 026 / 029 | loss: 0.35496 | error: 0.49099 | utility: 0.97599\n",
      "  batch 027 / 029 | loss: 0.35483 | error: 0.49074 | utility: 0.97437\n",
      "  batch 028 / 029 | loss: 0.35456 | error: 0.49051 | utility: 0.97412\n",
      "  batch 029 / 029 | loss: 0.35505 | error: 0.49084 | utility: 0.97027\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 004 / 010 | time: 033 sec | loss: 0.34624 | error: 0.48646 | utility: 0.98020\n",
      "Starting epoch 005 / 010.\n",
      "  batch 001 / 029 | loss: 0.44825 | error: 0.53125 | utility: 0.97641\n",
      "  batch 002 / 029 | loss: 0.39750 | error: 0.50781 | utility: 0.97762\n",
      "  batch 003 / 029 | loss: 0.38777 | error: 0.50521 | utility: 0.97827\n",
      "  batch 004 / 029 | loss: 0.38332 | error: 0.50391 | utility: 0.97812\n",
      "  batch 005 / 029 | loss: 0.41823 | error: 0.52187 | utility: 0.97850\n",
      "  batch 006 / 029 | loss: 0.37076 | error: 0.50000 | utility: 0.97814\n",
      "  batch 007 / 029 | loss: 0.37141 | error: 0.50000 | utility: 0.97790\n",
      "  batch 008 / 029 | loss: 0.37053 | error: 0.50000 | utility: 0.97800\n",
      "  batch 009 / 029 | loss: 0.37615 | error: 0.50174 | utility: 0.97823\n",
      "  batch 010 / 029 | loss: 0.37512 | error: 0.50156 | utility: 0.97579\n",
      "  batch 011 / 029 | loss: 0.37561 | error: 0.50142 | utility: 0.97675\n",
      "  batch 012 / 029 | loss: 0.36931 | error: 0.49870 | utility: 0.97383\n",
      "  batch 013 / 029 | loss: 0.35428 | error: 0.49159 | utility: 0.97073\n",
      "  batch 014 / 029 | loss: 0.37635 | error: 0.50223 | utility: 0.96958\n",
      "  batch 015 / 029 | loss: 0.36273 | error: 0.49479 | utility: 0.97119\n",
      "  batch 016 / 029 | loss: 0.35701 | error: 0.49121 | utility: 0.97044\n",
      "  batch 017 / 029 | loss: 0.35265 | error: 0.48897 | utility: 0.97294\n",
      "  batch 018 / 029 | loss: 0.35515 | error: 0.49045 | utility: 0.97176\n",
      "  batch 019 / 029 | loss: 0.35962 | error: 0.49260 | utility: 0.97169\n",
      "  batch 020 / 029 | loss: 0.35636 | error: 0.49141 | utility: 0.97175\n",
      "  batch 021 / 029 | loss: 0.35794 | error: 0.49256 | utility: 0.97432\n",
      "  batch 022 / 029 | loss: 0.35438 | error: 0.49077 | utility: 0.97497\n",
      "  batch 023 / 029 | loss: 0.35027 | error: 0.48913 | utility: 0.97084\n",
      "  batch 024 / 029 | loss: 0.35377 | error: 0.49089 | utility: 0.97411\n",
      "  batch 025 / 029 | loss: 0.35530 | error: 0.49188 | utility: 0.97410\n",
      "  batch 026 / 029 | loss: 0.35886 | error: 0.49339 | utility: 0.97569\n",
      "  batch 027 / 029 | loss: 0.35696 | error: 0.49248 | utility: 0.97537\n",
      "  batch 028 / 029 | loss: 0.35203 | error: 0.48996 | utility: 0.97468\n",
      "  batch 029 / 029 | loss: 0.35993 | error: 0.49461 | utility: 0.97222\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 005 / 010 | time: 030 sec | loss: 0.32543 | error: 0.47865 | utility: 0.97993\n",
      "Validation accuracy improved.\n",
      "Saving model to ./Results/utility/utility_1.000_model.pt.\n",
      "Starting epoch 006 / 010.\n",
      "  batch 001 / 029 | loss: 0.35578 | error: 0.50000 | utility: 0.97516\n",
      "  batch 002 / 029 | loss: 0.45889 | error: 0.54688 | utility: 0.97020\n",
      "  batch 003 / 029 | loss: 0.40927 | error: 0.52083 | utility: 0.97439\n",
      "  batch 004 / 029 | loss: 0.45268 | error: 0.53906 | utility: 0.97017\n",
      "  batch 005 / 029 | loss: 0.41567 | error: 0.52187 | utility: 0.97078\n",
      "  batch 006 / 029 | loss: 0.39289 | error: 0.51042 | utility: 0.96852\n",
      "  batch 007 / 029 | loss: 0.37972 | error: 0.50446 | utility: 0.97156\n",
      "  batch 008 / 029 | loss: 0.37870 | error: 0.50391 | utility: 0.97292\n",
      "  batch 009 / 029 | loss: 0.35933 | error: 0.49479 | utility: 0.97194\n",
      "  batch 010 / 029 | loss: 0.35367 | error: 0.49219 | utility: 0.97583\n",
      "  batch 011 / 029 | loss: 0.36326 | error: 0.49574 | utility: 0.97642\n",
      "  batch 012 / 029 | loss: 0.34172 | error: 0.48568 | utility: 0.97437\n",
      "  batch 013 / 029 | loss: 0.34848 | error: 0.48918 | utility: 0.97256\n",
      "  batch 014 / 029 | loss: 0.35438 | error: 0.49219 | utility: 0.97211\n",
      "  batch 015 / 029 | loss: 0.34982 | error: 0.49062 | utility: 0.97520\n",
      "  batch 016 / 029 | loss: 0.36139 | error: 0.49512 | utility: 0.97224\n",
      "  batch 017 / 029 | loss: 0.36638 | error: 0.49724 | utility: 0.97343\n",
      "  batch 018 / 029 | loss: 0.36574 | error: 0.49740 | utility: 0.97473\n",
      "  batch 019 / 029 | loss: 0.36996 | error: 0.49918 | utility: 0.97112\n",
      "  batch 020 / 029 | loss: 0.37685 | error: 0.50234 | utility: 0.97225\n",
      "  batch 021 / 029 | loss: 0.36844 | error: 0.49851 | utility: 0.97555\n",
      "  batch 022 / 029 | loss: 0.35834 | error: 0.49361 | utility: 0.97412\n",
      "  batch 023 / 029 | loss: 0.35429 | error: 0.49185 | utility: 0.97473\n",
      "  batch 024 / 029 | loss: 0.35097 | error: 0.49023 | utility: 0.97269\n",
      "  batch 025 / 029 | loss: 0.34877 | error: 0.48875 | utility: 0.97456\n",
      "  batch 026 / 029 | loss: 0.34371 | error: 0.48618 | utility: 0.97553\n",
      "  batch 027 / 029 | loss: 0.34605 | error: 0.48727 | utility: 0.97521\n",
      "  batch 028 / 029 | loss: 0.35386 | error: 0.49107 | utility: 0.97285\n",
      "  batch 029 / 029 | loss: 0.34898 | error: 0.48707 | utility: 0.97183\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 006 / 010 | time: 027 sec | loss: 0.37466 | error: 0.50208 | utility: 0.98176\n",
      "Starting epoch 007 / 010.\n",
      "  batch 001 / 029 | loss: 0.41474 | error: 0.51562 | utility: 0.97877\n",
      "  batch 002 / 029 | loss: 0.49320 | error: 0.55469 | utility: 0.98075\n",
      "  batch 003 / 029 | loss: 0.51147 | error: 0.56250 | utility: 0.98243\n",
      "  batch 004 / 029 | loss: 0.46133 | error: 0.53906 | utility: 0.98237\n",
      "  batch 005 / 029 | loss: 0.40466 | error: 0.51250 | utility: 0.98289\n",
      "  batch 006 / 029 | loss: 0.39509 | error: 0.50781 | utility: 0.98270\n",
      "  batch 007 / 029 | loss: 0.36072 | error: 0.49107 | utility: 0.98268\n",
      "  batch 008 / 029 | loss: 0.37436 | error: 0.49805 | utility: 0.98222\n",
      "  batch 009 / 029 | loss: 0.36662 | error: 0.49479 | utility: 0.98082\n",
      "  batch 010 / 029 | loss: 0.35739 | error: 0.49062 | utility: 0.98122\n",
      "  batch 011 / 029 | loss: 0.35102 | error: 0.48722 | utility: 0.98008\n",
      "  batch 012 / 029 | loss: 0.34428 | error: 0.48438 | utility: 0.97600\n",
      "  batch 013 / 029 | loss: 0.33811 | error: 0.48197 | utility: 0.97634\n",
      "  batch 014 / 029 | loss: 0.33506 | error: 0.47991 | utility: 0.97536\n",
      "  batch 015 / 029 | loss: 0.33101 | error: 0.47813 | utility: 0.97405\n",
      "  batch 016 / 029 | loss: 0.33780 | error: 0.48242 | utility: 0.97190\n",
      "  batch 017 / 029 | loss: 0.33217 | error: 0.47978 | utility: 0.97231\n",
      "  batch 018 / 029 | loss: 0.33338 | error: 0.48003 | utility: 0.97095\n",
      "  batch 019 / 029 | loss: 0.34690 | error: 0.48684 | utility: 0.96864\n",
      "  batch 020 / 029 | loss: 0.35066 | error: 0.48828 | utility: 0.97194\n",
      "  batch 021 / 029 | loss: 0.35772 | error: 0.49182 | utility: 0.96994\n",
      "  batch 022 / 029 | loss: 0.35855 | error: 0.49219 | utility: 0.97050\n",
      "  batch 023 / 029 | loss: 0.36057 | error: 0.49321 | utility: 0.97242\n",
      "  batch 024 / 029 | loss: 0.36242 | error: 0.49414 | utility: 0.97329\n",
      "  batch 025 / 029 | loss: 0.36105 | error: 0.49312 | utility: 0.96997\n",
      "  batch 026 / 029 | loss: 0.35577 | error: 0.49099 | utility: 0.96909\n",
      "  batch 027 / 029 | loss: 0.35157 | error: 0.48900 | utility: 0.97572\n",
      "  batch 028 / 029 | loss: 0.35383 | error: 0.48996 | utility: 0.97352\n",
      "  batch 029 / 029 | loss: 0.36335 | error: 0.49461 | utility: 0.97467\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 007 / 010 | time: 029 sec | loss: 0.32821 | error: 0.47865 | utility: 0.97988\n",
      "Starting epoch 008 / 010.\n",
      "  batch 001 / 029 | loss: 0.43125 | error: 0.53125 | utility: 0.97557\n",
      "  batch 002 / 029 | loss: 0.31994 | error: 0.47656 | utility: 0.97609\n",
      "  batch 003 / 029 | loss: 0.34365 | error: 0.48438 | utility: 0.97523\n",
      "  batch 004 / 029 | loss: 0.24807 | error: 0.43750 | utility: 0.97750\n",
      "  batch 005 / 029 | loss: 0.28909 | error: 0.45937 | utility: 0.97319\n",
      "  batch 006 / 029 | loss: 0.34125 | error: 0.48438 | utility: 0.97407\n",
      "  batch 007 / 029 | loss: 0.37359 | error: 0.50000 | utility: 0.97433\n",
      "  batch 008 / 029 | loss: 0.37692 | error: 0.50195 | utility: 0.97567\n",
      "  batch 009 / 029 | loss: 0.38227 | error: 0.50521 | utility: 0.97526\n",
      "  batch 010 / 029 | loss: 0.37567 | error: 0.50156 | utility: 0.97466\n",
      "  batch 011 / 029 | loss: 0.39368 | error: 0.50994 | utility: 0.97528\n",
      "  batch 012 / 029 | loss: 0.39704 | error: 0.51172 | utility: 0.97491\n",
      "  batch 013 / 029 | loss: 0.37708 | error: 0.50120 | utility: 0.97472\n",
      "  batch 014 / 029 | loss: 0.36732 | error: 0.49665 | utility: 0.97627\n",
      "  batch 015 / 029 | loss: 0.36574 | error: 0.49583 | utility: 0.97632\n",
      "  batch 016 / 029 | loss: 0.36730 | error: 0.49707 | utility: 0.97686\n",
      "  batch 017 / 029 | loss: 0.37888 | error: 0.50276 | utility: 0.97603\n",
      "  batch 018 / 029 | loss: 0.38914 | error: 0.50781 | utility: 0.97544\n",
      "  batch 019 / 029 | loss: 0.38462 | error: 0.50576 | utility: 0.97575\n",
      "  batch 020 / 029 | loss: 0.38160 | error: 0.50391 | utility: 0.97536\n",
      "  batch 021 / 029 | loss: 0.37328 | error: 0.50000 | utility: 0.97633\n",
      "  batch 022 / 029 | loss: 0.35808 | error: 0.49290 | utility: 0.97175\n",
      "  batch 023 / 029 | loss: 0.35564 | error: 0.49185 | utility: 0.97238\n",
      "  batch 024 / 029 | loss: 0.34791 | error: 0.48828 | utility: 0.97427\n",
      "  batch 025 / 029 | loss: 0.34617 | error: 0.48750 | utility: 0.97158\n",
      "  batch 026 / 029 | loss: 0.34409 | error: 0.48678 | utility: 0.97347\n",
      "  batch 027 / 029 | loss: 0.34932 | error: 0.48900 | utility: 0.96956\n",
      "  batch 028 / 029 | loss: 0.35245 | error: 0.49051 | utility: 0.96583\n",
      "  batch 029 / 029 | loss: 0.35398 | error: 0.49084 | utility: 0.96609\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 008 / 010 | time: 027 sec | loss: 0.35195 | error: 0.49167 | utility: 0.97969\n",
      "Starting epoch 009 / 010.\n",
      "  batch 001 / 029 | loss: 0.33275 | error: 0.48438 | utility: 0.97247\n",
      "  batch 002 / 029 | loss: 0.40543 | error: 0.52344 | utility: 0.97063\n",
      "  batch 003 / 029 | loss: 0.35612 | error: 0.49479 | utility: 0.97286\n",
      "  batch 004 / 029 | loss: 0.30266 | error: 0.46875 | utility: 0.97257\n",
      "  batch 005 / 029 | loss: 0.36937 | error: 0.50000 | utility: 0.97183\n",
      "  batch 006 / 029 | loss: 0.34614 | error: 0.48958 | utility: 0.97406\n",
      "  batch 007 / 029 | loss: 0.32698 | error: 0.47991 | utility: 0.97438\n",
      "  batch 008 / 029 | loss: 0.34031 | error: 0.48633 | utility: 0.97336\n",
      "  batch 009 / 029 | loss: 0.33422 | error: 0.48438 | utility: 0.97526\n",
      "  batch 010 / 029 | loss: 0.34999 | error: 0.49062 | utility: 0.97572\n",
      "  batch 011 / 029 | loss: 0.33402 | error: 0.48153 | utility: 0.97680\n",
      "  batch 012 / 029 | loss: 0.32853 | error: 0.47917 | utility: 0.97818\n",
      "  batch 013 / 029 | loss: 0.32529 | error: 0.47716 | utility: 0.97789\n",
      "  batch 014 / 029 | loss: 0.32423 | error: 0.47656 | utility: 0.97851\n",
      "  batch 015 / 029 | loss: 0.31446 | error: 0.47187 | utility: 0.98084\n",
      "  batch 016 / 029 | loss: 0.33035 | error: 0.47949 | utility: 0.97928\n",
      "  batch 017 / 029 | loss: 0.33425 | error: 0.48162 | utility: 0.97986\n",
      "  batch 018 / 029 | loss: 0.33831 | error: 0.48351 | utility: 0.98015\n",
      "  batch 019 / 029 | loss: 0.34303 | error: 0.48602 | utility: 0.97888\n",
      "  batch 020 / 029 | loss: 0.33558 | error: 0.48281 | utility: 0.97923\n",
      "  batch 021 / 029 | loss: 0.33184 | error: 0.48065 | utility: 0.97709\n",
      "  batch 022 / 029 | loss: 0.33532 | error: 0.48224 | utility: 0.97365\n",
      "  batch 023 / 029 | loss: 0.33404 | error: 0.48166 | utility: 0.97496\n",
      "  batch 024 / 029 | loss: 0.33102 | error: 0.47982 | utility: 0.97208\n",
      "  batch 025 / 029 | loss: 0.33285 | error: 0.48063 | utility: 0.97585\n",
      "  batch 026 / 029 | loss: 0.33748 | error: 0.48317 | utility: 0.97170\n",
      "  batch 027 / 029 | loss: 0.34311 | error: 0.48553 | utility: 0.97309\n",
      "  batch 028 / 029 | loss: 0.35441 | error: 0.49107 | utility: 0.97131\n",
      "  batch 029 / 029 | loss: 0.34538 | error: 0.48707 | utility: 0.97546\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 009 / 010 | time: 026 sec | loss: 0.34468 | error: 0.48646 | utility: 0.97618\n",
      "Ending training due to 4 consecutive epochs without improvement in validation accuracy.\n",
      "Total training time: 5 minutes (292.78598952293396 seconds).\n",
      "Loading model from ./Results/utility/utility_1.000_model.pt.\n",
      "---------- Training with lambda=1.05 ----------\n",
      "Starting epoch 001 / 010.\n",
      "  batch 001 / 029 | loss: 0.41113 | error: 0.40625 | utility: 0.93142\n",
      "  batch 002 / 029 | loss: 0.38151 | error: 0.40625 | utility: 0.93357\n",
      "  batch 003 / 029 | loss: 0.41818 | error: 0.44792 | utility: 0.94055\n",
      "  batch 004 / 029 | loss: 0.39892 | error: 0.45312 | utility: 0.94493\n",
      "  batch 005 / 029 | loss: 0.37535 | error: 0.45312 | utility: 0.94724\n",
      "  batch 006 / 029 | loss: 0.37427 | error: 0.45833 | utility: 0.94576\n",
      "  batch 007 / 029 | loss: 0.38434 | error: 0.46875 | utility: 0.94439\n",
      "  batch 008 / 029 | loss: 0.40080 | error: 0.48047 | utility: 0.94131\n",
      "  batch 009 / 029 | loss: 0.42638 | error: 0.49653 | utility: 0.94630\n",
      "  batch 010 / 029 | loss: 0.41764 | error: 0.49531 | utility: 0.94950\n",
      "  batch 011 / 029 | loss: 0.40043 | error: 0.49006 | utility: 0.95579\n",
      "  batch 012 / 029 | loss: 0.41640 | error: 0.49870 | utility: 0.95173\n",
      "  batch 013 / 029 | loss: 0.40644 | error: 0.49639 | utility: 0.94035\n",
      "  batch 014 / 029 | loss: 0.40911 | error: 0.50000 | utility: 0.95481\n",
      "  batch 015 / 029 | loss: 0.39603 | error: 0.49479 | utility: 0.95135\n",
      "  batch 016 / 029 | loss: 0.39264 | error: 0.49316 | utility: 0.95987\n",
      "  batch 017 / 029 | loss: 0.38919 | error: 0.49357 | utility: 0.94897\n",
      "  batch 018 / 029 | loss: 0.39791 | error: 0.49913 | utility: 0.95717\n",
      "  batch 019 / 029 | loss: 0.40392 | error: 0.50329 | utility: 0.95812\n",
      "  batch 020 / 029 | loss: 0.40709 | error: 0.50625 | utility: 0.96444\n",
      "  batch 021 / 029 | loss: 0.39532 | error: 0.50149 | utility: 0.96921\n",
      "  batch 022 / 029 | loss: 0.37957 | error: 0.49503 | utility: 0.96811\n",
      "  batch 023 / 029 | loss: 0.37507 | error: 0.49389 | utility: 0.96184\n",
      "  batch 024 / 029 | loss: 0.37379 | error: 0.49414 | utility: 0.97077\n",
      "  batch 025 / 029 | loss: 0.36959 | error: 0.49250 | utility: 0.97306\n",
      "  batch 026 / 029 | loss: 0.36563 | error: 0.49099 | utility: 0.97408\n",
      "  batch 027 / 029 | loss: 0.36445 | error: 0.49074 | utility: 0.97525\n",
      "  batch 028 / 029 | loss: 0.36207 | error: 0.49051 | utility: 0.97832\n",
      "  batch 029 / 029 | loss: 0.36028 | error: 0.49084 | utility: 0.97899\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 001 / 010 | time: 024 sec | loss: 0.33232 | error: 0.49688 | utility: 0.98357\n",
      "Saving model to ./Results/utility/utility_1.050_model.pt.\n",
      "Starting epoch 002 / 010.\n",
      "  batch 001 / 029 | loss: 0.41291 | error: 0.53125 | utility: 0.97793\n",
      "  batch 002 / 029 | loss: 0.39189 | error: 0.52344 | utility: 0.97954\n",
      "  batch 003 / 029 | loss: 0.39954 | error: 0.52604 | utility: 0.97884\n",
      "  batch 004 / 029 | loss: 0.37102 | error: 0.51172 | utility: 0.98070\n",
      "  batch 005 / 029 | loss: 0.37056 | error: 0.51250 | utility: 0.97955\n",
      "  batch 006 / 029 | loss: 0.35919 | error: 0.50781 | utility: 0.98004\n",
      "  batch 007 / 029 | loss: 0.37906 | error: 0.51786 | utility: 0.97868\n",
      "  batch 008 / 029 | loss: 0.34484 | error: 0.50195 | utility: 0.97977\n",
      "  batch 009 / 029 | loss: 0.32215 | error: 0.49132 | utility: 0.97905\n",
      "  batch 010 / 029 | loss: 0.29833 | error: 0.47969 | utility: 0.97756\n",
      "  batch 011 / 029 | loss: 0.29345 | error: 0.47727 | utility: 0.97861\n",
      "  batch 012 / 029 | loss: 0.30699 | error: 0.48438 | utility: 0.97527\n",
      "  batch 013 / 029 | loss: 0.31395 | error: 0.48798 | utility: 0.97527\n",
      "  batch 014 / 029 | loss: 0.32297 | error: 0.49107 | utility: 0.97473\n",
      "  batch 015 / 029 | loss: 0.30302 | error: 0.48125 | utility: 0.97772\n",
      "  batch 016 / 029 | loss: 0.29691 | error: 0.47852 | utility: 0.97396\n",
      "  batch 017 / 029 | loss: 0.29522 | error: 0.47794 | utility: 0.97629\n",
      "  batch 018 / 029 | loss: 0.29770 | error: 0.47917 | utility: 0.97733\n",
      "  batch 019 / 029 | loss: 0.30775 | error: 0.48438 | utility: 0.97546\n",
      "  batch 020 / 029 | loss: 0.30024 | error: 0.48047 | utility: 0.97598\n",
      "  batch 021 / 029 | loss: 0.31905 | error: 0.48884 | utility: 0.97665\n",
      "  batch 022 / 029 | loss: 0.31975 | error: 0.48935 | utility: 0.97665\n",
      "  batch 023 / 029 | loss: 0.31759 | error: 0.48845 | utility: 0.97977\n",
      "  batch 024 / 029 | loss: 0.31612 | error: 0.48763 | utility: 0.97847\n",
      "  batch 025 / 029 | loss: 0.32329 | error: 0.49125 | utility: 0.97773\n",
      "  batch 026 / 029 | loss: 0.31985 | error: 0.48978 | utility: 0.97778\n",
      "  batch 027 / 029 | loss: 0.32162 | error: 0.49074 | utility: 0.97797\n",
      "  batch 028 / 029 | loss: 0.32114 | error: 0.49051 | utility: 0.97883\n",
      "  batch 029 / 029 | loss: 0.32090 | error: 0.49084 | utility: 0.97762\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 002 / 010 | time: 029 sec | loss: 0.31850 | error: 0.49167 | utility: 0.98100\n",
      "Validation accuracy improved.\n",
      "Saving model to ./Results/utility/utility_1.050_model.pt.\n",
      "Starting epoch 003 / 010.\n",
      "  batch 001 / 029 | loss: 0.56264 | error: 0.60938 | utility: 0.97564\n",
      "  batch 002 / 029 | loss: 0.41570 | error: 0.53906 | utility: 0.97445\n",
      "  batch 003 / 029 | loss: 0.36275 | error: 0.51562 | utility: 0.97542\n",
      "  batch 004 / 029 | loss: 0.33446 | error: 0.50000 | utility: 0.97505\n",
      "  batch 005 / 029 | loss: 0.33383 | error: 0.50000 | utility: 0.97236\n",
      "  batch 006 / 029 | loss: 0.36012 | error: 0.51302 | utility: 0.97229\n",
      "  batch 007 / 029 | loss: 0.32759 | error: 0.49777 | utility: 0.97308\n",
      "  batch 008 / 029 | loss: 0.35132 | error: 0.50781 | utility: 0.97128\n",
      "  batch 009 / 029 | loss: 0.33660 | error: 0.50174 | utility: 0.96859\n",
      "  batch 010 / 029 | loss: 0.33304 | error: 0.50000 | utility: 0.96926\n",
      "  batch 011 / 029 | loss: 0.34543 | error: 0.50568 | utility: 0.96906\n",
      "  batch 012 / 029 | loss: 0.34898 | error: 0.50651 | utility: 0.96766\n",
      "  batch 013 / 029 | loss: 0.36189 | error: 0.51322 | utility: 0.96158\n",
      "  batch 014 / 029 | loss: 0.34565 | error: 0.50558 | utility: 0.97240\n",
      "  batch 015 / 029 | loss: 0.34013 | error: 0.50208 | utility: 0.96900\n",
      "  batch 016 / 029 | loss: 0.34486 | error: 0.50391 | utility: 0.97128\n",
      "  batch 017 / 029 | loss: 0.34123 | error: 0.50184 | utility: 0.97360\n",
      "  batch 018 / 029 | loss: 0.34246 | error: 0.50174 | utility: 0.96952\n",
      "  batch 019 / 029 | loss: 0.35327 | error: 0.50658 | utility: 0.97488\n",
      "  batch 020 / 029 | loss: 0.34645 | error: 0.50313 | utility: 0.97763\n",
      "  batch 021 / 029 | loss: 0.34147 | error: 0.50074 | utility: 0.97530\n",
      "  batch 022 / 029 | loss: 0.34027 | error: 0.50000 | utility: 0.97727\n",
      "  batch 023 / 029 | loss: 0.33312 | error: 0.49660 | utility: 0.97899\n",
      "  batch 024 / 029 | loss: 0.33739 | error: 0.49870 | utility: 0.97804\n",
      "  batch 025 / 029 | loss: 0.32752 | error: 0.49375 | utility: 0.97849\n",
      "  batch 026 / 029 | loss: 0.33036 | error: 0.49519 | utility: 0.97909\n",
      "  batch 027 / 029 | loss: 0.32712 | error: 0.49363 | utility: 0.97938\n",
      "  batch 028 / 029 | loss: 0.32139 | error: 0.49107 | utility: 0.97907\n",
      "  batch 029 / 029 | loss: 0.31205 | error: 0.48707 | utility: 0.97961\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 003 / 010 | time: 031 sec | loss: 0.30060 | error: 0.48125 | utility: 0.98276\n",
      "Validation accuracy improved.\n",
      "Saving model to ./Results/utility/utility_1.050_model.pt.\n",
      "Starting epoch 004 / 010.\n",
      "  batch 001 / 029 | loss: 0.40751 | error: 0.53125 | utility: 0.97846\n",
      "  batch 002 / 029 | loss: 0.34806 | error: 0.50000 | utility: 0.97771\n",
      "  batch 003 / 029 | loss: 0.27496 | error: 0.46875 | utility: 0.97717\n",
      "  batch 004 / 029 | loss: 0.23276 | error: 0.44922 | utility: 0.97743\n",
      "  batch 005 / 029 | loss: 0.24437 | error: 0.45312 | utility: 0.97641\n",
      "  batch 006 / 029 | loss: 0.25842 | error: 0.46094 | utility: 0.97442\n",
      "  batch 007 / 029 | loss: 0.26871 | error: 0.46652 | utility: 0.97590\n",
      "  batch 008 / 029 | loss: 0.26641 | error: 0.46484 | utility: 0.97320\n",
      "  batch 009 / 029 | loss: 0.29405 | error: 0.47569 | utility: 0.97227\n",
      "  batch 010 / 029 | loss: 0.27298 | error: 0.46719 | utility: 0.97486\n",
      "  batch 011 / 029 | loss: 0.28217 | error: 0.47159 | utility: 0.97238\n",
      "  batch 012 / 029 | loss: 0.30198 | error: 0.48047 | utility: 0.97282\n",
      "  batch 013 / 029 | loss: 0.29247 | error: 0.47716 | utility: 0.97537\n",
      "  batch 014 / 029 | loss: 0.29290 | error: 0.47768 | utility: 0.97373\n",
      "  batch 015 / 029 | loss: 0.29294 | error: 0.47813 | utility: 0.97565\n",
      "  batch 016 / 029 | loss: 0.30513 | error: 0.48340 | utility: 0.97333\n",
      "  batch 017 / 029 | loss: 0.31753 | error: 0.48897 | utility: 0.97337\n",
      "  batch 018 / 029 | loss: 0.31780 | error: 0.48872 | utility: 0.97269\n",
      "  batch 019 / 029 | loss: 0.32048 | error: 0.49013 | utility: 0.97341\n",
      "  batch 020 / 029 | loss: 0.31862 | error: 0.48906 | utility: 0.97299\n",
      "  batch 021 / 029 | loss: 0.31482 | error: 0.48735 | utility: 0.97548\n",
      "  batch 022 / 029 | loss: 0.31523 | error: 0.48722 | utility: 0.97323\n",
      "  batch 023 / 029 | loss: 0.31957 | error: 0.48913 | utility: 0.97404\n",
      "  batch 024 / 029 | loss: 0.32315 | error: 0.49089 | utility: 0.97564\n",
      "  batch 025 / 029 | loss: 0.31861 | error: 0.48875 | utility: 0.97688\n",
      "  batch 026 / 029 | loss: 0.32259 | error: 0.49099 | utility: 0.97786\n",
      "  batch 027 / 029 | loss: 0.32237 | error: 0.49074 | utility: 0.97642\n",
      "  batch 028 / 029 | loss: 0.32201 | error: 0.49051 | utility: 0.97636\n",
      "  batch 029 / 029 | loss: 0.32245 | error: 0.49084 | utility: 0.97329\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 004 / 010 | time: 026 sec | loss: 0.31310 | error: 0.48646 | utility: 0.98148\n",
      "Starting epoch 005 / 010.\n",
      "  batch 001 / 029 | loss: 0.41498 | error: 0.53125 | utility: 0.97810\n",
      "  batch 002 / 029 | loss: 0.36380 | error: 0.50781 | utility: 0.97919\n",
      "  batch 003 / 029 | loss: 0.35478 | error: 0.50521 | utility: 0.97968\n",
      "  batch 004 / 029 | loss: 0.35066 | error: 0.50391 | utility: 0.97949\n",
      "  batch 005 / 029 | loss: 0.38631 | error: 0.52187 | utility: 0.97980\n",
      "  batch 006 / 029 | loss: 0.33858 | error: 0.50000 | utility: 0.97941\n",
      "  batch 007 / 029 | loss: 0.33918 | error: 0.50000 | utility: 0.97909\n",
      "  batch 008 / 029 | loss: 0.33842 | error: 0.50000 | utility: 0.97907\n",
      "  batch 009 / 029 | loss: 0.34404 | error: 0.50174 | utility: 0.97919\n",
      "  batch 010 / 029 | loss: 0.34303 | error: 0.50156 | utility: 0.97674\n",
      "  batch 011 / 029 | loss: 0.34353 | error: 0.50142 | utility: 0.97762\n",
      "  batch 012 / 029 | loss: 0.33718 | error: 0.49870 | utility: 0.97476\n",
      "  batch 013 / 029 | loss: 0.32196 | error: 0.49159 | utility: 0.97233\n",
      "  batch 014 / 029 | loss: 0.34447 | error: 0.50223 | utility: 0.97092\n",
      "  batch 015 / 029 | loss: 0.33055 | error: 0.49479 | utility: 0.97255\n",
      "  batch 016 / 029 | loss: 0.32475 | error: 0.49121 | utility: 0.97184\n",
      "  batch 017 / 029 | loss: 0.32036 | error: 0.48897 | utility: 0.97435\n",
      "  batch 018 / 029 | loss: 0.32294 | error: 0.49045 | utility: 0.97338\n",
      "  batch 019 / 029 | loss: 0.32750 | error: 0.49260 | utility: 0.97345\n",
      "  batch 020 / 029 | loss: 0.32416 | error: 0.49141 | utility: 0.97363\n",
      "  batch 021 / 029 | loss: 0.32575 | error: 0.49256 | utility: 0.97603\n",
      "  batch 022 / 029 | loss: 0.32210 | error: 0.49077 | utility: 0.97664\n",
      "  batch 023 / 029 | loss: 0.31796 | error: 0.48913 | utility: 0.97337\n",
      "  batch 024 / 029 | loss: 0.32152 | error: 0.49089 | utility: 0.97596\n",
      "  batch 025 / 029 | loss: 0.32309 | error: 0.49188 | utility: 0.97585\n",
      "  batch 026 / 029 | loss: 0.32668 | error: 0.49339 | utility: 0.97733\n",
      "  batch 027 / 029 | loss: 0.32472 | error: 0.49248 | utility: 0.97704\n",
      "  batch 028 / 029 | loss: 0.31965 | error: 0.48996 | utility: 0.97634\n",
      "  batch 029 / 029 | loss: 0.32779 | error: 0.49461 | utility: 0.97446\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 005 / 010 | time: 026 sec | loss: 0.29189 | error: 0.47865 | utility: 0.98129\n",
      "Validation accuracy improved.\n",
      "Saving model to ./Results/utility/utility_1.050_model.pt.\n",
      "Starting epoch 006 / 010.\n",
      "  batch 001 / 029 | loss: 0.32427 | error: 0.50000 | utility: 0.97693\n",
      "  batch 002 / 029 | loss: 0.42828 | error: 0.54688 | utility: 0.97258\n",
      "  batch 003 / 029 | loss: 0.37761 | error: 0.52083 | utility: 0.97623\n",
      "  batch 004 / 029 | loss: 0.42124 | error: 0.53906 | utility: 0.97252\n",
      "  batch 005 / 029 | loss: 0.38368 | error: 0.52187 | utility: 0.97304\n",
      "  batch 006 / 029 | loss: 0.36035 | error: 0.51042 | utility: 0.97101\n",
      "  batch 007 / 029 | loss: 0.34711 | error: 0.50446 | utility: 0.97379\n",
      "  batch 008 / 029 | loss: 0.34624 | error: 0.50391 | utility: 0.97499\n",
      "  batch 009 / 029 | loss: 0.32658 | error: 0.49479 | utility: 0.97422\n",
      "  batch 010 / 029 | loss: 0.32097 | error: 0.49219 | utility: 0.97760\n",
      "  batch 011 / 029 | loss: 0.33077 | error: 0.49574 | utility: 0.97808\n",
      "  batch 012 / 029 | loss: 0.30893 | error: 0.48568 | utility: 0.97637\n",
      "  batch 013 / 029 | loss: 0.31587 | error: 0.48918 | utility: 0.97474\n",
      "  batch 014 / 029 | loss: 0.32198 | error: 0.49219 | utility: 0.97495\n",
      "  batch 015 / 029 | loss: 0.31742 | error: 0.49062 | utility: 0.97690\n",
      "  batch 016 / 029 | loss: 0.32903 | error: 0.49512 | utility: 0.97408\n",
      "  batch 017 / 029 | loss: 0.33406 | error: 0.49724 | utility: 0.97514\n",
      "  batch 018 / 029 | loss: 0.33345 | error: 0.49740 | utility: 0.97629\n",
      "  batch 019 / 029 | loss: 0.33771 | error: 0.49918 | utility: 0.97300\n",
      "  batch 020 / 029 | loss: 0.34474 | error: 0.50234 | utility: 0.97405\n",
      "  batch 021 / 029 | loss: 0.33629 | error: 0.49851 | utility: 0.97711\n",
      "  batch 022 / 029 | loss: 0.32596 | error: 0.49361 | utility: 0.97580\n",
      "  batch 023 / 029 | loss: 0.32191 | error: 0.49185 | utility: 0.97660\n",
      "  batch 024 / 029 | loss: 0.31850 | error: 0.49023 | utility: 0.97452\n",
      "  batch 025 / 029 | loss: 0.31618 | error: 0.48875 | utility: 0.97629\n",
      "  batch 026 / 029 | loss: 0.31105 | error: 0.48618 | utility: 0.97714\n",
      "  batch 027 / 029 | loss: 0.31343 | error: 0.48727 | utility: 0.97676\n",
      "  batch 028 / 029 | loss: 0.32136 | error: 0.49107 | utility: 0.97472\n",
      "  batch 029 / 029 | loss: 0.31602 | error: 0.48707 | utility: 0.97337\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 006 / 010 | time: 024 sec | loss: 0.34301 | error: 0.50208 | utility: 0.98284\n",
      "Starting epoch 007 / 010.\n",
      "  batch 001 / 029 | loss: 0.38256 | error: 0.51562 | utility: 0.97994\n",
      "  batch 002 / 029 | loss: 0.46337 | error: 0.55469 | utility: 0.98179\n",
      "  batch 003 / 029 | loss: 0.48229 | error: 0.56250 | utility: 0.98334\n",
      "  batch 004 / 029 | loss: 0.43140 | error: 0.53906 | utility: 0.98324\n",
      "  batch 005 / 029 | loss: 0.37373 | error: 0.51250 | utility: 0.98369\n",
      "  batch 006 / 029 | loss: 0.36402 | error: 0.50781 | utility: 0.98344\n",
      "  batch 007 / 029 | loss: 0.32927 | error: 0.49107 | utility: 0.98344\n",
      "  batch 008 / 029 | loss: 0.34292 | error: 0.49805 | utility: 0.98301\n",
      "  batch 009 / 029 | loss: 0.33500 | error: 0.49479 | utility: 0.98155\n",
      "  batch 010 / 029 | loss: 0.32553 | error: 0.49062 | utility: 0.98188\n",
      "  batch 011 / 029 | loss: 0.31901 | error: 0.48722 | utility: 0.98069\n",
      "  batch 012 / 029 | loss: 0.31217 | error: 0.48438 | utility: 0.97668\n",
      "  batch 013 / 029 | loss: 0.30597 | error: 0.48197 | utility: 0.97698\n",
      "  batch 014 / 029 | loss: 0.30282 | error: 0.47991 | utility: 0.97596\n",
      "  batch 015 / 029 | loss: 0.29862 | error: 0.47813 | utility: 0.97468\n",
      "  batch 016 / 029 | loss: 0.30550 | error: 0.48242 | utility: 0.97250\n",
      "  batch 017 / 029 | loss: 0.29980 | error: 0.47978 | utility: 0.97310\n",
      "  batch 018 / 029 | loss: 0.30099 | error: 0.48003 | utility: 0.97182\n",
      "  batch 019 / 029 | loss: 0.31470 | error: 0.48684 | utility: 0.96975\n",
      "  batch 020 / 029 | loss: 0.31849 | error: 0.48828 | utility: 0.97311\n",
      "  batch 021 / 029 | loss: 0.32564 | error: 0.49182 | utility: 0.97132\n",
      "  batch 022 / 029 | loss: 0.32639 | error: 0.49219 | utility: 0.97211\n",
      "  batch 023 / 029 | loss: 0.32847 | error: 0.49321 | utility: 0.97394\n",
      "  batch 024 / 029 | loss: 0.33030 | error: 0.49414 | utility: 0.97475\n",
      "  batch 025 / 029 | loss: 0.32883 | error: 0.49312 | utility: 0.97220\n",
      "  batch 026 / 029 | loss: 0.32349 | error: 0.49099 | utility: 0.97153\n",
      "  batch 027 / 029 | loss: 0.31924 | error: 0.48900 | utility: 0.97706\n",
      "  batch 028 / 029 | loss: 0.32147 | error: 0.48996 | utility: 0.97527\n",
      "  batch 029 / 029 | loss: 0.33118 | error: 0.49461 | utility: 0.97636\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 007 / 010 | time: 025 sec | loss: 0.29537 | error: 0.47865 | utility: 0.98110\n",
      "Starting epoch 008 / 010.\n",
      "  batch 001 / 029 | loss: 0.40084 | error: 0.53125 | utility: 0.97717\n",
      "  batch 002 / 029 | loss: 0.28726 | error: 0.47656 | utility: 0.97740\n",
      "  batch 003 / 029 | loss: 0.31132 | error: 0.48438 | utility: 0.97653\n",
      "  batch 004 / 029 | loss: 0.21449 | error: 0.43750 | utility: 0.97846\n",
      "  batch 005 / 029 | loss: 0.25627 | error: 0.45937 | utility: 0.97485\n",
      "  batch 006 / 029 | loss: 0.30902 | error: 0.48438 | utility: 0.97513\n",
      "  batch 007 / 029 | loss: 0.34159 | error: 0.50000 | utility: 0.97509\n",
      "  batch 008 / 029 | loss: 0.34509 | error: 0.50195 | utility: 0.97625\n",
      "  batch 009 / 029 | loss: 0.35045 | error: 0.50521 | utility: 0.97595\n",
      "  batch 010 / 029 | loss: 0.34390 | error: 0.50156 | utility: 0.97513\n",
      "  batch 011 / 029 | loss: 0.36204 | error: 0.50994 | utility: 0.97587\n",
      "  batch 012 / 029 | loss: 0.36534 | error: 0.51172 | utility: 0.97572\n",
      "  batch 013 / 029 | loss: 0.34520 | error: 0.50120 | utility: 0.97538\n",
      "  batch 014 / 029 | loss: 0.33533 | error: 0.49665 | utility: 0.97706\n",
      "  batch 015 / 029 | loss: 0.33376 | error: 0.49583 | utility: 0.97709\n",
      "  batch 016 / 029 | loss: 0.33536 | error: 0.49707 | utility: 0.97788\n",
      "  batch 017 / 029 | loss: 0.34700 | error: 0.50276 | utility: 0.97715\n",
      "  batch 018 / 029 | loss: 0.35738 | error: 0.50781 | utility: 0.97682\n",
      "  batch 019 / 029 | loss: 0.35278 | error: 0.50576 | utility: 0.97724\n",
      "  batch 020 / 029 | loss: 0.34963 | error: 0.50391 | utility: 0.97694\n",
      "  batch 021 / 029 | loss: 0.34123 | error: 0.50000 | utility: 0.97789\n",
      "  batch 022 / 029 | loss: 0.32579 | error: 0.49290 | utility: 0.97401\n",
      "  batch 023 / 029 | loss: 0.32330 | error: 0.49185 | utility: 0.97452\n",
      "  batch 024 / 029 | loss: 0.31547 | error: 0.48828 | utility: 0.97606\n",
      "  batch 025 / 029 | loss: 0.31370 | error: 0.48750 | utility: 0.97371\n",
      "  batch 026 / 029 | loss: 0.31166 | error: 0.48678 | utility: 0.97581\n",
      "  batch 027 / 029 | loss: 0.31695 | error: 0.48900 | utility: 0.97189\n",
      "  batch 028 / 029 | loss: 0.32015 | error: 0.49051 | utility: 0.96933\n",
      "  batch 029 / 029 | loss: 0.32160 | error: 0.49084 | utility: 0.96868\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 008 / 010 | time: 027 sec | loss: 0.31953 | error: 0.49167 | utility: 0.98130\n",
      "Starting epoch 009 / 010.\n",
      "  batch 001 / 029 | loss: 0.30125 | error: 0.48438 | utility: 0.97458\n",
      "  batch 002 / 029 | loss: 0.37521 | error: 0.52344 | utility: 0.97300\n",
      "  batch 003 / 029 | loss: 0.32450 | error: 0.49479 | utility: 0.97507\n",
      "  batch 004 / 029 | loss: 0.26962 | error: 0.46875 | utility: 0.97486\n",
      "  batch 005 / 029 | loss: 0.33729 | error: 0.50000 | utility: 0.97393\n",
      "  batch 006 / 029 | loss: 0.31365 | error: 0.48958 | utility: 0.97603\n",
      "  batch 007 / 029 | loss: 0.29401 | error: 0.47991 | utility: 0.97626\n",
      "  batch 008 / 029 | loss: 0.30756 | error: 0.48633 | utility: 0.97537\n",
      "  batch 009 / 029 | loss: 0.30139 | error: 0.48438 | utility: 0.97681\n",
      "  batch 010 / 029 | loss: 0.31720 | error: 0.49062 | utility: 0.97701\n",
      "  batch 011 / 029 | loss: 0.30084 | error: 0.48153 | utility: 0.97790\n",
      "  batch 012 / 029 | loss: 0.29534 | error: 0.47917 | utility: 0.97906\n",
      "  batch 013 / 029 | loss: 0.29201 | error: 0.47716 | utility: 0.97854\n",
      "  batch 014 / 029 | loss: 0.29095 | error: 0.47656 | utility: 0.97910\n",
      "  batch 015 / 029 | loss: 0.28111 | error: 0.47187 | utility: 0.98125\n",
      "  batch 016 / 029 | loss: 0.29719 | error: 0.47949 | utility: 0.97956\n",
      "  batch 017 / 029 | loss: 0.30111 | error: 0.48162 | utility: 0.98020\n",
      "  batch 018 / 029 | loss: 0.30520 | error: 0.48351 | utility: 0.98046\n",
      "  batch 019 / 029 | loss: 0.30998 | error: 0.48602 | utility: 0.97931\n",
      "  batch 020 / 029 | loss: 0.30250 | error: 0.48281 | utility: 0.97972\n",
      "  batch 021 / 029 | loss: 0.29872 | error: 0.48065 | utility: 0.97776\n",
      "  batch 022 / 029 | loss: 0.30228 | error: 0.48224 | utility: 0.97485\n",
      "  batch 023 / 029 | loss: 0.30103 | error: 0.48166 | utility: 0.97604\n",
      "  batch 024 / 029 | loss: 0.29790 | error: 0.47982 | utility: 0.97365\n",
      "  batch 025 / 029 | loss: 0.29981 | error: 0.48063 | utility: 0.97720\n",
      "  batch 026 / 029 | loss: 0.30459 | error: 0.48317 | utility: 0.97351\n",
      "  batch 027 / 029 | loss: 0.31028 | error: 0.48553 | utility: 0.97493\n",
      "  batch 028 / 029 | loss: 0.32182 | error: 0.49107 | utility: 0.97343\n",
      "  batch 029 / 029 | loss: 0.31275 | error: 0.48707 | utility: 0.97734\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 009 / 010 | time: 025 sec | loss: 0.31134 | error: 0.48646 | utility: 0.97828\n",
      "Ending training due to 4 consecutive epochs without improvement in validation accuracy.\n",
      "Total training time: 4 minutes (236.91910696029663 seconds).\n",
      "Loading model from ./Results/utility/utility_1.050_model.pt.\n",
      "---------- Training with lambda=1.1 ----------\n",
      "Starting epoch 001 / 010.\n",
      "  batch 001 / 029 | loss: 0.38907 | error: 0.40625 | utility: 0.93142\n",
      "  batch 002 / 029 | loss: 0.35855 | error: 0.40625 | utility: 0.93357\n",
      "  batch 003 / 029 | loss: 0.39430 | error: 0.44792 | utility: 0.94051\n",
      "  batch 004 / 029 | loss: 0.37404 | error: 0.45312 | utility: 0.94487\n",
      "  batch 005 / 029 | loss: 0.34960 | error: 0.45312 | utility: 0.94714\n",
      "  batch 006 / 029 | loss: 0.34792 | error: 0.45833 | utility: 0.94561\n",
      "  batch 007 / 029 | loss: 0.35757 | error: 0.46875 | utility: 0.94427\n",
      "  batch 008 / 029 | loss: 0.37371 | error: 0.48047 | utility: 0.94121\n",
      "  batch 009 / 029 | loss: 0.39905 | error: 0.49653 | utility: 0.94640\n",
      "  batch 010 / 029 | loss: 0.38983 | error: 0.49531 | utility: 0.94953\n",
      "  batch 011 / 029 | loss: 0.37220 | error: 0.49006 | utility: 0.95587\n",
      "  batch 012 / 029 | loss: 0.38790 | error: 0.49870 | utility: 0.95222\n",
      "  batch 013 / 029 | loss: 0.37763 | error: 0.49639 | utility: 0.94192\n",
      "  batch 014 / 029 | loss: 0.38013 | error: 0.50000 | utility: 0.95541\n",
      "  batch 015 / 029 | loss: 0.36673 | error: 0.49479 | utility: 0.95216\n",
      "  batch 016 / 029 | loss: 0.36303 | error: 0.49316 | utility: 0.96066\n",
      "  batch 017 / 029 | loss: 0.35953 | error: 0.49357 | utility: 0.95000\n",
      "  batch 018 / 029 | loss: 0.36827 | error: 0.49913 | utility: 0.95813\n",
      "  batch 019 / 029 | loss: 0.37433 | error: 0.50329 | utility: 0.95921\n",
      "  batch 020 / 029 | loss: 0.37752 | error: 0.50625 | utility: 0.96561\n",
      "  batch 021 / 029 | loss: 0.36546 | error: 0.50149 | utility: 0.97029\n",
      "  batch 022 / 029 | loss: 0.34942 | error: 0.49503 | utility: 0.96928\n",
      "  batch 023 / 029 | loss: 0.34477 | error: 0.49389 | utility: 0.96347\n",
      "  batch 024 / 029 | loss: 0.34343 | error: 0.49414 | utility: 0.97212\n",
      "  batch 025 / 029 | loss: 0.33909 | error: 0.49250 | utility: 0.97444\n",
      "  batch 026 / 029 | loss: 0.33494 | error: 0.49099 | utility: 0.97548\n",
      "  batch 027 / 029 | loss: 0.33368 | error: 0.49074 | utility: 0.97666\n",
      "  batch 028 / 029 | loss: 0.33128 | error: 0.49051 | utility: 0.97954\n",
      "  batch 029 / 029 | loss: 0.32942 | error: 0.49084 | utility: 0.98010\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 001 / 010 | time: 025 sec | loss: 0.30011 | error: 0.49688 | utility: 0.98459\n",
      "Saving model to ./Results/utility/utility_1.100_model.pt.\n",
      "Starting epoch 002 / 010.\n",
      "  batch 001 / 029 | loss: 0.38088 | error: 0.53125 | utility: 0.97910\n",
      "  batch 002 / 029 | loss: 0.36019 | error: 0.52344 | utility: 0.98066\n",
      "  batch 003 / 029 | loss: 0.36814 | error: 0.52604 | utility: 0.98000\n",
      "  batch 004 / 029 | loss: 0.33933 | error: 0.51172 | utility: 0.98173\n",
      "  batch 005 / 029 | loss: 0.33904 | error: 0.51250 | utility: 0.98060\n",
      "  batch 006 / 029 | loss: 0.32753 | error: 0.50781 | utility: 0.98108\n",
      "  batch 007 / 029 | loss: 0.34773 | error: 0.51786 | utility: 0.97970\n",
      "  batch 008 / 029 | loss: 0.31287 | error: 0.50195 | utility: 0.98068\n",
      "  batch 009 / 029 | loss: 0.28972 | error: 0.49132 | utility: 0.97998\n",
      "  batch 010 / 029 | loss: 0.26550 | error: 0.47969 | utility: 0.97851\n",
      "  batch 011 / 029 | loss: 0.26055 | error: 0.47727 | utility: 0.97946\n",
      "  batch 012 / 029 | loss: 0.27430 | error: 0.48438 | utility: 0.97601\n",
      "  batch 013 / 029 | loss: 0.28135 | error: 0.48798 | utility: 0.97605\n",
      "  batch 014 / 029 | loss: 0.29043 | error: 0.49107 | utility: 0.97513\n",
      "  batch 015 / 029 | loss: 0.27016 | error: 0.48125 | utility: 0.97815\n",
      "  batch 016 / 029 | loss: 0.26407 | error: 0.47852 | utility: 0.97451\n",
      "  batch 017 / 029 | loss: 0.26230 | error: 0.47794 | utility: 0.97655\n",
      "  batch 018 / 029 | loss: 0.26476 | error: 0.47917 | utility: 0.97750\n",
      "  batch 019 / 029 | loss: 0.27494 | error: 0.48438 | utility: 0.97598\n",
      "  batch 020 / 029 | loss: 0.26738 | error: 0.48047 | utility: 0.97662\n",
      "  batch 021 / 029 | loss: 0.28630 | error: 0.48884 | utility: 0.97704\n",
      "  batch 022 / 029 | loss: 0.28696 | error: 0.48935 | utility: 0.97720\n",
      "  batch 023 / 029 | loss: 0.28471 | error: 0.48845 | utility: 0.98041\n",
      "  batch 024 / 029 | loss: 0.28326 | error: 0.48763 | utility: 0.97914\n",
      "  batch 025 / 029 | loss: 0.29054 | error: 0.49125 | utility: 0.97854\n",
      "  batch 026 / 029 | loss: 0.28707 | error: 0.48978 | utility: 0.97873\n",
      "  batch 027 / 029 | loss: 0.28888 | error: 0.49074 | utility: 0.97899\n",
      "  batch 028 / 029 | loss: 0.28837 | error: 0.49051 | utility: 0.97975\n",
      "  batch 029 / 029 | loss: 0.28816 | error: 0.49084 | utility: 0.97874\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 002 / 010 | time: 025 sec | loss: 0.28586 | error: 0.49167 | utility: 0.98199\n",
      "Validation accuracy improved.\n",
      "Saving model to ./Results/utility/utility_1.100_model.pt.\n",
      "Starting epoch 003 / 010.\n",
      "  batch 001 / 029 | loss: 0.53317 | error: 0.60938 | utility: 0.97694\n",
      "  batch 002 / 029 | loss: 0.38343 | error: 0.53906 | utility: 0.97590\n",
      "  batch 003 / 029 | loss: 0.33044 | error: 0.51562 | utility: 0.97684\n",
      "  batch 004 / 029 | loss: 0.30163 | error: 0.50000 | utility: 0.97646\n",
      "  batch 005 / 029 | loss: 0.30126 | error: 0.50000 | utility: 0.97402\n",
      "  batch 006 / 029 | loss: 0.32798 | error: 0.51302 | utility: 0.97394\n",
      "  batch 007 / 029 | loss: 0.29514 | error: 0.49777 | utility: 0.97479\n",
      "  batch 008 / 029 | loss: 0.31909 | error: 0.50781 | utility: 0.97301\n",
      "  batch 009 / 029 | loss: 0.30418 | error: 0.50174 | utility: 0.97058\n",
      "  batch 010 / 029 | loss: 0.30067 | error: 0.50000 | utility: 0.97139\n",
      "  batch 011 / 029 | loss: 0.31328 | error: 0.50568 | utility: 0.97106\n",
      "  batch 012 / 029 | loss: 0.31674 | error: 0.50651 | utility: 0.96963\n",
      "  batch 013 / 029 | loss: 0.32987 | error: 0.51322 | utility: 0.96492\n",
      "  batch 014 / 029 | loss: 0.31338 | error: 0.50558 | utility: 0.97417\n",
      "  batch 015 / 029 | loss: 0.30773 | error: 0.50208 | utility: 0.97119\n",
      "  batch 016 / 029 | loss: 0.31246 | error: 0.50391 | utility: 0.97308\n",
      "  batch 017 / 029 | loss: 0.30876 | error: 0.50184 | utility: 0.97535\n",
      "  batch 018 / 029 | loss: 0.30988 | error: 0.50174 | utility: 0.97163\n",
      "  batch 019 / 029 | loss: 0.32088 | error: 0.50658 | utility: 0.97646\n",
      "  batch 020 / 029 | loss: 0.31400 | error: 0.50313 | utility: 0.97908\n",
      "  batch 021 / 029 | loss: 0.30888 | error: 0.50074 | utility: 0.97705\n",
      "  batch 022 / 029 | loss: 0.30765 | error: 0.50000 | utility: 0.97874\n",
      "  batch 023 / 029 | loss: 0.30045 | error: 0.49660 | utility: 0.98039\n",
      "  batch 024 / 029 | loss: 0.30479 | error: 0.49870 | utility: 0.97954\n",
      "  batch 025 / 029 | loss: 0.29473 | error: 0.49375 | utility: 0.97987\n",
      "  batch 026 / 029 | loss: 0.29762 | error: 0.49519 | utility: 0.98029\n",
      "  batch 027 / 029 | loss: 0.29433 | error: 0.49363 | utility: 0.98035\n",
      "  batch 028 / 029 | loss: 0.28852 | error: 0.49107 | utility: 0.97972\n",
      "  batch 029 / 029 | loss: 0.27902 | error: 0.48707 | utility: 0.98000\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 003 / 010 | time: 026 sec | loss: 0.26682 | error: 0.48125 | utility: 0.98315\n",
      "Validation accuracy improved.\n",
      "Saving model to ./Results/utility/utility_1.100_model.pt.\n",
      "Starting epoch 004 / 010.\n",
      "  batch 001 / 029 | loss: 0.37464 | error: 0.53125 | utility: 0.97884\n",
      "  batch 002 / 029 | loss: 0.31562 | error: 0.50000 | utility: 0.97790\n",
      "  batch 003 / 029 | loss: 0.24182 | error: 0.46875 | utility: 0.97720\n",
      "  batch 004 / 029 | loss: 0.19937 | error: 0.44922 | utility: 0.97762\n",
      "  batch 005 / 029 | loss: 0.21096 | error: 0.45312 | utility: 0.97642\n",
      "  batch 006 / 029 | loss: 0.22511 | error: 0.46094 | utility: 0.97441\n",
      "  batch 007 / 029 | loss: 0.23536 | error: 0.46652 | utility: 0.97602\n",
      "  batch 008 / 029 | loss: 0.23306 | error: 0.46484 | utility: 0.97364\n",
      "  batch 009 / 029 | loss: 0.26093 | error: 0.47569 | utility: 0.97287\n",
      "  batch 010 / 029 | loss: 0.23962 | error: 0.46719 | utility: 0.97532\n",
      "  batch 011 / 029 | loss: 0.24890 | error: 0.47159 | utility: 0.97305\n",
      "  batch 012 / 029 | loss: 0.26885 | error: 0.48047 | utility: 0.97364\n",
      "  batch 013 / 029 | loss: 0.25924 | error: 0.47716 | utility: 0.97633\n",
      "  batch 014 / 029 | loss: 0.25971 | error: 0.47768 | utility: 0.97497\n",
      "  batch 015 / 029 | loss: 0.25976 | error: 0.47813 | utility: 0.97682\n",
      "  batch 016 / 029 | loss: 0.27219 | error: 0.48340 | utility: 0.97504\n",
      "  batch 017 / 029 | loss: 0.28480 | error: 0.48897 | utility: 0.97500\n",
      "  batch 018 / 029 | loss: 0.28501 | error: 0.48872 | utility: 0.97467\n",
      "  batch 019 / 029 | loss: 0.28774 | error: 0.49013 | utility: 0.97547\n",
      "  batch 020 / 029 | loss: 0.28577 | error: 0.48906 | utility: 0.97519\n",
      "  batch 021 / 029 | loss: 0.28186 | error: 0.48735 | utility: 0.97749\n",
      "  batch 022 / 029 | loss: 0.28217 | error: 0.48722 | utility: 0.97571\n",
      "  batch 023 / 029 | loss: 0.28655 | error: 0.48913 | utility: 0.97627\n",
      "  batch 024 / 029 | loss: 0.29019 | error: 0.49089 | utility: 0.97758\n",
      "  batch 025 / 029 | loss: 0.28553 | error: 0.48875 | utility: 0.97855\n",
      "  batch 026 / 029 | loss: 0.28962 | error: 0.49099 | utility: 0.97922\n",
      "  batch 027 / 029 | loss: 0.28937 | error: 0.49074 | utility: 0.97762\n",
      "  batch 028 / 029 | loss: 0.28895 | error: 0.49051 | utility: 0.97742\n",
      "  batch 029 / 029 | loss: 0.28938 | error: 0.49084 | utility: 0.97474\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 004 / 010 | time: 026 sec | loss: 0.28013 | error: 0.48646 | utility: 0.98210\n",
      "Starting epoch 005 / 010.\n",
      "  batch 001 / 029 | loss: 0.38205 | error: 0.53125 | utility: 0.97860\n",
      "  batch 002 / 029 | loss: 0.33119 | error: 0.50781 | utility: 0.97962\n",
      "  batch 003 / 029 | loss: 0.32189 | error: 0.50521 | utility: 0.97976\n",
      "  batch 004 / 029 | loss: 0.31757 | error: 0.50391 | utility: 0.97979\n",
      "  batch 005 / 029 | loss: 0.35342 | error: 0.52187 | utility: 0.98007\n",
      "  batch 006 / 029 | loss: 0.30537 | error: 0.50000 | utility: 0.97960\n",
      "  batch 007 / 029 | loss: 0.30583 | error: 0.50000 | utility: 0.97928\n",
      "  batch 008 / 029 | loss: 0.30501 | error: 0.50000 | utility: 0.97930\n",
      "  batch 009 / 029 | loss: 0.31068 | error: 0.50174 | utility: 0.97950\n",
      "  batch 010 / 029 | loss: 0.30975 | error: 0.50156 | utility: 0.97716\n",
      "  batch 011 / 029 | loss: 0.31031 | error: 0.50142 | utility: 0.97818\n",
      "  batch 012 / 029 | loss: 0.30397 | error: 0.49870 | utility: 0.97553\n",
      "  batch 013 / 029 | loss: 0.28860 | error: 0.49159 | utility: 0.97399\n",
      "  batch 014 / 029 | loss: 0.31151 | error: 0.50223 | utility: 0.97253\n",
      "  batch 015 / 029 | loss: 0.29726 | error: 0.49479 | utility: 0.97419\n",
      "  batch 016 / 029 | loss: 0.29126 | error: 0.49121 | utility: 0.97373\n",
      "  batch 017 / 029 | loss: 0.28678 | error: 0.48897 | utility: 0.97606\n",
      "  batch 018 / 029 | loss: 0.28950 | error: 0.49045 | utility: 0.97531\n",
      "  batch 019 / 029 | loss: 0.29418 | error: 0.49260 | utility: 0.97552\n",
      "  batch 020 / 029 | loss: 0.29087 | error: 0.49141 | utility: 0.97585\n",
      "  batch 021 / 029 | loss: 0.29259 | error: 0.49256 | utility: 0.97789\n",
      "  batch 022 / 029 | loss: 0.28887 | error: 0.49077 | utility: 0.97853\n",
      "  batch 023 / 029 | loss: 0.28472 | error: 0.48913 | utility: 0.97575\n",
      "  batch 024 / 029 | loss: 0.28841 | error: 0.49089 | utility: 0.97783\n",
      "  batch 025 / 029 | loss: 0.29005 | error: 0.49188 | utility: 0.97760\n",
      "  batch 026 / 029 | loss: 0.29371 | error: 0.49339 | utility: 0.97876\n",
      "  batch 027 / 029 | loss: 0.29170 | error: 0.49248 | utility: 0.97846\n",
      "  batch 028 / 029 | loss: 0.28649 | error: 0.48996 | utility: 0.97754\n",
      "  batch 029 / 029 | loss: 0.29482 | error: 0.49461 | utility: 0.97547\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 005 / 010 | time: 026 sec | loss: 0.25830 | error: 0.47865 | utility: 0.98200\n",
      "Validation accuracy improved.\n",
      "Saving model to ./Results/utility/utility_1.100_model.pt.\n",
      "Starting epoch 006 / 010.\n",
      "  batch 001 / 029 | loss: 0.29079 | error: 0.50000 | utility: 0.97743\n",
      "  batch 002 / 029 | loss: 0.39622 | error: 0.54688 | utility: 0.97288\n",
      "  batch 003 / 029 | loss: 0.34513 | error: 0.52083 | utility: 0.97643\n",
      "  batch 004 / 029 | loss: 0.38929 | error: 0.53906 | utility: 0.97255\n",
      "  batch 005 / 029 | loss: 0.35137 | error: 0.52187 | utility: 0.97306\n",
      "  batch 006 / 029 | loss: 0.32792 | error: 0.51042 | utility: 0.97098\n",
      "  batch 007 / 029 | loss: 0.31466 | error: 0.50446 | utility: 0.97403\n",
      "  batch 008 / 029 | loss: 0.31380 | error: 0.50391 | utility: 0.97532\n",
      "  batch 009 / 029 | loss: 0.29393 | error: 0.49479 | utility: 0.97483\n",
      "  batch 010 / 029 | loss: 0.28816 | error: 0.49219 | utility: 0.97821\n",
      "  batch 011 / 029 | loss: 0.29795 | error: 0.49574 | utility: 0.97873\n",
      "  batch 012 / 029 | loss: 0.27592 | error: 0.48568 | utility: 0.97741\n",
      "  batch 013 / 029 | loss: 0.28300 | error: 0.48918 | utility: 0.97619\n",
      "  batch 014 / 029 | loss: 0.28917 | error: 0.49219 | utility: 0.97725\n",
      "  batch 015 / 029 | loss: 0.28457 | error: 0.49062 | utility: 0.97843\n",
      "  batch 016 / 029 | loss: 0.29615 | error: 0.49512 | utility: 0.97594\n",
      "  batch 017 / 029 | loss: 0.30118 | error: 0.49724 | utility: 0.97713\n",
      "  batch 018 / 029 | loss: 0.30065 | error: 0.49740 | utility: 0.97825\n",
      "  batch 019 / 029 | loss: 0.30489 | error: 0.49918 | utility: 0.97537\n",
      "  batch 020 / 029 | loss: 0.31203 | error: 0.50234 | utility: 0.97631\n",
      "  batch 021 / 029 | loss: 0.30352 | error: 0.49851 | utility: 0.97884\n",
      "  batch 022 / 029 | loss: 0.29299 | error: 0.49361 | utility: 0.97758\n",
      "  batch 023 / 029 | loss: 0.28896 | error: 0.49185 | utility: 0.97826\n",
      "  batch 024 / 029 | loss: 0.28551 | error: 0.49023 | utility: 0.97602\n",
      "  batch 025 / 029 | loss: 0.28311 | error: 0.48875 | utility: 0.97748\n",
      "  batch 026 / 029 | loss: 0.27792 | error: 0.48618 | utility: 0.97817\n",
      "  batch 027 / 029 | loss: 0.28032 | error: 0.48727 | utility: 0.97763\n",
      "  batch 028 / 029 | loss: 0.28836 | error: 0.49107 | utility: 0.97571\n",
      "  batch 029 / 029 | loss: 0.28285 | error: 0.48707 | utility: 0.97397\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 006 / 010 | time: 032 sec | loss: 0.31031 | error: 0.50208 | utility: 0.98336\n",
      "Starting epoch 007 / 010.\n",
      "  batch 001 / 029 | loss: 0.35053 | error: 0.51562 | utility: 0.98021\n",
      "  batch 002 / 029 | loss: 0.43225 | error: 0.55469 | utility: 0.98196\n",
      "  batch 003 / 029 | loss: 0.45136 | error: 0.56250 | utility: 0.98347\n",
      "  batch 004 / 029 | loss: 0.39964 | error: 0.53906 | utility: 0.98338\n",
      "  batch 005 / 029 | loss: 0.34113 | error: 0.51250 | utility: 0.98381\n",
      "  batch 006 / 029 | loss: 0.33128 | error: 0.50781 | utility: 0.98351\n",
      "  batch 007 / 029 | loss: 0.29648 | error: 0.49107 | utility: 0.98365\n",
      "  batch 008 / 029 | loss: 0.31021 | error: 0.49805 | utility: 0.98332\n",
      "  batch 009 / 029 | loss: 0.30225 | error: 0.49479 | utility: 0.98194\n",
      "  batch 010 / 029 | loss: 0.29259 | error: 0.49062 | utility: 0.98213\n",
      "  batch 011 / 029 | loss: 0.28595 | error: 0.48722 | utility: 0.98087\n",
      "  batch 012 / 029 | loss: 0.27895 | error: 0.48438 | utility: 0.97704\n",
      "  batch 013 / 029 | loss: 0.27267 | error: 0.48197 | utility: 0.97738\n",
      "  batch 014 / 029 | loss: 0.26949 | error: 0.47991 | utility: 0.97634\n",
      "  batch 015 / 029 | loss: 0.26525 | error: 0.47813 | utility: 0.97514\n",
      "  batch 016 / 029 | loss: 0.27229 | error: 0.48242 | utility: 0.97311\n",
      "  batch 017 / 029 | loss: 0.26658 | error: 0.47978 | utility: 0.97396\n",
      "  batch 018 / 029 | loss: 0.26783 | error: 0.48003 | utility: 0.97268\n",
      "  batch 019 / 029 | loss: 0.28175 | error: 0.48684 | utility: 0.97105\n",
      "  batch 020 / 029 | loss: 0.28559 | error: 0.48828 | utility: 0.97467\n",
      "  batch 021 / 029 | loss: 0.29283 | error: 0.49182 | utility: 0.97309\n",
      "  batch 022 / 029 | loss: 0.29352 | error: 0.49219 | utility: 0.97405\n",
      "  batch 023 / 029 | loss: 0.29567 | error: 0.49321 | utility: 0.97569\n",
      "  batch 024 / 029 | loss: 0.29755 | error: 0.49414 | utility: 0.97644\n",
      "  batch 025 / 029 | loss: 0.29599 | error: 0.49312 | utility: 0.97423\n",
      "  batch 026 / 029 | loss: 0.29058 | error: 0.49099 | utility: 0.97359\n",
      "  batch 027 / 029 | loss: 0.28627 | error: 0.48900 | utility: 0.97829\n",
      "  batch 028 / 029 | loss: 0.28851 | error: 0.48996 | utility: 0.97665\n",
      "  batch 029 / 029 | loss: 0.29838 | error: 0.49461 | utility: 0.97753\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 007 / 010 | time: 040 sec | loss: 0.26217 | error: 0.47865 | utility: 0.98196\n",
      "Starting epoch 008 / 010.\n",
      "  batch 001 / 029 | loss: 0.36941 | error: 0.53125 | utility: 0.97831\n",
      "  batch 002 / 029 | loss: 0.25437 | error: 0.47656 | utility: 0.97824\n",
      "  batch 003 / 029 | loss: 0.27896 | error: 0.48438 | utility: 0.97747\n",
      "  batch 004 / 029 | loss: 0.18124 | error: 0.43750 | utility: 0.97912\n",
      "  batch 005 / 029 | loss: 0.22341 | error: 0.45937 | utility: 0.97616\n",
      "  batch 006 / 029 | loss: 0.27656 | error: 0.48438 | utility: 0.97640\n",
      "  batch 007 / 029 | loss: 0.30958 | error: 0.50000 | utility: 0.97620\n",
      "  batch 008 / 029 | loss: 0.31311 | error: 0.50195 | utility: 0.97725\n",
      "  batch 009 / 029 | loss: 0.31855 | error: 0.50521 | utility: 0.97709\n",
      "  batch 010 / 029 | loss: 0.31185 | error: 0.50156 | utility: 0.97623\n",
      "  batch 011 / 029 | loss: 0.33025 | error: 0.50994 | utility: 0.97699\n",
      "  batch 012 / 029 | loss: 0.33356 | error: 0.51172 | utility: 0.97691\n",
      "  batch 013 / 029 | loss: 0.31294 | error: 0.50120 | utility: 0.97647\n",
      "  batch 014 / 029 | loss: 0.30296 | error: 0.49665 | utility: 0.97801\n",
      "  batch 015 / 029 | loss: 0.30133 | error: 0.49583 | utility: 0.97788\n",
      "  batch 016 / 029 | loss: 0.30291 | error: 0.49707 | utility: 0.97862\n",
      "  batch 017 / 029 | loss: 0.31462 | error: 0.50276 | utility: 0.97774\n",
      "  batch 018 / 029 | loss: 0.32506 | error: 0.50781 | utility: 0.97740\n",
      "  batch 019 / 029 | loss: 0.32045 | error: 0.50576 | utility: 0.97796\n",
      "  batch 020 / 029 | loss: 0.31719 | error: 0.50391 | utility: 0.97750\n",
      "  batch 021 / 029 | loss: 0.30873 | error: 0.50000 | utility: 0.97848\n",
      "  batch 022 / 029 | loss: 0.29312 | error: 0.49290 | utility: 0.97495\n",
      "  batch 023 / 029 | loss: 0.29057 | error: 0.49185 | utility: 0.97546\n",
      "  batch 024 / 029 | loss: 0.28262 | error: 0.48828 | utility: 0.97675\n",
      "  batch 025 / 029 | loss: 0.28084 | error: 0.48750 | utility: 0.97462\n",
      "  batch 026 / 029 | loss: 0.27879 | error: 0.48678 | utility: 0.97696\n",
      "  batch 027 / 029 | loss: 0.28411 | error: 0.48900 | utility: 0.97307\n",
      "  batch 028 / 029 | loss: 0.28734 | error: 0.49051 | utility: 0.97158\n",
      "  batch 029 / 029 | loss: 0.28877 | error: 0.49084 | utility: 0.97010\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 008 / 010 | time: 037 sec | loss: 0.28651 | error: 0.49167 | utility: 0.98247\n",
      "Starting epoch 009 / 010.\n",
      "  batch 001 / 029 | loss: 0.26804 | error: 0.48438 | utility: 0.97620\n",
      "  batch 002 / 029 | loss: 0.34341 | error: 0.52344 | utility: 0.97487\n",
      "  batch 003 / 029 | loss: 0.29152 | error: 0.49479 | utility: 0.97689\n",
      "  batch 004 / 029 | loss: 0.23582 | error: 0.46875 | utility: 0.97679\n",
      "  batch 005 / 029 | loss: 0.30445 | error: 0.50000 | utility: 0.97589\n",
      "  batch 006 / 029 | loss: 0.28049 | error: 0.48958 | utility: 0.97783\n",
      "  batch 007 / 029 | loss: 0.26047 | error: 0.47991 | utility: 0.97793\n",
      "  batch 008 / 029 | loss: 0.27430 | error: 0.48633 | utility: 0.97704\n",
      "  batch 009 / 029 | loss: 0.26811 | error: 0.48438 | utility: 0.97797\n",
      "  batch 010 / 029 | loss: 0.28409 | error: 0.49062 | utility: 0.97804\n",
      "  batch 011 / 029 | loss: 0.26737 | error: 0.48153 | utility: 0.97877\n",
      "  batch 012 / 029 | loss: 0.26187 | error: 0.47917 | utility: 0.97976\n",
      "  batch 013 / 029 | loss: 0.25849 | error: 0.47716 | utility: 0.97894\n",
      "  batch 014 / 029 | loss: 0.25736 | error: 0.47656 | utility: 0.97924\n",
      "  batch 015 / 029 | loss: 0.24738 | error: 0.47187 | utility: 0.98131\n",
      "  batch 016 / 029 | loss: 0.26349 | error: 0.47949 | utility: 0.97910\n",
      "  batch 017 / 029 | loss: 0.26732 | error: 0.48162 | utility: 0.97980\n",
      "  batch 018 / 029 | loss: 0.27137 | error: 0.48351 | utility: 0.97995\n",
      "  batch 019 / 029 | loss: 0.27620 | error: 0.48602 | utility: 0.97875\n",
      "  batch 020 / 029 | loss: 0.26861 | error: 0.48281 | utility: 0.97931\n",
      "  batch 021 / 029 | loss: 0.26495 | error: 0.48065 | utility: 0.97726\n",
      "  batch 022 / 029 | loss: 0.26861 | error: 0.48224 | utility: 0.97468\n",
      "  batch 023 / 029 | loss: 0.26736 | error: 0.48166 | utility: 0.97602\n",
      "  batch 024 / 029 | loss: 0.26421 | error: 0.47982 | utility: 0.97407\n",
      "  batch 025 / 029 | loss: 0.26619 | error: 0.48063 | utility: 0.97774\n",
      "  batch 026 / 029 | loss: 0.27110 | error: 0.48317 | utility: 0.97439\n",
      "  batch 027 / 029 | loss: 0.27686 | error: 0.48553 | utility: 0.97620\n",
      "  batch 028 / 029 | loss: 0.28861 | error: 0.49107 | utility: 0.97490\n",
      "  batch 029 / 029 | loss: 0.27951 | error: 0.48707 | utility: 0.97858\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 009 / 010 | time: 035 sec | loss: 0.27805 | error: 0.48646 | utility: 0.97981\n",
      "Ending training due to 4 consecutive epochs without improvement in validation accuracy.\n",
      "Total training time: 5 minutes (271.0864670276642 seconds).\n",
      "Loading model from ./Results/utility/utility_1.100_model.pt.\n",
      "---------- Training with lambda=1.1500000000000001 ----------\n",
      "Starting epoch 001 / 010.\n",
      "  batch 001 / 029 | loss: 0.36701 | error: 0.40625 | utility: 0.93142\n",
      "  batch 002 / 029 | loss: 0.33559 | error: 0.40625 | utility: 0.93357\n",
      "  batch 003 / 029 | loss: 0.37043 | error: 0.44792 | utility: 0.94047\n",
      "  batch 004 / 029 | loss: 0.34916 | error: 0.45312 | utility: 0.94482\n",
      "  batch 005 / 029 | loss: 0.32385 | error: 0.45312 | utility: 0.94705\n",
      "  batch 006 / 029 | loss: 0.32156 | error: 0.45833 | utility: 0.94547\n",
      "  batch 007 / 029 | loss: 0.33077 | error: 0.46875 | utility: 0.94417\n",
      "  batch 008 / 029 | loss: 0.34658 | error: 0.48047 | utility: 0.94114\n",
      "  batch 009 / 029 | loss: 0.37160 | error: 0.49653 | utility: 0.94650\n",
      "  batch 010 / 029 | loss: 0.36186 | error: 0.49531 | utility: 0.94956\n",
      "  batch 011 / 029 | loss: 0.34377 | error: 0.49006 | utility: 0.95590\n",
      "  batch 012 / 029 | loss: 0.35915 | error: 0.49870 | utility: 0.95254\n",
      "  batch 013 / 029 | loss: 0.34855 | error: 0.49639 | utility: 0.94315\n",
      "  batch 014 / 029 | loss: 0.35083 | error: 0.50000 | utility: 0.95577\n",
      "  batch 015 / 029 | loss: 0.33714 | error: 0.49479 | utility: 0.95265\n",
      "  batch 016 / 029 | loss: 0.33309 | error: 0.49316 | utility: 0.96120\n",
      "  batch 017 / 029 | loss: 0.32950 | error: 0.49357 | utility: 0.95069\n",
      "  batch 018 / 029 | loss: 0.33819 | error: 0.49913 | utility: 0.95878\n",
      "  batch 019 / 029 | loss: 0.34422 | error: 0.50329 | utility: 0.95998\n",
      "  batch 020 / 029 | loss: 0.34736 | error: 0.50625 | utility: 0.96648\n",
      "  batch 021 / 029 | loss: 0.33505 | error: 0.50149 | utility: 0.97113\n",
      "  batch 022 / 029 | loss: 0.31873 | error: 0.49503 | utility: 0.97020\n",
      "  batch 023 / 029 | loss: 0.31394 | error: 0.49389 | utility: 0.96479\n",
      "  batch 024 / 029 | loss: 0.31253 | error: 0.49414 | utility: 0.97320\n",
      "  batch 025 / 029 | loss: 0.30803 | error: 0.49250 | utility: 0.97554\n",
      "  batch 026 / 029 | loss: 0.30374 | error: 0.49099 | utility: 0.97655\n",
      "  batch 027 / 029 | loss: 0.30241 | error: 0.49074 | utility: 0.97772\n",
      "  batch 028 / 029 | loss: 0.29997 | error: 0.49051 | utility: 0.98047\n",
      "  batch 029 / 029 | loss: 0.29797 | error: 0.49084 | utility: 0.98101\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 001 / 010 | time: 040 sec | loss: 0.26728 | error: 0.49688 | utility: 0.98539\n",
      "Saving model to ./Results/utility/utility_1.150_model.pt.\n",
      "Starting epoch 002 / 010.\n",
      "  batch 001 / 029 | loss: 0.34911 | error: 0.53125 | utility: 0.98008\n",
      "  batch 002 / 029 | loss: 0.32832 | error: 0.52344 | utility: 0.98154\n",
      "  batch 003 / 029 | loss: 0.33665 | error: 0.52604 | utility: 0.98091\n",
      "  batch 004 / 029 | loss: 0.30732 | error: 0.51172 | utility: 0.98252\n",
      "  batch 005 / 029 | loss: 0.30700 | error: 0.51250 | utility: 0.98136\n",
      "  batch 006 / 029 | loss: 0.29530 | error: 0.50781 | utility: 0.98184\n",
      "  batch 007 / 029 | loss: 0.31580 | error: 0.51786 | utility: 0.98045\n",
      "  batch 008 / 029 | loss: 0.28030 | error: 0.50195 | utility: 0.98143\n",
      "  batch 009 / 029 | loss: 0.25671 | error: 0.49132 | utility: 0.98067\n",
      "  batch 010 / 029 | loss: 0.23204 | error: 0.47969 | utility: 0.97916\n",
      "  batch 011 / 029 | loss: 0.22702 | error: 0.47727 | utility: 0.98017\n",
      "  batch 012 / 029 | loss: 0.24096 | error: 0.48438 | utility: 0.97661\n",
      "  batch 013 / 029 | loss: 0.24807 | error: 0.48798 | utility: 0.97657\n",
      "  batch 014 / 029 | loss: 0.25721 | error: 0.49107 | utility: 0.97579\n",
      "  batch 015 / 029 | loss: 0.23659 | error: 0.48125 | utility: 0.97890\n",
      "  batch 016 / 029 | loss: 0.23034 | error: 0.47852 | utility: 0.97512\n",
      "  batch 017 / 029 | loss: 0.22851 | error: 0.47794 | utility: 0.97720\n",
      "  batch 018 / 029 | loss: 0.23096 | error: 0.47917 | utility: 0.97807\n",
      "  batch 019 / 029 | loss: 0.24129 | error: 0.48438 | utility: 0.97643\n",
      "  batch 020 / 029 | loss: 0.23366 | error: 0.48047 | utility: 0.97711\n",
      "  batch 021 / 029 | loss: 0.25276 | error: 0.48884 | utility: 0.97730\n",
      "  batch 022 / 029 | loss: 0.25339 | error: 0.48935 | utility: 0.97747\n",
      "  batch 023 / 029 | loss: 0.25107 | error: 0.48845 | utility: 0.98075\n",
      "  batch 024 / 029 | loss: 0.24967 | error: 0.48763 | utility: 0.97940\n",
      "  batch 025 / 029 | loss: 0.25703 | error: 0.49125 | utility: 0.97889\n",
      "  batch 026 / 029 | loss: 0.25354 | error: 0.48978 | utility: 0.97926\n",
      "  batch 027 / 029 | loss: 0.25541 | error: 0.49074 | utility: 0.97957\n",
      "  batch 028 / 029 | loss: 0.25488 | error: 0.49051 | utility: 0.98028\n",
      "  batch 029 / 029 | loss: 0.25468 | error: 0.49084 | utility: 0.97935\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 002 / 010 | time: 038 sec | loss: 0.25266 | error: 0.49167 | utility: 0.98256\n",
      "Validation accuracy improved.\n",
      "Saving model to ./Results/utility/utility_1.150_model.pt.\n",
      "Starting epoch 003 / 010.\n",
      "  batch 001 / 029 | loss: 0.50205 | error: 0.60938 | utility: 0.97766\n",
      "  batch 002 / 029 | loss: 0.35061 | error: 0.53906 | utility: 0.97675\n",
      "  batch 003 / 029 | loss: 0.29757 | error: 0.51562 | utility: 0.97779\n",
      "  batch 004 / 029 | loss: 0.26838 | error: 0.50000 | utility: 0.97740\n",
      "  batch 005 / 029 | loss: 0.26820 | error: 0.50000 | utility: 0.97526\n",
      "  batch 006 / 029 | loss: 0.29530 | error: 0.51302 | utility: 0.97521\n",
      "  batch 007 / 029 | loss: 0.26213 | error: 0.49777 | utility: 0.97622\n",
      "  batch 008 / 029 | loss: 0.28625 | error: 0.50781 | utility: 0.97444\n",
      "  batch 009 / 029 | loss: 0.27126 | error: 0.50174 | utility: 0.97231\n",
      "  batch 010 / 029 | loss: 0.26768 | error: 0.50000 | utility: 0.97322\n",
      "  batch 011 / 029 | loss: 0.28047 | error: 0.50568 | utility: 0.97288\n",
      "  batch 012 / 029 | loss: 0.28383 | error: 0.50651 | utility: 0.97147\n",
      "  batch 013 / 029 | loss: 0.29723 | error: 0.51322 | utility: 0.96784\n",
      "  batch 014 / 029 | loss: 0.28044 | error: 0.50558 | utility: 0.97567\n",
      "  batch 015 / 029 | loss: 0.27461 | error: 0.50208 | utility: 0.97303\n",
      "  batch 016 / 029 | loss: 0.27937 | error: 0.50391 | utility: 0.97484\n",
      "  batch 017 / 029 | loss: 0.27561 | error: 0.50184 | utility: 0.97700\n",
      "  batch 018 / 029 | loss: 0.27660 | error: 0.50174 | utility: 0.97360\n",
      "  batch 019 / 029 | loss: 0.28782 | error: 0.50658 | utility: 0.97796\n",
      "  batch 020 / 029 | loss: 0.28089 | error: 0.50313 | utility: 0.98041\n",
      "  batch 021 / 029 | loss: 0.27567 | error: 0.50074 | utility: 0.97864\n",
      "  batch 022 / 029 | loss: 0.27435 | error: 0.50000 | utility: 0.98011\n",
      "  batch 023 / 029 | loss: 0.26701 | error: 0.49660 | utility: 0.98166\n",
      "  batch 024 / 029 | loss: 0.27144 | error: 0.49870 | utility: 0.98080\n",
      "  batch 025 / 029 | loss: 0.26121 | error: 0.49375 | utility: 0.98110\n",
      "  batch 026 / 029 | loss: 0.26421 | error: 0.49519 | utility: 0.98135\n",
      "  batch 027 / 029 | loss: 0.26092 | error: 0.49363 | utility: 0.98125\n",
      "  batch 028 / 029 | loss: 0.25504 | error: 0.49107 | utility: 0.98052\n",
      "  batch 029 / 029 | loss: 0.24538 | error: 0.48707 | utility: 0.98071\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 003 / 010 | time: 035 sec | loss: 0.23276 | error: 0.48125 | utility: 0.98395\n",
      "Validation accuracy improved.\n",
      "Saving model to ./Results/utility/utility_1.150_model.pt.\n",
      "Starting epoch 004 / 010.\n",
      "  batch 001 / 029 | loss: 0.34322 | error: 0.53125 | utility: 0.97953\n",
      "  batch 002 / 029 | loss: 0.28313 | error: 0.50000 | utility: 0.97857\n",
      "  batch 003 / 029 | loss: 0.20817 | error: 0.46875 | utility: 0.97782\n",
      "  batch 004 / 029 | loss: 0.16529 | error: 0.44922 | utility: 0.97827\n",
      "  batch 005 / 029 | loss: 0.17696 | error: 0.45312 | utility: 0.97704\n",
      "  batch 006 / 029 | loss: 0.19130 | error: 0.46094 | utility: 0.97501\n",
      "  batch 007 / 029 | loss: 0.20169 | error: 0.46652 | utility: 0.97667\n",
      "  batch 008 / 029 | loss: 0.19930 | error: 0.46484 | utility: 0.97449\n",
      "  batch 009 / 029 | loss: 0.22740 | error: 0.47569 | utility: 0.97381\n",
      "  batch 010 / 029 | loss: 0.20581 | error: 0.46719 | utility: 0.97615\n",
      "  batch 011 / 029 | loss: 0.21529 | error: 0.47159 | utility: 0.97395\n",
      "  batch 012 / 029 | loss: 0.23540 | error: 0.48047 | utility: 0.97467\n",
      "  batch 013 / 029 | loss: 0.22573 | error: 0.47716 | utility: 0.97735\n",
      "  batch 014 / 029 | loss: 0.22621 | error: 0.47768 | utility: 0.97620\n",
      "  batch 015 / 029 | loss: 0.22624 | error: 0.47813 | utility: 0.97793\n",
      "  batch 016 / 029 | loss: 0.23877 | error: 0.48340 | utility: 0.97654\n",
      "  batch 017 / 029 | loss: 0.25153 | error: 0.48897 | utility: 0.97644\n",
      "  batch 018 / 029 | loss: 0.25171 | error: 0.48872 | utility: 0.97631\n",
      "  batch 019 / 029 | loss: 0.25451 | error: 0.49013 | utility: 0.97710\n",
      "  batch 020 / 029 | loss: 0.25247 | error: 0.48906 | utility: 0.97691\n",
      "  batch 021 / 029 | loss: 0.24848 | error: 0.48735 | utility: 0.97895\n",
      "  batch 022 / 029 | loss: 0.24875 | error: 0.48722 | utility: 0.97738\n",
      "  batch 023 / 029 | loss: 0.25314 | error: 0.48913 | utility: 0.97773\n",
      "  batch 024 / 029 | loss: 0.25685 | error: 0.49089 | utility: 0.97884\n",
      "  batch 025 / 029 | loss: 0.25212 | error: 0.48875 | utility: 0.97965\n",
      "  batch 026 / 029 | loss: 0.25631 | error: 0.49099 | utility: 0.98020\n",
      "  batch 027 / 029 | loss: 0.25602 | error: 0.49074 | utility: 0.97855\n",
      "  batch 028 / 029 | loss: 0.25558 | error: 0.49051 | utility: 0.97830\n",
      "  batch 029 / 029 | loss: 0.25601 | error: 0.49084 | utility: 0.97558\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 004 / 010 | time: 037 sec | loss: 0.24688 | error: 0.48646 | utility: 0.98251\n",
      "Starting epoch 005 / 010.\n",
      "  batch 001 / 029 | loss: 0.34840 | error: 0.53125 | utility: 0.97866\n",
      "  batch 002 / 029 | loss: 0.29823 | error: 0.50781 | utility: 0.97961\n",
      "  batch 003 / 029 | loss: 0.28827 | error: 0.50521 | utility: 0.97958\n",
      "  batch 004 / 029 | loss: 0.28405 | error: 0.50391 | utility: 0.97955\n",
      "  batch 005 / 029 | loss: 0.32016 | error: 0.52187 | utility: 0.97995\n",
      "  batch 006 / 029 | loss: 0.27197 | error: 0.50000 | utility: 0.97949\n",
      "  batch 007 / 029 | loss: 0.27239 | error: 0.50000 | utility: 0.97921\n",
      "  batch 008 / 029 | loss: 0.27163 | error: 0.50000 | utility: 0.97945\n",
      "  batch 009 / 029 | loss: 0.27733 | error: 0.50174 | utility: 0.97980\n",
      "  batch 010 / 029 | loss: 0.27634 | error: 0.50156 | utility: 0.97760\n",
      "  batch 011 / 029 | loss: 0.27692 | error: 0.50142 | utility: 0.97878\n",
      "  batch 012 / 029 | loss: 0.27049 | error: 0.49870 | utility: 0.97622\n",
      "  batch 013 / 029 | loss: 0.25497 | error: 0.49159 | utility: 0.97546\n",
      "  batch 014 / 029 | loss: 0.27818 | error: 0.50223 | utility: 0.97385\n",
      "  batch 015 / 029 | loss: 0.26371 | error: 0.49479 | utility: 0.97556\n",
      "  batch 016 / 029 | loss: 0.25750 | error: 0.49121 | utility: 0.97529\n",
      "  batch 017 / 029 | loss: 0.25296 | error: 0.48897 | utility: 0.97753\n",
      "  batch 018 / 029 | loss: 0.25578 | error: 0.49045 | utility: 0.97689\n",
      "  batch 019 / 029 | loss: 0.26056 | error: 0.49260 | utility: 0.97714\n",
      "  batch 020 / 029 | loss: 0.25723 | error: 0.49141 | utility: 0.97745\n",
      "  batch 021 / 029 | loss: 0.25903 | error: 0.49256 | utility: 0.97927\n",
      "  batch 022 / 029 | loss: 0.25526 | error: 0.49077 | utility: 0.97977\n",
      "  batch 023 / 029 | loss: 0.25107 | error: 0.48913 | utility: 0.97726\n",
      "  batch 024 / 029 | loss: 0.25485 | error: 0.49089 | utility: 0.97898\n",
      "  batch 025 / 029 | loss: 0.25652 | error: 0.49188 | utility: 0.97872\n",
      "  batch 026 / 029 | loss: 0.26022 | error: 0.49339 | utility: 0.97964\n",
      "  batch 027 / 029 | loss: 0.25817 | error: 0.49248 | utility: 0.97940\n",
      "  batch 028 / 029 | loss: 0.25294 | error: 0.48996 | utility: 0.97842\n",
      "  batch 029 / 029 | loss: 0.26147 | error: 0.49461 | utility: 0.97635\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 005 / 010 | time: 037 sec | loss: 0.22447 | error: 0.47865 | utility: 0.98280\n",
      "Validation accuracy improved.\n",
      "Saving model to ./Results/utility/utility_1.150_model.pt.\n",
      "Starting epoch 006 / 010.\n",
      "  batch 001 / 029 | loss: 0.25742 | error: 0.50000 | utility: 0.97823\n",
      "  batch 002 / 029 | loss: 0.36412 | error: 0.54688 | utility: 0.97369\n",
      "  batch 003 / 029 | loss: 0.31247 | error: 0.52083 | utility: 0.97720\n",
      "  batch 004 / 029 | loss: 0.35696 | error: 0.53906 | utility: 0.97323\n",
      "  batch 005 / 029 | loss: 0.31867 | error: 0.52187 | utility: 0.97348\n",
      "  batch 006 / 029 | loss: 0.29526 | error: 0.51042 | utility: 0.97121\n",
      "  batch 007 / 029 | loss: 0.28256 | error: 0.50446 | utility: 0.97420\n",
      "  batch 008 / 029 | loss: 0.28155 | error: 0.50391 | utility: 0.97549\n",
      "  batch 009 / 029 | loss: 0.26167 | error: 0.49479 | utility: 0.97509\n",
      "  batch 010 / 029 | loss: 0.25568 | error: 0.49219 | utility: 0.97845\n",
      "  batch 011 / 029 | loss: 0.26547 | error: 0.49574 | utility: 0.97898\n",
      "  batch 012 / 029 | loss: 0.24322 | error: 0.48568 | utility: 0.97806\n",
      "  batch 013 / 029 | loss: 0.25037 | error: 0.48918 | utility: 0.97717\n",
      "  batch 014 / 029 | loss: 0.25647 | error: 0.49219 | utility: 0.97860\n",
      "  batch 015 / 029 | loss: 0.25177 | error: 0.49062 | utility: 0.97951\n",
      "  batch 016 / 029 | loss: 0.26321 | error: 0.49512 | utility: 0.97724\n",
      "  batch 017 / 029 | loss: 0.26818 | error: 0.49724 | utility: 0.97847\n",
      "  batch 018 / 029 | loss: 0.26766 | error: 0.49740 | utility: 0.97961\n",
      "  batch 019 / 029 | loss: 0.27188 | error: 0.49918 | utility: 0.97706\n",
      "  batch 020 / 029 | loss: 0.27912 | error: 0.50234 | utility: 0.97799\n",
      "  batch 021 / 029 | loss: 0.27053 | error: 0.49851 | utility: 0.98029\n",
      "  batch 022 / 029 | loss: 0.25983 | error: 0.49361 | utility: 0.97920\n",
      "  batch 023 / 029 | loss: 0.25582 | error: 0.49185 | utility: 0.97989\n",
      "  batch 024 / 029 | loss: 0.25230 | error: 0.49023 | utility: 0.97771\n",
      "  batch 025 / 029 | loss: 0.24980 | error: 0.48875 | utility: 0.97895\n",
      "  batch 026 / 029 | loss: 0.24456 | error: 0.48618 | utility: 0.97938\n",
      "  batch 027 / 029 | loss: 0.24699 | error: 0.48727 | utility: 0.97865\n",
      "  batch 028 / 029 | loss: 0.25516 | error: 0.49107 | utility: 0.97683\n",
      "  batch 029 / 029 | loss: 0.24930 | error: 0.48707 | utility: 0.97485\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 006 / 010 | time: 036 sec | loss: 0.27683 | error: 0.50208 | utility: 0.98397\n",
      "Starting epoch 007 / 010.\n",
      "  batch 001 / 029 | loss: 0.31740 | error: 0.51562 | utility: 0.98063\n",
      "  batch 002 / 029 | loss: 0.39804 | error: 0.55469 | utility: 0.98212\n",
      "  batch 003 / 029 | loss: 0.41715 | error: 0.56250 | utility: 0.98356\n",
      "  batch 004 / 029 | loss: 0.36481 | error: 0.53906 | utility: 0.98321\n",
      "  batch 005 / 029 | loss: 0.30583 | error: 0.51250 | utility: 0.98361\n",
      "  batch 006 / 029 | loss: 0.29550 | error: 0.50781 | utility: 0.98299\n",
      "  batch 007 / 029 | loss: 0.26079 | error: 0.49107 | utility: 0.98331\n",
      "  batch 008 / 029 | loss: 0.27420 | error: 0.49805 | utility: 0.98258\n",
      "  batch 009 / 029 | loss: 0.26677 | error: 0.49479 | utility: 0.98133\n",
      "  batch 010 / 029 | loss: 0.25725 | error: 0.49062 | utility: 0.98164\n",
      "  batch 011 / 029 | loss: 0.25082 | error: 0.48722 | utility: 0.98071\n",
      "  batch 012 / 029 | loss: 0.24381 | error: 0.48438 | utility: 0.97730\n",
      "  batch 013 / 029 | loss: 0.23758 | error: 0.48197 | utility: 0.97811\n",
      "  batch 014 / 029 | loss: 0.23429 | error: 0.47991 | utility: 0.97740\n",
      "  batch 015 / 029 | loss: 0.23007 | error: 0.47813 | utility: 0.97665\n",
      "  batch 016 / 029 | loss: 0.23746 | error: 0.48242 | utility: 0.97512\n",
      "  batch 017 / 029 | loss: 0.23154 | error: 0.47978 | utility: 0.97614\n",
      "  batch 018 / 029 | loss: 0.23274 | error: 0.48003 | utility: 0.97530\n",
      "  batch 019 / 029 | loss: 0.24700 | error: 0.48684 | utility: 0.97391\n",
      "  batch 020 / 029 | loss: 0.25089 | error: 0.48828 | utility: 0.97675\n",
      "  batch 021 / 029 | loss: 0.25827 | error: 0.49182 | utility: 0.97549\n",
      "  batch 022 / 029 | loss: 0.25905 | error: 0.49219 | utility: 0.97632\n",
      "  batch 023 / 029 | loss: 0.26129 | error: 0.49321 | utility: 0.97763\n",
      "  batch 024 / 029 | loss: 0.26324 | error: 0.49414 | utility: 0.97808\n",
      "  batch 025 / 029 | loss: 0.26161 | error: 0.49312 | utility: 0.97624\n",
      "  batch 026 / 029 | loss: 0.25619 | error: 0.49099 | utility: 0.97548\n",
      "  batch 027 / 029 | loss: 0.25184 | error: 0.48900 | utility: 0.97955\n",
      "  batch 028 / 029 | loss: 0.25414 | error: 0.48996 | utility: 0.97805\n",
      "  batch 029 / 029 | loss: 0.26419 | error: 0.49461 | utility: 0.97839\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 007 / 010 | time: 037 sec | loss: 0.22751 | error: 0.47865 | utility: 0.98269\n",
      "Starting epoch 008 / 010.\n",
      "  batch 001 / 029 | loss: 0.33630 | error: 0.53125 | utility: 0.97905\n",
      "  batch 002 / 029 | loss: 0.22012 | error: 0.47656 | utility: 0.97905\n",
      "  batch 003 / 029 | loss: 0.24446 | error: 0.48438 | utility: 0.97818\n",
      "  batch 004 / 029 | loss: 0.14622 | error: 0.43750 | utility: 0.97959\n",
      "  batch 005 / 029 | loss: 0.18885 | error: 0.45937 | utility: 0.97659\n",
      "  batch 006 / 029 | loss: 0.24256 | error: 0.48438 | utility: 0.97667\n",
      "  batch 007 / 029 | loss: 0.27607 | error: 0.50000 | utility: 0.97640\n",
      "  batch 008 / 029 | loss: 0.27963 | error: 0.50195 | utility: 0.97744\n",
      "  batch 009 / 029 | loss: 0.28518 | error: 0.50521 | utility: 0.97744\n",
      "  batch 010 / 029 | loss: 0.27841 | error: 0.50156 | utility: 0.97687\n",
      "  batch 011 / 029 | loss: 0.29705 | error: 0.50994 | utility: 0.97777\n",
      "  batch 012 / 029 | loss: 0.30045 | error: 0.51172 | utility: 0.97788\n",
      "  batch 013 / 029 | loss: 0.27953 | error: 0.50120 | utility: 0.97765\n",
      "  batch 014 / 029 | loss: 0.26945 | error: 0.49665 | utility: 0.97929\n",
      "  batch 015 / 029 | loss: 0.26779 | error: 0.49583 | utility: 0.97932\n",
      "  batch 016 / 029 | loss: 0.26952 | error: 0.49707 | utility: 0.98005\n",
      "  batch 017 / 029 | loss: 0.28141 | error: 0.50276 | utility: 0.97919\n",
      "  batch 018 / 029 | loss: 0.29204 | error: 0.50781 | utility: 0.97891\n",
      "  batch 019 / 029 | loss: 0.28733 | error: 0.50576 | utility: 0.97934\n",
      "  batch 020 / 029 | loss: 0.28404 | error: 0.50391 | utility: 0.97881\n",
      "  batch 021 / 029 | loss: 0.27545 | error: 0.50000 | utility: 0.97964\n",
      "  batch 022 / 029 | loss: 0.25965 | error: 0.49290 | utility: 0.97631\n",
      "  batch 023 / 029 | loss: 0.25715 | error: 0.49185 | utility: 0.97651\n",
      "  batch 024 / 029 | loss: 0.24907 | error: 0.48828 | utility: 0.97774\n",
      "  batch 025 / 029 | loss: 0.24724 | error: 0.48750 | utility: 0.97551\n",
      "  batch 026 / 029 | loss: 0.24522 | error: 0.48678 | utility: 0.97780\n",
      "  batch 027 / 029 | loss: 0.25065 | error: 0.48900 | utility: 0.97388\n",
      "  batch 028 / 029 | loss: 0.25393 | error: 0.49051 | utility: 0.97291\n",
      "  batch 029 / 029 | loss: 0.25545 | error: 0.49084 | utility: 0.97069\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 008 / 010 | time: 037 sec | loss: 0.25320 | error: 0.49167 | utility: 0.98339\n",
      "Starting epoch 009 / 010.\n",
      "  batch 001 / 029 | loss: 0.23481 | error: 0.48438 | utility: 0.97719\n",
      "  batch 002 / 029 | loss: 0.31136 | error: 0.52344 | utility: 0.97584\n",
      "  batch 003 / 029 | loss: 0.25841 | error: 0.49479 | utility: 0.97794\n",
      "  batch 004 / 029 | loss: 0.20201 | error: 0.46875 | utility: 0.97790\n",
      "  batch 005 / 029 | loss: 0.27158 | error: 0.50000 | utility: 0.97701\n",
      "  batch 006 / 029 | loss: 0.24740 | error: 0.48958 | utility: 0.97880\n",
      "  batch 007 / 029 | loss: 0.22700 | error: 0.47991 | utility: 0.97887\n",
      "  batch 008 / 029 | loss: 0.24105 | error: 0.48633 | utility: 0.97793\n",
      "  batch 009 / 029 | loss: 0.23478 | error: 0.48438 | utility: 0.97871\n",
      "  batch 010 / 029 | loss: 0.25093 | error: 0.49062 | utility: 0.97865\n",
      "  batch 011 / 029 | loss: 0.23388 | error: 0.48153 | utility: 0.97935\n",
      "  batch 012 / 029 | loss: 0.22834 | error: 0.47917 | utility: 0.98022\n",
      "  batch 013 / 029 | loss: 0.22497 | error: 0.47716 | utility: 0.97926\n",
      "  batch 014 / 029 | loss: 0.22380 | error: 0.47656 | utility: 0.97950\n",
      "  batch 015 / 029 | loss: 0.21369 | error: 0.47187 | utility: 0.98153\n",
      "  batch 016 / 029 | loss: 0.22991 | error: 0.47949 | utility: 0.97904\n",
      "  batch 017 / 029 | loss: 0.23372 | error: 0.48162 | utility: 0.97979\n",
      "  batch 018 / 029 | loss: 0.23780 | error: 0.48351 | utility: 0.97995\n",
      "  batch 019 / 029 | loss: 0.24268 | error: 0.48602 | utility: 0.97871\n",
      "  batch 020 / 029 | loss: 0.23503 | error: 0.48281 | utility: 0.97939\n",
      "  batch 021 / 029 | loss: 0.23135 | error: 0.48065 | utility: 0.97734\n",
      "  batch 022 / 029 | loss: 0.23507 | error: 0.48224 | utility: 0.97492\n",
      "  batch 023 / 029 | loss: 0.23383 | error: 0.48166 | utility: 0.97639\n",
      "  batch 024 / 029 | loss: 0.23064 | error: 0.47982 | utility: 0.97469\n",
      "  batch 025 / 029 | loss: 0.23265 | error: 0.48063 | utility: 0.97846\n",
      "  batch 026 / 029 | loss: 0.23765 | error: 0.48317 | utility: 0.97533\n",
      "  batch 027 / 029 | loss: 0.24346 | error: 0.48553 | utility: 0.97726\n",
      "  batch 028 / 029 | loss: 0.25538 | error: 0.49107 | utility: 0.97620\n",
      "  batch 029 / 029 | loss: 0.24618 | error: 0.48707 | utility: 0.97979\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 009 / 010 | time: 037 sec | loss: 0.24396 | error: 0.48646 | utility: 0.98120\n",
      "Ending training due to 4 consecutive epochs without improvement in validation accuracy.\n",
      "Total training time: 6 minutes (333.0148468017578 seconds).\n",
      "Loading model from ./Results/utility/utility_1.150_model.pt.\n",
      "---------- Training with lambda=1.2000000000000002 ----------\n",
      "Starting epoch 001 / 010.\n",
      "  batch 001 / 029 | loss: 0.34495 | error: 0.40625 | utility: 0.93142\n",
      "  batch 002 / 029 | loss: 0.31263 | error: 0.40625 | utility: 0.93357\n",
      "  batch 003 / 029 | loss: 0.34656 | error: 0.44792 | utility: 0.94044\n",
      "  batch 004 / 029 | loss: 0.32428 | error: 0.45312 | utility: 0.94477\n",
      "  batch 005 / 029 | loss: 0.29808 | error: 0.45312 | utility: 0.94697\n",
      "  batch 006 / 029 | loss: 0.29516 | error: 0.45833 | utility: 0.94531\n",
      "  batch 007 / 029 | loss: 0.30393 | error: 0.46875 | utility: 0.94404\n",
      "  batch 008 / 029 | loss: 0.31943 | error: 0.48047 | utility: 0.94100\n",
      "  batch 009 / 029 | loss: 0.34416 | error: 0.49653 | utility: 0.94655\n",
      "  batch 010 / 029 | loss: 0.33393 | error: 0.49531 | utility: 0.94950\n",
      "  batch 011 / 029 | loss: 0.31539 | error: 0.49006 | utility: 0.95589\n",
      "  batch 012 / 029 | loss: 0.33045 | error: 0.49870 | utility: 0.95289\n",
      "  batch 013 / 029 | loss: 0.31951 | error: 0.49639 | utility: 0.94435\n",
      "  batch 014 / 029 | loss: 0.32158 | error: 0.50000 | utility: 0.95616\n",
      "  batch 015 / 029 | loss: 0.30755 | error: 0.49479 | utility: 0.95320\n",
      "  batch 016 / 029 | loss: 0.30316 | error: 0.49316 | utility: 0.96174\n",
      "  batch 017 / 029 | loss: 0.29948 | error: 0.49357 | utility: 0.95130\n",
      "  batch 018 / 029 | loss: 0.30815 | error: 0.49913 | utility: 0.95933\n",
      "  batch 019 / 029 | loss: 0.31415 | error: 0.50329 | utility: 0.96059\n",
      "  batch 020 / 029 | loss: 0.31726 | error: 0.50625 | utility: 0.96714\n",
      "  batch 021 / 029 | loss: 0.30470 | error: 0.50149 | utility: 0.97175\n",
      "  batch 022 / 029 | loss: 0.28808 | error: 0.49503 | utility: 0.97089\n",
      "  batch 023 / 029 | loss: 0.28315 | error: 0.49389 | utility: 0.96569\n",
      "  batch 024 / 029 | loss: 0.28164 | error: 0.49414 | utility: 0.97398\n",
      "  batch 025 / 029 | loss: 0.27700 | error: 0.49250 | utility: 0.97636\n",
      "  batch 026 / 029 | loss: 0.27256 | error: 0.49099 | utility: 0.97738\n",
      "  batch 027 / 029 | loss: 0.27115 | error: 0.49074 | utility: 0.97863\n",
      "  batch 028 / 029 | loss: 0.26865 | error: 0.49051 | utility: 0.98133\n",
      "  batch 029 / 029 | loss: 0.26654 | error: 0.49084 | utility: 0.98190\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 001 / 010 | time: 035 sec | loss: 0.23434 | error: 0.49688 | utility: 0.98621\n",
      "Saving model to ./Results/utility/utility_1.200_model.pt.\n",
      "Starting epoch 002 / 010.\n",
      "  batch 001 / 029 | loss: 0.31712 | error: 0.53125 | utility: 0.98105\n",
      "  batch 002 / 029 | loss: 0.29620 | error: 0.52344 | utility: 0.98254\n",
      "  batch 003 / 029 | loss: 0.30494 | error: 0.52604 | utility: 0.98203\n",
      "  batch 004 / 029 | loss: 0.27508 | error: 0.51172 | utility: 0.98357\n",
      "  batch 005 / 029 | loss: 0.27489 | error: 0.51250 | utility: 0.98251\n",
      "  batch 006 / 029 | loss: 0.26308 | error: 0.50781 | utility: 0.98300\n",
      "  batch 007 / 029 | loss: 0.28406 | error: 0.51786 | utility: 0.98172\n",
      "  batch 008 / 029 | loss: 0.24795 | error: 0.50195 | utility: 0.98263\n",
      "  batch 009 / 029 | loss: 0.22384 | error: 0.49132 | utility: 0.98192\n",
      "  batch 010 / 029 | loss: 0.19857 | error: 0.47969 | utility: 0.98053\n",
      "  batch 011 / 029 | loss: 0.19346 | error: 0.47727 | utility: 0.98148\n",
      "  batch 012 / 029 | loss: 0.20772 | error: 0.48438 | utility: 0.97804\n",
      "  batch 013 / 029 | loss: 0.21483 | error: 0.48798 | utility: 0.97793\n",
      "  batch 014 / 029 | loss: 0.22385 | error: 0.49107 | utility: 0.97719\n",
      "  batch 015 / 029 | loss: 0.20277 | error: 0.48125 | utility: 0.98009\n",
      "  batch 016 / 029 | loss: 0.19638 | error: 0.47852 | utility: 0.97635\n",
      "  batch 017 / 029 | loss: 0.19449 | error: 0.47794 | utility: 0.97822\n",
      "  batch 018 / 029 | loss: 0.19697 | error: 0.47917 | utility: 0.97891\n",
      "  batch 019 / 029 | loss: 0.20748 | error: 0.48438 | utility: 0.97713\n",
      "  batch 020 / 029 | loss: 0.19970 | error: 0.48047 | utility: 0.97777\n",
      "  batch 021 / 029 | loss: 0.21904 | error: 0.48884 | utility: 0.97770\n",
      "  batch 022 / 029 | loss: 0.21968 | error: 0.48935 | utility: 0.97783\n",
      "  batch 023 / 029 | loss: 0.21731 | error: 0.48845 | utility: 0.98112\n",
      "  batch 024 / 029 | loss: 0.21592 | error: 0.48763 | utility: 0.97963\n",
      "  batch 025 / 029 | loss: 0.22336 | error: 0.49125 | utility: 0.97925\n",
      "  batch 026 / 029 | loss: 0.21980 | error: 0.48978 | utility: 0.97969\n",
      "  batch 027 / 029 | loss: 0.22168 | error: 0.49074 | utility: 0.98008\n",
      "  batch 028 / 029 | loss: 0.22113 | error: 0.49051 | utility: 0.98076\n",
      "  batch 029 / 029 | loss: 0.22091 | error: 0.49084 | utility: 0.97989\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 002 / 010 | time: 036 sec | loss: 0.21897 | error: 0.49167 | utility: 0.98312\n",
      "Validation accuracy improved.\n",
      "Saving model to ./Results/utility/utility_1.200_model.pt.\n",
      "Starting epoch 003 / 010.\n",
      "  batch 001 / 029 | loss: 0.47109 | error: 0.60938 | utility: 0.97827\n",
      "  batch 002 / 029 | loss: 0.31783 | error: 0.53906 | utility: 0.97752\n",
      "  batch 003 / 029 | loss: 0.26448 | error: 0.51562 | utility: 0.97863\n",
      "  batch 004 / 029 | loss: 0.23484 | error: 0.50000 | utility: 0.97833\n",
      "  batch 005 / 029 | loss: 0.23473 | error: 0.50000 | utility: 0.97645\n",
      "  batch 006 / 029 | loss: 0.26218 | error: 0.51302 | utility: 0.97646\n",
      "  batch 007 / 029 | loss: 0.22885 | error: 0.49777 | utility: 0.97755\n",
      "  batch 008 / 029 | loss: 0.25309 | error: 0.50781 | utility: 0.97588\n",
      "  batch 009 / 029 | loss: 0.23788 | error: 0.50174 | utility: 0.97389\n",
      "  batch 010 / 029 | loss: 0.23430 | error: 0.50000 | utility: 0.97478\n",
      "  batch 011 / 029 | loss: 0.24723 | error: 0.50568 | utility: 0.97443\n",
      "  batch 012 / 029 | loss: 0.25046 | error: 0.50651 | utility: 0.97299\n",
      "  batch 013 / 029 | loss: 0.26406 | error: 0.51322 | utility: 0.97005\n",
      "  batch 014 / 029 | loss: 0.24705 | error: 0.50558 | utility: 0.97694\n",
      "  batch 015 / 029 | loss: 0.24108 | error: 0.50208 | utility: 0.97450\n",
      "  batch 016 / 029 | loss: 0.24586 | error: 0.50391 | utility: 0.97612\n",
      "  batch 017 / 029 | loss: 0.24206 | error: 0.50184 | utility: 0.97817\n",
      "  batch 018 / 029 | loss: 0.24299 | error: 0.50174 | utility: 0.97495\n",
      "  batch 019 / 029 | loss: 0.25438 | error: 0.50658 | utility: 0.97899\n",
      "  batch 020 / 029 | loss: 0.24739 | error: 0.50313 | utility: 0.98130\n",
      "  batch 021 / 029 | loss: 0.24208 | error: 0.50074 | utility: 0.97962\n",
      "  batch 022 / 029 | loss: 0.24072 | error: 0.50000 | utility: 0.98097\n",
      "  batch 023 / 029 | loss: 0.23328 | error: 0.49660 | utility: 0.98243\n",
      "  batch 024 / 029 | loss: 0.23776 | error: 0.49870 | utility: 0.98144\n",
      "  batch 025 / 029 | loss: 0.22741 | error: 0.49375 | utility: 0.98164\n",
      "  batch 026 / 029 | loss: 0.23047 | error: 0.49519 | utility: 0.98186\n",
      "  batch 027 / 029 | loss: 0.22707 | error: 0.49363 | utility: 0.98166\n",
      "  batch 028 / 029 | loss: 0.22109 | error: 0.49107 | utility: 0.98092\n",
      "  batch 029 / 029 | loss: 0.21130 | error: 0.48707 | utility: 0.98102\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 003 / 010 | time: 036 sec | loss: 0.19794 | error: 0.48125 | utility: 0.98447\n",
      "Validation accuracy improved.\n",
      "Saving model to ./Results/utility/utility_1.200_model.pt.\n",
      "Starting epoch 004 / 010.\n",
      "  batch 001 / 029 | loss: 0.30904 | error: 0.53125 | utility: 0.97992\n",
      "  batch 002 / 029 | loss: 0.24870 | error: 0.50000 | utility: 0.97908\n",
      "  batch 003 / 029 | loss: 0.17328 | error: 0.46875 | utility: 0.97830\n",
      "  batch 004 / 029 | loss: 0.12993 | error: 0.44922 | utility: 0.97891\n",
      "  batch 005 / 029 | loss: 0.14168 | error: 0.45312 | utility: 0.97762\n",
      "  batch 006 / 029 | loss: 0.15623 | error: 0.46094 | utility: 0.97576\n",
      "  batch 007 / 029 | loss: 0.16674 | error: 0.46652 | utility: 0.97754\n",
      "  batch 008 / 029 | loss: 0.16436 | error: 0.46484 | utility: 0.97573\n",
      "  batch 009 / 029 | loss: 0.19263 | error: 0.47569 | utility: 0.97523\n",
      "  batch 010 / 029 | loss: 0.17090 | error: 0.46719 | utility: 0.97741\n",
      "  batch 011 / 029 | loss: 0.18059 | error: 0.47159 | utility: 0.97548\n",
      "  batch 012 / 029 | loss: 0.20091 | error: 0.48047 | utility: 0.97615\n",
      "  batch 013 / 029 | loss: 0.19122 | error: 0.47716 | utility: 0.97866\n",
      "  batch 014 / 029 | loss: 0.19175 | error: 0.47768 | utility: 0.97773\n",
      "  batch 015 / 029 | loss: 0.19185 | error: 0.47813 | utility: 0.97928\n",
      "  batch 016 / 029 | loss: 0.20455 | error: 0.48340 | utility: 0.97803\n",
      "  batch 017 / 029 | loss: 0.21738 | error: 0.48897 | utility: 0.97787\n",
      "  batch 018 / 029 | loss: 0.21745 | error: 0.48872 | utility: 0.97757\n",
      "  batch 019 / 029 | loss: 0.22032 | error: 0.49013 | utility: 0.97821\n",
      "  batch 020 / 029 | loss: 0.21829 | error: 0.48906 | utility: 0.97786\n",
      "  batch 021 / 029 | loss: 0.21421 | error: 0.48735 | utility: 0.97975\n",
      "  batch 022 / 029 | loss: 0.21450 | error: 0.48722 | utility: 0.97832\n",
      "  batch 023 / 029 | loss: 0.21892 | error: 0.48913 | utility: 0.97846\n",
      "  batch 024 / 029 | loss: 0.22272 | error: 0.49089 | utility: 0.97943\n",
      "  batch 025 / 029 | loss: 0.21793 | error: 0.48875 | utility: 0.98021\n",
      "  batch 026 / 029 | loss: 0.22220 | error: 0.49099 | utility: 0.98077\n",
      "  batch 027 / 029 | loss: 0.22188 | error: 0.49074 | utility: 0.97918\n",
      "  batch 028 / 029 | loss: 0.22140 | error: 0.49051 | utility: 0.97888\n",
      "  batch 029 / 029 | loss: 0.22185 | error: 0.49084 | utility: 0.97614\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 004 / 010 | time: 036 sec | loss: 0.21219 | error: 0.48646 | utility: 0.98318\n",
      "Starting epoch 005 / 010.\n",
      "  batch 001 / 029 | loss: 0.31438 | error: 0.53125 | utility: 0.97914\n",
      "  batch 002 / 029 | loss: 0.26425 | error: 0.50781 | utility: 0.98010\n",
      "  batch 003 / 029 | loss: 0.25445 | error: 0.50521 | utility: 0.97994\n",
      "  batch 004 / 029 | loss: 0.25023 | error: 0.50391 | utility: 0.97991\n",
      "  batch 005 / 029 | loss: 0.28675 | error: 0.52187 | utility: 0.98030\n",
      "  batch 006 / 029 | loss: 0.23816 | error: 0.50000 | utility: 0.97978\n",
      "  batch 007 / 029 | loss: 0.23853 | error: 0.50000 | utility: 0.97951\n",
      "  batch 008 / 029 | loss: 0.23784 | error: 0.50000 | utility: 0.97977\n",
      "  batch 009 / 029 | loss: 0.24377 | error: 0.50174 | utility: 0.98016\n",
      "  batch 010 / 029 | loss: 0.24274 | error: 0.50156 | utility: 0.97808\n",
      "  batch 011 / 029 | loss: 0.24328 | error: 0.50142 | utility: 0.97936\n",
      "  batch 012 / 029 | loss: 0.23680 | error: 0.49870 | utility: 0.97697\n",
      "  batch 013 / 029 | loss: 0.22114 | error: 0.49159 | utility: 0.97640\n",
      "  batch 014 / 029 | loss: 0.24464 | error: 0.50223 | utility: 0.97472\n",
      "  batch 015 / 029 | loss: 0.22998 | error: 0.49479 | utility: 0.97641\n",
      "  batch 016 / 029 | loss: 0.22371 | error: 0.49121 | utility: 0.97611\n",
      "  batch 017 / 029 | loss: 0.21914 | error: 0.48897 | utility: 0.97830\n",
      "  batch 018 / 029 | loss: 0.22195 | error: 0.49045 | utility: 0.97780\n",
      "  batch 019 / 029 | loss: 0.22680 | error: 0.49260 | utility: 0.97811\n",
      "  batch 020 / 029 | loss: 0.22343 | error: 0.49141 | utility: 0.97851\n",
      "  batch 021 / 029 | loss: 0.22520 | error: 0.49256 | utility: 0.98017\n",
      "  batch 022 / 029 | loss: 0.22139 | error: 0.49077 | utility: 0.98073\n",
      "  batch 023 / 029 | loss: 0.21718 | error: 0.48913 | utility: 0.97851\n",
      "  batch 024 / 029 | loss: 0.22102 | error: 0.49089 | utility: 0.97996\n",
      "  batch 025 / 029 | loss: 0.22275 | error: 0.49188 | utility: 0.97967\n",
      "  batch 026 / 029 | loss: 0.22647 | error: 0.49339 | utility: 0.98050\n",
      "  batch 027 / 029 | loss: 0.22437 | error: 0.49248 | utility: 0.98030\n",
      "  batch 028 / 029 | loss: 0.21904 | error: 0.48996 | utility: 0.97929\n",
      "  batch 029 / 029 | loss: 0.22771 | error: 0.49461 | utility: 0.97724\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 005 / 010 | time: 037 sec | loss: 0.19010 | error: 0.47865 | utility: 0.98365\n",
      "Validation accuracy improved.\n",
      "Saving model to ./Results/utility/utility_1.200_model.pt.\n",
      "Starting epoch 006 / 010.\n",
      "  batch 001 / 029 | loss: 0.22376 | error: 0.50000 | utility: 0.97914\n",
      "  batch 002 / 029 | loss: 0.33239 | error: 0.54688 | utility: 0.97468\n",
      "  batch 003 / 029 | loss: 0.28001 | error: 0.52083 | utility: 0.97809\n",
      "  batch 004 / 029 | loss: 0.32486 | error: 0.53906 | utility: 0.97421\n",
      "  batch 005 / 029 | loss: 0.28589 | error: 0.52187 | utility: 0.97443\n",
      "  batch 006 / 029 | loss: 0.26188 | error: 0.51042 | utility: 0.97216\n",
      "  batch 007 / 029 | loss: 0.24869 | error: 0.50446 | utility: 0.97493\n",
      "  batch 008 / 029 | loss: 0.24781 | error: 0.50391 | utility: 0.97590\n",
      "  batch 009 / 029 | loss: 0.22781 | error: 0.49479 | utility: 0.97525\n",
      "  batch 010 / 029 | loss: 0.22173 | error: 0.49219 | utility: 0.97849\n",
      "  batch 011 / 029 | loss: 0.23159 | error: 0.49574 | utility: 0.97885\n",
      "  batch 012 / 029 | loss: 0.20931 | error: 0.48568 | utility: 0.97791\n",
      "  batch 013 / 029 | loss: 0.21655 | error: 0.48918 | utility: 0.97709\n",
      "  batch 014 / 029 | loss: 0.22255 | error: 0.49219 | utility: 0.97882\n",
      "  batch 015 / 029 | loss: 0.21775 | error: 0.49062 | utility: 0.97961\n",
      "  batch 016 / 029 | loss: 0.22920 | error: 0.49512 | utility: 0.97735\n",
      "  batch 017 / 029 | loss: 0.23409 | error: 0.49724 | utility: 0.97884\n",
      "  batch 018 / 029 | loss: 0.23349 | error: 0.49740 | utility: 0.98008\n",
      "  batch 019 / 029 | loss: 0.23773 | error: 0.49918 | utility: 0.97779\n",
      "  batch 020 / 029 | loss: 0.24505 | error: 0.50234 | utility: 0.97891\n",
      "  batch 021 / 029 | loss: 0.23641 | error: 0.49851 | utility: 0.98113\n",
      "  batch 022 / 029 | loss: 0.22566 | error: 0.49361 | utility: 0.98026\n",
      "  batch 023 / 029 | loss: 0.22168 | error: 0.49185 | utility: 0.98104\n",
      "  batch 024 / 029 | loss: 0.21817 | error: 0.49023 | utility: 0.97910\n",
      "  batch 025 / 029 | loss: 0.21559 | error: 0.48875 | utility: 0.98023\n",
      "  batch 026 / 029 | loss: 0.21026 | error: 0.48618 | utility: 0.98073\n",
      "  batch 027 / 029 | loss: 0.21273 | error: 0.48727 | utility: 0.98018\n",
      "  batch 028 / 029 | loss: 0.22103 | error: 0.49107 | utility: 0.97854\n",
      "  batch 029 / 029 | loss: 0.21491 | error: 0.48707 | utility: 0.97661\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 006 / 010 | time: 036 sec | loss: 0.24397 | error: 0.50208 | utility: 0.98481\n",
      "Starting epoch 007 / 010.\n",
      "  batch 001 / 029 | loss: 0.28411 | error: 0.51562 | utility: 0.98157\n",
      "  batch 002 / 029 | loss: 0.36717 | error: 0.55469 | utility: 0.98275\n",
      "  batch 003 / 029 | loss: 0.38683 | error: 0.56250 | utility: 0.98395\n",
      "  batch 004 / 029 | loss: 0.33319 | error: 0.53906 | utility: 0.98355\n",
      "  batch 005 / 029 | loss: 0.27312 | error: 0.51250 | utility: 0.98388\n",
      "  batch 006 / 029 | loss: 0.26259 | error: 0.50781 | utility: 0.98306\n",
      "  batch 007 / 029 | loss: 0.22744 | error: 0.49107 | utility: 0.98342\n",
      "  batch 008 / 029 | loss: 0.24074 | error: 0.49805 | utility: 0.98282\n",
      "  batch 009 / 029 | loss: 0.23317 | error: 0.49479 | utility: 0.98145\n",
      "  batch 010 / 029 | loss: 0.22344 | error: 0.49062 | utility: 0.98164\n",
      "  batch 011 / 029 | loss: 0.21690 | error: 0.48722 | utility: 0.98059\n",
      "  batch 012 / 029 | loss: 0.20982 | error: 0.48438 | utility: 0.97727\n",
      "  batch 013 / 029 | loss: 0.20353 | error: 0.48197 | utility: 0.97819\n",
      "  batch 014 / 029 | loss: 0.20021 | error: 0.47991 | utility: 0.97752\n",
      "  batch 015 / 029 | loss: 0.19588 | error: 0.47813 | utility: 0.97677\n",
      "  batch 016 / 029 | loss: 0.20336 | error: 0.48242 | utility: 0.97517\n",
      "  batch 017 / 029 | loss: 0.19739 | error: 0.47978 | utility: 0.97642\n",
      "  batch 018 / 029 | loss: 0.19862 | error: 0.48003 | utility: 0.97562\n",
      "  batch 019 / 029 | loss: 0.21310 | error: 0.48684 | utility: 0.97449\n",
      "  batch 020 / 029 | loss: 0.21701 | error: 0.48828 | utility: 0.97755\n",
      "  batch 021 / 029 | loss: 0.22448 | error: 0.49182 | utility: 0.97645\n",
      "  batch 022 / 029 | loss: 0.22527 | error: 0.49219 | utility: 0.97748\n",
      "  batch 023 / 029 | loss: 0.22757 | error: 0.49321 | utility: 0.97865\n",
      "  batch 024 / 029 | loss: 0.22956 | error: 0.49414 | utility: 0.97905\n",
      "  batch 025 / 029 | loss: 0.22784 | error: 0.49312 | utility: 0.97764\n",
      "  batch 026 / 029 | loss: 0.22241 | error: 0.49099 | utility: 0.97690\n",
      "  batch 027 / 029 | loss: 0.21797 | error: 0.48900 | utility: 0.98062\n",
      "  batch 028 / 029 | loss: 0.22026 | error: 0.48996 | utility: 0.97924\n",
      "  batch 029 / 029 | loss: 0.23041 | error: 0.49461 | utility: 0.97929\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 007 / 010 | time: 036 sec | loss: 0.19331 | error: 0.47865 | utility: 0.98340\n",
      "Starting epoch 008 / 010.\n",
      "  batch 001 / 029 | loss: 0.30292 | error: 0.53125 | utility: 0.98000\n",
      "  batch 002 / 029 | loss: 0.18586 | error: 0.47656 | utility: 0.97993\n",
      "  batch 003 / 029 | loss: 0.21012 | error: 0.48438 | utility: 0.97906\n",
      "  batch 004 / 029 | loss: 0.11124 | error: 0.43750 | utility: 0.98027\n",
      "  batch 005 / 029 | loss: 0.15435 | error: 0.45937 | utility: 0.97744\n",
      "  batch 006 / 029 | loss: 0.20849 | error: 0.48438 | utility: 0.97740\n",
      "  batch 007 / 029 | loss: 0.24246 | error: 0.50000 | utility: 0.97707\n",
      "  batch 008 / 029 | loss: 0.24601 | error: 0.50195 | utility: 0.97796\n",
      "  batch 009 / 029 | loss: 0.25167 | error: 0.50521 | utility: 0.97804\n",
      "  batch 010 / 029 | loss: 0.24469 | error: 0.50156 | utility: 0.97770\n",
      "  batch 011 / 029 | loss: 0.26352 | error: 0.50994 | utility: 0.97844\n",
      "  batch 012 / 029 | loss: 0.26695 | error: 0.51172 | utility: 0.97855\n",
      "  batch 013 / 029 | loss: 0.24581 | error: 0.50120 | utility: 0.97831\n",
      "  batch 014 / 029 | loss: 0.23564 | error: 0.49665 | utility: 0.97992\n",
      "  batch 015 / 029 | loss: 0.23397 | error: 0.49583 | utility: 0.97989\n",
      "  batch 016 / 029 | loss: 0.23576 | error: 0.49707 | utility: 0.98072\n",
      "  batch 017 / 029 | loss: 0.24781 | error: 0.50276 | utility: 0.97989\n",
      "  batch 018 / 029 | loss: 0.25856 | error: 0.50781 | utility: 0.97971\n",
      "  batch 019 / 029 | loss: 0.25379 | error: 0.50576 | utility: 0.98019\n",
      "  batch 020 / 029 | loss: 0.25045 | error: 0.50391 | utility: 0.97967\n",
      "  batch 021 / 029 | loss: 0.24177 | error: 0.50000 | utility: 0.98049\n",
      "  batch 022 / 029 | loss: 0.22576 | error: 0.49290 | utility: 0.97748\n",
      "  batch 023 / 029 | loss: 0.22328 | error: 0.49185 | utility: 0.97758\n",
      "  batch 024 / 029 | loss: 0.21506 | error: 0.48828 | utility: 0.97884\n",
      "  batch 025 / 029 | loss: 0.21319 | error: 0.48750 | utility: 0.97674\n",
      "  batch 026 / 029 | loss: 0.21120 | error: 0.48678 | utility: 0.97901\n",
      "  batch 027 / 029 | loss: 0.21672 | error: 0.48900 | utility: 0.97534\n",
      "  batch 028 / 029 | loss: 0.22007 | error: 0.49051 | utility: 0.97486\n",
      "  batch 029 / 029 | loss: 0.22154 | error: 0.49084 | utility: 0.97226\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 008 / 010 | time: 037 sec | loss: 0.21941 | error: 0.49167 | utility: 0.98443\n",
      "Starting epoch 009 / 010.\n",
      "  batch 001 / 029 | loss: 0.20089 | error: 0.48438 | utility: 0.97852\n",
      "  batch 002 / 029 | loss: 0.27875 | error: 0.52344 | utility: 0.97724\n",
      "  batch 003 / 029 | loss: 0.22488 | error: 0.49479 | utility: 0.97923\n",
      "  batch 004 / 029 | loss: 0.16784 | error: 0.46875 | utility: 0.97912\n",
      "  batch 005 / 029 | loss: 0.23844 | error: 0.50000 | utility: 0.97814\n",
      "  batch 006 / 029 | loss: 0.21404 | error: 0.48958 | utility: 0.97967\n",
      "  batch 007 / 029 | loss: 0.19331 | error: 0.47991 | utility: 0.97965\n",
      "  batch 008 / 029 | loss: 0.20751 | error: 0.48633 | utility: 0.97866\n",
      "  batch 009 / 029 | loss: 0.20111 | error: 0.48438 | utility: 0.97936\n",
      "  batch 010 / 029 | loss: 0.21743 | error: 0.49062 | utility: 0.97920\n",
      "  batch 011 / 029 | loss: 0.20006 | error: 0.48153 | utility: 0.98001\n",
      "  batch 012 / 029 | loss: 0.19446 | error: 0.47917 | utility: 0.98083\n",
      "  batch 013 / 029 | loss: 0.19107 | error: 0.47716 | utility: 0.97982\n",
      "  batch 014 / 029 | loss: 0.18988 | error: 0.47656 | utility: 0.98003\n",
      "  batch 015 / 029 | loss: 0.17961 | error: 0.47187 | utility: 0.98208\n",
      "  batch 016 / 029 | loss: 0.19600 | error: 0.47949 | utility: 0.97955\n",
      "  batch 017 / 029 | loss: 0.19986 | error: 0.48162 | utility: 0.98037\n",
      "  batch 018 / 029 | loss: 0.20400 | error: 0.48351 | utility: 0.98059\n",
      "  batch 019 / 029 | loss: 0.20896 | error: 0.48602 | utility: 0.97946\n",
      "  batch 020 / 029 | loss: 0.20121 | error: 0.48281 | utility: 0.98016\n",
      "  batch 021 / 029 | loss: 0.19742 | error: 0.48065 | utility: 0.97818\n",
      "  batch 022 / 029 | loss: 0.20117 | error: 0.48224 | utility: 0.97581\n",
      "  batch 023 / 029 | loss: 0.19992 | error: 0.48166 | utility: 0.97716\n",
      "  batch 024 / 029 | loss: 0.19671 | error: 0.47982 | utility: 0.97549\n",
      "  batch 025 / 029 | loss: 0.19877 | error: 0.48063 | utility: 0.97907\n",
      "  batch 026 / 029 | loss: 0.20384 | error: 0.48317 | utility: 0.97594\n",
      "  batch 027 / 029 | loss: 0.20972 | error: 0.48553 | utility: 0.97793\n",
      "  batch 028 / 029 | loss: 0.22180 | error: 0.49107 | utility: 0.97685\n",
      "  batch 029 / 029 | loss: 0.21254 | error: 0.48707 | utility: 0.98037\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "epoch 009 / 010 | time: 038 sec | loss: 0.21030 | error: 0.48646 | utility: 0.98199\n",
      "Ending training due to 4 consecutive epochs without improvement in validation accuracy.\n",
      "Total training time: 5 minutes (327.3783628940582 seconds).\n",
      "Loading model from ./Results/utility/utility_1.200_model.pt.\n",
      "Test took 126.38316003878911 minutes (7582.989602327347 seconds).\n"
     ]
    }
   ],
   "source": [
    "init_time = time.time()\n",
    "\n",
    "results = {\n",
    "    \"lambdas\": [],\n",
    "    \"accuracies\": [],\n",
    "    \"utilities\": []\n",
    "}\n",
    "\n",
    "print(f\"---------- Training with lambda={0:.3f} ----------\")\n",
    "model_name = f\"utility_{0:.3f}\"\n",
    "utility = Utility(0, quad_cost_torch, cost_const_kwargs={\"scale\": scale})  # Create utility from outside since reg=0.\n",
    "benchmark_model = StrategicModel(x_dim, batch_size, cost_fn=\"quad\", cost_const_kwargs={\"scale\": scale}, \n",
    "                                 social_measure_dict={\"utility\": utility}, strategic=True)\n",
    "benchmark_model.fit(X, Y, Xval, Yval, opt_class=torch.optim.Adam, opt_kwargs={\"lr\": 5e-2}, epochs=epochs,\n",
    "                    verbose=\"batches\", path=PATH, model_name=model_name)\n",
    "\n",
    "results[\"lambdas\"].append(0)\n",
    "accuracy = benchmark_model.evaluate(Xtest, Ytest, strategic_data=True)\n",
    "results[\"accuracies\"].append(accuracy)\n",
    "Xtest_opt, Ytest_pred = benchmark_model.forward(Xtest, requires_grad=False)\n",
    "utility = benchmark_model.social_measure_dict[\"utility\"].calc_utility(Xtest, Xtest_opt, Ytest_pred, requires_grad=False).item()\n",
    "results[\"utilities\"].append(utility)\n",
    "pd.DataFrame(results).to_csv(f\"{PATH}/results.csv\")\n",
    "\n",
    "for lamb in lambda_range:\n",
    "    print(f\"---------- Training with lambda={lamb:.3f} ----------\")\n",
    "    model_name = f\"utility_{lamb:.3f}\"\n",
    "    model = StrategicModel(x_dim, batch_size, cost_fn=\"quad\", cost_const_kwargs={\"scale\": scale}, utility_reg=lamb, strategic=True)\n",
    "    model.fit(X, Y, Xval, Yval, opt_class=torch.optim.Adam, opt_kwargs={\"lr\": 5e-2}, epochs=epochs,\n",
    "              verbose=\"batches\", path=PATH, model_name=model_name)\n",
    "    \n",
    "    # Calculate and save results.\n",
    "    results[\"lambdas\"].append(lamb)\n",
    "    accuracy = model.evaluate(Xtest, Ytest, strategic_data=True)\n",
    "    results[\"accuracies\"].append(accuracy)\n",
    "    Xtest_opt, Ytest_pred = model.forward(Xtest, requires_grad=False)\n",
    "    utility = model.social_measure_dict[\"utility\"].calc_utility(Xtest, Xtest_opt, Ytest_pred, requires_grad=False).item()\n",
    "    results[\"utilities\"].append(utility)\n",
    "    pd.DataFrame(results).to_csv(f\"{PATH}/results.csv\")\n",
    "\n",
    "final_time = time.time()\n",
    "total_time = final_time - init_time\n",
    "print(f\"Test took {total_time / 60} minutes ({total_time} seconds).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1728x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = pd.read_csv(\"Results/utility/results.csv\")\n",
    "accuracies = results[\"accuracies\"].to_list()\n",
    "utilities = results[\"utilities\"].to_list()\n",
    "benchmark = accuracies[0]\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(24, 6))\n",
    "\n",
    "_ = ax.set_xlabel(\"utility\")\n",
    "_ = ax.set_xlim([0, 1])\n",
    "_ = ax.set_ylabel(\"accuracy\")\n",
    "_ = ax.set_title(\"Expected utility tradeoff\")\n",
    "_ = ax.axhline(y=benchmark, linewidth=3, linestyle=\"--\", color=\"gray\", label=\"Benchmark\")\n",
    "_ = ax.plot(utilities, accuracies, 'o',  label=\"SERM\")\n",
    "_ = ax.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
