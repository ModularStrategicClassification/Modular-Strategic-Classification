{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from lib.StrategicModel import StrategicModel\n",
    "import DataGeneration as data\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "matplotlib.rc('font', size=14)\n",
    "\n",
    "PATH = \"./results/vanilla\"\n",
    "if not os.path.exists(PATH):\n",
    "    os.makedirs(PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_datas = []\n",
    "\n",
    "# credit dataset\n",
    "X, Y = data.load_credit_default_data()\n",
    "X, Y = X[:3000], Y[:3000]\n",
    "X, Y, Xval, Yval, Xtest, Ytest = data.split_validation_test(X, Y)\n",
    "training_datas.append({\"X\": X,\n",
    "                        \"Y\": Y,\n",
    "                        \"Xval\": Xval,\n",
    "                        \"Yval\": Yval,\n",
    "                        \"Xtest\": Xtest,\n",
    "                        \"Ytest\": Ytest,\n",
    "                        \"epochs\": 16,\n",
    "                        \"batch_size\": 64,\n",
    "                        \"train_slope\": 1,\n",
    "                        \"eval_slope\": 5,\n",
    "                        \"name\": \"credit\"})\n",
    "\n",
    "# distress dataset\n",
    "X, Y = data.load_financial_distress_data()\n",
    "X, Y, Xval, Yval, Xtest, Ytest = data.split_validation_test(X, Y)\n",
    "training_datas.append({\"X\": X,\n",
    "                        \"Y\": Y,\n",
    "                        \"Xval\": Xval,\n",
    "                        \"Yval\": Yval,\n",
    "                        \"Xtest\": Xtest,\n",
    "                        \"Ytest\": Ytest,\n",
    "                        \"epochs\": 16,\n",
    "                        \"batch_size\": 24,\n",
    "                        \"train_slope\": 1,\n",
    "                        \"eval_slope\": 5,\n",
    "                        \"name\": \"distress\"})\n",
    "\n",
    "# fraud dataset\n",
    "X, Y = data.load_card_fraud_data()\n",
    "X, Y, Xval, Yval, Xtest, Ytest = data.split_validation_test(X, Y)\n",
    "training_datas.append({\"X\": X,\n",
    "                       \"Y\": Y,\n",
    "                       \"Xval\": Xval,\n",
    "                       \"Yval\": Yval,\n",
    "                       \"Xtest\": Xtest,\n",
    "                       \"Ytest\": Ytest,\n",
    "                       \"epochs\": 16,\n",
    "                       \"batch_size\": 24,\n",
    "                       \"train_slope\": 1,\n",
    "                       \"eval_slope\": 3, \n",
    "                       \"name\": \"fraud\"})\n",
    "\n",
    "# spam dataset\n",
    "X, Y = data.load_spam_data()\n",
    "X, Y, Xval, Yval, Xtest, Ytest = data.split_validation_test(X, Y)\n",
    "training_datas.append({\"X\": X,\n",
    "                       \"Y\": Y,\n",
    "                       \"Xval\": Xval,\n",
    "                       \"Yval\": Yval,\n",
    "                       \"Xtest\": Xtest,\n",
    "                       \"Ytest\": Ytest,\n",
    "                       \"epochs\": 16,\n",
    "                       \"batch_size\": 128,\n",
    "                       \"train_slope\": 1,\n",
    "                       \"eval_slope\": 5,\n",
    "                       \"name\": \"spam\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "scales = [0.5, 1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Training non-strategically on credit with scale=0.5 ----------\n",
      "Starting epoch 001 / 016.\n",
      "Ended epoch 001 / 016 | time: 000 sec | loss: 0.71456 | error: 0.32604\n",
      "Model saved to ./results/vanilla/credit_0.5_non_strategic_model.pt.\n",
      "Starting epoch 002 / 016.\n",
      "Ended epoch 002 / 016 | time: 000 sec | loss: 0.68898 | error: 0.32760\n",
      "Starting epoch 003 / 016.\n",
      "Ended epoch 003 / 016 | time: 000 sec | loss: 0.68415 | error: 0.32917\n",
      "Starting epoch 004 / 016.\n",
      "Ended epoch 004 / 016 | time: 000 sec | loss: 0.69316 | error: 0.32760\n",
      "Starting epoch 005 / 016.\n",
      "Ended epoch 005 / 016 | time: 000 sec | loss: 0.68865 | error: 0.32917\n",
      "Ending training due to 4 consecutive epochs without improvement in validation accuracy.\n",
      "Total training time: 0.23337674140930176 seconds.\n",
      "Model loaded from ./results/vanilla/credit_0.5_non_strategic_model.pt.\n",
      "---------- Training strategically on credit with scale=0.5 ----------\n",
      "Starting epoch 001 / 016.\n",
      "  Ended batch 001 / 029 | loss: 0.82353 | error: 0.39062\n",
      "  Ended batch 002 / 029 | loss: 1.43071 | error: 0.51562\n",
      "  Ended batch 003 / 029 | loss: 0.95340 | error: 0.39062\n",
      "  Ended batch 004 / 029 | loss: 1.10748 | error: 0.51562\n",
      "  Ended batch 005 / 029 | loss: 0.91926 | error: 0.50000\n",
      "  Ended batch 006 / 029 | loss: 0.83598 | error: 0.39062\n",
      "  Ended batch 007 / 029 | loss: 0.88446 | error: 0.35938\n",
      "  Ended batch 008 / 029 | loss: 0.97455 | error: 0.46875\n",
      "  Ended batch 009 / 029 | loss: 1.10624 | error: 0.53125\n",
      "  Ended batch 010 / 029 | loss: 1.06242 | error: 0.56250\n",
      "  Ended batch 011 / 029 | loss: 0.79893 | error: 0.40625\n",
      "  Ended batch 012 / 029 | loss: 0.79782 | error: 0.25000\n",
      "  Ended batch 013 / 029 | loss: 0.66777 | error: 0.29688\n",
      "  Ended batch 014 / 029 | loss: 0.75157 | error: 0.34375\n",
      "  Ended batch 015 / 029 | loss: 0.98006 | error: 0.43750\n",
      "  Ended batch 016 / 029 | loss: 0.88994 | error: 0.32812\n",
      "  Ended batch 017 / 029 | loss: 1.19924 | error: 0.43750\n",
      "  Ended batch 018 / 029 | loss: 0.70924 | error: 0.29688\n",
      "  Ended batch 019 / 029 | loss: 0.62814 | error: 0.25000\n",
      "  Ended batch 020 / 029 | loss: 1.00520 | error: 0.42188\n",
      "  Ended batch 021 / 029 | loss: 0.94775 | error: 0.39062\n",
      "  Ended batch 022 / 029 | loss: 0.88218 | error: 0.34375\n",
      "  Ended batch 023 / 029 | loss: 0.87164 | error: 0.32812\n",
      "  Ended batch 024 / 029 | loss: 0.70577 | error: 0.31250\n",
      "  Ended batch 025 / 029 | loss: 0.73123 | error: 0.39062\n",
      "  Ended batch 026 / 029 | loss: 1.04434 | error: 0.54688\n",
      "  Ended batch 027 / 029 | loss: 0.82697 | error: 0.42188\n",
      "  Ended batch 028 / 029 | loss: 0.91896 | error: 0.50000\n",
      "  Ended batch 029 / 029 | loss: 1.00100 | error: 0.50000\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 001 / 016 | time: 020 sec | loss: 0.91165 | error: 0.38333\n",
      "Model saved to ./results/vanilla/credit_0.5_strategic_model.pt.\n",
      "Starting epoch 002 / 016.\n",
      "  Ended batch 001 / 029 | loss: 0.86897 | error: 0.25000\n",
      "  Ended batch 002 / 029 | loss: 0.79543 | error: 0.31250\n",
      "  Ended batch 003 / 029 | loss: 0.72117 | error: 0.34375\n",
      "  Ended batch 004 / 029 | loss: 0.89598 | error: 0.46875\n",
      "  Ended batch 005 / 029 | loss: 0.96220 | error: 0.48438\n",
      "  Ended batch 006 / 029 | loss: 0.82602 | error: 0.39062\n",
      "  Ended batch 007 / 029 | loss: 0.72622 | error: 0.37500\n",
      "  Ended batch 008 / 029 | loss: 0.86202 | error: 0.46875\n",
      "  Ended batch 009 / 029 | loss: 0.83141 | error: 0.39062\n",
      "  Ended batch 010 / 029 | loss: 0.66841 | error: 0.26562\n",
      "  Ended batch 011 / 029 | loss: 0.62173 | error: 0.21875\n",
      "  Ended batch 012 / 029 | loss: 0.65424 | error: 0.25000\n",
      "  Ended batch 013 / 029 | loss: 0.60577 | error: 0.29688\n",
      "  Ended batch 014 / 029 | loss: 0.82684 | error: 0.39062\n",
      "  Ended batch 015 / 029 | loss: 1.29031 | error: 0.57812\n",
      "  Ended batch 016 / 029 | loss: 0.85809 | error: 0.37500\n",
      "  Ended batch 017 / 029 | loss: 1.03587 | error: 0.48438\n",
      "  Ended batch 018 / 029 | loss: 0.71783 | error: 0.37500\n",
      "  Ended batch 019 / 029 | loss: 0.58488 | error: 0.21875\n",
      "  Ended batch 020 / 029 | loss: 0.80786 | error: 0.35938\n",
      "  Ended batch 021 / 029 | loss: 0.84319 | error: 0.34375\n",
      "  Ended batch 022 / 029 | loss: 0.84914 | error: 0.32812\n",
      "  Ended batch 023 / 029 | loss: 0.73193 | error: 0.35938\n",
      "  Ended batch 024 / 029 | loss: 0.84828 | error: 0.45312\n",
      "  Ended batch 025 / 029 | loss: 0.90896 | error: 0.48438\n",
      "  Ended batch 026 / 029 | loss: 1.08382 | error: 0.56250\n",
      "  Ended batch 027 / 029 | loss: 0.79193 | error: 0.35938\n",
      "  Ended batch 028 / 029 | loss: 0.78018 | error: 0.31250\n",
      "  Ended batch 029 / 029 | loss: 0.96378 | error: 0.50000\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 002 / 016 | time: 019 sec | loss: 0.90556 | error: 0.36458\n",
      "Validation accuracy improved.\n",
      "Model saved to ./results/vanilla/credit_0.5_strategic_model.pt.\n",
      "Starting epoch 003 / 016.\n",
      "  Ended batch 001 / 029 | loss: 0.80376 | error: 0.29688\n",
      "  Ended batch 002 / 029 | loss: 0.74165 | error: 0.32812\n",
      "  Ended batch 003 / 029 | loss: 0.66858 | error: 0.32812\n",
      "  Ended batch 004 / 029 | loss: 0.80679 | error: 0.42188\n",
      "  Ended batch 005 / 029 | loss: 0.93161 | error: 0.48438\n",
      "  Ended batch 006 / 029 | loss: 0.83681 | error: 0.40625\n",
      "  Ended batch 007 / 029 | loss: 0.75870 | error: 0.42188\n",
      "  Ended batch 008 / 029 | loss: 0.87972 | error: 0.48438\n",
      "  Ended batch 009 / 029 | loss: 0.84321 | error: 0.39062\n",
      "  Ended batch 010 / 029 | loss: 0.70889 | error: 0.29688\n",
      "  Ended batch 011 / 029 | loss: 0.69965 | error: 0.21875\n",
      "  Ended batch 012 / 029 | loss: 0.74125 | error: 0.32812\n",
      "  Ended batch 013 / 029 | loss: 0.67035 | error: 0.35938\n",
      "  Ended batch 014 / 029 | loss: 0.89086 | error: 0.42188\n",
      "  Ended batch 015 / 029 | loss: 1.30290 | error: 0.60938\n",
      "  Ended batch 016 / 029 | loss: 0.92990 | error: 0.43750\n",
      "  Ended batch 017 / 029 | loss: 1.07222 | error: 0.50000\n",
      "  Ended batch 018 / 029 | loss: 0.86697 | error: 0.45312\n",
      "  Ended batch 019 / 029 | loss: 0.64282 | error: 0.37500\n",
      "  Ended batch 020 / 029 | loss: 0.87037 | error: 0.34375\n",
      "  Ended batch 021 / 029 | loss: 0.84381 | error: 0.32812\n",
      "  Ended batch 022 / 029 | loss: 0.91221 | error: 0.34375\n",
      "  Ended batch 023 / 029 | loss: 0.77645 | error: 0.32812\n",
      "  Ended batch 024 / 029 | loss: 0.82219 | error: 0.40625\n",
      "  Ended batch 025 / 029 | loss: 1.10073 | error: 0.54688\n",
      "  Ended batch 026 / 029 | loss: 1.12333 | error: 0.54688\n",
      "  Ended batch 027 / 029 | loss: 0.84933 | error: 0.42188\n",
      "  Ended batch 028 / 029 | loss: 0.90550 | error: 0.46875\n",
      "  Ended batch 029 / 029 | loss: 0.92622 | error: 0.37500\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 003 / 016 | time: 019 sec | loss: 1.08024 | error: 0.46563\n",
      "Starting epoch 004 / 016.\n",
      "  Ended batch 001 / 029 | loss: 0.83746 | error: 0.32812\n",
      "  Ended batch 002 / 029 | loss: 0.92032 | error: 0.34375\n",
      "  Ended batch 003 / 029 | loss: 0.75149 | error: 0.32812\n",
      "  Ended batch 004 / 029 | loss: 0.85817 | error: 0.43750\n",
      "  Ended batch 005 / 029 | loss: 1.01458 | error: 0.50000\n",
      "  Ended batch 006 / 029 | loss: 0.91412 | error: 0.42188\n",
      "  Ended batch 007 / 029 | loss: 0.73400 | error: 0.35938\n",
      "  Ended batch 008 / 029 | loss: 0.83540 | error: 0.43750\n",
      "  Ended batch 009 / 029 | loss: 0.92820 | error: 0.46875\n",
      "  Ended batch 010 / 029 | loss: 0.68147 | error: 0.28125\n",
      "  Ended batch 011 / 029 | loss: 0.65082 | error: 0.21875\n",
      "  Ended batch 012 / 029 | loss: 0.63201 | error: 0.25000\n",
      "  Ended batch 013 / 029 | loss: 0.60953 | error: 0.29688\n",
      "  Ended batch 014 / 029 | loss: 0.76179 | error: 0.34375\n",
      "  Ended batch 015 / 029 | loss: 1.30007 | error: 0.56250\n",
      "  Ended batch 016 / 029 | loss: 0.83663 | error: 0.34375\n",
      "  Ended batch 017 / 029 | loss: 1.17293 | error: 0.50000\n",
      "  Ended batch 018 / 029 | loss: 0.93822 | error: 0.45312\n",
      "  Ended batch 019 / 029 | loss: 0.73701 | error: 0.39062\n",
      "  Ended batch 020 / 029 | loss: 0.92595 | error: 0.50000\n",
      "  Ended batch 021 / 029 | loss: 0.78906 | error: 0.34375\n",
      "  Ended batch 022 / 029 | loss: 0.88419 | error: 0.46875\n",
      "  Ended batch 023 / 029 | loss: 0.97033 | error: 0.45312\n",
      "  Ended batch 024 / 029 | loss: 0.85598 | error: 0.40625\n",
      "  Ended batch 025 / 029 | loss: 1.00455 | error: 0.56250\n",
      "  Ended batch 026 / 029 | loss: 1.08810 | error: 0.57812\n",
      "  Ended batch 027 / 029 | loss: 0.74421 | error: 0.34375\n",
      "  Ended batch 028 / 029 | loss: 0.82456 | error: 0.42188\n",
      "  Ended batch 029 / 029 | loss: 0.98755 | error: 0.50000\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 004 / 016 | time: 019 sec | loss: 0.84148 | error: 0.34271\n",
      "Validation accuracy improved.\n",
      "Model saved to ./results/vanilla/credit_0.5_strategic_model.pt.\n",
      "Starting epoch 005 / 016.\n",
      "  Ended batch 001 / 029 | loss: 0.73967 | error: 0.35938\n",
      "  Ended batch 002 / 029 | loss: 0.83071 | error: 0.42188\n",
      "  Ended batch 003 / 029 | loss: 0.68698 | error: 0.29688\n",
      "  Ended batch 004 / 029 | loss: 0.57896 | error: 0.31250\n",
      "  Ended batch 005 / 029 | loss: 0.73864 | error: 0.40625\n",
      "  Ended batch 006 / 029 | loss: 0.72788 | error: 0.34375\n",
      "  Ended batch 007 / 029 | loss: 0.69660 | error: 0.25000\n",
      "  Ended batch 008 / 029 | loss: 0.84416 | error: 0.43750\n",
      "  Ended batch 009 / 029 | loss: 0.92393 | error: 0.46875\n",
      "  Ended batch 010 / 029 | loss: 0.81439 | error: 0.43750\n",
      "  Ended batch 011 / 029 | loss: 0.60808 | error: 0.29688\n",
      "  Ended batch 012 / 029 | loss: 0.61609 | error: 0.26562\n",
      "  Ended batch 013 / 029 | loss: 0.65659 | error: 0.34375\n",
      "  Ended batch 014 / 029 | loss: 0.77905 | error: 0.40625\n",
      "  Ended batch 015 / 029 | loss: 1.10196 | error: 0.60938\n",
      "  Ended batch 016 / 029 | loss: 0.72065 | error: 0.34375\n",
      "  Ended batch 017 / 029 | loss: 0.91889 | error: 0.39062\n",
      "  Ended batch 018 / 029 | loss: 0.69291 | error: 0.29688\n",
      "  Ended batch 019 / 029 | loss: 0.63628 | error: 0.20312\n",
      "  Ended batch 020 / 029 | loss: 0.88658 | error: 0.35938\n",
      "  Ended batch 021 / 029 | loss: 0.75354 | error: 0.35938\n",
      "  Ended batch 022 / 029 | loss: 0.85216 | error: 0.39062\n",
      "  Ended batch 023 / 029 | loss: 0.68857 | error: 0.31250\n",
      "  Ended batch 024 / 029 | loss: 0.71747 | error: 0.39062\n",
      "  Ended batch 025 / 029 | loss: 0.75540 | error: 0.42188\n",
      "  Ended batch 026 / 029 | loss: 0.94294 | error: 0.50000\n",
      "  Ended batch 027 / 029 | loss: 0.73572 | error: 0.34375\n",
      "  Ended batch 028 / 029 | loss: 0.77616 | error: 0.32812\n",
      "  Ended batch 029 / 029 | loss: 0.95481 | error: 0.50000\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 005 / 016 | time: 020 sec | loss: 0.86991 | error: 0.33698\n",
      "Validation accuracy improved.\n",
      "Model saved to ./results/vanilla/credit_0.5_strategic_model.pt.\n",
      "Starting epoch 006 / 016.\n",
      "  Ended batch 001 / 029 | loss: 0.65489 | error: 0.29688\n",
      "  Ended batch 002 / 029 | loss: 0.80115 | error: 0.39062\n",
      "  Ended batch 003 / 029 | loss: 0.63080 | error: 0.31250\n",
      "  Ended batch 004 / 029 | loss: 0.78967 | error: 0.45312\n",
      "  Ended batch 005 / 029 | loss: 0.77236 | error: 0.46875\n",
      "  Ended batch 006 / 029 | loss: 0.76741 | error: 0.29688\n",
      "  Ended batch 007 / 029 | loss: 0.70432 | error: 0.28125\n",
      "  Ended batch 008 / 029 | loss: 0.87837 | error: 0.35938\n",
      "  Ended batch 009 / 029 | loss: 0.87640 | error: 0.46875\n",
      "  Ended batch 010 / 029 | loss: 0.76788 | error: 0.40625\n",
      "  Ended batch 011 / 029 | loss: 0.56642 | error: 0.21875\n",
      "  Ended batch 012 / 029 | loss: 0.64610 | error: 0.26562\n",
      "  Ended batch 013 / 029 | loss: 0.61504 | error: 0.29688\n",
      "  Ended batch 014 / 029 | loss: 0.74345 | error: 0.39062\n",
      "  Ended batch 015 / 029 | loss: 1.05801 | error: 0.56250\n",
      "  Ended batch 016 / 029 | loss: 0.71926 | error: 0.35938\n",
      "  Ended batch 017 / 029 | loss: 0.92306 | error: 0.42188\n",
      "  Ended batch 018 / 029 | loss: 0.66232 | error: 0.31250\n",
      "  Ended batch 019 / 029 | loss: 0.60066 | error: 0.18750\n",
      "  Ended batch 020 / 029 | loss: 0.89993 | error: 0.45312\n",
      "  Ended batch 021 / 029 | loss: 0.77360 | error: 0.34375\n",
      "  Ended batch 022 / 029 | loss: 0.89278 | error: 0.43750\n",
      "  Ended batch 023 / 029 | loss: 0.67578 | error: 0.31250\n",
      "  Ended batch 024 / 029 | loss: 0.73525 | error: 0.39062\n",
      "  Ended batch 025 / 029 | loss: 0.75695 | error: 0.42188\n",
      "  Ended batch 026 / 029 | loss: 0.88043 | error: 0.50000\n",
      "  Ended batch 027 / 029 | loss: 0.79035 | error: 0.32812\n",
      "  Ended batch 028 / 029 | loss: 0.81999 | error: 0.39062\n",
      "  Ended batch 029 / 029 | loss: 0.97519 | error: 0.50000\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 006 / 016 | time: 021 sec | loss: 0.86171 | error: 0.34792\n",
      "Starting epoch 007 / 016.\n",
      "  Ended batch 001 / 029 | loss: 0.74292 | error: 0.31250\n",
      "  Ended batch 002 / 029 | loss: 0.74452 | error: 0.34375\n",
      "  Ended batch 003 / 029 | loss: 0.65351 | error: 0.32812\n",
      "  Ended batch 004 / 029 | loss: 0.74788 | error: 0.43750\n",
      "  Ended batch 005 / 029 | loss: 0.78287 | error: 0.48438\n",
      "  Ended batch 006 / 029 | loss: 0.73100 | error: 0.32812\n",
      "  Ended batch 007 / 029 | loss: 0.69685 | error: 0.28125\n",
      "  Ended batch 008 / 029 | loss: 0.87134 | error: 0.35938\n",
      "  Ended batch 009 / 029 | loss: 0.87460 | error: 0.45312\n",
      "  Ended batch 010 / 029 | loss: 0.83181 | error: 0.39062\n",
      "  Ended batch 011 / 029 | loss: 0.60671 | error: 0.26562\n",
      "  Ended batch 012 / 029 | loss: 0.62928 | error: 0.25000\n",
      "  Ended batch 013 / 029 | loss: 0.63697 | error: 0.34375\n",
      "  Ended batch 014 / 029 | loss: 0.73457 | error: 0.37500\n",
      "  Ended batch 015 / 029 | loss: 1.04439 | error: 0.51562\n",
      "  Ended batch 016 / 029 | loss: 0.70089 | error: 0.32812\n",
      "  Ended batch 017 / 029 | loss: 0.93989 | error: 0.48438\n",
      "  Ended batch 018 / 029 | loss: 0.64580 | error: 0.28125\n",
      "  Ended batch 019 / 029 | loss: 0.60488 | error: 0.18750\n",
      "  Ended batch 020 / 029 | loss: 0.86620 | error: 0.40625\n",
      "  Ended batch 021 / 029 | loss: 0.72428 | error: 0.32812\n",
      "  Ended batch 022 / 029 | loss: 0.88325 | error: 0.43750\n",
      "  Ended batch 023 / 029 | loss: 0.65869 | error: 0.31250\n",
      "  Ended batch 024 / 029 | loss: 0.77649 | error: 0.42188\n",
      "  Ended batch 025 / 029 | loss: 0.81896 | error: 0.46875\n",
      "  Ended batch 026 / 029 | loss: 0.89982 | error: 0.43750\n",
      "  Ended batch 027 / 029 | loss: 0.80406 | error: 0.34375\n",
      "  Ended batch 028 / 029 | loss: 0.83743 | error: 0.29688\n",
      "  Ended batch 029 / 029 | loss: 0.98031 | error: 0.50000\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 007 / 016 | time: 020 sec | loss: 0.88827 | error: 0.36927\n",
      "Starting epoch 008 / 016.\n",
      "  Ended batch 001 / 029 | loss: 0.77830 | error: 0.28125\n",
      "  Ended batch 002 / 029 | loss: 0.77362 | error: 0.34375\n",
      "  Ended batch 003 / 029 | loss: 0.68453 | error: 0.35938\n",
      "  Ended batch 004 / 029 | loss: 0.80430 | error: 0.43750\n",
      "  Ended batch 005 / 029 | loss: 0.90026 | error: 0.51562\n",
      "  Ended batch 006 / 029 | loss: 0.70911 | error: 0.37500\n",
      "  Ended batch 007 / 029 | loss: 0.68705 | error: 0.28125\n",
      "  Ended batch 008 / 029 | loss: 0.86968 | error: 0.35938\n",
      "  Ended batch 009 / 029 | loss: 0.83138 | error: 0.39062\n",
      "  Ended batch 010 / 029 | loss: 0.70180 | error: 0.29688\n",
      "  Ended batch 011 / 029 | loss: 0.59738 | error: 0.21875\n",
      "  Ended batch 012 / 029 | loss: 0.67663 | error: 0.26562\n",
      "  Ended batch 013 / 029 | loss: 0.62656 | error: 0.32812\n",
      "  Ended batch 014 / 029 | loss: 0.70940 | error: 0.34375\n",
      "  Ended batch 015 / 029 | loss: 1.03086 | error: 0.53125\n",
      "  Ended batch 016 / 029 | loss: 0.74919 | error: 0.35938\n",
      "  Ended batch 017 / 029 | loss: 0.91840 | error: 0.39062\n",
      "  Ended batch 018 / 029 | loss: 0.71678 | error: 0.31250\n",
      "  Ended batch 019 / 029 | loss: 0.63567 | error: 0.20312\n",
      "  Ended batch 020 / 029 | loss: 0.91339 | error: 0.43750\n",
      "  Ended batch 021 / 029 | loss: 0.75207 | error: 0.32812\n",
      "  Ended batch 022 / 029 | loss: 0.90022 | error: 0.45312\n",
      "  Ended batch 023 / 029 | loss: 0.68036 | error: 0.34375\n",
      "  Ended batch 024 / 029 | loss: 0.75719 | error: 0.37500\n",
      "  Ended batch 025 / 029 | loss: 0.72357 | error: 0.37500\n",
      "  Ended batch 026 / 029 | loss: 0.86226 | error: 0.39062\n",
      "  Ended batch 027 / 029 | loss: 0.81423 | error: 0.34375\n",
      "  Ended batch 028 / 029 | loss: 0.81350 | error: 0.34375\n",
      "  Ended batch 029 / 029 | loss: 0.94395 | error: 0.50000\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 008 / 016 | time: 020 sec | loss: 0.81318 | error: 0.32917\n",
      "Validation accuracy improved.\n",
      "Model saved to ./results/vanilla/credit_0.5_strategic_model.pt.\n",
      "Starting epoch 009 / 016.\n",
      "  Ended batch 001 / 029 | loss: 0.72892 | error: 0.35938\n",
      "  Ended batch 002 / 029 | loss: 0.81018 | error: 0.40625\n",
      "  Ended batch 003 / 029 | loss: 0.62190 | error: 0.31250\n",
      "  Ended batch 004 / 029 | loss: 0.77700 | error: 0.46875\n",
      "  Ended batch 005 / 029 | loss: 0.75264 | error: 0.34375\n",
      "  Ended batch 006 / 029 | loss: 0.77248 | error: 0.28125\n",
      "  Ended batch 007 / 029 | loss: 0.72740 | error: 0.26562\n",
      "  Ended batch 008 / 029 | loss: 0.88778 | error: 0.39062\n",
      "  Ended batch 009 / 029 | loss: 0.93076 | error: 0.46875\n",
      "  Ended batch 010 / 029 | loss: 0.88197 | error: 0.50000\n",
      "  Ended batch 011 / 029 | loss: 0.63438 | error: 0.32812\n",
      "  Ended batch 012 / 029 | loss: 0.63922 | error: 0.25000\n",
      "  Ended batch 013 / 029 | loss: 0.64688 | error: 0.26562\n",
      "  Ended batch 014 / 029 | loss: 0.77051 | error: 0.35938\n",
      "  Ended batch 015 / 029 | loss: 1.14591 | error: 0.64062\n",
      "  Ended batch 016 / 029 | loss: 0.70239 | error: 0.34375\n",
      "  Ended batch 017 / 029 | loss: 0.92572 | error: 0.43750\n",
      "  Ended batch 018 / 029 | loss: 0.67910 | error: 0.31250\n",
      "  Ended batch 019 / 029 | loss: 0.62160 | error: 0.18750\n",
      "  Ended batch 020 / 029 | loss: 0.84127 | error: 0.39062\n",
      "  Ended batch 021 / 029 | loss: 0.78730 | error: 0.39062\n",
      "  Ended batch 022 / 029 | loss: 0.89772 | error: 0.40625\n",
      "  Ended batch 023 / 029 | loss: 0.66997 | error: 0.31250\n",
      "  Ended batch 024 / 029 | loss: 0.74517 | error: 0.40625\n",
      "  Ended batch 025 / 029 | loss: 0.75444 | error: 0.42188\n",
      "  Ended batch 026 / 029 | loss: 0.86535 | error: 0.43750\n",
      "  Ended batch 027 / 029 | loss: 0.80172 | error: 0.31250\n",
      "  Ended batch 028 / 029 | loss: 0.81268 | error: 0.34375\n",
      "  Ended batch 029 / 029 | loss: 0.99197 | error: 0.50000\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 009 / 016 | time: 021 sec | loss: 0.84679 | error: 0.33854\n",
      "Starting epoch 010 / 016.\n",
      "  Ended batch 001 / 029 | loss: 0.75399 | error: 0.28125\n",
      "  Ended batch 002 / 029 | loss: 0.73339 | error: 0.32812\n",
      "  Ended batch 003 / 029 | loss: 0.71078 | error: 0.35938\n",
      "  Ended batch 004 / 029 | loss: 0.82846 | error: 0.48438\n",
      "  Ended batch 005 / 029 | loss: 0.79829 | error: 0.48438\n",
      "  Ended batch 006 / 029 | loss: 0.72249 | error: 0.34375\n",
      "  Ended batch 007 / 029 | loss: 0.69505 | error: 0.28125\n",
      "  Ended batch 008 / 029 | loss: 0.86624 | error: 0.35938\n",
      "  Ended batch 009 / 029 | loss: 0.85827 | error: 0.42188\n",
      "  Ended batch 010 / 029 | loss: 0.76078 | error: 0.34375\n",
      "  Ended batch 011 / 029 | loss: 0.57974 | error: 0.21875\n",
      "  Ended batch 012 / 029 | loss: 0.66697 | error: 0.28125\n",
      "  Ended batch 013 / 029 | loss: 0.65049 | error: 0.34375\n",
      "  Ended batch 014 / 029 | loss: 0.69107 | error: 0.34375\n",
      "  Ended batch 015 / 029 | loss: 1.01741 | error: 0.50000\n",
      "  Ended batch 016 / 029 | loss: 0.78451 | error: 0.37500\n",
      "  Ended batch 017 / 029 | loss: 0.90384 | error: 0.45312\n",
      "  Ended batch 018 / 029 | loss: 0.64330 | error: 0.28125\n",
      "  Ended batch 019 / 029 | loss: 0.61288 | error: 0.20312\n",
      "  Ended batch 020 / 029 | loss: 0.89156 | error: 0.43750\n",
      "  Ended batch 021 / 029 | loss: 0.72501 | error: 0.34375\n",
      "  Ended batch 022 / 029 | loss: 0.85220 | error: 0.42188\n",
      "  Ended batch 023 / 029 | loss: 0.63245 | error: 0.31250\n",
      "  Ended batch 024 / 029 | loss: 0.80153 | error: 0.45312\n",
      "  Ended batch 025 / 029 | loss: 0.74932 | error: 0.42188\n",
      "  Ended batch 026 / 029 | loss: 0.91074 | error: 0.43750\n",
      "  Ended batch 027 / 029 | loss: 0.83276 | error: 0.32812\n",
      "  Ended batch 028 / 029 | loss: 0.83439 | error: 0.31250\n",
      "  Ended batch 029 / 029 | loss: 0.94971 | error: 0.62500\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 010 / 016 | time: 020 sec | loss: 0.86686 | error: 0.35521\n",
      "Starting epoch 011 / 016.\n",
      "  Ended batch 001 / 029 | loss: 0.76986 | error: 0.25000\n",
      "  Ended batch 002 / 029 | loss: 0.84334 | error: 0.45312\n",
      "  Ended batch 003 / 029 | loss: 0.68114 | error: 0.35938\n",
      "  Ended batch 004 / 029 | loss: 0.85838 | error: 0.48438\n",
      "  Ended batch 005 / 029 | loss: 0.86142 | error: 0.50000\n",
      "  Ended batch 006 / 029 | loss: 0.75239 | error: 0.35938\n",
      "  Ended batch 007 / 029 | loss: 0.69814 | error: 0.28125\n",
      "  Ended batch 008 / 029 | loss: 0.90171 | error: 0.37500\n",
      "  Ended batch 009 / 029 | loss: 0.85848 | error: 0.42188\n",
      "  Ended batch 010 / 029 | loss: 0.75743 | error: 0.37500\n",
      "  Ended batch 011 / 029 | loss: 0.58262 | error: 0.23438\n",
      "  Ended batch 012 / 029 | loss: 0.62792 | error: 0.28125\n",
      "  Ended batch 013 / 029 | loss: 0.61755 | error: 0.31250\n",
      "  Ended batch 014 / 029 | loss: 0.80063 | error: 0.40625\n",
      "  Ended batch 015 / 029 | loss: 0.98681 | error: 0.50000\n",
      "  Ended batch 016 / 029 | loss: 0.70898 | error: 0.34375\n",
      "  Ended batch 017 / 029 | loss: 0.89980 | error: 0.35938\n",
      "  Ended batch 018 / 029 | loss: 0.69121 | error: 0.31250\n",
      "  Ended batch 019 / 029 | loss: 0.60287 | error: 0.18750\n",
      "  Ended batch 020 / 029 | loss: 0.90467 | error: 0.48438\n",
      "  Ended batch 021 / 029 | loss: 0.80694 | error: 0.37500\n",
      "  Ended batch 022 / 029 | loss: 0.89449 | error: 0.45312\n",
      "  Ended batch 023 / 029 | loss: 0.67934 | error: 0.32812\n",
      "  Ended batch 024 / 029 | loss: 0.72693 | error: 0.37500\n",
      "  Ended batch 025 / 029 | loss: 0.75164 | error: 0.39062\n",
      "  Ended batch 026 / 029 | loss: 0.91753 | error: 0.45312\n",
      "  Ended batch 027 / 029 | loss: 0.78437 | error: 0.31250\n",
      "  Ended batch 028 / 029 | loss: 0.81545 | error: 0.34375\n",
      "  Ended batch 029 / 029 | loss: 0.97936 | error: 0.50000\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 011 / 016 | time: 020 sec | loss: 0.85396 | error: 0.35833\n",
      "Starting epoch 012 / 016.\n",
      "  Ended batch 001 / 029 | loss: 0.75359 | error: 0.29688\n",
      "  Ended batch 002 / 029 | loss: 0.74417 | error: 0.32812\n",
      "  Ended batch 003 / 029 | loss: 0.63058 | error: 0.31250\n",
      "  Ended batch 004 / 029 | loss: 0.82614 | error: 0.46875\n",
      "  Ended batch 005 / 029 | loss: 0.81411 | error: 0.46875\n",
      "  Ended batch 006 / 029 | loss: 0.73603 | error: 0.39062\n",
      "  Ended batch 007 / 029 | loss: 0.68491 | error: 0.28125\n",
      "  Ended batch 008 / 029 | loss: 0.84483 | error: 0.34375\n",
      "  Ended batch 009 / 029 | loss: 0.87031 | error: 0.39062\n",
      "  Ended batch 010 / 029 | loss: 0.75132 | error: 0.31250\n",
      "  Ended batch 011 / 029 | loss: 0.57574 | error: 0.21875\n",
      "  Ended batch 012 / 029 | loss: 0.62264 | error: 0.28125\n",
      "  Ended batch 013 / 029 | loss: 0.66575 | error: 0.34375\n",
      "  Ended batch 014 / 029 | loss: 0.82037 | error: 0.39062\n",
      "  Ended batch 015 / 029 | loss: 1.17082 | error: 0.57812\n",
      "  Ended batch 016 / 029 | loss: 0.77596 | error: 0.37500\n",
      "  Ended batch 017 / 029 | loss: 0.97392 | error: 0.48438\n",
      "  Ended batch 018 / 029 | loss: 0.66962 | error: 0.29688\n",
      "  Ended batch 019 / 029 | loss: 0.60549 | error: 0.18750\n",
      "  Ended batch 020 / 029 | loss: 0.83663 | error: 0.35938\n",
      "  Ended batch 021 / 029 | loss: 0.76229 | error: 0.34375\n",
      "  Ended batch 022 / 029 | loss: 0.88350 | error: 0.39062\n",
      "  Ended batch 023 / 029 | loss: 0.70383 | error: 0.34375\n",
      "  Ended batch 024 / 029 | loss: 0.75782 | error: 0.40625\n",
      "  Ended batch 025 / 029 | loss: 0.89364 | error: 0.50000\n",
      "  Ended batch 026 / 029 | loss: 0.96347 | error: 0.53125\n",
      "  Ended batch 027 / 029 | loss: 0.78225 | error: 0.32812\n",
      "  Ended batch 028 / 029 | loss: 0.81392 | error: 0.31250\n",
      "  Ended batch 029 / 029 | loss: 0.94394 | error: 0.50000\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 012 / 016 | time: 020 sec | loss: 0.88397 | error: 0.34792\n",
      "Ending training due to 4 consecutive epochs without improvement in validation accuracy.\n",
      "Total training time: 3.9798773566881818 minutes (238.7926414012909 seconds).\n",
      "Model loaded from ./results/vanilla/credit_0.5_strategic_model.pt.\n",
      "---------- Calculating results ----------\n",
      "Benchmark accuracy: 0.7383333333333333\n",
      "SERM accuracy: 0.72\n",
      "Blind accuracy: 0.57\n",
      "---------- Training non-strategically on credit with scale=1 ----------\n",
      "Starting epoch 001 / 016.\n",
      "Ended epoch 001 / 016 | time: 000 sec | loss: 0.73337 | error: 0.32344\n",
      "Model saved to ./results/vanilla/credit_1_non_strategic_model.pt.\n",
      "Starting epoch 002 / 016.\n",
      "Ended epoch 002 / 016 | time: 000 sec | loss: 0.69035 | error: 0.32760\n",
      "Starting epoch 003 / 016.\n",
      "Ended epoch 003 / 016 | time: 000 sec | loss: 0.68178 | error: 0.32760\n",
      "Starting epoch 004 / 016.\n",
      "Ended epoch 004 / 016 | time: 000 sec | loss: 0.68823 | error: 0.32760\n",
      "Starting epoch 005 / 016.\n",
      "Ended epoch 005 / 016 | time: 000 sec | loss: 0.68638 | error: 0.32917\n",
      "Ending training due to 4 consecutive epochs without improvement in validation accuracy.\n",
      "Total training time: 0.21741867065429688 seconds.\n",
      "Model loaded from ./results/vanilla/credit_1_non_strategic_model.pt.\n",
      "---------- Training strategically on credit with scale=1 ----------\n",
      "Starting epoch 001 / 016.\n",
      "  Ended batch 001 / 029 | loss: 1.16206 | error: 0.60938\n",
      "  Ended batch 002 / 029 | loss: 0.96955 | error: 0.46875\n",
      "  Ended batch 003 / 029 | loss: 0.72326 | error: 0.37500\n",
      "  Ended batch 004 / 029 | loss: 0.78711 | error: 0.42188\n",
      "  Ended batch 005 / 029 | loss: 0.71014 | error: 0.40625\n",
      "  Ended batch 006 / 029 | loss: 0.74819 | error: 0.31250\n",
      "  Ended batch 007 / 029 | loss: 0.69484 | error: 0.28125\n",
      "  Ended batch 008 / 029 | loss: 0.94648 | error: 0.50000\n",
      "  Ended batch 009 / 029 | loss: 0.84829 | error: 0.40625\n",
      "  Ended batch 010 / 029 | loss: 0.61454 | error: 0.31250\n",
      "  Ended batch 011 / 029 | loss: 0.50766 | error: 0.20312\n",
      "  Ended batch 012 / 029 | loss: 0.55585 | error: 0.25000\n",
      "  Ended batch 013 / 029 | loss: 0.62701 | error: 0.29688\n",
      "  Ended batch 014 / 029 | loss: 0.75853 | error: 0.35938\n",
      "  Ended batch 015 / 029 | loss: 0.88400 | error: 0.45312\n",
      "  Ended batch 016 / 029 | loss: 0.79467 | error: 0.32812\n",
      "  Ended batch 017 / 029 | loss: 0.85135 | error: 0.37500\n",
      "  Ended batch 018 / 029 | loss: 0.71056 | error: 0.29688\n",
      "  Ended batch 019 / 029 | loss: 0.54569 | error: 0.18750\n",
      "  Ended batch 020 / 029 | loss: 0.89339 | error: 0.40625\n",
      "  Ended batch 021 / 029 | loss: 0.77643 | error: 0.35938\n",
      "  Ended batch 022 / 029 | loss: 0.83193 | error: 0.34375\n",
      "  Ended batch 023 / 029 | loss: 0.65612 | error: 0.28125\n",
      "  Ended batch 024 / 029 | loss: 0.68537 | error: 0.37500\n",
      "  Ended batch 025 / 029 | loss: 0.68841 | error: 0.34375\n",
      "  Ended batch 026 / 029 | loss: 0.87161 | error: 0.45312\n",
      "  Ended batch 027 / 029 | loss: 0.76321 | error: 0.32812\n",
      "  Ended batch 028 / 029 | loss: 0.78639 | error: 0.31250\n",
      "  Ended batch 029 / 029 | loss: 1.01567 | error: 0.50000\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 001 / 016 | time: 019 sec | loss: 0.83065 | error: 0.32760\n",
      "Model saved to ./results/vanilla/credit_1_strategic_model.pt.\n",
      "Starting epoch 002 / 016.\n",
      "  Ended batch 001 / 029 | loss: 0.69752 | error: 0.25000\n",
      "  Ended batch 002 / 029 | loss: 0.71871 | error: 0.32812\n",
      "  Ended batch 003 / 029 | loss: 0.63157 | error: 0.28125\n",
      "  Ended batch 004 / 029 | loss: 0.72084 | error: 0.39062\n",
      "  Ended batch 005 / 029 | loss: 0.77021 | error: 0.43750\n",
      "  Ended batch 006 / 029 | loss: 0.74758 | error: 0.34375\n",
      "  Ended batch 007 / 029 | loss: 0.66614 | error: 0.25000\n",
      "  Ended batch 008 / 029 | loss: 0.80742 | error: 0.35938\n",
      "  Ended batch 009 / 029 | loss: 0.83917 | error: 0.39062\n",
      "  Ended batch 010 / 029 | loss: 0.66067 | error: 0.28125\n",
      "  Ended batch 011 / 029 | loss: 0.61433 | error: 0.21875\n",
      "  Ended batch 012 / 029 | loss: 0.65189 | error: 0.23438\n",
      "  Ended batch 013 / 029 | loss: 0.62303 | error: 0.34375\n",
      "  Ended batch 014 / 029 | loss: 0.72089 | error: 0.35938\n",
      "  Ended batch 015 / 029 | loss: 1.16914 | error: 0.56250\n",
      "  Ended batch 016 / 029 | loss: 0.84630 | error: 0.37500\n",
      "  Ended batch 017 / 029 | loss: 1.03122 | error: 0.50000\n",
      "  Ended batch 018 / 029 | loss: 0.85141 | error: 0.40625\n",
      "  Ended batch 019 / 029 | loss: 0.55407 | error: 0.20312\n",
      "  Ended batch 020 / 029 | loss: 0.77463 | error: 0.34375\n",
      "  Ended batch 021 / 029 | loss: 0.84094 | error: 0.34375\n",
      "  Ended batch 022 / 029 | loss: 0.87293 | error: 0.34375\n",
      "  Ended batch 023 / 029 | loss: 0.81420 | error: 0.34375\n",
      "  Ended batch 024 / 029 | loss: 0.70377 | error: 0.31250\n",
      "  Ended batch 025 / 029 | loss: 0.87143 | error: 0.51562\n",
      "  Ended batch 026 / 029 | loss: 1.05439 | error: 0.54688\n",
      "  Ended batch 027 / 029 | loss: 0.74882 | error: 0.37500\n",
      "  Ended batch 028 / 029 | loss: 0.75548 | error: 0.37500\n",
      "  Ended batch 029 / 029 | loss: 1.00602 | error: 0.50000\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 002 / 016 | time: 019 sec | loss: 0.85881 | error: 0.34167\n",
      "Starting epoch 003 / 016.\n",
      "  Ended batch 001 / 029 | loss: 0.79359 | error: 0.29688\n",
      "  Ended batch 002 / 029 | loss: 0.75040 | error: 0.32812\n",
      "  Ended batch 003 / 029 | loss: 0.69289 | error: 0.29688\n",
      "  Ended batch 004 / 029 | loss: 0.67567 | error: 0.35938\n",
      "  Ended batch 005 / 029 | loss: 0.82638 | error: 0.46875\n",
      "  Ended batch 006 / 029 | loss: 0.78324 | error: 0.34375\n",
      "  Ended batch 007 / 029 | loss: 0.61520 | error: 0.29688\n",
      "  Ended batch 008 / 029 | loss: 0.77669 | error: 0.34375\n",
      "  Ended batch 009 / 029 | loss: 0.84888 | error: 0.39062\n",
      "  Ended batch 010 / 029 | loss: 0.69613 | error: 0.31250\n",
      "  Ended batch 011 / 029 | loss: 0.63528 | error: 0.21875\n",
      "  Ended batch 012 / 029 | loss: 0.65121 | error: 0.25000\n",
      "  Ended batch 013 / 029 | loss: 0.64693 | error: 0.28125\n",
      "  Ended batch 014 / 029 | loss: 0.77885 | error: 0.39062\n",
      "  Ended batch 015 / 029 | loss: 1.20652 | error: 0.59375\n",
      "  Ended batch 016 / 029 | loss: 0.81647 | error: 0.35938\n",
      "  Ended batch 017 / 029 | loss: 1.07733 | error: 0.51562\n",
      "  Ended batch 018 / 029 | loss: 0.69457 | error: 0.32812\n",
      "  Ended batch 019 / 029 | loss: 0.53887 | error: 0.23438\n",
      "  Ended batch 020 / 029 | loss: 0.79186 | error: 0.35938\n",
      "  Ended batch 021 / 029 | loss: 0.82258 | error: 0.34375\n",
      "  Ended batch 022 / 029 | loss: 0.85760 | error: 0.34375\n",
      "  Ended batch 023 / 029 | loss: 0.82987 | error: 0.32812\n",
      "  Ended batch 024 / 029 | loss: 0.68679 | error: 0.26562\n",
      "  Ended batch 025 / 029 | loss: 0.77415 | error: 0.42188\n",
      "  Ended batch 026 / 029 | loss: 1.02986 | error: 0.51562\n",
      "  Ended batch 027 / 029 | loss: 0.77870 | error: 0.37500\n",
      "  Ended batch 028 / 029 | loss: 0.73736 | error: 0.39062\n",
      "  Ended batch 029 / 029 | loss: 0.96218 | error: 0.50000\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 003 / 016 | time: 018 sec | loss: 0.81958 | error: 0.33385\n",
      "Starting epoch 004 / 016.\n",
      "  Ended batch 001 / 029 | loss: 0.74565 | error: 0.25000\n",
      "  Ended batch 002 / 029 | loss: 0.74033 | error: 0.34375\n",
      "  Ended batch 003 / 029 | loss: 0.65932 | error: 0.28125\n",
      "  Ended batch 004 / 029 | loss: 0.61754 | error: 0.29688\n",
      "  Ended batch 005 / 029 | loss: 0.75099 | error: 0.40625\n",
      "  Ended batch 006 / 029 | loss: 0.73005 | error: 0.35938\n",
      "  Ended batch 007 / 029 | loss: 0.65533 | error: 0.26562\n",
      "  Ended batch 008 / 029 | loss: 0.81818 | error: 0.35938\n",
      "  Ended batch 009 / 029 | loss: 0.83810 | error: 0.39062\n",
      "  Ended batch 010 / 029 | loss: 0.67794 | error: 0.28125\n",
      "  Ended batch 011 / 029 | loss: 0.60359 | error: 0.21875\n",
      "  Ended batch 012 / 029 | loss: 0.66106 | error: 0.25000\n",
      "  Ended batch 013 / 029 | loss: 0.64427 | error: 0.29688\n",
      "  Ended batch 014 / 029 | loss: 0.81033 | error: 0.40625\n",
      "  Ended batch 015 / 029 | loss: 1.05020 | error: 0.53125\n",
      "  Ended batch 016 / 029 | loss: 0.76429 | error: 0.35938\n",
      "  Ended batch 017 / 029 | loss: 1.00994 | error: 0.51562\n",
      "  Ended batch 018 / 029 | loss: 0.67215 | error: 0.28125\n",
      "  Ended batch 019 / 029 | loss: 0.54317 | error: 0.18750\n",
      "  Ended batch 020 / 029 | loss: 0.77986 | error: 0.35938\n",
      "  Ended batch 021 / 029 | loss: 0.79133 | error: 0.34375\n",
      "  Ended batch 022 / 029 | loss: 0.82596 | error: 0.34375\n",
      "  Ended batch 023 / 029 | loss: 0.71670 | error: 0.34375\n",
      "  Ended batch 024 / 029 | loss: 0.67573 | error: 0.34375\n",
      "  Ended batch 025 / 029 | loss: 0.74360 | error: 0.39062\n",
      "  Ended batch 026 / 029 | loss: 0.91275 | error: 0.45312\n",
      "  Ended batch 027 / 029 | loss: 0.75174 | error: 0.32812\n",
      "  Ended batch 028 / 029 | loss: 0.76608 | error: 0.31250\n",
      "  Ended batch 029 / 029 | loss: 0.96732 | error: 0.50000\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 004 / 016 | time: 018 sec | loss: 0.83885 | error: 0.33385\n",
      "Starting epoch 005 / 016.\n",
      "  Ended batch 001 / 029 | loss: 0.76124 | error: 0.25000\n",
      "  Ended batch 002 / 029 | loss: 0.73439 | error: 0.34375\n",
      "  Ended batch 003 / 029 | loss: 0.64292 | error: 0.28125\n",
      "  Ended batch 004 / 029 | loss: 0.73784 | error: 0.35938\n",
      "  Ended batch 005 / 029 | loss: 0.83786 | error: 0.50000\n",
      "  Ended batch 006 / 029 | loss: 0.77083 | error: 0.37500\n",
      "  Ended batch 007 / 029 | loss: 0.63197 | error: 0.26562\n",
      "  Ended batch 008 / 029 | loss: 0.82752 | error: 0.35938\n",
      "  Ended batch 009 / 029 | loss: 0.84848 | error: 0.39062\n",
      "  Ended batch 010 / 029 | loss: 0.67247 | error: 0.29688\n",
      "  Ended batch 011 / 029 | loss: 0.62343 | error: 0.21875\n",
      "  Ended batch 012 / 029 | loss: 0.68692 | error: 0.28125\n",
      "  Ended batch 013 / 029 | loss: 0.62539 | error: 0.26562\n",
      "  Ended batch 014 / 029 | loss: 0.82274 | error: 0.42188\n",
      "  Ended batch 015 / 029 | loss: 1.08580 | error: 0.51562\n",
      "  Ended batch 016 / 029 | loss: 0.82398 | error: 0.37500\n",
      "  Ended batch 017 / 029 | loss: 1.05276 | error: 0.50000\n",
      "  Ended batch 018 / 029 | loss: 0.73841 | error: 0.37500\n",
      "  Ended batch 019 / 029 | loss: 0.54933 | error: 0.25000\n",
      "  Ended batch 020 / 029 | loss: 0.81381 | error: 0.35938\n",
      "  Ended batch 021 / 029 | loss: 0.83618 | error: 0.34375\n",
      "  Ended batch 022 / 029 | loss: 0.85676 | error: 0.34375\n",
      "  Ended batch 023 / 029 | loss: 0.84610 | error: 0.34375\n",
      "  Ended batch 024 / 029 | loss: 0.68355 | error: 0.26562\n",
      "  Ended batch 025 / 029 | loss: 0.75739 | error: 0.40625\n",
      "  Ended batch 026 / 029 | loss: 0.96479 | error: 0.50000\n",
      "  Ended batch 027 / 029 | loss: 0.77917 | error: 0.34375\n",
      "  Ended batch 028 / 029 | loss: 0.77705 | error: 0.37500\n",
      "  Ended batch 029 / 029 | loss: 0.93460 | error: 0.50000\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 005 / 016 | time: 018 sec | loss: 0.82362 | error: 0.33542\n",
      "Ending training due to 4 consecutive epochs without improvement in validation accuracy.\n",
      "Total training time: 1.5505198558171591 minutes (93.03119134902954 seconds).\n",
      "Model loaded from ./results/vanilla/credit_1_strategic_model.pt.\n",
      "---------- Calculating results ----------\n",
      "Benchmark accuracy: 0.7366666666666667\n",
      "SERM accuracy: 0.7366666666666667\n",
      "Blind accuracy: 0.625\n",
      "---------- Training non-strategically on credit with scale=2 ----------\n",
      "Starting epoch 001 / 016.\n",
      "Ended epoch 001 / 016 | time: 000 sec | loss: 0.71148 | error: 0.32760\n",
      "Model saved to ./results/vanilla/credit_2_non_strategic_model.pt.\n",
      "Starting epoch 002 / 016.\n",
      "Ended epoch 002 / 016 | time: 000 sec | loss: 0.69422 | error: 0.32760\n",
      "Starting epoch 003 / 016.\n",
      "Ended epoch 003 / 016 | time: 000 sec | loss: 0.68551 | error: 0.32760\n",
      "Starting epoch 004 / 016.\n",
      "Ended epoch 004 / 016 | time: 000 sec | loss: 0.68250 | error: 0.32760\n",
      "Starting epoch 005 / 016.\n",
      "Ended epoch 005 / 016 | time: 000 sec | loss: 0.69233 | error: 0.32760\n",
      "Ending training due to 4 consecutive epochs without improvement in validation accuracy.\n",
      "Total training time: 0.22041082382202148 seconds.\n",
      "Model loaded from ./results/vanilla/credit_2_non_strategic_model.pt.\n",
      "---------- Training strategically on credit with scale=2 ----------\n",
      "Starting epoch 001 / 016.\n",
      "  Ended batch 001 / 029 | loss: 0.84934 | error: 0.39062\n",
      "  Ended batch 002 / 029 | loss: 1.25194 | error: 0.51562\n",
      "  Ended batch 003 / 029 | loss: 0.83138 | error: 0.39062\n",
      "  Ended batch 004 / 029 | loss: 0.92830 | error: 0.46875\n",
      "  Ended batch 005 / 029 | loss: 0.73580 | error: 0.42188\n",
      "  Ended batch 006 / 029 | loss: 0.73793 | error: 0.35938\n",
      "  Ended batch 007 / 029 | loss: 0.58563 | error: 0.20312\n",
      "  Ended batch 008 / 029 | loss: 0.87357 | error: 0.37500\n",
      "  Ended batch 009 / 029 | loss: 0.92648 | error: 0.43750\n",
      "  Ended batch 010 / 029 | loss: 0.73137 | error: 0.29688\n",
      "  Ended batch 011 / 029 | loss: 0.58157 | error: 0.21875\n",
      "  Ended batch 012 / 029 | loss: 0.74915 | error: 0.26562\n",
      "  Ended batch 013 / 029 | loss: 0.68347 | error: 0.29688\n",
      "  Ended batch 014 / 029 | loss: 0.91849 | error: 0.34375\n",
      "  Ended batch 015 / 029 | loss: 1.00960 | error: 0.45312\n",
      "  Ended batch 016 / 029 | loss: 0.86134 | error: 0.34375\n",
      "  Ended batch 017 / 029 | loss: 1.05115 | error: 0.45312\n",
      "  Ended batch 018 / 029 | loss: 0.80673 | error: 0.40625\n",
      "  Ended batch 019 / 029 | loss: 0.52948 | error: 0.21875\n",
      "  Ended batch 020 / 029 | loss: 0.81919 | error: 0.35938\n",
      "  Ended batch 021 / 029 | loss: 0.80524 | error: 0.34375\n",
      "  Ended batch 022 / 029 | loss: 0.83925 | error: 0.34375\n",
      "  Ended batch 023 / 029 | loss: 0.76349 | error: 0.32812\n",
      "  Ended batch 024 / 029 | loss: 0.67427 | error: 0.29688\n",
      "  Ended batch 025 / 029 | loss: 0.71609 | error: 0.32812\n",
      "  Ended batch 026 / 029 | loss: 0.88494 | error: 0.43750\n",
      "  Ended batch 027 / 029 | loss: 0.74765 | error: 0.37500\n",
      "  Ended batch 028 / 029 | loss: 0.78802 | error: 0.37500\n",
      "  Ended batch 029 / 029 | loss: 0.94412 | error: 0.50000\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 001 / 016 | time: 018 sec | loss: 0.82093 | error: 0.32760\n",
      "Model saved to ./results/vanilla/credit_2_strategic_model.pt.\n",
      "Starting epoch 002 / 016.\n",
      "  Ended batch 001 / 029 | loss: 0.68039 | error: 0.28125\n",
      "  Ended batch 002 / 029 | loss: 0.73209 | error: 0.31250\n",
      "  Ended batch 003 / 029 | loss: 0.66425 | error: 0.31250\n",
      "  Ended batch 004 / 029 | loss: 0.58207 | error: 0.26562\n",
      "  Ended batch 005 / 029 | loss: 0.57798 | error: 0.25000\n",
      "  Ended batch 006 / 029 | loss: 0.73482 | error: 0.31250\n",
      "  Ended batch 007 / 029 | loss: 0.61721 | error: 0.28125\n",
      "  Ended batch 008 / 029 | loss: 0.78883 | error: 0.35938\n",
      "  Ended batch 009 / 029 | loss: 0.84305 | error: 0.39062\n",
      "  Ended batch 010 / 029 | loss: 0.63549 | error: 0.29688\n",
      "  Ended batch 011 / 029 | loss: 0.52932 | error: 0.21875\n",
      "  Ended batch 012 / 029 | loss: 0.67238 | error: 0.26562\n",
      "  Ended batch 013 / 029 | loss: 0.55854 | error: 0.25000\n",
      "  Ended batch 014 / 029 | loss: 0.74193 | error: 0.34375\n",
      "  Ended batch 015 / 029 | loss: 0.91433 | error: 0.39062\n",
      "  Ended batch 016 / 029 | loss: 0.71853 | error: 0.32812\n",
      "  Ended batch 017 / 029 | loss: 0.87605 | error: 0.40625\n",
      "  Ended batch 018 / 029 | loss: 0.64908 | error: 0.31250\n",
      "  Ended batch 019 / 029 | loss: 0.52399 | error: 0.18750\n",
      "  Ended batch 020 / 029 | loss: 0.79178 | error: 0.35938\n",
      "  Ended batch 021 / 029 | loss: 0.72668 | error: 0.34375\n",
      "  Ended batch 022 / 029 | loss: 0.81555 | error: 0.34375\n",
      "  Ended batch 023 / 029 | loss: 0.68044 | error: 0.32812\n",
      "  Ended batch 024 / 029 | loss: 0.62338 | error: 0.26562\n",
      "  Ended batch 025 / 029 | loss: 0.63355 | error: 0.29688\n",
      "  Ended batch 026 / 029 | loss: 0.90042 | error: 0.42188\n",
      "  Ended batch 027 / 029 | loss: 0.74486 | error: 0.32812\n",
      "  Ended batch 028 / 029 | loss: 0.75693 | error: 0.29688\n",
      "  Ended batch 029 / 029 | loss: 0.98190 | error: 0.50000\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 002 / 016 | time: 017 sec | loss: 0.83291 | error: 0.33698\n",
      "Starting epoch 003 / 016.\n",
      "  Ended batch 001 / 029 | loss: 0.77666 | error: 0.25000\n",
      "  Ended batch 002 / 029 | loss: 0.75159 | error: 0.32812\n",
      "  Ended batch 003 / 029 | loss: 0.69210 | error: 0.29688\n",
      "  Ended batch 004 / 029 | loss: 0.62801 | error: 0.26562\n",
      "  Ended batch 005 / 029 | loss: 0.69314 | error: 0.32812\n",
      "  Ended batch 006 / 029 | loss: 0.73688 | error: 0.35938\n",
      "  Ended batch 007 / 029 | loss: 0.60805 | error: 0.25000\n",
      "  Ended batch 008 / 029 | loss: 0.78470 | error: 0.35938\n",
      "  Ended batch 009 / 029 | loss: 0.89381 | error: 0.37500\n",
      "  Ended batch 010 / 029 | loss: 0.64099 | error: 0.29688\n",
      "  Ended batch 011 / 029 | loss: 0.56504 | error: 0.21875\n",
      "  Ended batch 012 / 029 | loss: 0.68652 | error: 0.26562\n",
      "  Ended batch 013 / 029 | loss: 0.61453 | error: 0.25000\n",
      "  Ended batch 014 / 029 | loss: 0.73200 | error: 0.29688\n",
      "  Ended batch 015 / 029 | loss: 0.98579 | error: 0.39062\n",
      "  Ended batch 016 / 029 | loss: 0.77359 | error: 0.29688\n",
      "  Ended batch 017 / 029 | loss: 0.96831 | error: 0.40625\n",
      "  Ended batch 018 / 029 | loss: 0.67138 | error: 0.29688\n",
      "  Ended batch 019 / 029 | loss: 0.49204 | error: 0.21875\n",
      "  Ended batch 020 / 029 | loss: 0.81706 | error: 0.35938\n",
      "  Ended batch 021 / 029 | loss: 0.80920 | error: 0.34375\n",
      "  Ended batch 022 / 029 | loss: 0.82353 | error: 0.34375\n",
      "  Ended batch 023 / 029 | loss: 0.78284 | error: 0.32812\n",
      "  Ended batch 024 / 029 | loss: 0.60351 | error: 0.26562\n",
      "  Ended batch 025 / 029 | loss: 0.63976 | error: 0.31250\n",
      "  Ended batch 026 / 029 | loss: 0.97797 | error: 0.46875\n",
      "  Ended batch 027 / 029 | loss: 0.75249 | error: 0.32812\n",
      "  Ended batch 028 / 029 | loss: 0.74539 | error: 0.34375\n",
      "  Ended batch 029 / 029 | loss: 0.97785 | error: 0.50000\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 003 / 016 | time: 017 sec | loss: 0.84550 | error: 0.33906\n",
      "Starting epoch 004 / 016.\n",
      "  Ended batch 001 / 029 | loss: 0.80387 | error: 0.35938\n",
      "  Ended batch 002 / 029 | loss: 0.75097 | error: 0.31250\n",
      "  Ended batch 003 / 029 | loss: 0.73541 | error: 0.28125\n",
      "  Ended batch 004 / 029 | loss: 0.63563 | error: 0.32812\n",
      "  Ended batch 005 / 029 | loss: 0.66699 | error: 0.28125\n",
      "  Ended batch 006 / 029 | loss: 0.72434 | error: 0.26562\n",
      "  Ended batch 007 / 029 | loss: 0.63826 | error: 0.25000\n",
      "  Ended batch 008 / 029 | loss: 0.82065 | error: 0.35938\n",
      "  Ended batch 009 / 029 | loss: 0.89624 | error: 0.34375\n",
      "  Ended batch 010 / 029 | loss: 0.62974 | error: 0.26562\n",
      "  Ended batch 011 / 029 | loss: 0.53431 | error: 0.20312\n",
      "  Ended batch 012 / 029 | loss: 0.62489 | error: 0.23438\n",
      "  Ended batch 013 / 029 | loss: 0.61691 | error: 0.25000\n",
      "  Ended batch 014 / 029 | loss: 0.72242 | error: 0.32812\n",
      "  Ended batch 015 / 029 | loss: 0.96305 | error: 0.40625\n",
      "  Ended batch 016 / 029 | loss: 0.76729 | error: 0.32812\n",
      "  Ended batch 017 / 029 | loss: 0.92334 | error: 0.43750\n",
      "  Ended batch 018 / 029 | loss: 0.67586 | error: 0.28125\n",
      "  Ended batch 019 / 029 | loss: 0.53529 | error: 0.20312\n",
      "  Ended batch 020 / 029 | loss: 0.79882 | error: 0.35938\n",
      "  Ended batch 021 / 029 | loss: 0.81333 | error: 0.35938\n",
      "  Ended batch 022 / 029 | loss: 0.77936 | error: 0.34375\n",
      "  Ended batch 023 / 029 | loss: 0.67941 | error: 0.32812\n",
      "  Ended batch 024 / 029 | loss: 0.63259 | error: 0.26562\n",
      "  Ended batch 025 / 029 | loss: 0.64649 | error: 0.29688\n",
      "  Ended batch 026 / 029 | loss: 0.94857 | error: 0.43750\n",
      "  Ended batch 027 / 029 | loss: 0.70223 | error: 0.32812\n",
      "  Ended batch 028 / 029 | loss: 0.69917 | error: 0.31250\n",
      "  Ended batch 029 / 029 | loss: 0.99430 | error: 0.50000\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 004 / 016 | time: 016 sec | loss: 0.81851 | error: 0.32917\n",
      "Starting epoch 005 / 016.\n",
      "  Ended batch 001 / 029 | loss: 0.71532 | error: 0.25000\n",
      "  Ended batch 002 / 029 | loss: 0.74633 | error: 0.32812\n",
      "  Ended batch 003 / 029 | loss: 0.70542 | error: 0.31250\n",
      "  Ended batch 004 / 029 | loss: 0.63174 | error: 0.26562\n",
      "  Ended batch 005 / 029 | loss: 0.68449 | error: 0.29688\n",
      "  Ended batch 006 / 029 | loss: 0.73932 | error: 0.29688\n",
      "  Ended batch 007 / 029 | loss: 0.60626 | error: 0.21875\n",
      "  Ended batch 008 / 029 | loss: 0.80730 | error: 0.35938\n",
      "  Ended batch 009 / 029 | loss: 0.88233 | error: 0.37500\n",
      "  Ended batch 010 / 029 | loss: 0.63576 | error: 0.28125\n",
      "  Ended batch 011 / 029 | loss: 0.54421 | error: 0.20312\n",
      "  Ended batch 012 / 029 | loss: 0.65373 | error: 0.23438\n",
      "  Ended batch 013 / 029 | loss: 0.61195 | error: 0.25000\n",
      "  Ended batch 014 / 029 | loss: 0.73811 | error: 0.31250\n",
      "  Ended batch 015 / 029 | loss: 0.91913 | error: 0.37500\n",
      "  Ended batch 016 / 029 | loss: 0.72902 | error: 0.29688\n",
      "  Ended batch 017 / 029 | loss: 0.90910 | error: 0.40625\n",
      "  Ended batch 018 / 029 | loss: 0.66331 | error: 0.28125\n",
      "  Ended batch 019 / 029 | loss: 0.50751 | error: 0.20312\n",
      "  Ended batch 020 / 029 | loss: 0.80635 | error: 0.34375\n",
      "  Ended batch 021 / 029 | loss: 0.80094 | error: 0.35938\n",
      "  Ended batch 022 / 029 | loss: 0.77488 | error: 0.34375\n",
      "  Ended batch 023 / 029 | loss: 0.70550 | error: 0.32812\n",
      "  Ended batch 024 / 029 | loss: 0.60815 | error: 0.26562\n",
      "  Ended batch 025 / 029 | loss: 0.61491 | error: 0.28125\n",
      "  Ended batch 026 / 029 | loss: 0.92577 | error: 0.43750\n",
      "  Ended batch 027 / 029 | loss: 0.71222 | error: 0.31250\n",
      "  Ended batch 028 / 029 | loss: 0.71451 | error: 0.31250\n",
      "  Ended batch 029 / 029 | loss: 1.00991 | error: 0.50000\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 005 / 016 | time: 016 sec | loss: 0.82093 | error: 0.33542\n",
      "Ending training due to 4 consecutive epochs without improvement in validation accuracy.\n",
      "Total training time: 1.3979616522789002 minutes (83.87769913673401 seconds).\n",
      "Model loaded from ./results/vanilla/credit_2_strategic_model.pt.\n",
      "---------- Calculating results ----------\n",
      "Benchmark accuracy: 0.7366666666666667\n",
      "SERM accuracy: 0.735\n",
      "Blind accuracy: 0.665\n",
      "---------- Training non-strategically on distress with scale=0.5 ----------\n",
      "Starting epoch 001 / 016.\n",
      "Ended epoch 001 / 016 | time: 000 sec | loss: 0.11585 | error: 0.04167\n",
      "Model saved to ./results/vanilla/distress_0.5_non_strategic_model.pt.\n",
      "Starting epoch 002 / 016.\n",
      "Ended epoch 002 / 016 | time: 000 sec | loss: 0.11396 | error: 0.04167\n",
      "Starting epoch 003 / 016.\n",
      "Ended epoch 003 / 016 | time: 000 sec | loss: 0.11974 | error: 0.04167\n",
      "Starting epoch 004 / 016.\n",
      "Ended epoch 004 / 016 | time: 000 sec | loss: 0.12476 | error: 0.04167\n",
      "Validation accuracy improved.\n",
      "Model saved to ./results/vanilla/distress_0.5_non_strategic_model.pt.\n",
      "Starting epoch 005 / 016.\n",
      "Ended epoch 005 / 016 | time: 000 sec | loss: 0.12439 | error: 0.04167\n",
      "Starting epoch 006 / 016.\n",
      "Ended epoch 006 / 016 | time: 000 sec | loss: 0.11779 | error: 0.06250\n",
      "Starting epoch 007 / 016.\n",
      "Ended epoch 007 / 016 | time: 000 sec | loss: 0.11922 | error: 0.05208\n",
      "Starting epoch 008 / 016.\n",
      "Ended epoch 008 / 016 | time: 000 sec | loss: 0.11649 | error: 0.05208\n",
      "Ending training due to 4 consecutive epochs without improvement in validation accuracy.\n",
      "Total training time: 0.08975958824157715 seconds.\n",
      "Model loaded from ./results/vanilla/distress_0.5_non_strategic_model.pt.\n",
      "---------- Training strategically on distress with scale=0.5 ----------\n",
      "Starting epoch 001 / 016.\n",
      "  Ended batch 001 / 011 | loss: 1.05613 | error: 0.79167\n",
      "  Ended batch 002 / 011 | loss: 0.65497 | error: 0.20833\n",
      "  Ended batch 003 / 011 | loss: 1.02831 | error: 0.29167\n",
      "  Ended batch 004 / 011 | loss: 2.07772 | error: 0.54167\n",
      "  Ended batch 005 / 011 | loss: 0.62331 | error: 0.16667\n",
      "  Ended batch 006 / 011 | loss: 1.43285 | error: 0.37500\n",
      "  Ended batch 007 / 011 | loss: 0.91690 | error: 0.25000\n",
      "  Ended batch 008 / 011 | loss: 1.09468 | error: 0.29167\n",
      "  Ended batch 009 / 011 | loss: 1.33303 | error: 0.33333\n",
      "  Ended batch 010 / 011 | loss: 0.64405 | error: 0.16667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\technion\\anaconda3\\envs\\ModularStrategicClassification\\lib\\site-packages\\cvxpy\\problems\\problem.py:1055: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  \"Solution may be inaccurate. Try another solver, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Ended batch 011 / 011 | loss: 1.04275 | error: 0.28571\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 001 / 016 | time: 008 sec | loss: 0.13404 | error: 0.05208\n",
      "Model saved to ./results/vanilla/distress_0.5_strategic_model.pt.\n",
      "Starting epoch 002 / 016.\n",
      "  Ended batch 001 / 011 | loss: 0.59940 | error: 0.16667\n",
      "  Ended batch 002 / 011 | loss: 0.67082 | error: 0.16667\n",
      "  Ended batch 003 / 011 | loss: 0.29811 | error: 0.08333\n",
      "  Ended batch 004 / 011 | loss: 1.85546 | error: 0.41667\n",
      "  Ended batch 005 / 011 | loss: 0.14793 | error: 0.04167\n",
      "  Ended batch 006 / 011 | loss: 0.76549 | error: 0.20833\n",
      "  Ended batch 007 / 011 | loss: 0.28450 | error: 0.08333\n",
      "  Ended batch 008 / 011 | loss: 0.85283 | error: 0.25000\n",
      "  Ended batch 009 / 011 | loss: 1.16028 | error: 0.33333\n",
      "  Ended batch 010 / 011 | loss: 0.28735 | error: 0.08333\n",
      "  Ended batch 011 / 011 | loss: 0.68449 | error: 0.21429\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 002 / 016 | time: 008 sec | loss: 0.12724 | error: 0.05208\n",
      "Starting epoch 003 / 016.\n",
      "  Ended batch 001 / 011 | loss: 0.26256 | error: 0.08333\n",
      "  Ended batch 002 / 011 | loss: 0.54346 | error: 0.16667\n",
      "  Ended batch 003 / 011 | loss: 0.24573 | error: 0.08333\n",
      "  Ended batch 004 / 011 | loss: 1.12587 | error: 0.37500\n",
      "  Ended batch 005 / 011 | loss: 0.22797 | error: 0.08333\n",
      "  Ended batch 006 / 011 | loss: 0.67404 | error: 0.25000\n",
      "  Ended batch 007 / 011 | loss: 0.20157 | error: 0.08333\n",
      "  Ended batch 008 / 011 | loss: 0.37523 | error: 0.16667\n",
      "  Ended batch 009 / 011 | loss: 0.51144 | error: 0.25000\n",
      "  Ended batch 010 / 011 | loss: 0.27490 | error: 0.00000\n",
      "  Ended batch 011 / 011 | loss: 0.32239 | error: 0.14286\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 003 / 016 | time: 009 sec | loss: 1.31499 | error: 0.42708\n",
      "Starting epoch 004 / 016.\n",
      "  Ended batch 001 / 011 | loss: 0.54271 | error: 0.20833\n",
      "  Ended batch 002 / 011 | loss: 0.62467 | error: 0.20833\n",
      "  Ended batch 003 / 011 | loss: 0.84554 | error: 0.29167\n",
      "  Ended batch 004 / 011 | loss: 1.50615 | error: 0.50000\n",
      "  Ended batch 005 / 011 | loss: 0.49505 | error: 0.16667\n",
      "  Ended batch 006 / 011 | loss: 0.86631 | error: 0.29167\n",
      "  Ended batch 007 / 011 | loss: 0.23917 | error: 0.08333\n",
      "  Ended batch 008 / 011 | loss: 0.48897 | error: 0.12500\n",
      "  Ended batch 009 / 011 | loss: 0.59829 | error: 0.20833\n",
      "  Ended batch 010 / 011 | loss: 0.11575 | error: 0.04167\n",
      "  Ended batch 011 / 011 | loss: 0.00000 | error: 0.00000\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 004 / 016 | time: 008 sec | loss: 1.21024 | error: 0.34375\n",
      "Starting epoch 005 / 016.\n",
      "  Ended batch 001 / 011 | loss: 0.00000 | error: 0.00000\n",
      "  Ended batch 002 / 011 | loss: 0.43356 | error: 0.12500\n",
      "  Ended batch 003 / 011 | loss: 0.20988 | error: 0.04167\n",
      "  Ended batch 004 / 011 | loss: 0.53353 | error: 0.12500\n",
      "  Ended batch 005 / 011 | loss: 0.23134 | error: 0.04167\n",
      "  Ended batch 006 / 011 | loss: 0.42399 | error: 0.12500\n",
      "  Ended batch 007 / 011 | loss: 0.23774 | error: 0.08333\n",
      "  Ended batch 008 / 011 | loss: 0.60296 | error: 0.20833\n",
      "  Ended batch 009 / 011 | loss: 0.84311 | error: 0.29167\n",
      "  Ended batch 010 / 011 | loss: 0.47455 | error: 0.16667\n",
      "  Ended batch 011 / 011 | loss: 0.71401 | error: 0.21429\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 005 / 016 | time: 007 sec | loss: 1.96611 | error: 0.55208\n",
      "Ending training due to 4 consecutive epochs without improvement in validation accuracy.\n",
      "Total training time: 40.1673378944397 seconds.\n",
      "Model loaded from ./results/vanilla/distress_0.5_strategic_model.pt.\n",
      "---------- Calculating results ----------\n",
      "Benchmark accuracy: 0.9285714285714286\n",
      "SERM accuracy: 0.9166666666666666\n",
      "Blind accuracy: 0.6309523809523809\n",
      "---------- Training non-strategically on distress with scale=1 ----------\n",
      "Starting epoch 001 / 016.\n",
      "Ended epoch 001 / 016 | time: 000 sec | loss: 0.11240 | error: 0.04167\n",
      "Model saved to ./results/vanilla/distress_1_non_strategic_model.pt.\n",
      "Starting epoch 002 / 016.\n",
      "Ended epoch 002 / 016 | time: 000 sec | loss: 0.11541 | error: 0.04167\n",
      "Starting epoch 003 / 016.\n",
      "Ended epoch 003 / 016 | time: 000 sec | loss: 0.12048 | error: 0.04167\n",
      "Starting epoch 004 / 016.\n",
      "Ended epoch 004 / 016 | time: 000 sec | loss: 0.12387 | error: 0.05208\n",
      "Starting epoch 005 / 016.\n",
      "Ended epoch 005 / 016 | time: 000 sec | loss: 0.12444 | error: 0.05208\n",
      "Ending training due to 4 consecutive epochs without improvement in validation accuracy.\n",
      "Total training time: 0.056995391845703125 seconds.\n",
      "Model loaded from ./results/vanilla/distress_1_non_strategic_model.pt.\n",
      "---------- Training strategically on distress with scale=1 ----------\n",
      "Starting epoch 001 / 016.\n",
      "  Ended batch 001 / 011 | loss: 1.15507 | error: 0.79167\n",
      "  Ended batch 002 / 011 | loss: 0.56551 | error: 0.20833\n",
      "  Ended batch 003 / 011 | loss: 0.83183 | error: 0.29167\n",
      "  Ended batch 004 / 011 | loss: 1.69147 | error: 0.54167\n",
      "  Ended batch 005 / 011 | loss: 0.49612 | error: 0.16667\n",
      "  Ended batch 006 / 011 | loss: 1.17873 | error: 0.37500\n",
      "  Ended batch 007 / 011 | loss: 0.75410 | error: 0.25000\n",
      "  Ended batch 008 / 011 | loss: 0.77815 | error: 0.25000\n",
      "  Ended batch 009 / 011 | loss: 1.10866 | error: 0.33333\n",
      "  Ended batch 010 / 011 | loss: 0.26947 | error: 0.08333\n",
      "  Ended batch 011 / 011 | loss: 0.45064 | error: 0.14286\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 001 / 016 | time: 008 sec | loss: 0.10233 | error: 0.04167\n",
      "Model saved to ./results/vanilla/distress_1_strategic_model.pt.\n",
      "Starting epoch 002 / 016.\n",
      "  Ended batch 001 / 011 | loss: 0.25949 | error: 0.08333\n",
      "  Ended batch 002 / 011 | loss: 0.81869 | error: 0.20833\n",
      "  Ended batch 003 / 011 | loss: 0.00000 | error: 0.00000\n",
      "  Ended batch 004 / 011 | loss: 1.55210 | error: 0.37500\n",
      "  Ended batch 005 / 011 | loss: 0.00000 | error: 0.00000\n",
      "  Ended batch 006 / 011 | loss: 0.66782 | error: 0.20833\n",
      "  Ended batch 007 / 011 | loss: 0.25051 | error: 0.08333\n",
      "  Ended batch 008 / 011 | loss: 0.38589 | error: 0.12500\n",
      "  Ended batch 009 / 011 | loss: 1.10982 | error: 0.33333\n",
      "  Ended batch 010 / 011 | loss: 0.37572 | error: 0.12500\n",
      "  Ended batch 011 / 011 | loss: 0.40865 | error: 0.14286\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 002 / 016 | time: 007 sec | loss: 0.14004 | error: 0.06250\n",
      "Starting epoch 003 / 016.\n",
      "  Ended batch 001 / 011 | loss: 0.46931 | error: 0.16667\n",
      "  Ended batch 002 / 011 | loss: 0.49677 | error: 0.16667\n",
      "  Ended batch 003 / 011 | loss: 0.22054 | error: 0.08333\n",
      "  Ended batch 004 / 011 | loss: 1.02373 | error: 0.37500\n",
      "  Ended batch 005 / 011 | loss: 0.41062 | error: 0.16667\n",
      "  Ended batch 006 / 011 | loss: 0.71793 | error: 0.29167\n",
      "  Ended batch 007 / 011 | loss: 0.55639 | error: 0.25000\n",
      "  Ended batch 008 / 011 | loss: 0.73404 | error: 0.33333\n",
      "  Ended batch 009 / 011 | loss: 0.61269 | error: 0.33333\n",
      "  Ended batch 010 / 011 | loss: 0.42320 | error: 0.08333\n",
      "  Ended batch 011 / 011 | loss: 0.51885 | error: 0.28571\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 003 / 016 | time: 008 sec | loss: 0.30952 | error: 0.05208\n",
      "Starting epoch 004 / 016.\n",
      "  Ended batch 001 / 011 | loss: 0.34390 | error: 0.16667\n",
      "  Ended batch 002 / 011 | loss: 0.56720 | error: 0.20833\n",
      "  Ended batch 003 / 011 | loss: 0.28515 | error: 0.12500\n",
      "  Ended batch 004 / 011 | loss: 0.94112 | error: 0.33333\n",
      "  Ended batch 005 / 011 | loss: 0.09540 | error: 0.04167\n",
      "  Ended batch 006 / 011 | loss: 0.39485 | error: 0.16667\n",
      "  Ended batch 007 / 011 | loss: 0.00000 | error: 0.00000\n",
      "  Ended batch 008 / 011 | loss: 0.18677 | error: 0.08333\n",
      "  Ended batch 009 / 011 | loss: 0.64323 | error: 0.29167\n",
      "  Ended batch 010 / 011 | loss: 0.16826 | error: 0.08333\n",
      "  Ended batch 011 / 011 | loss: 0.00368 | error: 0.00000\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 004 / 016 | time: 008 sec | loss: 1.07773 | error: 0.37500\n",
      "Starting epoch 005 / 016.\n",
      "  Ended batch 001 / 011 | loss: 0.01049 | error: 0.00000\n",
      "  Ended batch 002 / 011 | loss: 0.33062 | error: 0.12500\n",
      "  Ended batch 003 / 011 | loss: 0.15362 | error: 0.04167\n",
      "  Ended batch 004 / 011 | loss: 0.51599 | error: 0.25000\n",
      "  Ended batch 005 / 011 | loss: 0.00033 | error: 0.00000\n",
      "  Ended batch 006 / 011 | loss: 0.40125 | error: 0.16667\n",
      "  Ended batch 007 / 011 | loss: 0.08813 | error: 0.04167\n",
      "  Ended batch 008 / 011 | loss: 0.33086 | error: 0.16667\n",
      "  Ended batch 009 / 011 | loss: 0.32667 | error: 0.16667\n",
      "  Ended batch 010 / 011 | loss: 0.31553 | error: 0.16667\n",
      "  Ended batch 011 / 011 | loss: 0.07405 | error: 0.00000\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 005 / 016 | time: 008 sec | loss: 0.79427 | error: 0.27083\n",
      "Ending training due to 4 consecutive epochs without improvement in validation accuracy.\n",
      "Total training time: 39.83873748779297 seconds.\n",
      "Model loaded from ./results/vanilla/distress_1_strategic_model.pt.\n",
      "---------- Calculating results ----------\n",
      "Benchmark accuracy: 0.9285714285714286\n",
      "SERM accuracy: 0.9166666666666666\n",
      "Blind accuracy: 0.6428571428571429\n",
      "---------- Training non-strategically on distress with scale=2 ----------\n",
      "Starting epoch 001 / 016.\n",
      "Ended epoch 001 / 016 | time: 000 sec | loss: 0.11789 | error: 0.04167\n",
      "Model saved to ./results/vanilla/distress_2_non_strategic_model.pt.\n",
      "Starting epoch 002 / 016.\n",
      "Ended epoch 002 / 016 | time: 000 sec | loss: 0.12518 | error: 0.05208\n",
      "Starting epoch 003 / 016.\n",
      "Ended epoch 003 / 016 | time: 000 sec | loss: 0.13444 | error: 0.05208\n",
      "Starting epoch 004 / 016.\n",
      "Ended epoch 004 / 016 | time: 000 sec | loss: 0.13911 | error: 0.05208\n",
      "Starting epoch 005 / 016.\n",
      "Ended epoch 005 / 016 | time: 000 sec | loss: 0.13730 | error: 0.06250\n",
      "Ending training due to 4 consecutive epochs without improvement in validation accuracy.\n",
      "Total training time: 0.06183624267578125 seconds.\n",
      "Model loaded from ./results/vanilla/distress_2_non_strategic_model.pt.\n",
      "---------- Training strategically on distress with scale=2 ----------\n",
      "Starting epoch 001 / 016.\n",
      "  Ended batch 001 / 011 | loss: 0.44139 | error: 0.20833\n",
      "  Ended batch 002 / 011 | loss: 0.54002 | error: 0.20833\n",
      "  Ended batch 003 / 011 | loss: 0.67662 | error: 0.29167\n",
      "  Ended batch 004 / 011 | loss: 1.32382 | error: 0.45833\n",
      "  Ended batch 005 / 011 | loss: 0.32242 | error: 0.12500\n",
      "  Ended batch 006 / 011 | loss: 0.78353 | error: 0.29167\n",
      "  Ended batch 007 / 011 | loss: 0.32082 | error: 0.12500\n",
      "  Ended batch 008 / 011 | loss: 0.81602 | error: 0.25000\n",
      "  Ended batch 009 / 011 | loss: 0.88324 | error: 0.33333\n",
      "  Ended batch 010 / 011 | loss: 0.22240 | error: 0.08333\n",
      "  Ended batch 011 / 011 | loss: 0.18293 | error: 0.07143\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 001 / 016 | time: 008 sec | loss: 0.15777 | error: 0.06250\n",
      "Model saved to ./results/vanilla/distress_2_strategic_model.pt.\n",
      "Starting epoch 002 / 016.\n",
      "  Ended batch 001 / 011 | loss: 0.10356 | error: 0.04167\n",
      "  Ended batch 002 / 011 | loss: 0.54729 | error: 0.16667\n",
      "  Ended batch 003 / 011 | loss: 0.10212 | error: 0.04167\n",
      "  Ended batch 004 / 011 | loss: 0.76321 | error: 0.29167\n",
      "  Ended batch 005 / 011 | loss: 0.00000 | error: 0.00000\n",
      "  Ended batch 006 / 011 | loss: 0.48118 | error: 0.16667\n",
      "  Ended batch 007 / 011 | loss: 0.32084 | error: 0.08333\n",
      "  Ended batch 008 / 011 | loss: 0.20598 | error: 0.08333\n",
      "  Ended batch 009 / 011 | loss: 0.61147 | error: 0.25000\n",
      "  Ended batch 010 / 011 | loss: 0.50673 | error: 0.20833\n",
      "  Ended batch 011 / 011 | loss: 0.56729 | error: 0.21429\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 002 / 016 | time: 007 sec | loss: 0.39268 | error: 0.09375\n",
      "Starting epoch 003 / 016.\n",
      "  Ended batch 001 / 011 | loss: 0.37064 | error: 0.16667\n",
      "  Ended batch 002 / 011 | loss: 0.46709 | error: 0.20833\n",
      "  Ended batch 003 / 011 | loss: 0.34704 | error: 0.16667\n",
      "  Ended batch 004 / 011 | loss: 0.80812 | error: 0.37500\n",
      "  Ended batch 005 / 011 | loss: 0.16228 | error: 0.08333\n",
      "  Ended batch 006 / 011 | loss: 0.39071 | error: 0.16667\n",
      "  Ended batch 007 / 011 | loss: 0.17350 | error: 0.08333\n",
      "  Ended batch 008 / 011 | loss: 0.25919 | error: 0.12500\n",
      "  Ended batch 009 / 011 | loss: 0.44827 | error: 0.16667\n",
      "  Ended batch 010 / 011 | loss: 0.43612 | error: 0.16667\n",
      "  Ended batch 011 / 011 | loss: 0.15636 | error: 0.07143\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 003 / 016 | time: 008 sec | loss: 0.53009 | error: 0.17708\n",
      "Starting epoch 004 / 016.\n",
      "  Ended batch 001 / 011 | loss: 0.18048 | error: 0.08333\n",
      "  Ended batch 002 / 011 | loss: 0.48354 | error: 0.16667\n",
      "  Ended batch 003 / 011 | loss: 0.00000 | error: 0.00000\n",
      "  Ended batch 004 / 011 | loss: 0.46850 | error: 0.16667\n",
      "  Ended batch 005 / 011 | loss: 0.16610 | error: 0.04167\n",
      "  Ended batch 006 / 011 | loss: 0.43613 | error: 0.20833\n",
      "  Ended batch 007 / 011 | loss: 0.22580 | error: 0.08333\n",
      "  Ended batch 008 / 011 | loss: 0.33181 | error: 0.16667\n",
      "  Ended batch 009 / 011 | loss: 0.46326 | error: 0.25000\n",
      "  Ended batch 010 / 011 | loss: 0.32439 | error: 0.16667\n",
      "  Ended batch 011 / 011 | loss: 0.36186 | error: 0.21429\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 004 / 016 | time: 008 sec | loss: 0.39641 | error: 0.08333\n",
      "Starting epoch 005 / 016.\n",
      "  Ended batch 001 / 011 | loss: 0.15857 | error: 0.08333\n",
      "  Ended batch 002 / 011 | loss: 0.44060 | error: 0.16667\n",
      "  Ended batch 003 / 011 | loss: 0.08408 | error: 0.04167\n",
      "  Ended batch 004 / 011 | loss: 0.74476 | error: 0.25000\n",
      "  Ended batch 005 / 011 | loss: 0.00000 | error: 0.00000\n",
      "  Ended batch 006 / 011 | loss: 0.36728 | error: 0.12500\n",
      "  Ended batch 007 / 011 | loss: 0.00000 | error: 0.00000\n",
      "  Ended batch 008 / 011 | loss: 0.10576 | error: 0.04167\n",
      "  Ended batch 009 / 011 | loss: 0.64150 | error: 0.25000\n",
      "  Ended batch 010 / 011 | loss: 0.11773 | error: 0.04167\n",
      "  Ended batch 011 / 011 | loss: 0.17763 | error: 0.07143\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 005 / 016 | time: 006 sec | loss: 0.12928 | error: 0.05208\n",
      "Validation accuracy improved.\n",
      "Model saved to ./results/vanilla/distress_2_strategic_model.pt.\n",
      "Starting epoch 006 / 016.\n",
      "  Ended batch 001 / 011 | loss: 0.00000 | error: 0.00000\n",
      "  Ended batch 002 / 011 | loss: 0.63666 | error: 0.20833\n",
      "  Ended batch 003 / 011 | loss: 0.00000 | error: 0.00000\n",
      "  Ended batch 004 / 011 | loss: 1.07590 | error: 0.37500\n",
      "  Ended batch 005 / 011 | loss: 0.10416 | error: 0.04167\n",
      "  Ended batch 006 / 011 | loss: 0.53093 | error: 0.20833\n",
      "  Ended batch 007 / 011 | loss: 0.20541 | error: 0.08333\n",
      "  Ended batch 008 / 011 | loss: 0.30673 | error: 0.12500\n",
      "  Ended batch 009 / 011 | loss: 0.70961 | error: 0.29167\n",
      "  Ended batch 010 / 011 | loss: 0.38989 | error: 0.16667\n",
      "  Ended batch 011 / 011 | loss: 0.30860 | error: 0.14286\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 006 / 016 | time: 007 sec | loss: 0.33290 | error: 0.09375\n",
      "Starting epoch 007 / 016.\n",
      "  Ended batch 001 / 011 | loss: 0.26236 | error: 0.12500\n",
      "  Ended batch 002 / 011 | loss: 0.34435 | error: 0.16667\n",
      "  Ended batch 003 / 011 | loss: 0.11689 | error: 0.04167\n",
      "  Ended batch 004 / 011 | loss: 0.31394 | error: 0.16667\n",
      "  Ended batch 005 / 011 | loss: 0.10040 | error: 0.00000\n",
      "  Ended batch 006 / 011 | loss: 0.31553 | error: 0.16667\n",
      "  Ended batch 007 / 011 | loss: 0.08508 | error: 0.04167\n",
      "  Ended batch 008 / 011 | loss: 0.27255 | error: 0.12500\n",
      "  Ended batch 009 / 011 | loss: 0.83160 | error: 0.33333\n",
      "  Ended batch 010 / 011 | loss: 0.57279 | error: 0.16667\n",
      "  Ended batch 011 / 011 | loss: 0.46657 | error: 0.21429\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 007 / 016 | time: 008 sec | loss: 0.23347 | error: 0.04167\n",
      "Validation accuracy improved.\n",
      "Model saved to ./results/vanilla/distress_2_strategic_model.pt.\n",
      "Starting epoch 008 / 016.\n",
      "  Ended batch 001 / 011 | loss: 0.09059 | error: 0.04167\n",
      "  Ended batch 002 / 011 | loss: 0.47070 | error: 0.16667\n",
      "  Ended batch 003 / 011 | loss: 0.08709 | error: 0.04167\n",
      "  Ended batch 004 / 011 | loss: 0.52903 | error: 0.25000\n",
      "  Ended batch 005 / 011 | loss: 0.08018 | error: 0.04167\n",
      "  Ended batch 006 / 011 | loss: 0.17668 | error: 0.08333\n",
      "  Ended batch 007 / 011 | loss: 0.08484 | error: 0.04167\n",
      "  Ended batch 008 / 011 | loss: 0.22548 | error: 0.12500\n",
      "  Ended batch 009 / 011 | loss: 0.36984 | error: 0.20833\n",
      "  Ended batch 010 / 011 | loss: 0.18280 | error: 0.08333\n",
      "  Ended batch 011 / 011 | loss: 0.24346 | error: 0.07143\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 008 / 016 | time: 009 sec | loss: 0.46374 | error: 0.10417\n",
      "Starting epoch 009 / 016.\n",
      "  Ended batch 001 / 011 | loss: 0.15245 | error: 0.04167\n",
      "  Ended batch 002 / 011 | loss: 0.32500 | error: 0.12500\n",
      "  Ended batch 003 / 011 | loss: 0.17148 | error: 0.08333\n",
      "  Ended batch 004 / 011 | loss: 0.85996 | error: 0.37500\n",
      "  Ended batch 005 / 011 | loss: 0.27384 | error: 0.12500\n",
      "  Ended batch 006 / 011 | loss: 0.62541 | error: 0.29167\n",
      "  Ended batch 007 / 011 | loss: 0.26357 | error: 0.12500\n",
      "  Ended batch 008 / 011 | loss: 0.34339 | error: 0.16667\n",
      "  Ended batch 009 / 011 | loss: 0.26644 | error: 0.12500\n",
      "  Ended batch 010 / 011 | loss: 0.23051 | error: 0.12500\n",
      "  Ended batch 011 / 011 | loss: 0.02773 | error: 0.00000\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 009 / 016 | time: 008 sec | loss: 0.50643 | error: 0.14583\n",
      "Starting epoch 010 / 016.\n",
      "  Ended batch 001 / 011 | loss: 0.01491 | error: 0.00000\n",
      "  Ended batch 002 / 011 | loss: 0.35014 | error: 0.12500\n",
      "  Ended batch 003 / 011 | loss: 0.13430 | error: 0.04167\n",
      "  Ended batch 004 / 011 | loss: 0.58040 | error: 0.20833\n",
      "  Ended batch 005 / 011 | loss: 0.14694 | error: 0.04167\n",
      "  Ended batch 006 / 011 | loss: 0.46726 | error: 0.20833\n",
      "  Ended batch 007 / 011 | loss: 0.25527 | error: 0.12500\n",
      "  Ended batch 008 / 011 | loss: 0.42003 | error: 0.20833\n",
      "  Ended batch 009 / 011 | loss: 0.54862 | error: 0.29167\n",
      "  Ended batch 010 / 011 | loss: 0.19223 | error: 0.08333\n",
      "  Ended batch 011 / 011 | loss: 0.44346 | error: 0.28571\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 010 / 016 | time: 007 sec | loss: 0.30875 | error: 0.06250\n",
      "Starting epoch 011 / 016.\n",
      "  Ended batch 001 / 011 | loss: 0.07720 | error: 0.04167\n",
      "  Ended batch 002 / 011 | loss: 0.45742 | error: 0.16667\n",
      "  Ended batch 003 / 011 | loss: 0.00000 | error: 0.00000\n",
      "  Ended batch 004 / 011 | loss: 0.50721 | error: 0.16667\n",
      "  Ended batch 005 / 011 | loss: 0.00000 | error: 0.00000\n",
      "  Ended batch 006 / 011 | loss: 0.34543 | error: 0.12500\n",
      "  Ended batch 007 / 011 | loss: 0.08888 | error: 0.04167\n",
      "  Ended batch 008 / 011 | loss: 0.29182 | error: 0.12500\n",
      "  Ended batch 009 / 011 | loss: 0.58092 | error: 0.25000\n",
      "  Ended batch 010 / 011 | loss: 0.27687 | error: 0.12500\n",
      "  Ended batch 011 / 011 | loss: 0.14866 | error: 0.07143\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 011 / 016 | time: 007 sec | loss: 0.22640 | error: 0.06250\n",
      "Ending training due to 4 consecutive epochs without improvement in validation accuracy.\n",
      "Total training time: 1.3903161883354187 minutes (83.41897130012512 seconds).\n",
      "Model loaded from ./results/vanilla/distress_2_strategic_model.pt.\n",
      "---------- Calculating results ----------\n",
      "Benchmark accuracy: 0.9404761904761905\n",
      "SERM accuracy: 0.9285714285714286\n",
      "Blind accuracy: 0.6666666666666666\n",
      "---------- Training non-strategically on fraud with scale=0.5 ----------\n",
      "Starting epoch 001 / 016.\n",
      "Ended epoch 001 / 016 | time: 000 sec | loss: 0.28257 | error: 0.12870\n",
      "Model saved to ./results/vanilla/fraud_0.5_non_strategic_model.pt.\n",
      "Starting epoch 002 / 016.\n",
      "Ended epoch 002 / 016 | time: 000 sec | loss: 0.24906 | error: 0.09259\n",
      "Validation accuracy improved.\n",
      "Model saved to ./results/vanilla/fraud_0.5_non_strategic_model.pt.\n",
      "Starting epoch 003 / 016.\n",
      "Ended epoch 003 / 016 | time: 000 sec | loss: 0.24345 | error: 0.09722\n",
      "Starting epoch 004 / 016.\n",
      "Ended epoch 004 / 016 | time: 000 sec | loss: 0.23287 | error: 0.12407\n",
      "Starting epoch 005 / 016.\n",
      "Ended epoch 005 / 016 | time: 000 sec | loss: 0.22873 | error: 0.12407\n",
      "Starting epoch 006 / 016.\n",
      "Ended epoch 006 / 016 | time: 000 sec | loss: 0.21878 | error: 0.11481\n",
      "Ending training due to 4 consecutive epochs without improvement in validation accuracy.\n",
      "Total training time: 0.14660954475402832 seconds.\n",
      "Model loaded from ./results/vanilla/fraud_0.5_non_strategic_model.pt.\n",
      "---------- Training strategically on fraud with scale=0.5 ----------\n",
      "Starting epoch 001 / 016.\n",
      "  Ended batch 001 / 025 | loss: 0.99198 | error: 0.33333\n",
      "  Ended batch 002 / 025 | loss: 0.80526 | error: 0.37500\n",
      "  Ended batch 003 / 025 | loss: 1.19918 | error: 0.50000\n",
      "  Ended batch 004 / 025 | loss: 0.85427 | error: 0.37500\n",
      "  Ended batch 005 / 025 | loss: 0.54701 | error: 0.25000\n",
      "  Ended batch 006 / 025 | loss: 0.33394 | error: 0.16667\n",
      "  Ended batch 007 / 025 | loss: 0.57362 | error: 0.20833\n",
      "  Ended batch 008 / 025 | loss: 0.39360 | error: 0.16667\n",
      "  Ended batch 009 / 025 | loss: 0.27039 | error: 0.12500\n",
      "  Ended batch 010 / 025 | loss: 0.29031 | error: 0.12500\n",
      "  Ended batch 011 / 025 | loss: 0.19688 | error: 0.08333\n",
      "  Ended batch 012 / 025 | loss: 0.09685 | error: 0.04167\n",
      "  Ended batch 013 / 025 | loss: 0.30058 | error: 0.12500\n",
      "  Ended batch 014 / 025 | loss: 0.19818 | error: 0.08333\n",
      "  Ended batch 015 / 025 | loss: 0.25307 | error: 0.08333\n",
      "  Ended batch 016 / 025 | loss: 0.19493 | error: 0.08333\n",
      "  Ended batch 017 / 025 | loss: 0.10046 | error: 0.04167\n",
      "  Ended batch 018 / 025 | loss: 0.09815 | error: 0.04167\n",
      "  Ended batch 019 / 025 | loss: 0.26963 | error: 0.08333\n",
      "  Ended batch 020 / 025 | loss: 0.41599 | error: 0.12500\n",
      "  Ended batch 021 / 025 | loss: 0.34132 | error: 0.08333\n",
      "  Ended batch 022 / 025 | loss: 0.37521 | error: 0.16667\n",
      "  Ended batch 023 / 025 | loss: 0.00000 | error: 0.00000\n",
      "  Ended batch 024 / 025 | loss: 0.40338 | error: 0.16667\n",
      "  Ended batch 025 / 025 | loss: 0.15013 | error: 0.06667\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 001 / 016 | time: 010 sec | loss: 1.67149 | error: 0.48241\n",
      "Model saved to ./results/vanilla/fraud_0.5_strategic_model.pt.\n",
      "Starting epoch 002 / 016.\n",
      "  Ended batch 001 / 025 | loss: 0.09263 | error: 0.04167\n",
      "  Ended batch 002 / 025 | loss: 0.26457 | error: 0.12500\n",
      "  Ended batch 003 / 025 | loss: 0.33744 | error: 0.12500\n",
      "  Ended batch 004 / 025 | loss: 0.55113 | error: 0.16667\n",
      "  Ended batch 005 / 025 | loss: 0.25888 | error: 0.12500\n",
      "  Ended batch 006 / 025 | loss: 0.34560 | error: 0.16667\n",
      "  Ended batch 007 / 025 | loss: 0.42597 | error: 0.20833\n",
      "  Ended batch 008 / 025 | loss: 0.27062 | error: 0.12500\n",
      "  Ended batch 009 / 025 | loss: 0.17096 | error: 0.08333\n",
      "  Ended batch 010 / 025 | loss: 0.59272 | error: 0.25000\n",
      "  Ended batch 011 / 025 | loss: 0.34003 | error: 0.16667\n",
      "  Ended batch 012 / 025 | loss: 0.33513 | error: 0.16667\n",
      "  Ended batch 013 / 025 | loss: 0.37100 | error: 0.16667\n",
      "  Ended batch 014 / 025 | loss: 0.17699 | error: 0.08333\n",
      "  Ended batch 015 / 025 | loss: 0.45186 | error: 0.20833\n",
      "  Ended batch 016 / 025 | loss: 0.54688 | error: 0.25000\n",
      "  Ended batch 017 / 025 | loss: 0.61780 | error: 0.29167\n",
      "  Ended batch 018 / 025 | loss: 0.61581 | error: 0.29167\n",
      "  Ended batch 019 / 025 | loss: 0.33289 | error: 0.16667\n",
      "  Ended batch 020 / 025 | loss: 0.39209 | error: 0.12500\n",
      "  Ended batch 021 / 025 | loss: 0.32748 | error: 0.16667\n",
      "  Ended batch 022 / 025 | loss: 0.74133 | error: 0.33333\n",
      "  Ended batch 023 / 025 | loss: 0.44761 | error: 0.20833\n",
      "  Ended batch 024 / 025 | loss: 0.55356 | error: 0.25000\n",
      "  Ended batch 025 / 025 | loss: 0.56136 | error: 0.26667\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 002 / 016 | time: 011 sec | loss: 0.82742 | error: 0.31574\n",
      "Validation accuracy improved.\n",
      "Model saved to ./results/vanilla/fraud_0.5_strategic_model.pt.\n",
      "Starting epoch 003 / 016.\n",
      "  Ended batch 001 / 025 | loss: 0.33160 | error: 0.16667\n",
      "  Ended batch 002 / 025 | loss: 0.28899 | error: 0.08333\n",
      "  Ended batch 003 / 025 | loss: 0.40855 | error: 0.20833\n",
      "  Ended batch 004 / 025 | loss: 0.41026 | error: 0.20833\n",
      "  Ended batch 005 / 025 | loss: 0.35822 | error: 0.16667\n",
      "  Ended batch 006 / 025 | loss: 0.44043 | error: 0.20833\n",
      "  Ended batch 007 / 025 | loss: 0.44520 | error: 0.20833\n",
      "  Ended batch 008 / 025 | loss: 0.34032 | error: 0.16667\n",
      "  Ended batch 009 / 025 | loss: 0.30997 | error: 0.12500\n",
      "  Ended batch 010 / 025 | loss: 0.26305 | error: 0.12500\n",
      "  Ended batch 011 / 025 | loss: 0.25951 | error: 0.12500\n",
      "  Ended batch 012 / 025 | loss: 0.27182 | error: 0.12500\n",
      "  Ended batch 013 / 025 | loss: 0.55045 | error: 0.25000\n",
      "  Ended batch 014 / 025 | loss: 0.28175 | error: 0.12500\n",
      "  Ended batch 015 / 025 | loss: 0.46852 | error: 0.20833\n",
      "  Ended batch 016 / 025 | loss: 0.27362 | error: 0.12500\n",
      "  Ended batch 017 / 025 | loss: 0.18207 | error: 0.08333\n",
      "  Ended batch 018 / 025 | loss: 0.35518 | error: 0.16667\n",
      "  Ended batch 019 / 025 | loss: 0.08362 | error: 0.04167\n",
      "  Ended batch 020 / 025 | loss: 0.19882 | error: 0.08333\n",
      "  Ended batch 021 / 025 | loss: 0.16857 | error: 0.08333\n",
      "  Ended batch 022 / 025 | loss: 0.51670 | error: 0.25000\n",
      "  Ended batch 023 / 025 | loss: 0.08398 | error: 0.04167\n",
      "  Ended batch 024 / 025 | loss: 0.35727 | error: 0.16667\n",
      "  Ended batch 025 / 025 | loss: 0.26532 | error: 0.13333\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 003 / 016 | time: 009 sec | loss: 1.65193 | error: 0.48704\n",
      "Starting epoch 004 / 016.\n",
      "  Ended batch 001 / 025 | loss: 0.16817 | error: 0.08333\n",
      "  Ended batch 002 / 025 | loss: 0.11783 | error: 0.04167\n",
      "  Ended batch 003 / 025 | loss: 0.26179 | error: 0.12500\n",
      "  Ended batch 004 / 025 | loss: 0.34359 | error: 0.12500\n",
      "  Ended batch 005 / 025 | loss: 0.28143 | error: 0.12500\n",
      "  Ended batch 006 / 025 | loss: 0.38192 | error: 0.16667\n",
      "  Ended batch 007 / 025 | loss: 0.47828 | error: 0.20833\n",
      "  Ended batch 008 / 025 | loss: 0.28133 | error: 0.12500\n",
      "  Ended batch 009 / 025 | loss: 0.17956 | error: 0.08333\n",
      "  Ended batch 010 / 025 | loss: 0.08747 | error: 0.04167\n",
      "  Ended batch 011 / 025 | loss: 0.08516 | error: 0.04167\n",
      "  Ended batch 012 / 025 | loss: 0.11813 | error: 0.04167\n",
      "  Ended batch 013 / 025 | loss: 0.15839 | error: 0.04167\n",
      "  Ended batch 014 / 025 | loss: 0.09361 | error: 0.04167\n",
      "  Ended batch 015 / 025 | loss: 0.18461 | error: 0.08333\n",
      "  Ended batch 016 / 025 | loss: 0.19016 | error: 0.08333\n",
      "  Ended batch 017 / 025 | loss: 0.19668 | error: 0.08333\n",
      "  Ended batch 018 / 025 | loss: 0.49582 | error: 0.20833\n",
      "  Ended batch 019 / 025 | loss: 0.28355 | error: 0.12500\n",
      "  Ended batch 020 / 025 | loss: 0.37356 | error: 0.16667\n",
      "  Ended batch 021 / 025 | loss: 0.18408 | error: 0.08333\n",
      "  Ended batch 022 / 025 | loss: 0.52316 | error: 0.25000\n",
      "  Ended batch 023 / 025 | loss: 0.00482 | error: 0.00000\n",
      "  Ended batch 024 / 025 | loss: 0.27654 | error: 0.12500\n",
      "  Ended batch 025 / 025 | loss: 0.13223 | error: 0.06667\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 004 / 016 | time: 009 sec | loss: 1.54026 | error: 0.48241\n",
      "Starting epoch 005 / 016.\n",
      "  Ended batch 001 / 025 | loss: 0.26771 | error: 0.12500\n",
      "  Ended batch 002 / 025 | loss: 0.18352 | error: 0.08333\n",
      "  Ended batch 003 / 025 | loss: 0.46586 | error: 0.20833\n",
      "  Ended batch 004 / 025 | loss: 0.43836 | error: 0.16667\n",
      "  Ended batch 005 / 025 | loss: 0.18715 | error: 0.08333\n",
      "  Ended batch 006 / 025 | loss: 0.18066 | error: 0.08333\n",
      "  Ended batch 007 / 025 | loss: 0.26578 | error: 0.12500\n",
      "  Ended batch 008 / 025 | loss: 0.25157 | error: 0.12500\n",
      "  Ended batch 009 / 025 | loss: 0.11846 | error: 0.04167\n",
      "  Ended batch 010 / 025 | loss: 0.25836 | error: 0.12500\n",
      "  Ended batch 011 / 025 | loss: 0.09212 | error: 0.04167\n",
      "  Ended batch 012 / 025 | loss: 0.37670 | error: 0.16667\n",
      "  Ended batch 013 / 025 | loss: 0.36703 | error: 0.16667\n",
      "  Ended batch 014 / 025 | loss: 0.28203 | error: 0.12500\n",
      "  Ended batch 015 / 025 | loss: 0.18153 | error: 0.08333\n",
      "  Ended batch 016 / 025 | loss: 0.08977 | error: 0.04167\n",
      "  Ended batch 017 / 025 | loss: 0.09075 | error: 0.04167\n",
      "  Ended batch 018 / 025 | loss: 0.26233 | error: 0.12500\n",
      "  Ended batch 019 / 025 | loss: 0.00072 | error: 0.00000\n",
      "  Ended batch 020 / 025 | loss: 0.29961 | error: 0.08333\n",
      "  Ended batch 021 / 025 | loss: 0.17368 | error: 0.08333\n",
      "  Ended batch 022 / 025 | loss: 0.54931 | error: 0.25000\n",
      "  Ended batch 023 / 025 | loss: 0.27119 | error: 0.12500\n",
      "  Ended batch 024 / 025 | loss: 0.38446 | error: 0.16667\n",
      "  Ended batch 025 / 025 | loss: 0.43942 | error: 0.20000\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 005 / 016 | time: 010 sec | loss: 1.30204 | error: 0.44074\n",
      "Starting epoch 006 / 016.\n",
      "  Ended batch 001 / 025 | loss: 0.18886 | error: 0.08333\n",
      "  Ended batch 002 / 025 | loss: 0.18112 | error: 0.08333\n",
      "  Ended batch 003 / 025 | loss: 0.26196 | error: 0.12500\n",
      "  Ended batch 004 / 025 | loss: 0.24795 | error: 0.08333\n",
      "  Ended batch 005 / 025 | loss: 0.17171 | error: 0.08333\n",
      "  Ended batch 006 / 025 | loss: 0.25580 | error: 0.12500\n",
      "  Ended batch 007 / 025 | loss: 0.43658 | error: 0.20833\n",
      "  Ended batch 008 / 025 | loss: 0.26239 | error: 0.12500\n",
      "  Ended batch 009 / 025 | loss: 0.24986 | error: 0.12500\n",
      "  Ended batch 010 / 025 | loss: 0.25291 | error: 0.12500\n",
      "  Ended batch 011 / 025 | loss: 0.10183 | error: 0.04167\n",
      "  Ended batch 012 / 025 | loss: 0.34588 | error: 0.16667\n",
      "  Ended batch 013 / 025 | loss: 0.34082 | error: 0.16667\n",
      "  Ended batch 014 / 025 | loss: 0.26674 | error: 0.12500\n",
      "  Ended batch 015 / 025 | loss: 0.26551 | error: 0.12500\n",
      "  Ended batch 016 / 025 | loss: 0.16854 | error: 0.08333\n",
      "  Ended batch 017 / 025 | loss: 0.08405 | error: 0.04167\n",
      "  Ended batch 018 / 025 | loss: 0.25353 | error: 0.12500\n",
      "  Ended batch 019 / 025 | loss: 0.08883 | error: 0.04167\n",
      "  Ended batch 020 / 025 | loss: 0.24452 | error: 0.12500\n",
      "  Ended batch 021 / 025 | loss: 0.17121 | error: 0.08333\n",
      "  Ended batch 022 / 025 | loss: 0.51938 | error: 0.25000\n",
      "  Ended batch 023 / 025 | loss: 0.07993 | error: 0.04167\n",
      "  Ended batch 024 / 025 | loss: 0.34417 | error: 0.16667\n",
      "  Ended batch 025 / 025 | loss: 0.38445 | error: 0.20000\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 006 / 016 | time: 009 sec | loss: 1.49058 | error: 0.48704\n",
      "Ending training due to 4 consecutive epochs without improvement in validation accuracy.\n",
      "Total training time: 57.45492124557495 seconds.\n",
      "Model loaded from ./results/vanilla/fraud_0.5_strategic_model.pt.\n",
      "---------- Calculating results ----------\n",
      "Benchmark accuracy: 0.9489795918367347\n",
      "SERM accuracy: 0.7602040816326531\n",
      "Blind accuracy: 0.6530612244897959\n",
      "---------- Training non-strategically on fraud with scale=1 ----------\n",
      "Starting epoch 001 / 016.\n",
      "Ended epoch 001 / 016 | time: 000 sec | loss: 0.36570 | error: 0.14259\n",
      "Model saved to ./results/vanilla/fraud_1_non_strategic_model.pt.\n",
      "Starting epoch 002 / 016.\n",
      "Ended epoch 002 / 016 | time: 000 sec | loss: 0.27241 | error: 0.12870\n",
      "Validation accuracy improved.\n",
      "Model saved to ./results/vanilla/fraud_1_non_strategic_model.pt.\n",
      "Starting epoch 003 / 016.\n",
      "Ended epoch 003 / 016 | time: 000 sec | loss: 0.25270 | error: 0.08796\n",
      "Validation accuracy improved.\n",
      "Model saved to ./results/vanilla/fraud_1_non_strategic_model.pt.\n",
      "Starting epoch 004 / 016.\n",
      "Ended epoch 004 / 016 | time: 000 sec | loss: 0.23000 | error: 0.11944\n",
      "Starting epoch 005 / 016.\n",
      "Ended epoch 005 / 016 | time: 000 sec | loss: 0.22582 | error: 0.11944\n",
      "Starting epoch 006 / 016.\n",
      "Ended epoch 006 / 016 | time: 000 sec | loss: 0.21913 | error: 0.11019\n",
      "Starting epoch 007 / 016.\n",
      "Ended epoch 007 / 016 | time: 000 sec | loss: 0.21649 | error: 0.10556\n",
      "Ending training due to 4 consecutive epochs without improvement in validation accuracy.\n",
      "Total training time: 0.18742966651916504 seconds.\n",
      "Model loaded from ./results/vanilla/fraud_1_non_strategic_model.pt.\n",
      "---------- Training strategically on fraud with scale=1 ----------\n",
      "Starting epoch 001 / 016.\n",
      "  Ended batch 001 / 025 | loss: 0.90189 | error: 0.29167\n",
      "  Ended batch 002 / 025 | loss: 0.70484 | error: 0.37500\n",
      "  Ended batch 003 / 025 | loss: 0.91025 | error: 0.45833\n",
      "  Ended batch 004 / 025 | loss: 0.49771 | error: 0.29167\n",
      "  Ended batch 005 / 025 | loss: 0.38820 | error: 0.16667\n",
      "  Ended batch 006 / 025 | loss: 0.34150 | error: 0.16667\n",
      "  Ended batch 007 / 025 | loss: 0.43407 | error: 0.20833\n",
      "  Ended batch 008 / 025 | loss: 0.37889 | error: 0.16667\n",
      "  Ended batch 009 / 025 | loss: 0.37698 | error: 0.16667\n",
      "  Ended batch 010 / 025 | loss: 0.28950 | error: 0.12500\n",
      "  Ended batch 011 / 025 | loss: 0.19614 | error: 0.08333\n",
      "  Ended batch 012 / 025 | loss: 0.09038 | error: 0.04167\n",
      "  Ended batch 013 / 025 | loss: 0.44784 | error: 0.16667\n",
      "  Ended batch 014 / 025 | loss: 0.00000 | error: 0.00000\n",
      "  Ended batch 015 / 025 | loss: 0.25106 | error: 0.08333\n",
      "  Ended batch 016 / 025 | loss: 0.00000 | error: 0.00000\n",
      "  Ended batch 017 / 025 | loss: 0.00000 | error: 0.00000\n",
      "  Ended batch 018 / 025 | loss: 0.12135 | error: 0.04167\n",
      "  Ended batch 019 / 025 | loss: 0.00000 | error: 0.00000\n",
      "  Ended batch 020 / 025 | loss: 0.14204 | error: 0.04167\n",
      "  Ended batch 021 / 025 | loss: 0.17418 | error: 0.04167\n",
      "  Ended batch 022 / 025 | loss: 0.36844 | error: 0.16667\n",
      "  Ended batch 023 / 025 | loss: 0.00000 | error: 0.00000\n",
      "  Ended batch 024 / 025 | loss: 0.29462 | error: 0.12500\n",
      "  Ended batch 025 / 025 | loss: 0.00000 | error: 0.00000\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 001 / 016 | time: 010 sec | loss: 1.54142 | error: 0.46852\n",
      "Model saved to ./results/vanilla/fraud_1_strategic_model.pt.\n",
      "Starting epoch 002 / 016.\n",
      "  Ended batch 001 / 025 | loss: 0.22754 | error: 0.08333\n",
      "  Ended batch 002 / 025 | loss: 0.18875 | error: 0.08333\n",
      "  Ended batch 003 / 025 | loss: 0.37644 | error: 0.16667\n",
      "  Ended batch 004 / 025 | loss: 0.09035 | error: 0.04167\n",
      "  Ended batch 005 / 025 | loss: 0.27228 | error: 0.12500\n",
      "  Ended batch 006 / 025 | loss: 0.32726 | error: 0.12500\n",
      "  Ended batch 007 / 025 | loss: 0.29462 | error: 0.12500\n",
      "  Ended batch 008 / 025 | loss: 0.26284 | error: 0.12500\n",
      "  Ended batch 009 / 025 | loss: 0.08581 | error: 0.04167\n",
      "  Ended batch 010 / 025 | loss: 0.17276 | error: 0.08333\n",
      "  Ended batch 011 / 025 | loss: 0.17051 | error: 0.08333\n",
      "  Ended batch 012 / 025 | loss: 0.08923 | error: 0.04167\n",
      "  Ended batch 013 / 025 | loss: 0.16470 | error: 0.08333\n",
      "  Ended batch 014 / 025 | loss: 0.08690 | error: 0.04167\n",
      "  Ended batch 015 / 025 | loss: 0.16487 | error: 0.08333\n",
      "  Ended batch 016 / 025 | loss: 0.08671 | error: 0.04167\n",
      "  Ended batch 017 / 025 | loss: 0.08326 | error: 0.04167\n",
      "  Ended batch 018 / 025 | loss: 0.26091 | error: 0.12500\n",
      "  Ended batch 019 / 025 | loss: 0.09432 | error: 0.04167\n",
      "  Ended batch 020 / 025 | loss: 0.25860 | error: 0.12500\n",
      "  Ended batch 021 / 025 | loss: 0.17613 | error: 0.08333\n",
      "  Ended batch 022 / 025 | loss: 0.46129 | error: 0.20833\n",
      "  Ended batch 023 / 025 | loss: 0.09016 | error: 0.04167\n",
      "  Ended batch 024 / 025 | loss: 0.27152 | error: 0.12500\n",
      "  Ended batch 025 / 025 | loss: 0.13742 | error: 0.06667\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 002 / 016 | time: 009 sec | loss: 1.38472 | error: 0.46852\n",
      "Starting epoch 003 / 016.\n",
      "  Ended batch 001 / 025 | loss: 0.16657 | error: 0.08333\n",
      "  Ended batch 002 / 025 | loss: 0.35246 | error: 0.12500\n",
      "  Ended batch 003 / 025 | loss: 0.26326 | error: 0.12500\n",
      "  Ended batch 004 / 025 | loss: 0.32817 | error: 0.12500\n",
      "  Ended batch 005 / 025 | loss: 0.27916 | error: 0.12500\n",
      "  Ended batch 006 / 025 | loss: 0.36515 | error: 0.16667\n",
      "  Ended batch 007 / 025 | loss: 0.46538 | error: 0.20833\n",
      "  Ended batch 008 / 025 | loss: 0.27291 | error: 0.12500\n",
      "  Ended batch 009 / 025 | loss: 0.16973 | error: 0.08333\n",
      "  Ended batch 010 / 025 | loss: 0.25656 | error: 0.12500\n",
      "  Ended batch 011 / 025 | loss: 0.17315 | error: 0.08333\n",
      "  Ended batch 012 / 025 | loss: 0.33377 | error: 0.16667\n",
      "  Ended batch 013 / 025 | loss: 0.24433 | error: 0.12500\n",
      "  Ended batch 014 / 025 | loss: 0.09054 | error: 0.04167\n",
      "  Ended batch 015 / 025 | loss: 0.24084 | error: 0.12500\n",
      "  Ended batch 016 / 025 | loss: 0.08262 | error: 0.04167\n",
      "  Ended batch 017 / 025 | loss: 0.08661 | error: 0.04167\n",
      "  Ended batch 018 / 025 | loss: 0.25458 | error: 0.12500\n",
      "  Ended batch 019 / 025 | loss: 0.00232 | error: 0.00000\n",
      "  Ended batch 020 / 025 | loss: 0.08744 | error: 0.04167\n",
      "  Ended batch 021 / 025 | loss: 0.16920 | error: 0.08333\n",
      "  Ended batch 022 / 025 | loss: 0.43664 | error: 0.20833\n",
      "  Ended batch 023 / 025 | loss: 0.16484 | error: 0.08333\n",
      "  Ended batch 024 / 025 | loss: 0.37792 | error: 0.16667\n",
      "  Ended batch 025 / 025 | loss: 0.16070 | error: 0.06667\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 003 / 016 | time: 009 sec | loss: 1.33332 | error: 0.45000\n",
      "Validation accuracy improved.\n",
      "Model saved to ./results/vanilla/fraud_1_strategic_model.pt.\n",
      "Starting epoch 004 / 016.\n",
      "  Ended batch 001 / 025 | loss: 0.17053 | error: 0.08333\n",
      "  Ended batch 002 / 025 | loss: 0.25290 | error: 0.12500\n",
      "  Ended batch 003 / 025 | loss: 0.35057 | error: 0.16667\n",
      "  Ended batch 004 / 025 | loss: 0.23064 | error: 0.08333\n",
      "  Ended batch 005 / 025 | loss: 0.17066 | error: 0.08333\n",
      "  Ended batch 006 / 025 | loss: 0.30520 | error: 0.12500\n",
      "  Ended batch 007 / 025 | loss: 0.33721 | error: 0.16667\n",
      "  Ended batch 008 / 025 | loss: 0.25491 | error: 0.12500\n",
      "  Ended batch 009 / 025 | loss: 0.24665 | error: 0.12500\n",
      "  Ended batch 010 / 025 | loss: 0.25264 | error: 0.12500\n",
      "  Ended batch 011 / 025 | loss: 0.24218 | error: 0.12500\n",
      "  Ended batch 012 / 025 | loss: 0.18644 | error: 0.08333\n",
      "  Ended batch 013 / 025 | loss: 0.08307 | error: 0.04167\n",
      "  Ended batch 014 / 025 | loss: 0.08985 | error: 0.04167\n",
      "  Ended batch 015 / 025 | loss: 0.43857 | error: 0.20833\n",
      "  Ended batch 016 / 025 | loss: 0.17507 | error: 0.08333\n",
      "  Ended batch 017 / 025 | loss: 0.09084 | error: 0.04167\n",
      "  Ended batch 018 / 025 | loss: 0.43445 | error: 0.20833\n",
      "  Ended batch 019 / 025 | loss: 0.24066 | error: 0.12500\n",
      "  Ended batch 020 / 025 | loss: 0.35399 | error: 0.12500\n",
      "  Ended batch 021 / 025 | loss: 0.16513 | error: 0.08333\n",
      "  Ended batch 022 / 025 | loss: 0.68991 | error: 0.33333\n",
      "  Ended batch 023 / 025 | loss: 0.16422 | error: 0.08333\n",
      "  Ended batch 024 / 025 | loss: 0.26103 | error: 0.12500\n",
      "  Ended batch 025 / 025 | loss: 0.12882 | error: 0.06667\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 004 / 016 | time: 010 sec | loss: 1.03969 | error: 0.38056\n",
      "Validation accuracy improved.\n",
      "Model saved to ./results/vanilla/fraud_1_strategic_model.pt.\n",
      "Starting epoch 005 / 016.\n",
      "  Ended batch 001 / 025 | loss: 0.16701 | error: 0.08333\n",
      "  Ended batch 002 / 025 | loss: 0.18924 | error: 0.08333\n",
      "  Ended batch 003 / 025 | loss: 0.34940 | error: 0.16667\n",
      "  Ended batch 004 / 025 | loss: 0.50805 | error: 0.25000\n",
      "  Ended batch 005 / 025 | loss: 0.27360 | error: 0.12500\n",
      "  Ended batch 006 / 025 | loss: 0.35025 | error: 0.16667\n",
      "  Ended batch 007 / 025 | loss: 0.34419 | error: 0.16667\n",
      "  Ended batch 008 / 025 | loss: 0.27520 | error: 0.12500\n",
      "  Ended batch 009 / 025 | loss: 0.23567 | error: 0.12500\n",
      "  Ended batch 010 / 025 | loss: 0.25628 | error: 0.12500\n",
      "  Ended batch 011 / 025 | loss: 0.16956 | error: 0.08333\n",
      "  Ended batch 012 / 025 | loss: 0.08651 | error: 0.04167\n",
      "  Ended batch 013 / 025 | loss: 0.24501 | error: 0.12500\n",
      "  Ended batch 014 / 025 | loss: 0.08890 | error: 0.04167\n",
      "  Ended batch 015 / 025 | loss: 0.23937 | error: 0.12500\n",
      "  Ended batch 016 / 025 | loss: 0.07994 | error: 0.04167\n",
      "  Ended batch 017 / 025 | loss: 0.08911 | error: 0.04167\n",
      "  Ended batch 018 / 025 | loss: 0.33462 | error: 0.16667\n",
      "  Ended batch 019 / 025 | loss: 0.08126 | error: 0.04167\n",
      "  Ended batch 020 / 025 | loss: 0.24727 | error: 0.12500\n",
      "  Ended batch 021 / 025 | loss: 0.17337 | error: 0.08333\n",
      "  Ended batch 022 / 025 | loss: 0.41304 | error: 0.20833\n",
      "  Ended batch 023 / 025 | loss: 0.00857 | error: 0.00000\n",
      "  Ended batch 024 / 025 | loss: 0.27619 | error: 0.12500\n",
      "  Ended batch 025 / 025 | loss: 0.12995 | error: 0.06667\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 005 / 016 | time: 009 sec | loss: 1.37590 | error: 0.46389\n",
      "Starting epoch 006 / 016.\n",
      "  Ended batch 001 / 025 | loss: 0.16404 | error: 0.08333\n",
      "  Ended batch 002 / 025 | loss: 0.16528 | error: 0.08333\n",
      "  Ended batch 003 / 025 | loss: 0.24909 | error: 0.12500\n",
      "  Ended batch 004 / 025 | loss: 0.26398 | error: 0.08333\n",
      "  Ended batch 005 / 025 | loss: 0.16979 | error: 0.08333\n",
      "  Ended batch 006 / 025 | loss: 0.34141 | error: 0.16667\n",
      "  Ended batch 007 / 025 | loss: 0.34295 | error: 0.16667\n",
      "  Ended batch 008 / 025 | loss: 0.24642 | error: 0.12500\n",
      "  Ended batch 009 / 025 | loss: 0.10281 | error: 0.04167\n",
      "  Ended batch 010 / 025 | loss: 0.24784 | error: 0.12500\n",
      "  Ended batch 011 / 025 | loss: 0.08607 | error: 0.04167\n",
      "  Ended batch 012 / 025 | loss: 0.25552 | error: 0.12500\n",
      "  Ended batch 013 / 025 | loss: 0.14104 | error: 0.04167\n",
      "  Ended batch 014 / 025 | loss: 0.08753 | error: 0.04167\n",
      "  Ended batch 015 / 025 | loss: 0.00000 | error: 0.00000\n",
      "  Ended batch 016 / 025 | loss: 0.07998 | error: 0.04167\n",
      "  Ended batch 017 / 025 | loss: 0.08490 | error: 0.04167\n",
      "  Ended batch 018 / 025 | loss: 0.25238 | error: 0.12500\n",
      "  Ended batch 019 / 025 | loss: 0.01084 | error: 0.00000\n",
      "  Ended batch 020 / 025 | loss: 0.25834 | error: 0.12500\n",
      "  Ended batch 021 / 025 | loss: 0.17130 | error: 0.08333\n",
      "  Ended batch 022 / 025 | loss: 0.53120 | error: 0.25000\n",
      "  Ended batch 023 / 025 | loss: 0.16592 | error: 0.08333\n",
      "  Ended batch 024 / 025 | loss: 0.25445 | error: 0.12500\n",
      "  Ended batch 025 / 025 | loss: 0.13411 | error: 0.06667\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 006 / 016 | time: 009 sec | loss: 1.30410 | error: 0.46389\n",
      "Starting epoch 007 / 016.\n",
      "  Ended batch 001 / 025 | loss: 0.17259 | error: 0.08333\n",
      "  Ended batch 002 / 025 | loss: 0.18476 | error: 0.08333\n",
      "  Ended batch 003 / 025 | loss: 0.34718 | error: 0.16667\n",
      "  Ended batch 004 / 025 | loss: 0.38777 | error: 0.16667\n",
      "  Ended batch 005 / 025 | loss: 0.27723 | error: 0.12500\n",
      "  Ended batch 006 / 025 | loss: 0.36549 | error: 0.16667\n",
      "  Ended batch 007 / 025 | loss: 0.45888 | error: 0.20833\n",
      "  Ended batch 008 / 025 | loss: 0.27255 | error: 0.12500\n",
      "  Ended batch 009 / 025 | loss: 0.32159 | error: 0.16667\n",
      "  Ended batch 010 / 025 | loss: 0.28080 | error: 0.12500\n",
      "  Ended batch 011 / 025 | loss: 0.09497 | error: 0.04167\n",
      "  Ended batch 012 / 025 | loss: 0.35627 | error: 0.16667\n",
      "  Ended batch 013 / 025 | loss: 0.16728 | error: 0.08333\n",
      "  Ended batch 014 / 025 | loss: 0.27249 | error: 0.12500\n",
      "  Ended batch 015 / 025 | loss: 0.35185 | error: 0.16667\n",
      "  Ended batch 016 / 025 | loss: 0.17423 | error: 0.08333\n",
      "  Ended batch 017 / 025 | loss: 0.16939 | error: 0.08333\n",
      "  Ended batch 018 / 025 | loss: 0.34331 | error: 0.16667\n",
      "  Ended batch 019 / 025 | loss: 0.05017 | error: 0.00000\n",
      "  Ended batch 020 / 025 | loss: 0.20443 | error: 0.08333\n",
      "  Ended batch 021 / 025 | loss: 0.17639 | error: 0.08333\n",
      "  Ended batch 022 / 025 | loss: 0.64596 | error: 0.29167\n",
      "  Ended batch 023 / 025 | loss: 0.27609 | error: 0.12500\n",
      "  Ended batch 024 / 025 | loss: 0.42970 | error: 0.16667\n",
      "  Ended batch 025 / 025 | loss: 0.45356 | error: 0.20000\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 007 / 016 | time: 010 sec | loss: 0.31507 | error: 0.09630\n",
      "Validation accuracy improved.\n",
      "Model saved to ./results/vanilla/fraud_1_strategic_model.pt.\n",
      "Starting epoch 008 / 016.\n",
      "  Ended batch 001 / 025 | loss: 0.47413 | error: 0.20833\n",
      "  Ended batch 002 / 025 | loss: 0.18624 | error: 0.08333\n",
      "  Ended batch 003 / 025 | loss: 0.36344 | error: 0.16667\n",
      "  Ended batch 004 / 025 | loss: 0.22140 | error: 0.08333\n",
      "  Ended batch 005 / 025 | loss: 0.16707 | error: 0.08333\n",
      "  Ended batch 006 / 025 | loss: 0.37509 | error: 0.12500\n",
      "  Ended batch 007 / 025 | loss: 0.41884 | error: 0.20833\n",
      "  Ended batch 008 / 025 | loss: 0.25983 | error: 0.12500\n",
      "  Ended batch 009 / 025 | loss: 0.25309 | error: 0.12500\n",
      "  Ended batch 010 / 025 | loss: 0.26154 | error: 0.12500\n",
      "  Ended batch 011 / 025 | loss: 0.08371 | error: 0.04167\n",
      "  Ended batch 012 / 025 | loss: 0.26568 | error: 0.12500\n",
      "  Ended batch 013 / 025 | loss: 0.00501 | error: 0.00000\n",
      "  Ended batch 014 / 025 | loss: 0.09352 | error: 0.04167\n",
      "  Ended batch 015 / 025 | loss: 0.35919 | error: 0.16667\n",
      "  Ended batch 016 / 025 | loss: 0.18036 | error: 0.08333\n",
      "  Ended batch 017 / 025 | loss: 0.26848 | error: 0.12500\n",
      "  Ended batch 018 / 025 | loss: 0.36441 | error: 0.16667\n",
      "  Ended batch 019 / 025 | loss: 0.24330 | error: 0.12500\n",
      "  Ended batch 020 / 025 | loss: 0.26924 | error: 0.12500\n",
      "  Ended batch 021 / 025 | loss: 0.16408 | error: 0.08333\n",
      "  Ended batch 022 / 025 | loss: 0.42056 | error: 0.20833\n",
      "  Ended batch 023 / 025 | loss: 0.07934 | error: 0.04167\n",
      "  Ended batch 024 / 025 | loss: 0.25099 | error: 0.12500\n",
      "  Ended batch 025 / 025 | loss: 0.12975 | error: 0.06667\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 008 / 016 | time: 010 sec | loss: 1.18368 | error: 0.41759\n",
      "Starting epoch 009 / 016.\n",
      "  Ended batch 001 / 025 | loss: 0.16699 | error: 0.08333\n",
      "  Ended batch 002 / 025 | loss: 0.27851 | error: 0.12500\n",
      "  Ended batch 003 / 025 | loss: 0.34883 | error: 0.16667\n",
      "  Ended batch 004 / 025 | loss: 0.33838 | error: 0.16667\n",
      "  Ended batch 005 / 025 | loss: 0.26585 | error: 0.12500\n",
      "  Ended batch 006 / 025 | loss: 0.34754 | error: 0.16667\n",
      "  Ended batch 007 / 025 | loss: 0.33658 | error: 0.16667\n",
      "  Ended batch 008 / 025 | loss: 0.27464 | error: 0.12500\n",
      "  Ended batch 009 / 025 | loss: 0.24898 | error: 0.12500\n",
      "  Ended batch 010 / 025 | loss: 0.25796 | error: 0.12500\n",
      "  Ended batch 011 / 025 | loss: 0.18087 | error: 0.08333\n",
      "  Ended batch 012 / 025 | loss: 0.36268 | error: 0.16667\n",
      "  Ended batch 013 / 025 | loss: 0.24779 | error: 0.12500\n",
      "  Ended batch 014 / 025 | loss: 0.09619 | error: 0.04167\n",
      "  Ended batch 015 / 025 | loss: 0.30318 | error: 0.12500\n",
      "  Ended batch 016 / 025 | loss: 0.08870 | error: 0.04167\n",
      "  Ended batch 017 / 025 | loss: 0.08537 | error: 0.04167\n",
      "  Ended batch 018 / 025 | loss: 0.35825 | error: 0.16667\n",
      "  Ended batch 019 / 025 | loss: 0.08218 | error: 0.04167\n",
      "  Ended batch 020 / 025 | loss: 0.24733 | error: 0.12500\n",
      "  Ended batch 021 / 025 | loss: 0.17683 | error: 0.08333\n",
      "  Ended batch 022 / 025 | loss: 0.33770 | error: 0.16667\n",
      "  Ended batch 023 / 025 | loss: 0.08143 | error: 0.04167\n",
      "  Ended batch 024 / 025 | loss: 0.32857 | error: 0.12500\n",
      "  Ended batch 025 / 025 | loss: 0.26050 | error: 0.13333\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 009 / 016 | time: 009 sec | loss: 1.35461 | error: 0.45926\n",
      "Starting epoch 010 / 016.\n",
      "  Ended batch 001 / 025 | loss: 0.24774 | error: 0.12500\n",
      "  Ended batch 002 / 025 | loss: 0.25585 | error: 0.12500\n",
      "  Ended batch 003 / 025 | loss: 0.33513 | error: 0.16667\n",
      "  Ended batch 004 / 025 | loss: 0.18528 | error: 0.04167\n",
      "  Ended batch 005 / 025 | loss: 0.16654 | error: 0.08333\n",
      "  Ended batch 006 / 025 | loss: 0.40483 | error: 0.16667\n",
      "  Ended batch 007 / 025 | loss: 0.34684 | error: 0.16667\n",
      "  Ended batch 008 / 025 | loss: 0.34016 | error: 0.16667\n",
      "  Ended batch 009 / 025 | loss: 0.16695 | error: 0.08333\n",
      "  Ended batch 010 / 025 | loss: 0.24496 | error: 0.12500\n",
      "  Ended batch 011 / 025 | loss: 0.23985 | error: 0.12500\n",
      "  Ended batch 012 / 025 | loss: 0.24334 | error: 0.12500\n",
      "  Ended batch 013 / 025 | loss: 0.08307 | error: 0.04167\n",
      "  Ended batch 014 / 025 | loss: 0.09183 | error: 0.04167\n",
      "  Ended batch 015 / 025 | loss: 0.32384 | error: 0.16667\n",
      "  Ended batch 016 / 025 | loss: 0.15470 | error: 0.08333\n",
      "  Ended batch 017 / 025 | loss: 0.08693 | error: 0.04167\n",
      "  Ended batch 018 / 025 | loss: 0.32186 | error: 0.16667\n",
      "  Ended batch 019 / 025 | loss: 0.15921 | error: 0.08333\n",
      "  Ended batch 020 / 025 | loss: 0.24333 | error: 0.12500\n",
      "  Ended batch 021 / 025 | loss: 0.17068 | error: 0.08333\n",
      "  Ended batch 022 / 025 | loss: 0.50619 | error: 0.25000\n",
      "  Ended batch 023 / 025 | loss: 0.07751 | error: 0.04167\n",
      "  Ended batch 024 / 025 | loss: 0.24919 | error: 0.12500\n",
      "  Ended batch 025 / 025 | loss: 0.13717 | error: 0.06667\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 010 / 016 | time: 010 sec | loss: 0.81242 | error: 0.27593\n",
      "Starting epoch 011 / 016.\n",
      "  Ended batch 001 / 025 | loss: 0.17411 | error: 0.08333\n",
      "  Ended batch 002 / 025 | loss: 0.17762 | error: 0.08333\n",
      "  Ended batch 003 / 025 | loss: 0.36612 | error: 0.16667\n",
      "  Ended batch 004 / 025 | loss: 0.57406 | error: 0.25000\n",
      "  Ended batch 005 / 025 | loss: 0.25489 | error: 0.12500\n",
      "  Ended batch 006 / 025 | loss: 0.45957 | error: 0.20833\n",
      "  Ended batch 007 / 025 | loss: 0.33843 | error: 0.16667\n",
      "  Ended batch 008 / 025 | loss: 0.32775 | error: 0.16667\n",
      "  Ended batch 009 / 025 | loss: 0.33656 | error: 0.16667\n",
      "  Ended batch 010 / 025 | loss: 0.40136 | error: 0.16667\n",
      "  Ended batch 011 / 025 | loss: 0.17001 | error: 0.08333\n",
      "  Ended batch 012 / 025 | loss: 0.17888 | error: 0.08333\n",
      "  Ended batch 013 / 025 | loss: 0.25253 | error: 0.12500\n",
      "  Ended batch 014 / 025 | loss: 0.17409 | error: 0.08333\n",
      "  Ended batch 015 / 025 | loss: 0.43088 | error: 0.20833\n",
      "  Ended batch 016 / 025 | loss: 0.17052 | error: 0.08333\n",
      "  Ended batch 017 / 025 | loss: 0.08262 | error: 0.04167\n",
      "  Ended batch 018 / 025 | loss: 0.33979 | error: 0.16667\n",
      "  Ended batch 019 / 025 | loss: 0.22349 | error: 0.08333\n",
      "  Ended batch 020 / 025 | loss: 0.25634 | error: 0.12500\n",
      "  Ended batch 021 / 025 | loss: 0.33034 | error: 0.16667\n",
      "  Ended batch 022 / 025 | loss: 0.60900 | error: 0.29167\n",
      "  Ended batch 023 / 025 | loss: 0.15434 | error: 0.08333\n",
      "  Ended batch 024 / 025 | loss: 0.36552 | error: 0.16667\n",
      "  Ended batch 025 / 025 | loss: 0.38031 | error: 0.20000\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 011 / 016 | time: 010 sec | loss: 0.63498 | error: 0.22500\n",
      "Ending training due to 4 consecutive epochs without improvement in validation accuracy.\n",
      "Total training time: 1.735736091931661 minutes (104.14416551589966 seconds).\n",
      "Model loaded from ./results/vanilla/fraud_1_strategic_model.pt.\n",
      "---------- Calculating results ----------\n",
      "Benchmark accuracy: 0.9540816326530612\n",
      "SERM accuracy: 0.9540816326530612\n",
      "Blind accuracy: 0.6683673469387755\n",
      "---------- Training non-strategically on fraud with scale=2 ----------\n",
      "Starting epoch 001 / 016.\n",
      "Ended epoch 001 / 016 | time: 000 sec | loss: 0.35799 | error: 0.14259\n",
      "Model saved to ./results/vanilla/fraud_2_non_strategic_model.pt.\n",
      "Starting epoch 002 / 016.\n",
      "Ended epoch 002 / 016 | time: 000 sec | loss: 0.26741 | error: 0.12870\n",
      "Validation accuracy improved.\n",
      "Model saved to ./results/vanilla/fraud_2_non_strategic_model.pt.\n",
      "Starting epoch 003 / 016.\n",
      "Ended epoch 003 / 016 | time: 000 sec | loss: 0.25473 | error: 0.11944\n",
      "Validation accuracy improved.\n",
      "Model saved to ./results/vanilla/fraud_2_non_strategic_model.pt.\n",
      "Starting epoch 004 / 016.\n",
      "Ended epoch 004 / 016 | time: 000 sec | loss: 0.23458 | error: 0.12407\n",
      "Starting epoch 005 / 016.\n",
      "Ended epoch 005 / 016 | time: 000 sec | loss: 0.21833 | error: 0.10556\n",
      "Validation accuracy improved.\n",
      "Model saved to ./results/vanilla/fraud_2_non_strategic_model.pt.\n",
      "Starting epoch 006 / 016.\n",
      "Ended epoch 006 / 016 | time: 000 sec | loss: 0.21796 | error: 0.11481\n",
      "Starting epoch 007 / 016.\n",
      "Ended epoch 007 / 016 | time: 000 sec | loss: 0.21384 | error: 0.11481\n",
      "Starting epoch 008 / 016.\n",
      "Ended epoch 008 / 016 | time: 000 sec | loss: 0.21838 | error: 0.11019\n",
      "Starting epoch 009 / 016.\n",
      "Ended epoch 009 / 016 | time: 000 sec | loss: 0.22462 | error: 0.10556\n",
      "Ending training due to 4 consecutive epochs without improvement in validation accuracy.\n",
      "Total training time: 0.23432040214538574 seconds.\n",
      "Model loaded from ./results/vanilla/fraud_2_non_strategic_model.pt.\n",
      "---------- Training strategically on fraud with scale=2 ----------\n",
      "Starting epoch 001 / 016.\n",
      "  Ended batch 001 / 025 | loss: 1.02009 | error: 0.50000\n",
      "  Ended batch 002 / 025 | loss: 0.53344 | error: 0.29167\n",
      "  Ended batch 003 / 025 | loss: 0.86706 | error: 0.45833\n",
      "  Ended batch 004 / 025 | loss: 0.62559 | error: 0.33333\n",
      "  Ended batch 005 / 025 | loss: 0.43881 | error: 0.20833\n",
      "  Ended batch 006 / 025 | loss: 0.32917 | error: 0.16667\n",
      "  Ended batch 007 / 025 | loss: 0.26779 | error: 0.12500\n",
      "  Ended batch 008 / 025 | loss: 0.27998 | error: 0.12500\n",
      "  Ended batch 009 / 025 | loss: 0.16763 | error: 0.08333\n",
      "  Ended batch 010 / 025 | loss: 0.24529 | error: 0.12500\n",
      "  Ended batch 011 / 025 | loss: 0.17542 | error: 0.08333\n",
      "  Ended batch 012 / 025 | loss: 0.08729 | error: 0.04167\n",
      "  Ended batch 013 / 025 | loss: 0.42652 | error: 0.16667\n",
      "  Ended batch 014 / 025 | loss: 0.08843 | error: 0.04167\n",
      "  Ended batch 015 / 025 | loss: 0.17392 | error: 0.08333\n",
      "  Ended batch 016 / 025 | loss: 0.00000 | error: 0.00000\n",
      "  Ended batch 017 / 025 | loss: 0.00072 | error: 0.00000\n",
      "  Ended batch 018 / 025 | loss: 0.25442 | error: 0.12500\n",
      "  Ended batch 019 / 025 | loss: 0.27147 | error: 0.08333\n",
      "  Ended batch 020 / 025 | loss: 0.48535 | error: 0.12500\n",
      "  Ended batch 021 / 025 | loss: 0.42002 | error: 0.12500\n",
      "  Ended batch 022 / 025 | loss: 0.17609 | error: 0.08333\n",
      "  Ended batch 023 / 025 | loss: 0.00000 | error: 0.00000\n",
      "  Ended batch 024 / 025 | loss: 0.28264 | error: 0.12500\n",
      "  Ended batch 025 / 025 | loss: 0.00000 | error: 0.00000\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 001 / 016 | time: 010 sec | loss: 1.30902 | error: 0.43611\n",
      "Model saved to ./results/vanilla/fraud_2_strategic_model.pt.\n",
      "Starting epoch 002 / 016.\n",
      "  Ended batch 001 / 025 | loss: 0.18343 | error: 0.08333\n",
      "  Ended batch 002 / 025 | loss: 0.09178 | error: 0.04167\n",
      "  Ended batch 003 / 025 | loss: 0.28231 | error: 0.12500\n",
      "  Ended batch 004 / 025 | loss: 0.39104 | error: 0.08333\n",
      "  Ended batch 005 / 025 | loss: 0.27568 | error: 0.12500\n",
      "  Ended batch 006 / 025 | loss: 0.09163 | error: 0.04167\n",
      "  Ended batch 007 / 025 | loss: 0.27657 | error: 0.12500\n",
      "  Ended batch 008 / 025 | loss: 0.43162 | error: 0.16667\n",
      "  Ended batch 009 / 025 | loss: 0.24095 | error: 0.08333\n",
      "  Ended batch 010 / 025 | loss: 0.34778 | error: 0.12500\n",
      "  Ended batch 011 / 025 | loss: 0.37006 | error: 0.12500\n",
      "  Ended batch 012 / 025 | loss: 0.17259 | error: 0.08333\n",
      "  Ended batch 013 / 025 | loss: 0.29795 | error: 0.12500\n",
      "  Ended batch 014 / 025 | loss: 0.08829 | error: 0.04167\n",
      "  Ended batch 015 / 025 | loss: 0.15744 | error: 0.08333\n",
      "  Ended batch 016 / 025 | loss: 0.09044 | error: 0.04167\n",
      "  Ended batch 017 / 025 | loss: 0.08816 | error: 0.04167\n",
      "  Ended batch 018 / 025 | loss: 0.34620 | error: 0.16667\n",
      "  Ended batch 019 / 025 | loss: 0.08101 | error: 0.04167\n",
      "  Ended batch 020 / 025 | loss: 0.26754 | error: 0.12500\n",
      "  Ended batch 021 / 025 | loss: 0.16635 | error: 0.08333\n",
      "  Ended batch 022 / 025 | loss: 0.41678 | error: 0.20833\n",
      "  Ended batch 023 / 025 | loss: 0.08199 | error: 0.04167\n",
      "  Ended batch 024 / 025 | loss: 0.25132 | error: 0.12500\n",
      "  Ended batch 025 / 025 | loss: 0.14081 | error: 0.06667\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 002 / 016 | time: 010 sec | loss: 0.36027 | error: 0.11111\n",
      "Validation accuracy improved.\n",
      "Model saved to ./results/vanilla/fraud_2_strategic_model.pt.\n",
      "Starting epoch 003 / 016.\n",
      "  Ended batch 001 / 025 | loss: 0.17620 | error: 0.08333\n",
      "  Ended batch 002 / 025 | loss: 0.26081 | error: 0.12500\n",
      "  Ended batch 003 / 025 | loss: 0.28995 | error: 0.12500\n",
      "  Ended batch 004 / 025 | loss: 0.16986 | error: 0.08333\n",
      "  Ended batch 005 / 025 | loss: 0.28476 | error: 0.12500\n",
      "  Ended batch 006 / 025 | loss: 0.27289 | error: 0.12500\n",
      "  Ended batch 007 / 025 | loss: 0.44631 | error: 0.20833\n",
      "  Ended batch 008 / 025 | loss: 0.26459 | error: 0.12500\n",
      "  Ended batch 009 / 025 | loss: 0.23151 | error: 0.12500\n",
      "  Ended batch 010 / 025 | loss: 0.29529 | error: 0.12500\n",
      "  Ended batch 011 / 025 | loss: 0.17051 | error: 0.08333\n",
      "  Ended batch 012 / 025 | loss: 0.23385 | error: 0.12500\n",
      "  Ended batch 013 / 025 | loss: 0.32229 | error: 0.16667\n",
      "  Ended batch 014 / 025 | loss: 0.09351 | error: 0.04167\n",
      "  Ended batch 015 / 025 | loss: 0.33498 | error: 0.16667\n",
      "  Ended batch 016 / 025 | loss: 0.08718 | error: 0.04167\n",
      "  Ended batch 017 / 025 | loss: 0.09216 | error: 0.04167\n",
      "  Ended batch 018 / 025 | loss: 0.35338 | error: 0.16667\n",
      "  Ended batch 019 / 025 | loss: 0.08267 | error: 0.04167\n",
      "  Ended batch 020 / 025 | loss: 0.23580 | error: 0.12500\n",
      "  Ended batch 021 / 025 | loss: 0.08848 | error: 0.04167\n",
      "  Ended batch 022 / 025 | loss: 0.33407 | error: 0.16667\n",
      "  Ended batch 023 / 025 | loss: 0.00844 | error: 0.00000\n",
      "  Ended batch 024 / 025 | loss: 0.26297 | error: 0.12500\n",
      "  Ended batch 025 / 025 | loss: 0.12786 | error: 0.06667\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 003 / 016 | time: 010 sec | loss: 0.68684 | error: 0.21574\n",
      "Starting epoch 004 / 016.\n",
      "  Ended batch 001 / 025 | loss: 0.17228 | error: 0.08333\n",
      "  Ended batch 002 / 025 | loss: 0.17739 | error: 0.08333\n",
      "  Ended batch 003 / 025 | loss: 0.27454 | error: 0.12500\n",
      "  Ended batch 004 / 025 | loss: 0.27788 | error: 0.08333\n",
      "  Ended batch 005 / 025 | loss: 0.25993 | error: 0.12500\n",
      "  Ended batch 006 / 025 | loss: 0.48954 | error: 0.20833\n",
      "  Ended batch 007 / 025 | loss: 0.33935 | error: 0.16667\n",
      "  Ended batch 008 / 025 | loss: 0.24981 | error: 0.12500\n",
      "  Ended batch 009 / 025 | loss: 0.10042 | error: 0.04167\n",
      "  Ended batch 010 / 025 | loss: 0.24379 | error: 0.12500\n",
      "  Ended batch 011 / 025 | loss: 0.08312 | error: 0.04167\n",
      "  Ended batch 012 / 025 | loss: 0.16644 | error: 0.08333\n",
      "  Ended batch 013 / 025 | loss: 0.13248 | error: 0.04167\n",
      "  Ended batch 014 / 025 | loss: 0.08658 | error: 0.04167\n",
      "  Ended batch 015 / 025 | loss: 0.31545 | error: 0.16667\n",
      "  Ended batch 016 / 025 | loss: 0.08111 | error: 0.04167\n",
      "  Ended batch 017 / 025 | loss: 0.08679 | error: 0.04167\n",
      "  Ended batch 018 / 025 | loss: 0.33755 | error: 0.16667\n",
      "  Ended batch 019 / 025 | loss: 0.08307 | error: 0.04167\n",
      "  Ended batch 020 / 025 | loss: 0.25719 | error: 0.12500\n",
      "  Ended batch 021 / 025 | loss: 0.16404 | error: 0.08333\n",
      "  Ended batch 022 / 025 | loss: 0.47191 | error: 0.25000\n",
      "  Ended batch 023 / 025 | loss: 0.07473 | error: 0.04167\n",
      "  Ended batch 024 / 025 | loss: 0.31444 | error: 0.16667\n",
      "  Ended batch 025 / 025 | loss: 0.12580 | error: 0.06667\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 004 / 016 | time: 010 sec | loss: 0.45614 | error: 0.13796\n",
      "Starting epoch 005 / 016.\n",
      "  Ended batch 001 / 025 | loss: 0.16646 | error: 0.08333\n",
      "  Ended batch 002 / 025 | loss: 0.16801 | error: 0.08333\n",
      "  Ended batch 003 / 025 | loss: 0.34080 | error: 0.16667\n",
      "  Ended batch 004 / 025 | loss: 0.34330 | error: 0.16667\n",
      "  Ended batch 005 / 025 | loss: 0.25664 | error: 0.12500\n",
      "  Ended batch 006 / 025 | loss: 0.25136 | error: 0.12500\n",
      "  Ended batch 007 / 025 | loss: 0.33859 | error: 0.16667\n",
      "  Ended batch 008 / 025 | loss: 0.26747 | error: 0.12500\n",
      "  Ended batch 009 / 025 | loss: 0.24234 | error: 0.12500\n",
      "  Ended batch 010 / 025 | loss: 0.25442 | error: 0.12500\n",
      "  Ended batch 011 / 025 | loss: 0.16452 | error: 0.08333\n",
      "  Ended batch 012 / 025 | loss: 0.35228 | error: 0.16667\n",
      "  Ended batch 013 / 025 | loss: 0.21097 | error: 0.08333\n",
      "  Ended batch 014 / 025 | loss: 0.10238 | error: 0.04167\n",
      "  Ended batch 015 / 025 | loss: 0.22779 | error: 0.12500\n",
      "  Ended batch 016 / 025 | loss: 0.15933 | error: 0.08333\n",
      "  Ended batch 017 / 025 | loss: 0.08610 | error: 0.04167\n",
      "  Ended batch 018 / 025 | loss: 0.34166 | error: 0.16667\n",
      "  Ended batch 019 / 025 | loss: 0.07897 | error: 0.04167\n",
      "  Ended batch 020 / 025 | loss: 0.25012 | error: 0.12500\n",
      "  Ended batch 021 / 025 | loss: 0.16494 | error: 0.08333\n",
      "  Ended batch 022 / 025 | loss: 0.64907 | error: 0.33333\n",
      "  Ended batch 023 / 025 | loss: 0.22064 | error: 0.12500\n",
      "  Ended batch 024 / 025 | loss: 0.32569 | error: 0.16667\n",
      "  Ended batch 025 / 025 | loss: 0.16878 | error: 0.06667\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 005 / 016 | time: 009 sec | loss: 0.39600 | error: 0.12407\n",
      "Starting epoch 006 / 016.\n",
      "  Ended batch 001 / 025 | loss: 0.17308 | error: 0.08333\n",
      "  Ended batch 002 / 025 | loss: 0.25310 | error: 0.12500\n",
      "  Ended batch 003 / 025 | loss: 0.45450 | error: 0.20833\n",
      "  Ended batch 004 / 025 | loss: 0.46249 | error: 0.20833\n",
      "  Ended batch 005 / 025 | loss: 0.27843 | error: 0.12500\n",
      "  Ended batch 006 / 025 | loss: 0.34540 | error: 0.16667\n",
      "  Ended batch 007 / 025 | loss: 0.43286 | error: 0.20833\n",
      "  Ended batch 008 / 025 | loss: 0.32644 | error: 0.16667\n",
      "  Ended batch 009 / 025 | loss: 0.26602 | error: 0.12500\n",
      "  Ended batch 010 / 025 | loss: 0.25646 | error: 0.12500\n",
      "  Ended batch 011 / 025 | loss: 0.16358 | error: 0.08333\n",
      "  Ended batch 012 / 025 | loss: 0.26233 | error: 0.12500\n",
      "  Ended batch 013 / 025 | loss: 0.16371 | error: 0.08333\n",
      "  Ended batch 014 / 025 | loss: 0.25431 | error: 0.12500\n",
      "  Ended batch 015 / 025 | loss: 0.32709 | error: 0.16667\n",
      "  Ended batch 016 / 025 | loss: 0.16370 | error: 0.08333\n",
      "  Ended batch 017 / 025 | loss: 0.16374 | error: 0.08333\n",
      "  Ended batch 018 / 025 | loss: 0.25676 | error: 0.12500\n",
      "  Ended batch 019 / 025 | loss: 0.09688 | error: 0.04167\n",
      "  Ended batch 020 / 025 | loss: 0.27102 | error: 0.12500\n",
      "  Ended batch 021 / 025 | loss: 0.16422 | error: 0.08333\n",
      "  Ended batch 022 / 025 | loss: 0.59547 | error: 0.29167\n",
      "  Ended batch 023 / 025 | loss: 0.16410 | error: 0.08333\n",
      "  Ended batch 024 / 025 | loss: 0.37433 | error: 0.16667\n",
      "  Ended batch 025 / 025 | loss: 0.39468 | error: 0.20000\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 006 / 016 | time: 010 sec | loss: 0.49517 | error: 0.16481\n",
      "Ending training due to 4 consecutive epochs without improvement in validation accuracy.\n",
      "Total training time: 58.1418240070343 seconds.\n",
      "Model loaded from ./results/vanilla/fraud_2_strategic_model.pt.\n",
      "---------- Calculating results ----------\n",
      "Benchmark accuracy: 0.9642857142857143\n",
      "SERM accuracy: 0.9387755102040817\n",
      "Blind accuracy: 0.7602040816326531\n",
      "---------- Training non-strategically on spam with scale=0.5 ----------\n",
      "Starting epoch 001 / 016.\n",
      "Ended epoch 001 / 016 | time: 000 sec | loss: 0.45689 | error: 0.18806\n",
      "Model saved to ./results/vanilla/spam_0.5_non_strategic_model.pt.\n",
      "Starting epoch 002 / 016.\n",
      "Ended epoch 002 / 016 | time: 000 sec | loss: 0.44263 | error: 0.20647\n",
      "Starting epoch 003 / 016.\n",
      "Ended epoch 003 / 016 | time: 000 sec | loss: 0.44054 | error: 0.21233\n",
      "Starting epoch 004 / 016.\n",
      "Ended epoch 004 / 016 | time: 000 sec | loss: 0.44041 | error: 0.20973\n",
      "Starting epoch 005 / 016.\n",
      "Ended epoch 005 / 016 | time: 000 sec | loss: 0.43883 | error: 0.20778\n",
      "Ending training due to 4 consecutive epochs without improvement in validation accuracy.\n",
      "Total training time: 0.3959176540374756 seconds.\n",
      "Model loaded from ./results/vanilla/spam_0.5_non_strategic_model.pt.\n",
      "---------- Training strategically on spam with scale=0.5 ----------\n",
      "Starting epoch 001 / 016.\n",
      "  Ended batch 001 / 034 | loss: 0.89937 | error: 0.46094\n",
      "  Ended batch 002 / 034 | loss: 1.32288 | error: 0.48438\n",
      "  Ended batch 003 / 034 | loss: 1.33762 | error: 0.52344\n",
      "  Ended batch 004 / 034 | loss: 1.07663 | error: 0.51562\n",
      "  Ended batch 005 / 034 | loss: 0.82832 | error: 0.46094\n",
      "  Ended batch 006 / 034 | loss: 0.87403 | error: 0.27344\n",
      "  Ended batch 007 / 034 | loss: 0.88575 | error: 0.34375\n",
      "  Ended batch 008 / 034 | loss: 0.73059 | error: 0.37500\n",
      "  Ended batch 009 / 034 | loss: 0.71095 | error: 0.32031\n",
      "  Ended batch 010 / 034 | loss: 0.68108 | error: 0.35938\n",
      "  Ended batch 011 / 034 | loss: 0.62251 | error: 0.31250\n",
      "  Ended batch 012 / 034 | loss: 0.71889 | error: 0.35938\n",
      "  Ended batch 013 / 034 | loss: 0.56889 | error: 0.23438\n",
      "  Ended batch 014 / 034 | loss: 0.64292 | error: 0.20312\n",
      "  Ended batch 015 / 034 | loss: 0.37495 | error: 0.14062\n",
      "  Ended batch 016 / 034 | loss: 0.49032 | error: 0.21094\n",
      "  Ended batch 017 / 034 | loss: 0.52469 | error: 0.21875\n",
      "  Ended batch 018 / 034 | loss: 0.51149 | error: 0.21094\n",
      "  Ended batch 019 / 034 | loss: 0.51421 | error: 0.19531\n",
      "  Ended batch 020 / 034 | loss: 0.55535 | error: 0.21875\n",
      "  Ended batch 021 / 034 | loss: 0.40651 | error: 0.16406\n",
      "  Ended batch 022 / 034 | loss: 0.45850 | error: 0.17188\n",
      "  Ended batch 023 / 034 | loss: 0.41269 | error: 0.18750\n",
      "  Ended batch 024 / 034 | loss: 0.44497 | error: 0.21094\n",
      "  Ended batch 025 / 034 | loss: 0.78141 | error: 0.36719\n",
      "  Ended batch 026 / 034 | loss: 0.62418 | error: 0.31250\n",
      "  Ended batch 027 / 034 | loss: 0.57241 | error: 0.26562\n",
      "  Ended batch 028 / 034 | loss: 0.48959 | error: 0.21875\n",
      "  Ended batch 029 / 034 | loss: 0.58286 | error: 0.28906\n",
      "  Ended batch 030 / 034 | loss: 0.65265 | error: 0.31250\n",
      "  Ended batch 031 / 034 | loss: 0.63858 | error: 0.30469\n",
      "  Ended batch 032 / 034 | loss: 0.82229 | error: 0.40625\n",
      "  Ended batch 033 / 034 | loss: 0.57367 | error: 0.28906\n",
      "  Ended batch 034 / 034 | loss: 0.55677 | error: 0.27273\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 001 / 016 | time: 048 sec | loss: 1.28785 | error: 0.48624\n",
      "Model saved to ./results/vanilla/spam_0.5_strategic_model.pt.\n",
      "Starting epoch 002 / 016.\n",
      "  Ended batch 001 / 034 | loss: 0.67630 | error: 0.35156\n",
      "  Ended batch 002 / 034 | loss: 0.60628 | error: 0.31250\n",
      "  Ended batch 003 / 034 | loss: 0.78932 | error: 0.41406\n",
      "  Ended batch 004 / 034 | loss: 0.70153 | error: 0.36719\n",
      "  Ended batch 005 / 034 | loss: 0.55193 | error: 0.28125\n",
      "  Ended batch 006 / 034 | loss: 0.38819 | error: 0.18750\n",
      "  Ended batch 007 / 034 | loss: 0.79825 | error: 0.42969\n",
      "  Ended batch 008 / 034 | loss: 0.56998 | error: 0.30469\n",
      "  Ended batch 009 / 034 | loss: 0.65185 | error: 0.34375\n",
      "  Ended batch 010 / 034 | loss: 0.58672 | error: 0.28906\n",
      "  Ended batch 011 / 034 | loss: 0.45721 | error: 0.22656\n",
      "  Ended batch 012 / 034 | loss: 0.79389 | error: 0.43750\n",
      "  Ended batch 013 / 034 | loss: 0.64636 | error: 0.32812\n",
      "  Ended batch 014 / 034 | loss: 0.66488 | error: 0.33594\n",
      "  Ended batch 015 / 034 | loss: 0.71558 | error: 0.39844\n",
      "  Ended batch 016 / 034 | loss: 0.64155 | error: 0.35156\n",
      "  Ended batch 017 / 034 | loss: 0.68673 | error: 0.38281\n",
      "  Ended batch 018 / 034 | loss: 0.63225 | error: 0.33594\n",
      "  Ended batch 019 / 034 | loss: 0.65911 | error: 0.35938\n",
      "  Ended batch 020 / 034 | loss: 0.81557 | error: 0.42969\n",
      "  Ended batch 021 / 034 | loss: 0.74551 | error: 0.42188\n",
      "  Ended batch 022 / 034 | loss: 0.68774 | error: 0.37500\n",
      "  Ended batch 023 / 034 | loss: 0.65629 | error: 0.33594\n",
      "  Ended batch 024 / 034 | loss: 0.73366 | error: 0.39844\n",
      "  Ended batch 025 / 034 | loss: 0.69725 | error: 0.38281\n",
      "  Ended batch 026 / 034 | loss: 0.76537 | error: 0.42969\n",
      "  Ended batch 027 / 034 | loss: 0.68629 | error: 0.39062\n",
      "  Ended batch 028 / 034 | loss: 0.76741 | error: 0.42969\n",
      "  Ended batch 029 / 034 | loss: 0.61554 | error: 0.34375\n",
      "  Ended batch 030 / 034 | loss: 0.61571 | error: 0.34375\n",
      "  Ended batch 031 / 034 | loss: 0.69240 | error: 0.38281\n",
      "  Ended batch 032 / 034 | loss: 0.79296 | error: 0.42969\n",
      "  Ended batch 033 / 034 | loss: 0.74159 | error: 0.37500\n",
      "  Ended batch 034 / 034 | loss: 0.67516 | error: 0.36364\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 002 / 016 | time: 055 sec | loss: 0.80092 | error: 0.29483\n",
      "Validation accuracy improved.\n",
      "Model saved to ./results/vanilla/spam_0.5_strategic_model.pt.\n",
      "Starting epoch 003 / 016.\n",
      "  Ended batch 001 / 034 | loss: 0.70945 | error: 0.38281\n",
      "  Ended batch 002 / 034 | loss: 0.68972 | error: 0.38281\n",
      "  Ended batch 003 / 034 | loss: 0.75461 | error: 0.42188\n",
      "  Ended batch 004 / 034 | loss: 0.72189 | error: 0.40625\n",
      "  Ended batch 005 / 034 | loss: 0.62616 | error: 0.34375\n",
      "  Ended batch 006 / 034 | loss: 0.54867 | error: 0.29688\n",
      "  Ended batch 007 / 034 | loss: 0.80891 | error: 0.46094\n",
      "  Ended batch 008 / 034 | loss: 0.61940 | error: 0.35156\n",
      "  Ended batch 009 / 034 | loss: 0.66396 | error: 0.35156\n",
      "  Ended batch 010 / 034 | loss: 0.66225 | error: 0.34375\n",
      "  Ended batch 011 / 034 | loss: 0.53360 | error: 0.28906\n",
      "  Ended batch 012 / 034 | loss: 0.83347 | error: 0.45312\n",
      "  Ended batch 013 / 034 | loss: 0.68459 | error: 0.35938\n",
      "  Ended batch 014 / 034 | loss: 0.71810 | error: 0.35938\n",
      "  Ended batch 015 / 034 | loss: 0.67961 | error: 0.37500\n",
      "  Ended batch 016 / 034 | loss: 0.62538 | error: 0.33594\n",
      "  Ended batch 017 / 034 | loss: 0.69234 | error: 0.38281\n",
      "  Ended batch 018 / 034 | loss: 0.65372 | error: 0.35938\n",
      "  Ended batch 019 / 034 | loss: 0.66131 | error: 0.35938\n",
      "  Ended batch 020 / 034 | loss: 0.77755 | error: 0.41406\n",
      "  Ended batch 021 / 034 | loss: 0.73446 | error: 0.41406\n",
      "  Ended batch 022 / 034 | loss: 0.66107 | error: 0.35938\n",
      "  Ended batch 023 / 034 | loss: 0.70473 | error: 0.39062\n",
      "  Ended batch 024 / 034 | loss: 0.77504 | error: 0.44531\n",
      "  Ended batch 025 / 034 | loss: 0.70556 | error: 0.39844\n",
      "  Ended batch 026 / 034 | loss: 0.69788 | error: 0.28125\n",
      "  Ended batch 027 / 034 | loss: 0.63572 | error: 0.28906\n",
      "  Ended batch 028 / 034 | loss: 0.79785 | error: 0.42969\n",
      "  Ended batch 029 / 034 | loss: 0.67786 | error: 0.39062\n",
      "  Ended batch 030 / 034 | loss: 0.60960 | error: 0.33594\n",
      "  Ended batch 031 / 034 | loss: 0.69669 | error: 0.38281\n",
      "  Ended batch 032 / 034 | loss: 0.80783 | error: 0.44531\n",
      "  Ended batch 033 / 034 | loss: 0.74003 | error: 0.36719\n",
      "  Ended batch 034 / 034 | loss: 0.77755 | error: 0.45455\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 003 / 016 | time: 049 sec | loss: 1.11383 | error: 0.48038\n",
      "Starting epoch 004 / 016.\n",
      "  Ended batch 001 / 034 | loss: 0.72296 | error: 0.25000\n",
      "  Ended batch 002 / 034 | loss: 0.68468 | error: 0.21875\n",
      "  Ended batch 003 / 034 | loss: 0.72756 | error: 0.39844\n",
      "  Ended batch 004 / 034 | loss: 0.73697 | error: 0.40625\n",
      "  Ended batch 005 / 034 | loss: 0.67329 | error: 0.37500\n",
      "  Ended batch 006 / 034 | loss: 0.58141 | error: 0.32812\n",
      "  Ended batch 007 / 034 | loss: 0.76413 | error: 0.43750\n",
      "  Ended batch 008 / 034 | loss: 0.55209 | error: 0.28125\n",
      "  Ended batch 009 / 034 | loss: 0.65204 | error: 0.33594\n",
      "  Ended batch 010 / 034 | loss: 0.65250 | error: 0.32031\n",
      "  Ended batch 011 / 034 | loss: 0.53549 | error: 0.28125\n",
      "  Ended batch 012 / 034 | loss: 0.84468 | error: 0.43750\n",
      "  Ended batch 013 / 034 | loss: 0.63340 | error: 0.31250\n",
      "  Ended batch 014 / 034 | loss: 0.63972 | error: 0.28125\n",
      "  Ended batch 015 / 034 | loss: 0.60727 | error: 0.32031\n",
      "  Ended batch 016 / 034 | loss: 0.64700 | error: 0.34375\n",
      "  Ended batch 017 / 034 | loss: 0.69992 | error: 0.37500\n",
      "  Ended batch 018 / 034 | loss: 0.64162 | error: 0.34375\n",
      "  Ended batch 019 / 034 | loss: 0.65475 | error: 0.35156\n",
      "  Ended batch 020 / 034 | loss: 0.77721 | error: 0.41406\n",
      "  Ended batch 021 / 034 | loss: 0.70070 | error: 0.39062\n",
      "  Ended batch 022 / 034 | loss: 0.67697 | error: 0.36719\n",
      "  Ended batch 023 / 034 | loss: 0.70534 | error: 0.39844\n",
      "  Ended batch 024 / 034 | loss: 0.77330 | error: 0.44531\n",
      "  Ended batch 025 / 034 | loss: 0.70470 | error: 0.39062\n",
      "  Ended batch 026 / 034 | loss: 0.74091 | error: 0.41406\n",
      "  Ended batch 027 / 034 | loss: 0.60507 | error: 0.31250\n",
      "  Ended batch 028 / 034 | loss: 0.77345 | error: 0.43750\n",
      "  Ended batch 029 / 034 | loss: 0.69834 | error: 0.40625\n",
      "  Ended batch 030 / 034 | loss: 0.61985 | error: 0.34375\n",
      "  Ended batch 031 / 034 | loss: 0.67287 | error: 0.36719\n",
      "  Ended batch 032 / 034 | loss: 0.82164 | error: 0.44531\n",
      "  Ended batch 033 / 034 | loss: 0.75514 | error: 0.39062\n",
      "  Ended batch 034 / 034 | loss: 0.73453 | error: 0.40909\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 004 / 016 | time: 054 sec | loss: 0.85281 | error: 0.32217\n",
      "Starting epoch 005 / 016.\n",
      "  Ended batch 001 / 034 | loss: 0.69269 | error: 0.35938\n",
      "  Ended batch 002 / 034 | loss: 0.62123 | error: 0.32031\n",
      "  Ended batch 003 / 034 | loss: 0.76910 | error: 0.42969\n",
      "  Ended batch 004 / 034 | loss: 0.73471 | error: 0.40625\n",
      "  Ended batch 005 / 034 | loss: 0.64125 | error: 0.35938\n",
      "  Ended batch 006 / 034 | loss: 0.57080 | error: 0.32031\n",
      "  Ended batch 007 / 034 | loss: 0.84917 | error: 0.49219\n",
      "  Ended batch 008 / 034 | loss: 0.58402 | error: 0.32031\n",
      "  Ended batch 009 / 034 | loss: 0.65747 | error: 0.34375\n",
      "  Ended batch 010 / 034 | loss: 0.68466 | error: 0.35938\n",
      "  Ended batch 011 / 034 | loss: 0.55670 | error: 0.30469\n",
      "  Ended batch 012 / 034 | loss: 0.90113 | error: 0.49219\n",
      "  Ended batch 013 / 034 | loss: 0.68908 | error: 0.35938\n",
      "  Ended batch 014 / 034 | loss: 0.72108 | error: 0.35938\n",
      "  Ended batch 015 / 034 | loss: 0.69809 | error: 0.39062\n",
      "  Ended batch 016 / 034 | loss: 0.63947 | error: 0.34375\n",
      "  Ended batch 017 / 034 | loss: 0.68364 | error: 0.38281\n",
      "  Ended batch 018 / 034 | loss: 0.65852 | error: 0.35938\n",
      "  Ended batch 019 / 034 | loss: 0.66672 | error: 0.36719\n",
      "  Ended batch 020 / 034 | loss: 0.77949 | error: 0.41406\n",
      "  Ended batch 021 / 034 | loss: 0.73429 | error: 0.41406\n",
      "  Ended batch 022 / 034 | loss: 0.67962 | error: 0.36719\n",
      "  Ended batch 023 / 034 | loss: 0.71883 | error: 0.40625\n",
      "  Ended batch 024 / 034 | loss: 0.77403 | error: 0.44531\n",
      "  Ended batch 025 / 034 | loss: 0.72611 | error: 0.40625\n",
      "  Ended batch 026 / 034 | loss: 0.75391 | error: 0.42969\n",
      "  Ended batch 027 / 034 | loss: 0.67052 | error: 0.35156\n",
      "  Ended batch 028 / 034 | loss: 0.77781 | error: 0.42969\n",
      "  Ended batch 029 / 034 | loss: 0.60941 | error: 0.33594\n",
      "  Ended batch 030 / 034 | loss: 0.60308 | error: 0.32812\n",
      "  Ended batch 031 / 034 | loss: 0.69105 | error: 0.36719\n",
      "  Ended batch 032 / 034 | loss: 0.83050 | error: 0.42969\n",
      "  Ended batch 033 / 034 | loss: 0.73503 | error: 0.35938\n",
      "  Ended batch 034 / 034 | loss: 0.80965 | error: 0.45455\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 005 / 016 | time: 049 sec | loss: 1.15989 | error: 0.48103\n",
      "Starting epoch 006 / 016.\n",
      "  Ended batch 001 / 034 | loss: 0.73105 | error: 0.33594\n",
      "  Ended batch 002 / 034 | loss: 0.63000 | error: 0.28906\n",
      "  Ended batch 003 / 034 | loss: 0.72444 | error: 0.39844\n",
      "  Ended batch 004 / 034 | loss: 0.80179 | error: 0.41406\n",
      "  Ended batch 005 / 034 | loss: 0.71829 | error: 0.39844\n",
      "  Ended batch 006 / 034 | loss: 0.60186 | error: 0.31250\n",
      "  Ended batch 007 / 034 | loss: 0.64316 | error: 0.27344\n",
      "  Ended batch 008 / 034 | loss: 0.56675 | error: 0.14062\n",
      "  Ended batch 009 / 034 | loss: 0.67793 | error: 0.35938\n",
      "  Ended batch 010 / 034 | loss: 0.76396 | error: 0.39062\n",
      "  Ended batch 011 / 034 | loss: 0.73466 | error: 0.36719\n",
      "  Ended batch 012 / 034 | loss: 0.93588 | error: 0.47656\n",
      "  Ended batch 013 / 034 | loss: 0.59756 | error: 0.29688\n",
      "  Ended batch 014 / 034 | loss: 0.66272 | error: 0.27344\n",
      "  Ended batch 015 / 034 | loss: 0.63100 | error: 0.32031\n",
      "  Ended batch 016 / 034 | loss: 0.62267 | error: 0.32812\n",
      "  Ended batch 017 / 034 | loss: 0.80848 | error: 0.42969\n",
      "  Ended batch 018 / 034 | loss: 0.65182 | error: 0.34375\n",
      "  Ended batch 019 / 034 | loss: 0.60802 | error: 0.29688\n",
      "  Ended batch 020 / 034 | loss: 0.70856 | error: 0.35938\n",
      "  Ended batch 021 / 034 | loss: 0.64595 | error: 0.34375\n",
      "  Ended batch 022 / 034 | loss: 0.63820 | error: 0.34375\n",
      "  Ended batch 023 / 034 | loss: 0.72527 | error: 0.39062\n",
      "  Ended batch 024 / 034 | loss: 0.68737 | error: 0.37500\n",
      "  Ended batch 025 / 034 | loss: 0.67480 | error: 0.35156\n",
      "  Ended batch 026 / 034 | loss: 0.68744 | error: 0.35156\n",
      "  Ended batch 027 / 034 | loss: 0.59634 | error: 0.31250\n",
      "  Ended batch 028 / 034 | loss: 0.72571 | error: 0.39844\n",
      "  Ended batch 029 / 034 | loss: 0.65899 | error: 0.35938\n",
      "  Ended batch 030 / 034 | loss: 0.60930 | error: 0.33594\n",
      "  Ended batch 031 / 034 | loss: 0.67801 | error: 0.36719\n",
      "  Ended batch 032 / 034 | loss: 0.73565 | error: 0.39844\n",
      "  Ended batch 033 / 034 | loss: 0.74023 | error: 0.37500\n",
      "  Ended batch 034 / 034 | loss: 0.73502 | error: 0.40909\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 006 / 016 | time: 055 sec | loss: 0.76471 | error: 0.27465\n",
      "Validation accuracy improved.\n",
      "Model saved to ./results/vanilla/spam_0.5_strategic_model.pt.\n",
      "Starting epoch 007 / 016.\n",
      "  Ended batch 001 / 034 | loss: 0.73033 | error: 0.40625\n",
      "  Ended batch 002 / 034 | loss: 0.68181 | error: 0.38281\n",
      "  Ended batch 003 / 034 | loss: 0.74555 | error: 0.42188\n",
      "  Ended batch 004 / 034 | loss: 0.71951 | error: 0.40625\n",
      "  Ended batch 005 / 034 | loss: 0.67221 | error: 0.39062\n",
      "  Ended batch 006 / 034 | loss: 0.55223 | error: 0.31250\n",
      "  Ended batch 007 / 034 | loss: 0.84115 | error: 0.47656\n",
      "  Ended batch 008 / 034 | loss: 0.60897 | error: 0.34375\n",
      "  Ended batch 009 / 034 | loss: 0.67340 | error: 0.35938\n",
      "  Ended batch 010 / 034 | loss: 0.66932 | error: 0.35156\n",
      "  Ended batch 011 / 034 | loss: 0.55241 | error: 0.29688\n",
      "  Ended batch 012 / 034 | loss: 0.85796 | error: 0.47656\n",
      "  Ended batch 013 / 034 | loss: 0.66916 | error: 0.36719\n",
      "  Ended batch 014 / 034 | loss: 0.69337 | error: 0.35156\n",
      "  Ended batch 015 / 034 | loss: 0.71284 | error: 0.40625\n",
      "  Ended batch 016 / 034 | loss: 0.68332 | error: 0.38281\n",
      "  Ended batch 017 / 034 | loss: 0.65910 | error: 0.36719\n",
      "  Ended batch 018 / 034 | loss: 0.65608 | error: 0.35156\n",
      "  Ended batch 019 / 034 | loss: 0.63927 | error: 0.34375\n",
      "  Ended batch 020 / 034 | loss: 0.78696 | error: 0.41406\n",
      "  Ended batch 021 / 034 | loss: 0.75153 | error: 0.42969\n",
      "  Ended batch 022 / 034 | loss: 0.68350 | error: 0.34375\n",
      "  Ended batch 023 / 034 | loss: 0.66229 | error: 0.35938\n",
      "  Ended batch 024 / 034 | loss: 0.76334 | error: 0.44531\n",
      "  Ended batch 025 / 034 | loss: 0.72867 | error: 0.41406\n",
      "  Ended batch 026 / 034 | loss: 0.76973 | error: 0.42969\n",
      "  Ended batch 027 / 034 | loss: 0.65785 | error: 0.36719\n",
      "  Ended batch 028 / 034 | loss: 0.74235 | error: 0.41406\n",
      "  Ended batch 029 / 034 | loss: 0.61934 | error: 0.32031\n",
      "  Ended batch 030 / 034 | loss: 0.58307 | error: 0.30469\n",
      "  Ended batch 031 / 034 | loss: 0.65703 | error: 0.35938\n",
      "  Ended batch 032 / 034 | loss: 0.83324 | error: 0.43750\n",
      "  Ended batch 033 / 034 | loss: 0.73949 | error: 0.37500\n",
      "  Ended batch 034 / 034 | loss: 0.72778 | error: 0.40909\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 007 / 016 | time: 050 sec | loss: 1.18459 | error: 0.48493\n",
      "Starting epoch 008 / 016.\n",
      "  Ended batch 001 / 034 | loss: 0.67321 | error: 0.27344\n",
      "  Ended batch 002 / 034 | loss: 0.60794 | error: 0.28906\n",
      "  Ended batch 003 / 034 | loss: 0.75409 | error: 0.41406\n",
      "  Ended batch 004 / 034 | loss: 0.78716 | error: 0.41406\n",
      "  Ended batch 005 / 034 | loss: 0.63035 | error: 0.35156\n",
      "  Ended batch 006 / 034 | loss: 0.57155 | error: 0.31250\n",
      "  Ended batch 007 / 034 | loss: 0.77589 | error: 0.45312\n",
      "  Ended batch 008 / 034 | loss: 0.57873 | error: 0.31250\n",
      "  Ended batch 009 / 034 | loss: 0.65383 | error: 0.34375\n",
      "  Ended batch 010 / 034 | loss: 0.65869 | error: 0.35156\n",
      "  Ended batch 011 / 034 | loss: 0.55933 | error: 0.30469\n",
      "  Ended batch 012 / 034 | loss: 0.82386 | error: 0.46094\n",
      "  Ended batch 013 / 034 | loss: 0.63069 | error: 0.30469\n",
      "  Ended batch 014 / 034 | loss: 0.67826 | error: 0.30469\n",
      "  Ended batch 015 / 034 | loss: 0.71200 | error: 0.39844\n",
      "  Ended batch 016 / 034 | loss: 0.72643 | error: 0.39844\n",
      "  Ended batch 017 / 034 | loss: 0.69036 | error: 0.37500\n",
      "  Ended batch 018 / 034 | loss: 0.64669 | error: 0.35156\n",
      "  Ended batch 019 / 034 | loss: 0.66109 | error: 0.35156\n",
      "  Ended batch 020 / 034 | loss: 0.75212 | error: 0.39844\n",
      "  Ended batch 021 / 034 | loss: 0.75026 | error: 0.42969\n",
      "  Ended batch 022 / 034 | loss: 0.70003 | error: 0.38281\n",
      "  Ended batch 023 / 034 | loss: 0.69453 | error: 0.39062\n",
      "  Ended batch 024 / 034 | loss: 0.73199 | error: 0.42188\n",
      "  Ended batch 025 / 034 | loss: 0.71537 | error: 0.39844\n",
      "  Ended batch 026 / 034 | loss: 0.71413 | error: 0.37500\n",
      "  Ended batch 027 / 034 | loss: 0.60811 | error: 0.31250\n",
      "  Ended batch 028 / 034 | loss: 0.74022 | error: 0.41406\n",
      "  Ended batch 029 / 034 | loss: 0.70740 | error: 0.39844\n",
      "  Ended batch 030 / 034 | loss: 0.62784 | error: 0.35156\n",
      "  Ended batch 031 / 034 | loss: 0.66553 | error: 0.36719\n",
      "  Ended batch 032 / 034 | loss: 0.72292 | error: 0.39844\n",
      "  Ended batch 033 / 034 | loss: 0.73967 | error: 0.36719\n",
      "  Ended batch 034 / 034 | loss: 0.74007 | error: 0.40909\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 008 / 016 | time: 054 sec | loss: 0.93756 | error: 0.36644\n",
      "Starting epoch 009 / 016.\n",
      "  Ended batch 001 / 034 | loss: 0.70848 | error: 0.36719\n",
      "  Ended batch 002 / 034 | loss: 0.66027 | error: 0.35156\n",
      "  Ended batch 003 / 034 | loss: 0.67705 | error: 0.36719\n",
      "  Ended batch 004 / 034 | loss: 0.74924 | error: 0.40625\n",
      "  Ended batch 005 / 034 | loss: 0.60746 | error: 0.33594\n",
      "  Ended batch 006 / 034 | loss: 0.51191 | error: 0.27344\n",
      "  Ended batch 007 / 034 | loss: 0.78106 | error: 0.43750\n",
      "  Ended batch 008 / 034 | loss: 0.55634 | error: 0.30469\n",
      "  Ended batch 009 / 034 | loss: 0.63873 | error: 0.33594\n",
      "  Ended batch 010 / 034 | loss: 0.67445 | error: 0.35156\n",
      "  Ended batch 011 / 034 | loss: 0.49847 | error: 0.26562\n",
      "  Ended batch 012 / 034 | loss: 0.79016 | error: 0.43750\n",
      "  Ended batch 013 / 034 | loss: 0.61724 | error: 0.30469\n",
      "  Ended batch 014 / 034 | loss: 0.68338 | error: 0.34375\n",
      "  Ended batch 015 / 034 | loss: 0.73229 | error: 0.40625\n",
      "  Ended batch 016 / 034 | loss: 0.66796 | error: 0.36719\n",
      "  Ended batch 017 / 034 | loss: 0.69861 | error: 0.39062\n",
      "  Ended batch 018 / 034 | loss: 0.64349 | error: 0.34375\n",
      "  Ended batch 019 / 034 | loss: 0.66446 | error: 0.35938\n",
      "  Ended batch 020 / 034 | loss: 0.80291 | error: 0.42969\n",
      "  Ended batch 021 / 034 | loss: 0.75317 | error: 0.42969\n",
      "  Ended batch 022 / 034 | loss: 0.70354 | error: 0.38281\n",
      "  Ended batch 023 / 034 | loss: 0.65938 | error: 0.35938\n",
      "  Ended batch 024 / 034 | loss: 0.71217 | error: 0.40625\n",
      "  Ended batch 025 / 034 | loss: 0.73831 | error: 0.42188\n",
      "  Ended batch 026 / 034 | loss: 0.77247 | error: 0.43750\n",
      "  Ended batch 027 / 034 | loss: 0.66840 | error: 0.38281\n",
      "  Ended batch 028 / 034 | loss: 0.71054 | error: 0.38281\n",
      "  Ended batch 029 / 034 | loss: 0.59861 | error: 0.32031\n",
      "  Ended batch 030 / 034 | loss: 0.61553 | error: 0.33594\n",
      "  Ended batch 031 / 034 | loss: 0.67020 | error: 0.36719\n",
      "  Ended batch 032 / 034 | loss: 0.83551 | error: 0.44531\n",
      "  Ended batch 033 / 034 | loss: 0.74095 | error: 0.38281\n",
      "  Ended batch 034 / 034 | loss: 0.73387 | error: 0.40909\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 009 / 016 | time: 055 sec | loss: 0.95559 | error: 0.38793\n",
      "Starting epoch 010 / 016.\n",
      "  Ended batch 001 / 034 | loss: 0.72195 | error: 0.36719\n",
      "  Ended batch 002 / 034 | loss: 0.65716 | error: 0.32031\n",
      "  Ended batch 003 / 034 | loss: 0.73996 | error: 0.41406\n",
      "  Ended batch 004 / 034 | loss: 0.72156 | error: 0.39844\n",
      "  Ended batch 005 / 034 | loss: 0.68385 | error: 0.39062\n",
      "  Ended batch 006 / 034 | loss: 0.55543 | error: 0.31250\n",
      "  Ended batch 007 / 034 | loss: 0.81021 | error: 0.46875\n",
      "  Ended batch 008 / 034 | loss: 0.57157 | error: 0.30469\n",
      "  Ended batch 009 / 034 | loss: 0.65859 | error: 0.34375\n",
      "  Ended batch 010 / 034 | loss: 0.62869 | error: 0.30469\n",
      "  Ended batch 011 / 034 | loss: 0.55172 | error: 0.29688\n",
      "  Ended batch 012 / 034 | loss: 0.90754 | error: 0.48438\n",
      "  Ended batch 013 / 034 | loss: 0.66563 | error: 0.34375\n",
      "  Ended batch 014 / 034 | loss: 0.68553 | error: 0.32812\n",
      "  Ended batch 015 / 034 | loss: 0.69349 | error: 0.38281\n",
      "  Ended batch 016 / 034 | loss: 0.64483 | error: 0.35156\n",
      "  Ended batch 017 / 034 | loss: 0.72674 | error: 0.39844\n",
      "  Ended batch 018 / 034 | loss: 0.65846 | error: 0.35938\n",
      "  Ended batch 019 / 034 | loss: 0.65056 | error: 0.35156\n",
      "  Ended batch 020 / 034 | loss: 0.76688 | error: 0.40625\n",
      "  Ended batch 021 / 034 | loss: 0.73348 | error: 0.41406\n",
      "  Ended batch 022 / 034 | loss: 0.67504 | error: 0.36719\n",
      "  Ended batch 023 / 034 | loss: 0.73075 | error: 0.40625\n",
      "  Ended batch 024 / 034 | loss: 0.73147 | error: 0.41406\n",
      "  Ended batch 025 / 034 | loss: 0.70974 | error: 0.39062\n",
      "  Ended batch 026 / 034 | loss: 0.74191 | error: 0.40625\n",
      "  Ended batch 027 / 034 | loss: 0.62152 | error: 0.32031\n",
      "  Ended batch 028 / 034 | loss: 0.80155 | error: 0.42969\n",
      "  Ended batch 029 / 034 | loss: 0.73252 | error: 0.42188\n",
      "  Ended batch 030 / 034 | loss: 0.60227 | error: 0.32812\n",
      "  Ended batch 031 / 034 | loss: 0.67051 | error: 0.36719\n",
      "  Ended batch 032 / 034 | loss: 0.80646 | error: 0.43750\n",
      "  Ended batch 033 / 034 | loss: 0.75368 | error: 0.39062\n",
      "  Ended batch 034 / 034 | loss: 0.74590 | error: 0.40909\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 010 / 016 | time: 053 sec | loss: 0.77942 | error: 0.28506\n",
      "Ending training due to 4 consecutive epochs without improvement in validation accuracy.\n",
      "Total training time: 8.705296560128529 minutes (522.3177936077118 seconds).\n",
      "Model loaded from ./results/vanilla/spam_0.5_strategic_model.pt.\n",
      "---------- Calculating results ----------\n",
      "Benchmark accuracy: 0.8141342756183746\n",
      "SERM accuracy: 0.719434628975265\n",
      "Blind accuracy: 0.5681978798586572\n",
      "---------- Training non-strategically on spam with scale=1 ----------\n",
      "Starting epoch 001 / 016.\n",
      "Ended epoch 001 / 016 | time: 000 sec | loss: 0.45938 | error: 0.20126\n",
      "Model saved to ./results/vanilla/spam_1_non_strategic_model.pt.\n",
      "Starting epoch 002 / 016.\n",
      "Ended epoch 002 / 016 | time: 000 sec | loss: 0.44429 | error: 0.20647\n",
      "Starting epoch 003 / 016.\n",
      "Ended epoch 003 / 016 | time: 000 sec | loss: 0.44208 | error: 0.20843\n",
      "Starting epoch 004 / 016.\n",
      "Ended epoch 004 / 016 | time: 000 sec | loss: 0.44009 | error: 0.21103\n",
      "Starting epoch 005 / 016.\n",
      "Ended epoch 005 / 016 | time: 000 sec | loss: 0.44039 | error: 0.21038\n",
      "Ending training due to 4 consecutive epochs without improvement in validation accuracy.\n",
      "Total training time: 0.41591358184814453 seconds.\n",
      "Model loaded from ./results/vanilla/spam_1_non_strategic_model.pt.\n",
      "---------- Training strategically on spam with scale=1 ----------\n",
      "Starting epoch 001 / 016.\n",
      "  Ended batch 001 / 034 | loss: 0.93641 | error: 0.45312\n",
      "  Ended batch 002 / 034 | loss: 1.02924 | error: 0.46875\n",
      "  Ended batch 003 / 034 | loss: 1.03811 | error: 0.50000\n",
      "  Ended batch 004 / 034 | loss: 0.80921 | error: 0.46094\n",
      "  Ended batch 005 / 034 | loss: 0.71194 | error: 0.23438\n",
      "  Ended batch 006 / 034 | loss: 0.65456 | error: 0.17969\n",
      "  Ended batch 007 / 034 | loss: 0.68409 | error: 0.26562\n",
      "  Ended batch 008 / 034 | loss: 0.55838 | error: 0.21094\n",
      "  Ended batch 009 / 034 | loss: 0.61619 | error: 0.32031\n",
      "  Ended batch 010 / 034 | loss: 0.58248 | error: 0.27344\n",
      "  Ended batch 011 / 034 | loss: 0.43418 | error: 0.21094\n",
      "  Ended batch 012 / 034 | loss: 0.62755 | error: 0.30469\n",
      "  Ended batch 013 / 034 | loss: 0.53994 | error: 0.20312\n",
      "  Ended batch 014 / 034 | loss: 0.61191 | error: 0.20312\n",
      "  Ended batch 015 / 034 | loss: 0.45235 | error: 0.17969\n",
      "  Ended batch 016 / 034 | loss: 0.43850 | error: 0.17188\n",
      "  Ended batch 017 / 034 | loss: 0.47629 | error: 0.18750\n",
      "  Ended batch 018 / 034 | loss: 0.42770 | error: 0.15625\n",
      "  Ended batch 019 / 034 | loss: 0.45322 | error: 0.16406\n",
      "  Ended batch 020 / 034 | loss: 0.63476 | error: 0.23438\n",
      "  Ended batch 021 / 034 | loss: 0.42394 | error: 0.17188\n",
      "  Ended batch 022 / 034 | loss: 0.44437 | error: 0.18750\n",
      "  Ended batch 023 / 034 | loss: 0.40492 | error: 0.18750\n",
      "  Ended batch 024 / 034 | loss: 0.42722 | error: 0.20312\n",
      "  Ended batch 025 / 034 | loss: 0.58358 | error: 0.27344\n",
      "  Ended batch 026 / 034 | loss: 0.56829 | error: 0.28906\n",
      "  Ended batch 027 / 034 | loss: 0.62583 | error: 0.32812\n",
      "  Ended batch 028 / 034 | loss: 0.61488 | error: 0.32031\n",
      "  Ended batch 029 / 034 | loss: 0.60657 | error: 0.32031\n",
      "  Ended batch 030 / 034 | loss: 0.60436 | error: 0.32031\n",
      "  Ended batch 031 / 034 | loss: 0.53866 | error: 0.28125\n",
      "  Ended batch 032 / 034 | loss: 0.67966 | error: 0.37500\n",
      "  Ended batch 033 / 034 | loss: 0.62059 | error: 0.32812\n",
      "  Ended batch 034 / 034 | loss: 0.66392 | error: 0.36364\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 001 / 016 | time: 054 sec | loss: 0.69521 | error: 0.23363\n",
      "Model saved to ./results/vanilla/spam_1_strategic_model.pt.\n",
      "Starting epoch 002 / 016.\n",
      "  Ended batch 001 / 034 | loss: 0.56212 | error: 0.31250\n",
      "  Ended batch 002 / 034 | loss: 0.56810 | error: 0.31250\n",
      "  Ended batch 003 / 034 | loss: 0.66286 | error: 0.36719\n",
      "  Ended batch 004 / 034 | loss: 0.62329 | error: 0.35156\n",
      "  Ended batch 005 / 034 | loss: 0.53934 | error: 0.28125\n",
      "  Ended batch 006 / 034 | loss: 0.39498 | error: 0.20312\n",
      "  Ended batch 007 / 034 | loss: 0.73513 | error: 0.41406\n",
      "  Ended batch 008 / 034 | loss: 0.50117 | error: 0.28125\n",
      "  Ended batch 009 / 034 | loss: 0.64762 | error: 0.35938\n",
      "  Ended batch 010 / 034 | loss: 0.59753 | error: 0.32031\n",
      "  Ended batch 011 / 034 | loss: 0.42869 | error: 0.21094\n",
      "  Ended batch 012 / 034 | loss: 0.67945 | error: 0.40625\n",
      "  Ended batch 013 / 034 | loss: 0.58239 | error: 0.32031\n",
      "  Ended batch 014 / 034 | loss: 0.65673 | error: 0.34375\n",
      "  Ended batch 015 / 034 | loss: 0.64649 | error: 0.37500\n",
      "  Ended batch 016 / 034 | loss: 0.59168 | error: 0.33594\n",
      "  Ended batch 017 / 034 | loss: 0.62929 | error: 0.36719\n",
      "  Ended batch 018 / 034 | loss: 0.62975 | error: 0.33594\n",
      "  Ended batch 019 / 034 | loss: 0.55953 | error: 0.27344\n",
      "  Ended batch 020 / 034 | loss: 0.71714 | error: 0.39062\n",
      "  Ended batch 021 / 034 | loss: 0.66640 | error: 0.38281\n",
      "  Ended batch 022 / 034 | loss: 0.61429 | error: 0.32031\n",
      "  Ended batch 023 / 034 | loss: 0.61128 | error: 0.33594\n",
      "  Ended batch 024 / 034 | loss: 0.66078 | error: 0.32812\n",
      "  Ended batch 025 / 034 | loss: 0.58593 | error: 0.28906\n",
      "  Ended batch 026 / 034 | loss: 0.66111 | error: 0.35938\n",
      "  Ended batch 027 / 034 | loss: 0.55532 | error: 0.31250\n",
      "  Ended batch 028 / 034 | loss: 0.62608 | error: 0.34375\n",
      "  Ended batch 029 / 034 | loss: 0.56043 | error: 0.32812\n",
      "  Ended batch 030 / 034 | loss: 0.52105 | error: 0.28906\n",
      "  Ended batch 031 / 034 | loss: 0.57263 | error: 0.29688\n",
      "  Ended batch 032 / 034 | loss: 0.65006 | error: 0.35156\n",
      "  Ended batch 033 / 034 | loss: 0.70430 | error: 0.36719\n",
      "  Ended batch 034 / 034 | loss: 0.59937 | error: 0.31818\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 002 / 016 | time: 051 sec | loss: 0.69647 | error: 0.23624\n",
      "Starting epoch 003 / 016.\n",
      "  Ended batch 001 / 034 | loss: 0.67723 | error: 0.36719\n",
      "  Ended batch 002 / 034 | loss: 0.60988 | error: 0.32031\n",
      "  Ended batch 003 / 034 | loss: 0.62304 | error: 0.35156\n",
      "  Ended batch 004 / 034 | loss: 0.62915 | error: 0.35156\n",
      "  Ended batch 005 / 034 | loss: 0.53299 | error: 0.28906\n",
      "  Ended batch 006 / 034 | loss: 0.47444 | error: 0.27344\n",
      "  Ended batch 007 / 034 | loss: 0.63586 | error: 0.34375\n",
      "  Ended batch 008 / 034 | loss: 0.40189 | error: 0.20312\n",
      "  Ended batch 009 / 034 | loss: 0.57904 | error: 0.30469\n",
      "  Ended batch 010 / 034 | loss: 0.61723 | error: 0.31250\n",
      "  Ended batch 011 / 034 | loss: 0.41435 | error: 0.21875\n",
      "  Ended batch 012 / 034 | loss: 0.62162 | error: 0.34375\n",
      "  Ended batch 013 / 034 | loss: 0.54406 | error: 0.23438\n",
      "  Ended batch 014 / 034 | loss: 0.57769 | error: 0.25000\n",
      "  Ended batch 015 / 034 | loss: 0.61211 | error: 0.32031\n",
      "  Ended batch 016 / 034 | loss: 0.57012 | error: 0.29688\n",
      "  Ended batch 017 / 034 | loss: 0.62502 | error: 0.32812\n",
      "  Ended batch 018 / 034 | loss: 0.61930 | error: 0.33594\n",
      "  Ended batch 019 / 034 | loss: 0.53444 | error: 0.25000\n",
      "  Ended batch 020 / 034 | loss: 0.65106 | error: 0.33594\n",
      "  Ended batch 021 / 034 | loss: 0.61895 | error: 0.34375\n",
      "  Ended batch 022 / 034 | loss: 0.59460 | error: 0.32031\n",
      "  Ended batch 023 / 034 | loss: 0.63278 | error: 0.35156\n",
      "  Ended batch 024 / 034 | loss: 0.67129 | error: 0.38281\n",
      "  Ended batch 025 / 034 | loss: 0.62908 | error: 0.33594\n",
      "  Ended batch 026 / 034 | loss: 0.63524 | error: 0.29688\n",
      "  Ended batch 027 / 034 | loss: 0.55282 | error: 0.28125\n",
      "  Ended batch 028 / 034 | loss: 0.67780 | error: 0.35938\n",
      "  Ended batch 029 / 034 | loss: 0.56616 | error: 0.32031\n",
      "  Ended batch 030 / 034 | loss: 0.51592 | error: 0.28906\n",
      "  Ended batch 031 / 034 | loss: 0.57133 | error: 0.31250\n",
      "  Ended batch 032 / 034 | loss: 0.65008 | error: 0.33594\n",
      "  Ended batch 033 / 034 | loss: 0.73709 | error: 0.35938\n",
      "  Ended batch 034 / 034 | loss: 0.66277 | error: 0.36364\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 003 / 016 | time: 053 sec | loss: 0.66564 | error: 0.21605\n",
      "Validation accuracy improved.\n",
      "Model saved to ./results/vanilla/spam_1_strategic_model.pt.\n",
      "Starting epoch 004 / 016.\n",
      "  Ended batch 001 / 034 | loss: 0.66821 | error: 0.36719\n",
      "  Ended batch 002 / 034 | loss: 0.62706 | error: 0.35156\n",
      "  Ended batch 003 / 034 | loss: 0.63412 | error: 0.35938\n",
      "  Ended batch 004 / 034 | loss: 0.67335 | error: 0.39844\n",
      "  Ended batch 005 / 034 | loss: 0.56993 | error: 0.27344\n",
      "  Ended batch 006 / 034 | loss: 0.45462 | error: 0.17969\n",
      "  Ended batch 007 / 034 | loss: 0.65459 | error: 0.37500\n",
      "  Ended batch 008 / 034 | loss: 0.50772 | error: 0.28125\n",
      "  Ended batch 009 / 034 | loss: 0.62163 | error: 0.33594\n",
      "  Ended batch 010 / 034 | loss: 0.51647 | error: 0.25781\n",
      "  Ended batch 011 / 034 | loss: 0.44930 | error: 0.24219\n",
      "  Ended batch 012 / 034 | loss: 0.69573 | error: 0.39062\n",
      "  Ended batch 013 / 034 | loss: 0.59595 | error: 0.29688\n",
      "  Ended batch 014 / 034 | loss: 0.65261 | error: 0.29688\n",
      "  Ended batch 015 / 034 | loss: 0.54326 | error: 0.28906\n",
      "  Ended batch 016 / 034 | loss: 0.59431 | error: 0.32812\n",
      "  Ended batch 017 / 034 | loss: 0.63361 | error: 0.35156\n",
      "  Ended batch 018 / 034 | loss: 0.62422 | error: 0.34375\n",
      "  Ended batch 019 / 034 | loss: 0.58524 | error: 0.30469\n",
      "  Ended batch 020 / 034 | loss: 0.72014 | error: 0.38281\n",
      "  Ended batch 021 / 034 | loss: 0.67886 | error: 0.39062\n",
      "  Ended batch 022 / 034 | loss: 0.59514 | error: 0.32812\n",
      "  Ended batch 023 / 034 | loss: 0.57170 | error: 0.31250\n",
      "  Ended batch 024 / 034 | loss: 0.66390 | error: 0.38281\n",
      "  Ended batch 025 / 034 | loss: 0.60554 | error: 0.33594\n",
      "  Ended batch 026 / 034 | loss: 0.65447 | error: 0.35938\n",
      "  Ended batch 027 / 034 | loss: 0.55192 | error: 0.28906\n",
      "  Ended batch 028 / 034 | loss: 0.65340 | error: 0.36719\n",
      "  Ended batch 029 / 034 | loss: 0.54932 | error: 0.32031\n",
      "  Ended batch 030 / 034 | loss: 0.48519 | error: 0.26562\n",
      "  Ended batch 031 / 034 | loss: 0.59859 | error: 0.34375\n",
      "  Ended batch 032 / 034 | loss: 0.68974 | error: 0.38281\n",
      "  Ended batch 033 / 034 | loss: 0.69336 | error: 0.35938\n",
      "  Ended batch 034 / 034 | loss: 0.62703 | error: 0.31818\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 004 / 016 | time: 052 sec | loss: 0.65486 | error: 0.22061\n",
      "Starting epoch 005 / 016.\n",
      "  Ended batch 001 / 034 | loss: 0.67734 | error: 0.38281\n",
      "  Ended batch 002 / 034 | loss: 0.60789 | error: 0.33594\n",
      "  Ended batch 003 / 034 | loss: 0.66874 | error: 0.37500\n",
      "  Ended batch 004 / 034 | loss: 0.67292 | error: 0.38281\n",
      "  Ended batch 005 / 034 | loss: 0.54410 | error: 0.29688\n",
      "  Ended batch 006 / 034 | loss: 0.45343 | error: 0.22656\n",
      "  Ended batch 007 / 034 | loss: 0.69180 | error: 0.40625\n",
      "  Ended batch 008 / 034 | loss: 0.46594 | error: 0.25781\n",
      "  Ended batch 009 / 034 | loss: 0.58787 | error: 0.30469\n",
      "  Ended batch 010 / 034 | loss: 0.53955 | error: 0.25781\n",
      "  Ended batch 011 / 034 | loss: 0.47079 | error: 0.25781\n",
      "  Ended batch 012 / 034 | loss: 0.66937 | error: 0.37500\n",
      "  Ended batch 013 / 034 | loss: 0.55405 | error: 0.26562\n",
      "  Ended batch 014 / 034 | loss: 0.62675 | error: 0.30469\n",
      "  Ended batch 015 / 034 | loss: 0.62189 | error: 0.33594\n",
      "  Ended batch 016 / 034 | loss: 0.62637 | error: 0.35156\n",
      "  Ended batch 017 / 034 | loss: 0.62059 | error: 0.35938\n",
      "  Ended batch 018 / 034 | loss: 0.61093 | error: 0.28906\n",
      "  Ended batch 019 / 034 | loss: 0.55936 | error: 0.20312\n",
      "  Ended batch 020 / 034 | loss: 0.69918 | error: 0.36719\n",
      "  Ended batch 021 / 034 | loss: 0.70199 | error: 0.39844\n",
      "  Ended batch 022 / 034 | loss: 0.63032 | error: 0.34375\n",
      "  Ended batch 023 / 034 | loss: 0.61561 | error: 0.33594\n",
      "  Ended batch 024 / 034 | loss: 0.65499 | error: 0.35938\n",
      "  Ended batch 025 / 034 | loss: 0.59504 | error: 0.30469\n",
      "  Ended batch 026 / 034 | loss: 0.63126 | error: 0.33594\n",
      "  Ended batch 027 / 034 | loss: 0.56310 | error: 0.32031\n",
      "  Ended batch 028 / 034 | loss: 0.70520 | error: 0.38281\n",
      "  Ended batch 029 / 034 | loss: 0.55189 | error: 0.32031\n",
      "  Ended batch 030 / 034 | loss: 0.46913 | error: 0.22656\n",
      "  Ended batch 031 / 034 | loss: 0.58467 | error: 0.32812\n",
      "  Ended batch 032 / 034 | loss: 0.65940 | error: 0.35156\n",
      "  Ended batch 033 / 034 | loss: 0.69397 | error: 0.35938\n",
      "  Ended batch 034 / 034 | loss: 0.63847 | error: 0.36364\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 005 / 016 | time: 052 sec | loss: 0.68537 | error: 0.23103\n",
      "Starting epoch 006 / 016.\n",
      "  Ended batch 001 / 034 | loss: 0.68913 | error: 0.37500\n",
      "  Ended batch 002 / 034 | loss: 0.54971 | error: 0.27344\n",
      "  Ended batch 003 / 034 | loss: 0.61842 | error: 0.34375\n",
      "  Ended batch 004 / 034 | loss: 0.68413 | error: 0.38281\n",
      "  Ended batch 005 / 034 | loss: 0.57128 | error: 0.32812\n",
      "  Ended batch 006 / 034 | loss: 0.46392 | error: 0.26562\n",
      "  Ended batch 007 / 034 | loss: 0.63609 | error: 0.37500\n",
      "  Ended batch 008 / 034 | loss: 0.45525 | error: 0.24219\n",
      "  Ended batch 009 / 034 | loss: 0.59656 | error: 0.32031\n",
      "  Ended batch 010 / 034 | loss: 0.60291 | error: 0.32031\n",
      "  Ended batch 011 / 034 | loss: 0.47846 | error: 0.26562\n",
      "  Ended batch 012 / 034 | loss: 0.68684 | error: 0.39844\n",
      "  Ended batch 013 / 034 | loss: 0.56588 | error: 0.25781\n",
      "  Ended batch 014 / 034 | loss: 0.60628 | error: 0.28125\n",
      "  Ended batch 015 / 034 | loss: 0.61310 | error: 0.34375\n",
      "  Ended batch 016 / 034 | loss: 0.60359 | error: 0.32812\n",
      "  Ended batch 017 / 034 | loss: 0.62849 | error: 0.35156\n",
      "  Ended batch 018 / 034 | loss: 0.62344 | error: 0.33594\n",
      "  Ended batch 019 / 034 | loss: 0.55365 | error: 0.24219\n",
      "  Ended batch 020 / 034 | loss: 0.68835 | error: 0.36719\n",
      "  Ended batch 021 / 034 | loss: 0.64725 | error: 0.36719\n",
      "  Ended batch 022 / 034 | loss: 0.58424 | error: 0.31250\n",
      "  Ended batch 023 / 034 | loss: 0.55699 | error: 0.30469\n",
      "  Ended batch 024 / 034 | loss: 0.65772 | error: 0.36719\n",
      "  Ended batch 025 / 034 | loss: 0.58370 | error: 0.30469\n",
      "  Ended batch 026 / 034 | loss: 0.63170 | error: 0.32812\n",
      "  Ended batch 027 / 034 | loss: 0.54241 | error: 0.31250\n",
      "  Ended batch 028 / 034 | loss: 0.65653 | error: 0.37500\n",
      "  Ended batch 029 / 034 | loss: 0.56315 | error: 0.32031\n",
      "  Ended batch 030 / 034 | loss: 0.48840 | error: 0.27344\n",
      "  Ended batch 031 / 034 | loss: 0.55566 | error: 0.30469\n",
      "  Ended batch 032 / 034 | loss: 0.62931 | error: 0.33594\n",
      "  Ended batch 033 / 034 | loss: 0.66854 | error: 0.34375\n",
      "  Ended batch 034 / 034 | loss: 0.63776 | error: 0.36364\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 006 / 016 | time: 051 sec | loss: 0.63111 | error: 0.20889\n",
      "Validation accuracy improved.\n",
      "Model saved to ./results/vanilla/spam_1_strategic_model.pt.\n",
      "Starting epoch 007 / 016.\n",
      "  Ended batch 001 / 034 | loss: 0.66647 | error: 0.38281\n",
      "  Ended batch 002 / 034 | loss: 0.60294 | error: 0.34375\n",
      "  Ended batch 003 / 034 | loss: 0.64809 | error: 0.36719\n",
      "  Ended batch 004 / 034 | loss: 0.64964 | error: 0.37500\n",
      "  Ended batch 005 / 034 | loss: 0.52462 | error: 0.27344\n",
      "  Ended batch 006 / 034 | loss: 0.43904 | error: 0.24219\n",
      "  Ended batch 007 / 034 | loss: 0.70082 | error: 0.39844\n",
      "  Ended batch 008 / 034 | loss: 0.51989 | error: 0.29688\n",
      "  Ended batch 009 / 034 | loss: 0.61877 | error: 0.33594\n",
      "  Ended batch 010 / 034 | loss: 0.51233 | error: 0.24219\n",
      "  Ended batch 011 / 034 | loss: 0.42627 | error: 0.22656\n",
      "  Ended batch 012 / 034 | loss: 0.70002 | error: 0.39844\n",
      "  Ended batch 013 / 034 | loss: 0.56708 | error: 0.28906\n",
      "  Ended batch 014 / 034 | loss: 0.59925 | error: 0.29688\n",
      "  Ended batch 015 / 034 | loss: 0.59387 | error: 0.33594\n",
      "  Ended batch 016 / 034 | loss: 0.59422 | error: 0.33594\n",
      "  Ended batch 017 / 034 | loss: 0.60311 | error: 0.34375\n",
      "  Ended batch 018 / 034 | loss: 0.63500 | error: 0.35156\n",
      "  Ended batch 019 / 034 | loss: 0.54497 | error: 0.28906\n",
      "  Ended batch 020 / 034 | loss: 0.72103 | error: 0.37500\n",
      "  Ended batch 021 / 034 | loss: 0.66553 | error: 0.37500\n",
      "  Ended batch 022 / 034 | loss: 0.60569 | error: 0.32031\n",
      "  Ended batch 023 / 034 | loss: 0.55897 | error: 0.30469\n",
      "  Ended batch 024 / 034 | loss: 0.66381 | error: 0.38281\n",
      "  Ended batch 025 / 034 | loss: 0.60207 | error: 0.33594\n",
      "  Ended batch 026 / 034 | loss: 0.65582 | error: 0.35938\n",
      "  Ended batch 027 / 034 | loss: 0.55491 | error: 0.30469\n",
      "  Ended batch 028 / 034 | loss: 0.63648 | error: 0.35938\n",
      "  Ended batch 029 / 034 | loss: 0.53507 | error: 0.28906\n",
      "  Ended batch 030 / 034 | loss: 0.51357 | error: 0.28125\n",
      "  Ended batch 031 / 034 | loss: 0.57904 | error: 0.32812\n",
      "  Ended batch 032 / 034 | loss: 0.65226 | error: 0.35156\n",
      "  Ended batch 033 / 034 | loss: 0.68449 | error: 0.35156\n",
      "  Ended batch 034 / 034 | loss: 0.60930 | error: 0.31818\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 007 / 016 | time: 052 sec | loss: 0.73906 | error: 0.25381\n",
      "Starting epoch 008 / 016.\n",
      "  Ended batch 001 / 034 | loss: 0.66751 | error: 0.35156\n",
      "  Ended batch 002 / 034 | loss: 0.61229 | error: 0.32031\n",
      "  Ended batch 003 / 034 | loss: 0.67459 | error: 0.36719\n",
      "  Ended batch 004 / 034 | loss: 0.67959 | error: 0.35938\n",
      "  Ended batch 005 / 034 | loss: 0.54380 | error: 0.28906\n",
      "  Ended batch 006 / 034 | loss: 0.42742 | error: 0.22656\n",
      "  Ended batch 007 / 034 | loss: 0.64994 | error: 0.35156\n",
      "  Ended batch 008 / 034 | loss: 0.50122 | error: 0.27344\n",
      "  Ended batch 009 / 034 | loss: 0.58630 | error: 0.31250\n",
      "  Ended batch 010 / 034 | loss: 0.49163 | error: 0.21875\n",
      "  Ended batch 011 / 034 | loss: 0.39594 | error: 0.20312\n",
      "  Ended batch 012 / 034 | loss: 0.61874 | error: 0.32812\n",
      "  Ended batch 013 / 034 | loss: 0.55342 | error: 0.26562\n",
      "  Ended batch 014 / 034 | loss: 0.54427 | error: 0.25000\n",
      "  Ended batch 015 / 034 | loss: 0.62734 | error: 0.33594\n",
      "  Ended batch 016 / 034 | loss: 0.56703 | error: 0.31250\n",
      "  Ended batch 017 / 034 | loss: 0.63007 | error: 0.35156\n",
      "  Ended batch 018 / 034 | loss: 0.59117 | error: 0.28906\n",
      "  Ended batch 019 / 034 | loss: 0.58193 | error: 0.24219\n",
      "  Ended batch 020 / 034 | loss: 0.71950 | error: 0.38281\n",
      "  Ended batch 021 / 034 | loss: 0.68849 | error: 0.39062\n",
      "  Ended batch 022 / 034 | loss: 0.63611 | error: 0.35938\n",
      "  Ended batch 023 / 034 | loss: 0.58865 | error: 0.32812\n",
      "  Ended batch 024 / 034 | loss: 0.65484 | error: 0.37500\n",
      "  Ended batch 025 / 034 | loss: 0.60748 | error: 0.32031\n",
      "  Ended batch 026 / 034 | loss: 0.66150 | error: 0.35938\n",
      "  Ended batch 027 / 034 | loss: 0.54986 | error: 0.30469\n",
      "  Ended batch 028 / 034 | loss: 0.66186 | error: 0.36719\n",
      "  Ended batch 029 / 034 | loss: 0.51569 | error: 0.28125\n",
      "  Ended batch 030 / 034 | loss: 0.48112 | error: 0.25781\n",
      "  Ended batch 031 / 034 | loss: 0.59103 | error: 0.32812\n",
      "  Ended batch 032 / 034 | loss: 0.73286 | error: 0.39844\n",
      "  Ended batch 033 / 034 | loss: 0.69651 | error: 0.35156\n",
      "  Ended batch 034 / 034 | loss: 0.58153 | error: 0.31818\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 008 / 016 | time: 053 sec | loss: 0.68953 | error: 0.23624\n",
      "Starting epoch 009 / 016.\n",
      "  Ended batch 001 / 034 | loss: 0.67164 | error: 0.37500\n",
      "  Ended batch 002 / 034 | loss: 0.61239 | error: 0.33594\n",
      "  Ended batch 003 / 034 | loss: 0.61833 | error: 0.34375\n",
      "  Ended batch 004 / 034 | loss: 0.68351 | error: 0.39062\n",
      "  Ended batch 005 / 034 | loss: 0.52494 | error: 0.28906\n",
      "  Ended batch 006 / 034 | loss: 0.46424 | error: 0.26562\n",
      "  Ended batch 007 / 034 | loss: 0.65861 | error: 0.37500\n",
      "  Ended batch 008 / 034 | loss: 0.45843 | error: 0.25000\n",
      "  Ended batch 009 / 034 | loss: 0.59278 | error: 0.31250\n",
      "  Ended batch 010 / 034 | loss: 0.53694 | error: 0.26562\n",
      "  Ended batch 011 / 034 | loss: 0.47252 | error: 0.25781\n",
      "  Ended batch 012 / 034 | loss: 0.71734 | error: 0.39844\n",
      "  Ended batch 013 / 034 | loss: 0.56775 | error: 0.28125\n",
      "  Ended batch 014 / 034 | loss: 0.61719 | error: 0.28125\n",
      "  Ended batch 015 / 034 | loss: 0.57271 | error: 0.32031\n",
      "  Ended batch 016 / 034 | loss: 0.58778 | error: 0.32812\n",
      "  Ended batch 017 / 034 | loss: 0.63746 | error: 0.35938\n",
      "  Ended batch 018 / 034 | loss: 0.63356 | error: 0.35156\n",
      "  Ended batch 019 / 034 | loss: 0.57589 | error: 0.30469\n",
      "  Ended batch 020 / 034 | loss: 0.71677 | error: 0.37500\n",
      "  Ended batch 021 / 034 | loss: 0.69039 | error: 0.39844\n",
      "  Ended batch 022 / 034 | loss: 0.60726 | error: 0.32812\n",
      "  Ended batch 023 / 034 | loss: 0.57643 | error: 0.32812\n",
      "  Ended batch 024 / 034 | loss: 0.64985 | error: 0.36719\n",
      "  Ended batch 025 / 034 | loss: 0.60264 | error: 0.32031\n",
      "  Ended batch 026 / 034 | loss: 0.65849 | error: 0.36719\n",
      "  Ended batch 027 / 034 | loss: 0.55367 | error: 0.30469\n",
      "  Ended batch 028 / 034 | loss: 0.63549 | error: 0.33594\n",
      "  Ended batch 029 / 034 | loss: 0.53463 | error: 0.29688\n",
      "  Ended batch 030 / 034 | loss: 0.52245 | error: 0.28906\n",
      "  Ended batch 031 / 034 | loss: 0.59050 | error: 0.33594\n",
      "  Ended batch 032 / 034 | loss: 0.63768 | error: 0.34375\n",
      "  Ended batch 033 / 034 | loss: 0.71509 | error: 0.37500\n",
      "  Ended batch 034 / 034 | loss: 0.66239 | error: 0.36364\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 009 / 016 | time: 052 sec | loss: 0.69670 | error: 0.23558\n",
      "Starting epoch 010 / 016.\n",
      "  Ended batch 001 / 034 | loss: 0.66830 | error: 0.35938\n",
      "  Ended batch 002 / 034 | loss: 0.59894 | error: 0.32031\n",
      "  Ended batch 003 / 034 | loss: 0.62322 | error: 0.34375\n",
      "  Ended batch 004 / 034 | loss: 0.66977 | error: 0.36719\n",
      "  Ended batch 005 / 034 | loss: 0.55914 | error: 0.31250\n",
      "  Ended batch 006 / 034 | loss: 0.42866 | error: 0.22656\n",
      "  Ended batch 007 / 034 | loss: 0.68910 | error: 0.38281\n",
      "  Ended batch 008 / 034 | loss: 0.47316 | error: 0.26562\n",
      "  Ended batch 009 / 034 | loss: 0.57881 | error: 0.30469\n",
      "  Ended batch 010 / 034 | loss: 0.51572 | error: 0.24219\n",
      "  Ended batch 011 / 034 | loss: 0.41563 | error: 0.21875\n",
      "  Ended batch 012 / 034 | loss: 0.70351 | error: 0.38281\n",
      "  Ended batch 013 / 034 | loss: 0.56573 | error: 0.28125\n",
      "  Ended batch 014 / 034 | loss: 0.58110 | error: 0.26562\n",
      "  Ended batch 015 / 034 | loss: 0.56725 | error: 0.30469\n",
      "  Ended batch 016 / 034 | loss: 0.55935 | error: 0.30469\n",
      "  Ended batch 017 / 034 | loss: 0.65485 | error: 0.36719\n",
      "  Ended batch 018 / 034 | loss: 0.63287 | error: 0.35938\n",
      "  Ended batch 019 / 034 | loss: 0.57198 | error: 0.30469\n",
      "  Ended batch 020 / 034 | loss: 0.71214 | error: 0.37500\n",
      "  Ended batch 021 / 034 | loss: 0.63553 | error: 0.35938\n",
      "  Ended batch 022 / 034 | loss: 0.58476 | error: 0.31250\n",
      "  Ended batch 023 / 034 | loss: 0.59578 | error: 0.33594\n",
      "  Ended batch 024 / 034 | loss: 0.66416 | error: 0.37500\n",
      "  Ended batch 025 / 034 | loss: 0.60155 | error: 0.31250\n",
      "  Ended batch 026 / 034 | loss: 0.64604 | error: 0.35938\n",
      "  Ended batch 027 / 034 | loss: 0.55739 | error: 0.32031\n",
      "  Ended batch 028 / 034 | loss: 0.64087 | error: 0.36719\n",
      "  Ended batch 029 / 034 | loss: 0.56788 | error: 0.33594\n",
      "  Ended batch 030 / 034 | loss: 0.48243 | error: 0.22656\n",
      "  Ended batch 031 / 034 | loss: 0.57699 | error: 0.30469\n",
      "  Ended batch 032 / 034 | loss: 0.65508 | error: 0.35938\n",
      "  Ended batch 033 / 034 | loss: 0.72746 | error: 0.37500\n",
      "  Ended batch 034 / 034 | loss: 0.58802 | error: 0.31818\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 010 / 016 | time: 055 sec | loss: 0.72705 | error: 0.24926\n",
      "Ending training due to 4 consecutive epochs without improvement in validation accuracy.\n",
      "Total training time: 8.754660820960998 minutes (525.2796492576599 seconds).\n",
      "Model loaded from ./results/vanilla/spam_1_strategic_model.pt.\n",
      "---------- Calculating results ----------\n",
      "Benchmark accuracy: 0.8148409893992933\n",
      "SERM accuracy: 0.7865724381625442\n",
      "Blind accuracy: 0.5879858657243816\n",
      "---------- Training non-strategically on spam with scale=2 ----------\n",
      "Starting epoch 001 / 016.\n",
      "Ended epoch 001 / 016 | time: 000 sec | loss: 0.44973 | error: 0.19931\n",
      "Model saved to ./results/vanilla/spam_2_non_strategic_model.pt.\n",
      "Starting epoch 002 / 016.\n",
      "Ended epoch 002 / 016 | time: 000 sec | loss: 0.44281 | error: 0.20712\n",
      "Starting epoch 003 / 016.\n",
      "Ended epoch 003 / 016 | time: 000 sec | loss: 0.44083 | error: 0.21168\n",
      "Starting epoch 004 / 016.\n",
      "Ended epoch 004 / 016 | time: 000 sec | loss: 0.44076 | error: 0.21038\n",
      "Starting epoch 005 / 016.\n",
      "Ended epoch 005 / 016 | time: 000 sec | loss: 0.43954 | error: 0.20778\n",
      "Ending training due to 4 consecutive epochs without improvement in validation accuracy.\n",
      "Total training time: 0.47339725494384766 seconds.\n",
      "Model loaded from ./results/vanilla/spam_2_non_strategic_model.pt.\n",
      "---------- Training strategically on spam with scale=2 ----------\n",
      "Starting epoch 001 / 016.\n",
      "  Ended batch 001 / 034 | loss: 0.94517 | error: 0.46094\n",
      "  Ended batch 002 / 034 | loss: 0.97293 | error: 0.46875\n",
      "  Ended batch 003 / 034 | loss: 0.96975 | error: 0.46094\n",
      "  Ended batch 004 / 034 | loss: 0.78750 | error: 0.42188\n",
      "  Ended batch 005 / 034 | loss: 0.60744 | error: 0.30469\n",
      "  Ended batch 006 / 034 | loss: 0.52826 | error: 0.14844\n",
      "  Ended batch 007 / 034 | loss: 0.61536 | error: 0.25000\n",
      "  Ended batch 008 / 034 | loss: 0.49651 | error: 0.16406\n",
      "  Ended batch 009 / 034 | loss: 0.60153 | error: 0.28906\n",
      "  Ended batch 010 / 034 | loss: 0.55142 | error: 0.25000\n",
      "  Ended batch 011 / 034 | loss: 0.41656 | error: 0.21094\n",
      "  Ended batch 012 / 034 | loss: 0.69794 | error: 0.35156\n",
      "  Ended batch 013 / 034 | loss: 0.59903 | error: 0.25000\n",
      "  Ended batch 014 / 034 | loss: 0.61842 | error: 0.23438\n",
      "  Ended batch 015 / 034 | loss: 0.44547 | error: 0.19531\n",
      "  Ended batch 016 / 034 | loss: 0.40903 | error: 0.17969\n",
      "  Ended batch 017 / 034 | loss: 0.46105 | error: 0.20312\n",
      "  Ended batch 018 / 034 | loss: 0.40460 | error: 0.16406\n",
      "  Ended batch 019 / 034 | loss: 0.49399 | error: 0.18750\n",
      "  Ended batch 020 / 034 | loss: 0.63511 | error: 0.23438\n",
      "  Ended batch 021 / 034 | loss: 0.42744 | error: 0.19531\n",
      "  Ended batch 022 / 034 | loss: 0.38364 | error: 0.17188\n",
      "  Ended batch 023 / 034 | loss: 0.48768 | error: 0.22656\n",
      "  Ended batch 024 / 034 | loss: 0.44445 | error: 0.21094\n",
      "  Ended batch 025 / 034 | loss: 0.61012 | error: 0.27344\n",
      "  Ended batch 026 / 034 | loss: 0.52282 | error: 0.25781\n",
      "  Ended batch 027 / 034 | loss: 0.49635 | error: 0.25000\n",
      "  Ended batch 028 / 034 | loss: 0.41583 | error: 0.19531\n",
      "  Ended batch 029 / 034 | loss: 0.41577 | error: 0.20312\n",
      "  Ended batch 030 / 034 | loss: 0.42027 | error: 0.21094\n",
      "  Ended batch 031 / 034 | loss: 0.49273 | error: 0.25000\n",
      "  Ended batch 032 / 034 | loss: 0.53613 | error: 0.28125\n",
      "  Ended batch 033 / 034 | loss: 0.48340 | error: 0.23438\n",
      "  Ended batch 034 / 034 | loss: 0.60278 | error: 0.31818\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 001 / 016 | time: 053 sec | loss: 0.69677 | error: 0.22972\n",
      "Model saved to ./results/vanilla/spam_2_strategic_model.pt.\n",
      "Starting epoch 002 / 016.\n",
      "  Ended batch 001 / 034 | loss: 0.47522 | error: 0.22656\n",
      "  Ended batch 002 / 034 | loss: 0.40266 | error: 0.17969\n",
      "  Ended batch 003 / 034 | loss: 0.59435 | error: 0.32812\n",
      "  Ended batch 004 / 034 | loss: 0.59540 | error: 0.35156\n",
      "  Ended batch 005 / 034 | loss: 0.44704 | error: 0.24219\n",
      "  Ended batch 006 / 034 | loss: 0.32401 | error: 0.14062\n",
      "  Ended batch 007 / 034 | loss: 0.51206 | error: 0.28125\n",
      "  Ended batch 008 / 034 | loss: 0.41197 | error: 0.23438\n",
      "  Ended batch 009 / 034 | loss: 0.56280 | error: 0.30469\n",
      "  Ended batch 010 / 034 | loss: 0.47560 | error: 0.22656\n",
      "  Ended batch 011 / 034 | loss: 0.35233 | error: 0.18750\n",
      "  Ended batch 012 / 034 | loss: 0.55580 | error: 0.30469\n",
      "  Ended batch 013 / 034 | loss: 0.50067 | error: 0.25000\n",
      "  Ended batch 014 / 034 | loss: 0.55283 | error: 0.22656\n",
      "  Ended batch 015 / 034 | loss: 0.48307 | error: 0.25000\n",
      "  Ended batch 016 / 034 | loss: 0.52066 | error: 0.28906\n",
      "  Ended batch 017 / 034 | loss: 0.55611 | error: 0.31250\n",
      "  Ended batch 018 / 034 | loss: 0.54190 | error: 0.28906\n",
      "  Ended batch 019 / 034 | loss: 0.48629 | error: 0.17969\n",
      "  Ended batch 020 / 034 | loss: 0.59345 | error: 0.25000\n",
      "  Ended batch 021 / 034 | loss: 0.53862 | error: 0.28125\n",
      "  Ended batch 022 / 034 | loss: 0.51307 | error: 0.27344\n",
      "  Ended batch 023 / 034 | loss: 0.53885 | error: 0.29688\n",
      "  Ended batch 024 / 034 | loss: 0.56684 | error: 0.31250\n",
      "  Ended batch 025 / 034 | loss: 0.54445 | error: 0.30469\n",
      "  Ended batch 026 / 034 | loss: 0.55960 | error: 0.26562\n",
      "  Ended batch 027 / 034 | loss: 0.41828 | error: 0.20312\n",
      "  Ended batch 028 / 034 | loss: 0.54233 | error: 0.32031\n",
      "  Ended batch 029 / 034 | loss: 0.50268 | error: 0.28125\n",
      "  Ended batch 030 / 034 | loss: 0.36917 | error: 0.18750\n",
      "  Ended batch 031 / 034 | loss: 0.43322 | error: 0.21875\n",
      "  Ended batch 032 / 034 | loss: 0.50962 | error: 0.24219\n",
      "  Ended batch 033 / 034 | loss: 0.61727 | error: 0.27344\n",
      "  Ended batch 034 / 034 | loss: 0.57312 | error: 0.31818\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 002 / 016 | time: 060 sec | loss: 0.65072 | error: 0.21084\n",
      "Validation accuracy improved.\n",
      "Model saved to ./results/vanilla/spam_2_strategic_model.pt.\n",
      "Starting epoch 003 / 016.\n",
      "  Ended batch 001 / 034 | loss: 0.46545 | error: 0.21875\n",
      "  Ended batch 002 / 034 | loss: 0.53370 | error: 0.29688\n",
      "  Ended batch 003 / 034 | loss: 0.56738 | error: 0.32031\n",
      "  Ended batch 004 / 034 | loss: 0.49189 | error: 0.25000\n",
      "  Ended batch 005 / 034 | loss: 0.43163 | error: 0.21875\n",
      "  Ended batch 006 / 034 | loss: 0.44247 | error: 0.26562\n",
      "  Ended batch 007 / 034 | loss: 0.63626 | error: 0.37500\n",
      "  Ended batch 008 / 034 | loss: 0.40789 | error: 0.22656\n",
      "  Ended batch 009 / 034 | loss: 0.55192 | error: 0.28906\n",
      "  Ended batch 010 / 034 | loss: 0.41330 | error: 0.16406\n",
      "  Ended batch 011 / 034 | loss: 0.36288 | error: 0.18750\n",
      "  Ended batch 012 / 034 | loss: 0.57217 | error: 0.31250\n",
      "  Ended batch 013 / 034 | loss: 0.54136 | error: 0.26562\n",
      "  Ended batch 014 / 034 | loss: 0.60907 | error: 0.27344\n",
      "  Ended batch 015 / 034 | loss: 0.49984 | error: 0.25781\n",
      "  Ended batch 016 / 034 | loss: 0.49296 | error: 0.25000\n",
      "  Ended batch 017 / 034 | loss: 0.52434 | error: 0.28125\n",
      "  Ended batch 018 / 034 | loss: 0.52901 | error: 0.25781\n",
      "  Ended batch 019 / 034 | loss: 0.46235 | error: 0.20312\n",
      "  Ended batch 020 / 034 | loss: 0.63082 | error: 0.28906\n",
      "  Ended batch 021 / 034 | loss: 0.58902 | error: 0.32812\n",
      "  Ended batch 022 / 034 | loss: 0.49143 | error: 0.25000\n",
      "  Ended batch 023 / 034 | loss: 0.50915 | error: 0.28125\n",
      "  Ended batch 024 / 034 | loss: 0.58255 | error: 0.34375\n",
      "  Ended batch 025 / 034 | loss: 0.54646 | error: 0.25000\n",
      "  Ended batch 026 / 034 | loss: 0.59007 | error: 0.29688\n",
      "  Ended batch 027 / 034 | loss: 0.48305 | error: 0.25781\n",
      "  Ended batch 028 / 034 | loss: 0.53713 | error: 0.31250\n",
      "  Ended batch 029 / 034 | loss: 0.46792 | error: 0.26562\n",
      "  Ended batch 030 / 034 | loss: 0.36293 | error: 0.17188\n",
      "  Ended batch 031 / 034 | loss: 0.42835 | error: 0.21875\n",
      "  Ended batch 032 / 034 | loss: 0.52220 | error: 0.25000\n",
      "  Ended batch 033 / 034 | loss: 0.65156 | error: 0.30469\n",
      "  Ended batch 034 / 034 | loss: 0.59231 | error: 0.31818\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 003 / 016 | time: 051 sec | loss: 0.64881 | error: 0.20889\n",
      "Validation accuracy improved.\n",
      "Model saved to ./results/vanilla/spam_2_strategic_model.pt.\n",
      "Starting epoch 004 / 016.\n",
      "  Ended batch 001 / 034 | loss: 0.47708 | error: 0.23438\n",
      "  Ended batch 002 / 034 | loss: 0.50275 | error: 0.25781\n",
      "  Ended batch 003 / 034 | loss: 0.58677 | error: 0.32812\n",
      "  Ended batch 004 / 034 | loss: 0.55693 | error: 0.30469\n",
      "  Ended batch 005 / 034 | loss: 0.44493 | error: 0.21094\n",
      "  Ended batch 006 / 034 | loss: 0.36028 | error: 0.17188\n",
      "  Ended batch 007 / 034 | loss: 0.64602 | error: 0.37500\n",
      "  Ended batch 008 / 034 | loss: 0.48929 | error: 0.29688\n",
      "  Ended batch 009 / 034 | loss: 0.57560 | error: 0.32031\n",
      "  Ended batch 010 / 034 | loss: 0.41325 | error: 0.17188\n",
      "  Ended batch 011 / 034 | loss: 0.35892 | error: 0.17188\n",
      "  Ended batch 012 / 034 | loss: 0.52523 | error: 0.28125\n",
      "  Ended batch 013 / 034 | loss: 0.51272 | error: 0.22656\n",
      "  Ended batch 014 / 034 | loss: 0.55407 | error: 0.22656\n",
      "  Ended batch 015 / 034 | loss: 0.48071 | error: 0.25000\n",
      "  Ended batch 016 / 034 | loss: 0.54824 | error: 0.29688\n",
      "  Ended batch 017 / 034 | loss: 0.54879 | error: 0.29688\n",
      "  Ended batch 018 / 034 | loss: 0.51031 | error: 0.27344\n",
      "  Ended batch 019 / 034 | loss: 0.46753 | error: 0.22656\n",
      "  Ended batch 020 / 034 | loss: 0.62997 | error: 0.29688\n",
      "  Ended batch 021 / 034 | loss: 0.55948 | error: 0.28906\n",
      "  Ended batch 022 / 034 | loss: 0.53116 | error: 0.28125\n",
      "  Ended batch 023 / 034 | loss: 0.55104 | error: 0.31250\n",
      "  Ended batch 024 / 034 | loss: 0.59939 | error: 0.35938\n",
      "  Ended batch 025 / 034 | loss: 0.55720 | error: 0.28906\n",
      "  Ended batch 026 / 034 | loss: 0.55852 | error: 0.27344\n",
      "  Ended batch 027 / 034 | loss: 0.46823 | error: 0.25000\n",
      "  Ended batch 028 / 034 | loss: 0.56075 | error: 0.31250\n",
      "  Ended batch 029 / 034 | loss: 0.44849 | error: 0.24219\n",
      "  Ended batch 030 / 034 | loss: 0.35454 | error: 0.17188\n",
      "  Ended batch 031 / 034 | loss: 0.49015 | error: 0.26562\n",
      "  Ended batch 032 / 034 | loss: 0.51366 | error: 0.25000\n",
      "  Ended batch 033 / 034 | loss: 0.63800 | error: 0.28906\n",
      "  Ended batch 034 / 034 | loss: 0.58150 | error: 0.27273\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 004 / 016 | time: 046 sec | loss: 0.65475 | error: 0.21280\n",
      "Starting epoch 005 / 016.\n",
      "  Ended batch 001 / 034 | loss: 0.49026 | error: 0.24219\n",
      "  Ended batch 002 / 034 | loss: 0.51027 | error: 0.27344\n",
      "  Ended batch 003 / 034 | loss: 0.62414 | error: 0.35156\n",
      "  Ended batch 004 / 034 | loss: 0.62662 | error: 0.34375\n",
      "  Ended batch 005 / 034 | loss: 0.43930 | error: 0.21875\n",
      "  Ended batch 006 / 034 | loss: 0.35390 | error: 0.17188\n",
      "  Ended batch 007 / 034 | loss: 0.60151 | error: 0.35156\n",
      "  Ended batch 008 / 034 | loss: 0.45055 | error: 0.26562\n",
      "  Ended batch 009 / 034 | loss: 0.56979 | error: 0.32031\n",
      "  Ended batch 010 / 034 | loss: 0.44987 | error: 0.20312\n",
      "  Ended batch 011 / 034 | loss: 0.34922 | error: 0.16406\n",
      "  Ended batch 012 / 034 | loss: 0.52964 | error: 0.28906\n",
      "  Ended batch 013 / 034 | loss: 0.52006 | error: 0.22656\n",
      "  Ended batch 014 / 034 | loss: 0.55440 | error: 0.22656\n",
      "  Ended batch 015 / 034 | loss: 0.49138 | error: 0.25781\n",
      "  Ended batch 016 / 034 | loss: 0.55799 | error: 0.30469\n",
      "  Ended batch 017 / 034 | loss: 0.53564 | error: 0.28906\n",
      "  Ended batch 018 / 034 | loss: 0.50507 | error: 0.24219\n",
      "  Ended batch 019 / 034 | loss: 0.48022 | error: 0.18750\n",
      "  Ended batch 020 / 034 | loss: 0.62671 | error: 0.29688\n",
      "  Ended batch 021 / 034 | loss: 0.59080 | error: 0.32031\n",
      "  Ended batch 022 / 034 | loss: 0.51114 | error: 0.28125\n",
      "  Ended batch 023 / 034 | loss: 0.52826 | error: 0.29688\n",
      "  Ended batch 024 / 034 | loss: 0.57766 | error: 0.34375\n",
      "  Ended batch 025 / 034 | loss: 0.56252 | error: 0.26562\n",
      "  Ended batch 026 / 034 | loss: 0.59570 | error: 0.28125\n",
      "  Ended batch 027 / 034 | loss: 0.47057 | error: 0.22656\n",
      "  Ended batch 028 / 034 | loss: 0.55968 | error: 0.32812\n",
      "  Ended batch 029 / 034 | loss: 0.48559 | error: 0.27344\n",
      "  Ended batch 030 / 034 | loss: 0.40095 | error: 0.21875\n",
      "  Ended batch 031 / 034 | loss: 0.47653 | error: 0.25000\n",
      "  Ended batch 032 / 034 | loss: 0.54579 | error: 0.25781\n",
      "  Ended batch 033 / 034 | loss: 0.64675 | error: 0.28906\n",
      "  Ended batch 034 / 034 | loss: 0.58825 | error: 0.31818\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 005 / 016 | time: 046 sec | loss: 0.65774 | error: 0.20694\n",
      "Validation accuracy improved.\n",
      "Model saved to ./results/vanilla/spam_2_strategic_model.pt.\n",
      "Starting epoch 006 / 016.\n",
      "  Ended batch 001 / 034 | loss: 0.49515 | error: 0.23438\n",
      "  Ended batch 002 / 034 | loss: 0.55887 | error: 0.31250\n",
      "  Ended batch 003 / 034 | loss: 0.59817 | error: 0.33594\n",
      "  Ended batch 004 / 034 | loss: 0.56921 | error: 0.32812\n",
      "  Ended batch 005 / 034 | loss: 0.45054 | error: 0.20312\n",
      "  Ended batch 006 / 034 | loss: 0.34732 | error: 0.15625\n",
      "  Ended batch 007 / 034 | loss: 0.62083 | error: 0.35938\n",
      "  Ended batch 008 / 034 | loss: 0.45993 | error: 0.27344\n",
      "  Ended batch 009 / 034 | loss: 0.55613 | error: 0.30469\n",
      "  Ended batch 010 / 034 | loss: 0.43923 | error: 0.18750\n",
      "  Ended batch 011 / 034 | loss: 0.36841 | error: 0.17969\n",
      "  Ended batch 012 / 034 | loss: 0.53604 | error: 0.28906\n",
      "  Ended batch 013 / 034 | loss: 0.52754 | error: 0.23438\n",
      "  Ended batch 014 / 034 | loss: 0.56454 | error: 0.22656\n",
      "  Ended batch 015 / 034 | loss: 0.49343 | error: 0.25781\n",
      "  Ended batch 016 / 034 | loss: 0.50532 | error: 0.26562\n",
      "  Ended batch 017 / 034 | loss: 0.57364 | error: 0.31250\n",
      "  Ended batch 018 / 034 | loss: 0.57728 | error: 0.33594\n",
      "  Ended batch 019 / 034 | loss: 0.46427 | error: 0.21094\n",
      "  Ended batch 020 / 034 | loss: 0.61909 | error: 0.28906\n",
      "  Ended batch 021 / 034 | loss: 0.54884 | error: 0.25000\n",
      "  Ended batch 022 / 034 | loss: 0.52073 | error: 0.27344\n",
      "  Ended batch 023 / 034 | loss: 0.53611 | error: 0.29688\n",
      "  Ended batch 024 / 034 | loss: 0.59890 | error: 0.35156\n",
      "  Ended batch 025 / 034 | loss: 0.55922 | error: 0.29688\n",
      "  Ended batch 026 / 034 | loss: 0.56121 | error: 0.25000\n",
      "  Ended batch 027 / 034 | loss: 0.45731 | error: 0.23438\n",
      "  Ended batch 028 / 034 | loss: 0.55018 | error: 0.31250\n",
      "  Ended batch 029 / 034 | loss: 0.46634 | error: 0.25781\n",
      "  Ended batch 030 / 034 | loss: 0.38149 | error: 0.19531\n",
      "  Ended batch 031 / 034 | loss: 0.44073 | error: 0.21875\n",
      "  Ended batch 032 / 034 | loss: 0.50521 | error: 0.25000\n",
      "  Ended batch 033 / 034 | loss: 0.65528 | error: 0.31250\n",
      "  Ended batch 034 / 034 | loss: 0.59500 | error: 0.31818\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 006 / 016 | time: 047 sec | loss: 0.64380 | error: 0.20629\n",
      "Validation accuracy improved.\n",
      "Model saved to ./results/vanilla/spam_2_strategic_model.pt.\n",
      "Starting epoch 007 / 016.\n",
      "  Ended batch 001 / 034 | loss: 0.47903 | error: 0.23438\n",
      "  Ended batch 002 / 034 | loss: 0.48454 | error: 0.25781\n",
      "  Ended batch 003 / 034 | loss: 0.54107 | error: 0.28906\n",
      "  Ended batch 004 / 034 | loss: 0.55185 | error: 0.30469\n",
      "  Ended batch 005 / 034 | loss: 0.48301 | error: 0.25000\n",
      "  Ended batch 006 / 034 | loss: 0.42406 | error: 0.25000\n",
      "  Ended batch 007 / 034 | loss: 0.57105 | error: 0.32031\n",
      "  Ended batch 008 / 034 | loss: 0.36836 | error: 0.18750\n",
      "  Ended batch 009 / 034 | loss: 0.55161 | error: 0.29688\n",
      "  Ended batch 010 / 034 | loss: 0.41484 | error: 0.17969\n",
      "  Ended batch 011 / 034 | loss: 0.37614 | error: 0.19531\n",
      "  Ended batch 012 / 034 | loss: 0.56124 | error: 0.30469\n",
      "  Ended batch 013 / 034 | loss: 0.51753 | error: 0.24219\n",
      "  Ended batch 014 / 034 | loss: 0.58172 | error: 0.24219\n",
      "  Ended batch 015 / 034 | loss: 0.44626 | error: 0.21094\n",
      "  Ended batch 016 / 034 | loss: 0.47477 | error: 0.24219\n",
      "  Ended batch 017 / 034 | loss: 0.56744 | error: 0.29688\n",
      "  Ended batch 018 / 034 | loss: 0.45900 | error: 0.24219\n",
      "  Ended batch 019 / 034 | loss: 0.43791 | error: 0.21875\n",
      "  Ended batch 020 / 034 | loss: 0.67276 | error: 0.35156\n",
      "  Ended batch 021 / 034 | loss: 0.60712 | error: 0.35156\n",
      "  Ended batch 022 / 034 | loss: 0.47420 | error: 0.21094\n",
      "  Ended batch 023 / 034 | loss: 0.51892 | error: 0.26562\n",
      "  Ended batch 024 / 034 | loss: 0.58388 | error: 0.33594\n",
      "  Ended batch 025 / 034 | loss: 0.61933 | error: 0.34375\n",
      "  Ended batch 026 / 034 | loss: 0.57795 | error: 0.32031\n",
      "  Ended batch 027 / 034 | loss: 0.43309 | error: 0.20312\n",
      "  Ended batch 028 / 034 | loss: 0.46272 | error: 0.22656\n",
      "  Ended batch 029 / 034 | loss: 0.44924 | error: 0.23438\n",
      "  Ended batch 030 / 034 | loss: 0.41127 | error: 0.21094\n",
      "  Ended batch 031 / 034 | loss: 0.50440 | error: 0.25000\n",
      "  Ended batch 032 / 034 | loss: 0.53107 | error: 0.25781\n",
      "  Ended batch 033 / 034 | loss: 0.66979 | error: 0.30469\n",
      "  Ended batch 034 / 034 | loss: 0.60305 | error: 0.31818\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 007 / 016 | time: 048 sec | loss: 0.71054 | error: 0.22842\n",
      "Starting epoch 008 / 016.\n",
      "  Ended batch 001 / 034 | loss: 0.50470 | error: 0.21094\n",
      "  Ended batch 002 / 034 | loss: 0.43409 | error: 0.20312\n",
      "  Ended batch 003 / 034 | loss: 0.62581 | error: 0.34375\n",
      "  Ended batch 004 / 034 | loss: 0.65094 | error: 0.36719\n",
      "  Ended batch 005 / 034 | loss: 0.57472 | error: 0.32812\n",
      "  Ended batch 006 / 034 | loss: 0.37153 | error: 0.14844\n",
      "  Ended batch 007 / 034 | loss: 0.49898 | error: 0.23438\n",
      "  Ended batch 008 / 034 | loss: 0.37940 | error: 0.16406\n",
      "  Ended batch 009 / 034 | loss: 0.58614 | error: 0.32031\n",
      "  Ended batch 010 / 034 | loss: 0.55372 | error: 0.31250\n",
      "  Ended batch 011 / 034 | loss: 0.40559 | error: 0.22656\n",
      "  Ended batch 012 / 034 | loss: 0.58638 | error: 0.33594\n",
      "  Ended batch 013 / 034 | loss: 0.50691 | error: 0.21875\n",
      "  Ended batch 014 / 034 | loss: 0.57204 | error: 0.19531\n",
      "  Ended batch 015 / 034 | loss: 0.45744 | error: 0.21875\n",
      "  Ended batch 016 / 034 | loss: 0.50815 | error: 0.27344\n",
      "  Ended batch 017 / 034 | loss: 0.60196 | error: 0.32812\n",
      "  Ended batch 018 / 034 | loss: 0.58666 | error: 0.33594\n",
      "  Ended batch 019 / 034 | loss: 0.47544 | error: 0.25000\n",
      "  Ended batch 020 / 034 | loss: 0.60255 | error: 0.28906\n",
      "  Ended batch 021 / 034 | loss: 0.52155 | error: 0.23438\n",
      "  Ended batch 022 / 034 | loss: 0.48467 | error: 0.21094\n",
      "  Ended batch 023 / 034 | loss: 0.58480 | error: 0.34375\n",
      "  Ended batch 024 / 034 | loss: 0.60984 | error: 0.35156\n",
      "  Ended batch 025 / 034 | loss: 0.62275 | error: 0.35156\n",
      "  Ended batch 026 / 034 | loss: 0.55494 | error: 0.22656\n",
      "  Ended batch 027 / 034 | loss: 0.44744 | error: 0.18750\n",
      "  Ended batch 028 / 034 | loss: 0.48545 | error: 0.20312\n",
      "  Ended batch 029 / 034 | loss: 0.46572 | error: 0.25000\n",
      "  Ended batch 030 / 034 | loss: 0.42884 | error: 0.21875\n",
      "  Ended batch 031 / 034 | loss: 0.55903 | error: 0.28125\n",
      "  Ended batch 032 / 034 | loss: 0.57965 | error: 0.26562\n",
      "  Ended batch 033 / 034 | loss: 0.68851 | error: 0.29688\n",
      "  Ended batch 034 / 034 | loss: 0.58713 | error: 0.31818\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 008 / 016 | time: 048 sec | loss: 0.78332 | error: 0.25316\n",
      "Starting epoch 009 / 016.\n",
      "  Ended batch 001 / 034 | loss: 0.54002 | error: 0.21094\n",
      "  Ended batch 002 / 034 | loss: 0.46296 | error: 0.18750\n",
      "  Ended batch 003 / 034 | loss: 0.52262 | error: 0.27344\n",
      "  Ended batch 004 / 034 | loss: 0.57023 | error: 0.31250\n",
      "  Ended batch 005 / 034 | loss: 0.50167 | error: 0.26562\n",
      "  Ended batch 006 / 034 | loss: 0.40065 | error: 0.22656\n",
      "  Ended batch 007 / 034 | loss: 0.50232 | error: 0.25781\n",
      "  Ended batch 008 / 034 | loss: 0.36438 | error: 0.14844\n",
      "  Ended batch 009 / 034 | loss: 0.55344 | error: 0.27344\n",
      "  Ended batch 010 / 034 | loss: 0.42618 | error: 0.20312\n",
      "  Ended batch 011 / 034 | loss: 0.36078 | error: 0.19531\n",
      "  Ended batch 012 / 034 | loss: 0.64595 | error: 0.35938\n",
      "  Ended batch 013 / 034 | loss: 0.53119 | error: 0.27344\n",
      "  Ended batch 014 / 034 | loss: 0.56159 | error: 0.25781\n",
      "  Ended batch 015 / 034 | loss: 0.44360 | error: 0.22656\n",
      "  Ended batch 016 / 034 | loss: 0.45412 | error: 0.21875\n",
      "  Ended batch 017 / 034 | loss: 0.49824 | error: 0.26562\n",
      "  Ended batch 018 / 034 | loss: 0.51893 | error: 0.26562\n",
      "  Ended batch 019 / 034 | loss: 0.42493 | error: 0.21875\n",
      "  Ended batch 020 / 034 | loss: 0.67551 | error: 0.34375\n",
      "  Ended batch 021 / 034 | loss: 0.55033 | error: 0.31250\n",
      "  Ended batch 022 / 034 | loss: 0.45178 | error: 0.20312\n",
      "  Ended batch 023 / 034 | loss: 0.44288 | error: 0.21875\n",
      "  Ended batch 024 / 034 | loss: 0.61339 | error: 0.35156\n",
      "  Ended batch 025 / 034 | loss: 0.54800 | error: 0.27344\n",
      "  Ended batch 026 / 034 | loss: 0.50382 | error: 0.25000\n",
      "  Ended batch 027 / 034 | loss: 0.45583 | error: 0.24219\n",
      "  Ended batch 028 / 034 | loss: 0.51882 | error: 0.28906\n",
      "  Ended batch 029 / 034 | loss: 0.48051 | error: 0.25781\n",
      "  Ended batch 030 / 034 | loss: 0.37579 | error: 0.17969\n",
      "  Ended batch 031 / 034 | loss: 0.37804 | error: 0.17188\n",
      "  Ended batch 032 / 034 | loss: 0.47375 | error: 0.21875\n",
      "  Ended batch 033 / 034 | loss: 0.61338 | error: 0.28125\n",
      "  Ended batch 034 / 034 | loss: 0.60318 | error: 0.31818\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 009 / 016 | time: 047 sec | loss: 0.67185 | error: 0.21996\n",
      "Starting epoch 010 / 016.\n",
      "  Ended batch 001 / 034 | loss: 0.44118 | error: 0.20312\n",
      "  Ended batch 002 / 034 | loss: 0.45523 | error: 0.23438\n",
      "  Ended batch 003 / 034 | loss: 0.58815 | error: 0.32812\n",
      "  Ended batch 004 / 034 | loss: 0.57043 | error: 0.32031\n",
      "  Ended batch 005 / 034 | loss: 0.46378 | error: 0.23438\n",
      "  Ended batch 006 / 034 | loss: 0.36009 | error: 0.17969\n",
      "  Ended batch 007 / 034 | loss: 0.62292 | error: 0.37500\n",
      "  Ended batch 008 / 034 | loss: 0.45943 | error: 0.26562\n",
      "  Ended batch 009 / 034 | loss: 0.57380 | error: 0.31250\n",
      "  Ended batch 010 / 034 | loss: 0.40010 | error: 0.16406\n",
      "  Ended batch 011 / 034 | loss: 0.36869 | error: 0.17969\n",
      "  Ended batch 012 / 034 | loss: 0.49928 | error: 0.26562\n",
      "  Ended batch 013 / 034 | loss: 0.50000 | error: 0.24219\n",
      "  Ended batch 014 / 034 | loss: 0.56288 | error: 0.25000\n",
      "  Ended batch 015 / 034 | loss: 0.46334 | error: 0.23438\n",
      "  Ended batch 016 / 034 | loss: 0.54623 | error: 0.30469\n",
      "  Ended batch 017 / 034 | loss: 0.58257 | error: 0.32031\n",
      "  Ended batch 018 / 034 | loss: 0.48283 | error: 0.25000\n",
      "  Ended batch 019 / 034 | loss: 0.48255 | error: 0.19531\n",
      "  Ended batch 020 / 034 | loss: 0.64915 | error: 0.28906\n",
      "  Ended batch 021 / 034 | loss: 0.55569 | error: 0.28906\n",
      "  Ended batch 022 / 034 | loss: 0.50381 | error: 0.25781\n",
      "  Ended batch 023 / 034 | loss: 0.52189 | error: 0.28906\n",
      "  Ended batch 024 / 034 | loss: 0.58915 | error: 0.35156\n",
      "  Ended batch 025 / 034 | loss: 0.58009 | error: 0.28906\n",
      "  Ended batch 026 / 034 | loss: 0.56279 | error: 0.24219\n",
      "  Ended batch 027 / 034 | loss: 0.42501 | error: 0.20312\n",
      "  Ended batch 028 / 034 | loss: 0.55390 | error: 0.32031\n",
      "  Ended batch 029 / 034 | loss: 0.45027 | error: 0.23438\n",
      "  Ended batch 030 / 034 | loss: 0.36633 | error: 0.18750\n",
      "  Ended batch 031 / 034 | loss: 0.45022 | error: 0.21875\n",
      "  Ended batch 032 / 034 | loss: 0.54264 | error: 0.25781\n",
      "  Ended batch 033 / 034 | loss: 0.66740 | error: 0.28906\n",
      "  Ended batch 034 / 034 | loss: 0.60189 | error: 0.31818\n",
      "  Finished training step, calculating validation loss and accuracy.\n",
      "Ended epoch 010 / 016 | time: 048 sec | loss: 0.69492 | error: 0.21996\n",
      "Ending training due to 4 consecutive epochs without improvement in validation accuracy.\n",
      "Total training time: 8.2092453956604 minutes (492.554723739624 seconds).\n",
      "Model loaded from ./results/vanilla/spam_2_strategic_model.pt.\n",
      "---------- Calculating results ----------\n",
      "Benchmark accuracy: 0.8190812720848056\n",
      "SERM accuracy: 0.7795053003533569\n",
      "Blind accuracy: 0.6176678445229682\n",
      "Test took 39.97046823898951 minutes (2398.2280943393707 seconds).\n"
     ]
    }
   ],
   "source": [
    "init_time = time.time()\n",
    "\n",
    "for training_data in training_datas:\n",
    "    # Load dataset\n",
    "    X = training_data[\"X\"]\n",
    "    Y = training_data[\"Y\"]\n",
    "    Xval = training_data[\"Xval\"]\n",
    "    Yval = training_data[\"Yval\"]\n",
    "    Xtest = training_data[\"Xtest\"]\n",
    "    Ytest = training_data[\"Ytest\"]\n",
    "    \n",
    "    # Training parameters\n",
    "    x_dim = len(X[0])\n",
    "    epochs = training_data[\"epochs\"]\n",
    "    batch_size = training_data[\"batch_size\"]\n",
    "    train_slope = training_data[\"train_slope\"]\n",
    "    eval_slope = training_data[\"eval_slope\"]\n",
    "        \n",
    "    # Training data name and results\n",
    "    name = training_data[\"name\"]\n",
    "    results = {\n",
    "        \"scales\": [],\n",
    "        \"benchmark\": [],\n",
    "        \"SERM\": [],\n",
    "        \"blind\": []\n",
    "    }\n",
    "    \n",
    "    for scale in scales:\n",
    "        # Non-strategic classification\n",
    "        print(f\"---------- Training non-strategically on {name} with scale={scale} ----------\")\n",
    "        model_name = f\"{name}_{scale}_non_strategic\"\n",
    "        non_strategic_model = StrategicModel(x_dim, batch_size, cost_fn=\"quad\", cost_const_kwargs={\"scale\": scale}, train_slope=train_slope, eval_slope=eval_slope, strategic=False)\n",
    "        non_strategic_model.fit(X, Y, Xval, Yval, opt_class=torch.optim.Adam, opt_kwargs={\"lr\": 1e-1},\n",
    "                                epochs=epochs, verbose=\"epochs\", path=PATH, model_name=model_name)\n",
    "        non_strategic_model.normalize_parameters()\n",
    "        \n",
    "        # Strategic classification\n",
    "        print(f\"---------- Training strategically on {name} with scale={scale} ----------\")\n",
    "        model_name = f\"{name}_{scale}_strategic\"\n",
    "        strategic_model = StrategicModel(x_dim, batch_size, cost_fn=\"quad\", cost_const_kwargs={\"scale\": scale}, train_slope=train_slope, eval_slope=eval_slope, strategic=True)\n",
    "        strategic_model.fit(X, Y, Xval, Yval, opt_class=torch.optim.Adam, opt_kwargs={\"lr\": 5e-1},\n",
    "                            epochs=epochs, verbose=\"batches\", path=PATH, model_name=model_name)\n",
    "        \n",
    "        # Calculate results\n",
    "        print(\"---------- Calculating results ----------\")\n",
    "        results[\"scales\"].append(scale)\n",
    "        # Non-strategic model & non-strategic data - Benchmark\n",
    "        benchmark_accuracy = non_strategic_model.evaluate(Xtest, Ytest, strategic_data=False)\n",
    "        print(f\"Benchmark accuracy: {benchmark_accuracy}\")\n",
    "        results[\"benchmark\"].append(benchmark_accuracy)\n",
    "        # Strategic model & strategic data - SERM\n",
    "        SERM_accuracy = strategic_model.evaluate(Xtest, Ytest, strategic_data=True)\n",
    "        print(f\"SERM accuracy: {SERM_accuracy}\")\n",
    "        results[\"SERM\"].append(SERM_accuracy)\n",
    "        # Non-strategic model & strategic data - Blind\n",
    "        blind_accuracy = non_strategic_model.evaluate(Xtest, Ytest, strategic_data=True)\n",
    "        print(f\"Blind accuracy: {blind_accuracy}\")\n",
    "        results[\"blind\"].append(blind_accuracy)\n",
    "        \n",
    "        # Save results\n",
    "        pd.DataFrame(results).to_csv(f\"{PATH}/{name}_results.csv\")\n",
    "\n",
    "final_time = time.time()\n",
    "total_time = final_time - init_time\n",
    "print(f\"Test took {total_time / 60} minutes ({total_time} seconds).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x648 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "credit_results = pd.read_csv(\"results/vanilla/credit_results.csv\")\n",
    "distress_results = pd.read_csv(\"results/vanilla/distress_results.csv\")\n",
    "fraud_results = pd.read_csv(\"results/vanilla/fraud_results.csv\")\n",
    "spam_results = pd.read_csv(\"results/vanilla/spam_results.csv\")\n",
    "scales = credit_results[\"scales\"].tolist()\n",
    "\n",
    "results = [credit_results, distress_results, fraud_results, spam_results]\n",
    "dataset_names = [\"credit\", \"fin. distress\", \"fraud\", \"spam\"]\n",
    "\n",
    "fig, axes = plt.subplots(3, 4, figsize=(16, 9))\n",
    "_ = fig.suptitle(\"Accuracy for various datasets and cost scales\")\n",
    "\n",
    "for j in range(4):\n",
    "    _ = axes[0, j].set_title(dataset_names[j])\n",
    "    result = results[j]\n",
    "    for i in range(3):\n",
    "        benchmark = result[\"benchmark\"][i]\n",
    "        SERM = result[\"SERM\"][i]\n",
    "        blind = result[\"blind\"][i]\n",
    "        _ = axes[i, j].axhline(y=benchmark, linewidth=3, linestyle=\"--\", color=\"tab:gray\", label=\"Benchmark\")\n",
    "        _ = axes[i, j].bar(1, SERM, 0.8, label=\"SERM\")\n",
    "        _ = axes[i, j].bar(2, blind, 0.8, label=\"Blind\")\n",
    "        _ = axes[i, j].get_xaxis().set_visible(False)\n",
    "        _ = axes[i, j].set_ylim([0.5, 1])\n",
    "        _ = axes[i, j].set_yticks([0.5, 1])\n",
    "        _ = axes[i, j].label_outer()\n",
    "\n",
    "lines, labels = fig.axes[-1].get_legend_handles_labels()\n",
    "_ = fig.legend(lines, labels, loc=\"lower center\", ncol=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
