{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla vs Hardt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "import pandas as pd\n",
    "\n",
    "from SCMP import SCMP\n",
    "import DataGeneration as data\n",
    "import Presentation\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "PATH = \"./Results/vanilla_vs_hardt\"\n",
    "if not os.path.exists(PATH):\n",
    "    os.makedirs(PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = data.load_spam_data()\n",
    "X, Y, Xval, Yval, Xtest, Ytest = data.split_validation_test(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dim = len(X[0])\n",
    "epochs = 16\n",
    "batch_size = 128\n",
    "\n",
    "v = torch.tensor([-1,-1,-1,-1,-1,-1,-1,1,1,0.1,1,0.1,0.1,1,0.1])\n",
    "small_eps = 0.02\n",
    "epsilons = [0.01, 0.02, 0.05, 0.1, 0.2, 0.4, 0.6, 0.8, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    \"epsilons\": [],\n",
    "    \"benchmark\": [],\n",
    "    \"SERM\": [],\n",
    "    \"blind\": [],\n",
    "    \"Hardt\": []\n",
    "}\n",
    "\n",
    "print(f\"---------- Training Hardt et al's model (strategic with eps={small_eps}) ----------\")\n",
    "model_name = \"strategic_approx\"\n",
    "strategic_model_approx = SCMP(x_dim, batch_size, cost_fn=\"linear\", cost_const_kwargs={\"v\": v, \"epsilon\": small_eps}, strategic=True)\n",
    "strategic_model_approx.fit(X, Y, Xval, Yval, opt_class=torch.optim.Adam, opt_kwargs={\"lr\": 2e-1}, epochs=epochs, verbose=\"batches\", path=PATH, model_name=model_name)\n",
    "\n",
    "for eps in epsilons:\n",
    "    print(f\"------------------------- {eps} -------------------------\")\n",
    "    \n",
    "    # Non-strategic classification\n",
    "    print(f\"---------- Training non-strategically with epsilon={eps} ----------\")\n",
    "    model_name = f\"non_strategic_{eps}\"\n",
    "    non_strategic_model = SCMP(x_dim, batch_size, cost_fn=\"linear\", cost_const_kwargs={\"v\": v, \"epsilon\": eps}, strategic=False)\n",
    "    non_strategic_model.fit(X, Y, Xval, Yval, opt_class=torch.optim.Adam, opt_kwargs={\"lr\": 5e-1}, epochs=epochs, verbose=\"batches\", path=PATH, model_name=model_name)\n",
    "    \n",
    "    non_strategic_model = SCMP(x_dim, batch_size, cost_fn=\"linear\", cost_const_kwargs={\"v\": v, \"epsilon\": eps}, strategic=False)\n",
    "    non_strategic_model.load_model(PATH, model_name)\n",
    "    non_strategic_model.normalize_weights()\n",
    "    \n",
    "    # Strategic classification\n",
    "    print(f\"---------- Training strategically with epsilon={eps} ----------\")\n",
    "    model_name = f\"strategic_real_{eps}\"\n",
    "    strategic_model_real = SCMP(x_dim, batch_size, cost_fn=\"linear\", cost_const_kwargs={\"v\": v, \"epsilon\": eps}, strategic=True)\n",
    "    strategic_model_real.fit(X, Y, Xval, Yval, opt_class=torch.optim.Adam, opt_kwargs={\"lr\": 5e-1}, epochs=epochs, verbose=\"batches\", path=PATH, model_name=model_name)\n",
    "    \n",
    "    strategic_model_real = SCMP(x_dim, batch_size, cost_fn=\"linear\", cost_const_kwargs={\"v\": v, \"epsilon\": eps}, strategic=True)\n",
    "    strategic_model_real.load_model(PATH, model_name)\n",
    "    \n",
    "    # Approximate strategic classification (set evaluation epsilon to eps)\n",
    "    model_name = \"strategic_approx\"\n",
    "    strategic_model_approx = SCMP(x_dim, batch_size, cost_fn=\"linear\", cost_const_kwargs={\"v\": v, \"epsilon\": eps}, strategic=True)\n",
    "    strategic_model_approx.load_model(PATH, model_name)\n",
    "    \n",
    "    # Calculate results\n",
    "    print(\"---------- Calculating results ----------\")\n",
    "    results[\"epsilons\"].append(eps)\n",
    "    # Non-strategic model & non-strategic data - Benchmark\n",
    "    results[\"benchmark\"].append(non_strategic_model.evaluate(Xtest, Ytest, strategic_data=False))\n",
    "    # Approx strategic model & strategic data - Hardt et al\n",
    "    results[\"Hardt\"].append(strategic_model_approx.evaluate(Xtest, Ytest, strategic_data=True))\n",
    "    # Real strategic model & strategic data - SERM\n",
    "    results[\"SERM\"].append(strategic_model_real.evaluate(Xtest, Ytest, strategic_data=True))\n",
    "    # Non-strategic model & strategic data - Blind\n",
    "    results[\"blind\"].append(non_strategic_model.evaluate(Xtest, Ytest, strategic_data=True))\n",
    "    pd.DataFrame(results).to_csv(f\"{PATH}/results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Presentation.show_vanilla_vs_hardt_results()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
